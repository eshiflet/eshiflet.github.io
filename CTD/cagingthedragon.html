<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Caging the Dragon, by James Carothers - The Containment of Underground Nuclear Explosions</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="This site contains an on-line electronic version of the book Caging the Dragon, by James Carothers - The Containment of Underground Nuclear Explosions. It is a fascinating history told by the people who designed and implemented the containment of the United States underground nuclear test program. This page contains the entire electronic book in HTML format, though it uses Bootstrap CSS for some formatting.">
    <meta name="author" content="James Carothers">

    <!-- Styles -->
    <link href="../bootstrap-232/css/bootstrap.css" rel="stylesheet">
    <style type="text/css">
      body {
		  padding-top: 60px;
		  padding-bottom: 40px;
      }
      .sidebar-nav {
		  padding: 9px 0;
      }
	  .tab {
		  text-indent: 40px;
	  }
	  .indent {
		  margin-left: 40px;
	  }
    </style>

	<script src="http://code.jquery.com/jquery-1.9.1.js"></script>

    <!-- Favorite and touch icons -->
    <link rel="shortcut icon" href="../icons/favicon.ico">

	<!-- Google Analytics -->
	<script type="text/javascript">
	  var _gaq = _gaq || [];
	  _gaq.push(['_setAccount', 'UA-32244838-1']);
	  _gaq.push(['_trackPageview']);

	  (function() {
	    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
	    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
	    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
	  })();
	</script>

  </head>

  <body>

    <div class="navbar navbar-inverse navbar-fixed-top">
      <div class="navbar-inner">
        <div class="container">
          <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="http://www.ericshiflet.com">EricShiflet.com</a>
          <div class="nav-collapse">
            <ul class="nav">
              <li class="active"><a href="http://www.ericshiflet.com">Home</a></li>
              <li><a href="#about">About</a></li>
              <li><a href="contact.html">Contact</a></li>
            </ul>
          </div><!-- /.nav-collapse -->
        </div><!-- /container -->
      </div><!-- /navbar-inner -->
    </div><!-- /navbar -->

    <div class="container-fluid">
      <div class="row-fluid">
	  
        <div class="span3" id="left">
            <ul id="nav" class="nav nav-list">
            	<hr>
					<li class="nav-header">Caging the Dragon, by James Carothers</li>
					<li class=""> <a href="#note"><i class="icon-chevron-right"></i> Publisher's Note</a></li>
					<li class=""> <a href="#preface"><i class="icon-chevron-right"></i> Preface</a></li>
					<li class=""> <a href="#intro"><i class="icon-chevron-right"></i> Introduction</a></li>
					<li class=""> <a href="#ch1"> <i class="icon-chevron-right"></i> 1: The Origins of Containment</a></li>
					<li class=""> <a href="#ch2"> <i class="icon-chevron-right"></i> 2: The Rainier Event</a></li>
					<li class=""> <a href="#ch3"> <i class="icon-chevron-right"></i> 3: The Moratorium and the Return to Testing</a></li>
					<li class=""> <a href="#ch4"> <i class="icon-chevron-right"></i> 4: The Beginnings of Containment Programs</a></li>
					<li class=""> <a href="#ch5"> <i class="icon-chevron-right"></i> 5: The Nevada Test Site</a></li>
					<li class=""> <a href="#ch6"> <i class="icon-chevron-right"></i> 6: Earth Materials and Their Properties</a></li>
					<li class=""> <a href="#ch7"> <i class="icon-chevron-right"></i> 7: Logging and Logging Tools</a></li>
					<li class=""> <a href="#ch8"> <i class="icon-chevron-right"></i> 8: Energy Coupling and Partition</a></li>
					<li class=""> <a href="#ch9"> <i class="icon-chevron-right"></i> 9: Cavities and How They Grow</a></li>
					<li class=""> <a href="#ch10"><i class="icon-chevron-right"></i> 10: Cavity Collapse, Chimneys and Craters</a></li>
					<li class=""> <a href="#ch11"><i class="icon-chevron-right"></i> 11: The Residual Stress Cage</a></li>
					<li class=""> <a href="#ch12"><i class="icon-chevron-right"></i> 12: Hydrofractures</a></li>
					<li class=""> <a href="#ch13"><i class="icon-chevron-right"></i> 13: Block Motion</a></li>
					<li class=""> <a href="#ch14"><i class="icon-chevron-right"></i> 14: Depths of Burial, Drilling</a></li>
					<li class=""> <a href="#ch15"><i class="icon-chevron-right"></i> 15: Emplacement Holes, Stemming, Plugs, and Cable Blocks</a></li>
					<li class=""> <a href="#ch16"><i class="icon-chevron-right"></i> 16: Tunnels and Line-of-Sight Pipes</a></li>
					<li class=""> <a href="#ch17"><i class="icon-chevron-right"></i> 17: Pipe Closure Hardware</a></li>
					<li class=""> <a href="#ch18"><i class="icon-chevron-right"></i> 18: Pipe Flow</a></li>
					<li class=""> <a href="#ch19"><i class="icon-chevron-right"></i> 19: Codes and Calculations</a></li>
					<li class=""> <a href="#ch20"><i class="icon-chevron-right"></i> 20: Current Practice</a></li>
					<li class=""> <a href="#ch21"><i class="icon-chevron-right"></i> 21: Sometimes the Dragon Wins</a></li>
					<li class=""> <a href="#ch22"><i class="icon-chevron-right"></i> 22: About the Containment Evaluation Panel</a></li>
					<li class=""> <a href="#ch23"><i class="icon-chevron-right"></i> 23: Thoughts, Opinions, Concerns</a></li>
					<li class=""> <a href="#appendix"><i class="icon-chevron-right"></i> Appendix</a></li>
				<hr>
            </ul>
        </div><!--/span3 -->
		
		
        <div class="span9" id="right">
           <div class="hero-unit">

<br><br>
<h1>Caging the Dragon</h1>
<h2>The Containment of Underground Nuclear Explosions</h2>
<h2>by James Carothers</h2>

<a name="note"></a>
<br><br>
<h2>Publisher's Note</h2>
<br>

<p class="tab">
On July 16, 1945 the first nuclear explosion, the Trinity test, took place in the Nevada desert. It was an
atmospheric detonation and was highly successful, releasing radiation into the air that
will forever be recorded in our planet's geological history. 
During the next seventeen years over 200 above ground tests were conducted by the United States,
in addition to over 200 above ground tests by the Soviet Union.
It became obvious that atmospheric testing was a health risk because of the
dangerous radioactive byproducts being detected around the world,
many thousands of miles away from the test sites. In 1963 the Partial Nuclear Test Ban Treaty 
was signed by the United States, Soviet Union and United Kingdom
agreeing to limit testing to underground explosions and contain
any radioactive byproducts within the border of the country conducting the test. This
effectively meant that underground nuclear explosions could not leak into the atmosphere,
a very difficult requirement to meet.</p>

<p class="tab">
This book is a history of the design and implementation
of the containment of the United States' underground nuclear test program told as a first person narrative
by the people who actually did the work. The successes and failures of these tests are still affecting us
today. As is often quoted, every breath of air you breathe includes a
molecule from Caesar’s last breath. Even more so, every breath you take includes radioactive
byproducts from the nuclear tests described here. The people in this book understood this and did everything
within their scientific, engineering and budgetary power to contain the radioactive byproducts.</p>

<p class="tab">
I did not write this book or capture the narrative of
the people working on this project, I merely converted it to a modern electronic format for easy
reading, studying and sharing because I think it should be. It is an important part of the story of people
like you and me trying to control the most powerful force of nature we know of.</p>

<p class="tab">
Since this book is an original work by the United States 
government, it is part of the public domain. The original book contained poor quality photographs that were 
not captured in this electronic edition. If it's possible to find a source of the photos with reasonable quality,
I'll update this on-line document.</p>

<br>Eric M. Shiflet
<br>July 16, 2015
<br>


<a name="preface"></a>
<br><br>
<h2>Preface</h2>
<br>

<p class="tab">
Robert Brownlee, in a talk given at the Monterey Containment Symposium on August 26, 1981, said:</p>

<br>
<p class="tab"><i>
It has been said that there is no such thing as history, only biography. Assuming this
to be true, a description of the evolution of containment would contain the story
of the people involved - their experiments, beliefs, motivations, successes,
failures, foibles, and idiosyncrasies. We might then be able to understand our
current faith and practice, and their origins, in a far better way.</i></p>

<p class="tab"><i>
Even for the earliest moments of containment of under-ground nuclear tests, when the
number of individuals involved in the subject was very few, the complexity of
the subject, and the parallel and relatively independent pursuits of Los Alamos
and Livermore, make a retrieval of biographical knowledge quite impossible.</i></p>
<br>

<p class="tab">
In that context, this
book is an attempt to approach that impossibility. It has been my pleasure to
have had the opportunity to talk with people I know who played a role in the
development of our current faith and practice. This book is really theirs, and
that is shown in the extensive quotations from people who have spent much of
their professional careers dealing with the truly difficult problems
encountered. This book does not deal with the formulae and the mathematics, the
charts and graphs that make up the structure of the scientific and engineering
practice of the containment of underground nuclear explosives. Those things can
be found in the documents and reports written by many of the individuals who
have worked in the field during the past thirty-five years or so.</p>

<p class="tab">
Here there are only
the recollections, memories, opinions, and stories of some of those many
people. Recollections can be faulty, memories fade, opinions change, and
stories often become better in the telling, but taken as a whole they may
convey something of how we came to be where we are in the containment world.</p>

<p class="tab">
One regret I have is
that the quoted printed word does not capture the emotional content of the
spoken word - the humor, satire, frustration, sincerity that I heard during
these talks that we had. All are muted in a quotation on the printed page. The
inflection of a single word can change the way a statement is to be taken, but
how to convey that? The only way I know to attempt it is to give some brief
background on each of the people, in their own words. That doesn't have to do
directly with containment, but it does have to do with perhaps putting the
statements of that person in a personal context.</p>

<p class="tab">
As for the context of
myself, I went in 1952 from being a newly graduated graduate student who had
done his thesis work at the U. C. Radiation Laboratory, to work with Herb York
on what he initially described to me, somewhat vaguely, as a "small
project." I somehow got the impression that it would be in Berkeley, and
would deal with controlled fusion as a source of power, and indeed that was
what I started to do. A few months later I had moved to Livermore with my
family, and by then I was aware that the "small project" was a second
nuclear weapons design Laboratory. Nine years later the Lawrence Livermore
Radiation Laboratory had a staff of perhaps 5,000 people, and I became involved
with nuclear test work.</p>

<p class="tab">
Since that time in
1961 I have been associated with the test program of the United States in
various capacities. First as the Division Leader of L Division, the people at
Livermore responsible for the design and fielding of the diagnostic
measurements on Livermore nuclear experiments. Later as the person responsible
for the overall Livermore Test Program, and since 1971 as the Chairman of the
DOE-NVO Containment Evaluation Panel, whose function is better explained later
in this book.</p>

<p class="tab">
I can say from my own
knowledge that the people, my friends, whose words are quoted in this book, are
all dedicated individuals who grappled with the dragon, and eventually caged
him, albeit uneasily, because they retained their sense of perspective, and of
the limitations of their knowledge, while doing so. I did not say "subdued
him", because they know, as I know, that whenever a nuclear explosion
occurs he is there, just as enormously strong, clever, and dangerous as ever.
Those who may be called upon someday to do an underground detonation should
remember that. The amount of energy released by a "small" one kiloton
nuclear device is simply beyond human experience and comprehension, except
possibly that of the unfortunate people in Japan who were near the second and
third nuclear detonations.</p>

<p class="tab">
It was the Department
of Energy Nevada Operations Office which supported this work, and to the people
there, particularly Richard Navarro, I give my grateful acknowledgement. Byron
Ristvet of the Department of Defense Nuclear Agency was principally responsible
for arranging the support required for the printing of the book. Without his
interest and the Defense Nuclear Agency's support, the publication of this work
might well not have happened.</p>

<p class="tab">
The people I talked
with were always cooperative in giving me their time for the interviews and for
editing the transcripts, and my thanks go to each of those quoted in the text.
Gary Higgins and Bob Brownlee were generous with their time in reviewing the
book and offered many valuable suggestions on various points.</p>

<p class="tab">
The table in Chapter
22 was compiled by Gregory Van der Vink of OTA. The pictures in the book were
provided by Roger Meade of Los Alamos, Steve Wofford of Livermore, and John
Weydert of Sandia. My appreciation also goes to the unknown Livermore artist
who, in the early seventies, captured the feeling of many people who were
grappling with containment problems.</p>

<p class="tab">
Particular thanks are
due two people. Beverly Babcock assisted with many of the interviews and
transcriptions. She was also most helpful in such matters as arranging times
and places for the interviews, and gently encouraging the interviewees to finish
and return their edits. Aside from providing photographs for the illustrations,
Steve Wofford gave unfailing support on many questions of how best to arrange
the chapters and format the text. He deserves my thanks for helping in a very
substantial way on this project.</p>

<a name="intro"></a>
<br><br>
<h2>Introduction</h2>
<br>

<p class="tab">
The science of the containment of the radioactive by-products of a nuclear detonation exists only 
because there was a period of from 1957 to 1992 when nuclear detonations were carried out underground 
by the United States, the Soviet Union, the United Kingdom, and France.</p>

<p class="tab">
The elements of several scientific and engineering fields are inextricably intertwined when people 
attempt to understand, calculate, and predict what will happen when a nuclear detonation occurs 
underground. The interactions which occur do so in regimes of material interactions, times, temperatures, 
and pressures that are never encountered in any other field.</p>

<p class="tab">
The earth, from the surface to the mile or so in depth that has been used in underground nuclear 
testing is an inhomogeneous body of materials. Such things as the density, the strength, the chemical 
composition, and the water content of the rocks vary in a three dimensional fashion over almost 
any dimensional element that is chosen, ranging from molecular size to kilometers. Given the volume 
over which significant effects take place, the expense of obtaining sufficient representative samples 
to test in the laboratory, and the fact that laboratory measurements cannot reproduce many of the 
regimes of interest, it is not possible to know all, or even most, of the details of the medium where 
the detonation takes place.</p>

<p class="tab">
So, empirical rules are developed, approximations are made and are used in computer codes to model 
the behavior of the earth materials following a detonation, but there is a further complication. 
Important processes occur during a time span that ranges from fractions of a microsecond to hours. 
Different measurement techniques and different calculational codes are required for different parts 
of this time span, and somehow must be linked together to try to understand the overall picture of 
what happens.</p>

<p class="tab">
In such a situation experience and empirical evidence from previous detonations assumes a considerable 
importance when trying to judge what will happen when a particular detonation takes place in some 
specific location. The experience and evidence that there is has been gathered over the years, 
sometimes in a costly fashion. Experience and its role in judgment is difficult to codify and make 
available to people who might be newly charged with the responsibility to detonate a device, obtain 
the necessary data from it, and simultaneously "successfully contain" the radioactive materials produced. 
Such a situation may never arise; if it does perhaps the words here may be helpful.</p>


<a name="ch1"></a>
<br><br>
<h2>Chapter 1: The Origins of Containment</h2>
<br>

<p class="tab">
To discuss the
containment of nuclear explosions it would be helpful to have an understanding
of what "containment" is. Unfortunately, there is no simple
definition, or indeed, no uniform agreement as to what it is. Basically, it is
whatever someone in the appropriate position of authority says it is, as is the
case with many politically defined terms. And that also means that what it is
can change from time to time.</p>

<p class="tab">
There are documents
which shed some light on this. The most important is the Nuclear Test Ban
Treaty, signed on August 5, 1963 by the Soviet Union, the United Kingdom, and
the United States. This Treaty called for the signatory nations to conduct
nuclear detonations only underground, and in such a way that there would be no
nuclear debris beyond the boundaries of the State which conducted the
detonation. The operative article of the Treaty which relates to what would
become "containment," as it is currently known in the United States,
is Article I, Section 1. of the English version.</p>

<br>
<p class="tab"><i>
Article I</i></p>

<p class="indent"><i>
1. Each of the Parties to this Treaty undertakes to prohibit, to prevent, and not
to carry out any nuclear weapon test explosion, or any other nuclear explosion,
at any place under its jurisdiction or control:</i></p>

<p class="indent"><i>
(a) in the atmosphere; beyond its limits, including outer space; or underwater,
including territorial waters or high seas; or</i></p>

<p class="indent"><i>
(b) in any other environment if such explosion causes radioactive debris to be present
outside the territorial limits of the State under whose jurisdiction or control
such explosion is conducted.</i></p>
<br>

<p class="tab">
This seems clear
enough, but there are some things that, on careful examination of subparagraph
(b), are open to interpretation. The first, and most important of these, are
the words "... causes radioactive debris to be present ..." What comprises
the radioactive debris of a nuclear explosion? Is it any radioactive product
produced by the explosion? Or is it only those radioactive products which will
ultimately be deposited on the ground, and thereby become "debris" - the
dictionary definition of which is: "The scattered remains of something
broken or destroyed; ruins?" This could be interpreted as meaning that if
you cannot go about the ground and find "scattered remains," or
fallout particles, you have not violated the Treaty. Hence, any release of
noble gases, which dilute in the atmosphere, which are biologically inert, and
which do not deposit on the ground, do not count. The answer to this question
of interpretation is of considerable importance to the people who are charged
with conducting a nuclear detonation, and at the same time with complying with
the terms of the Treaty.</p>

<p class="tab">
With one
interpretation, a seepage of gases from a detonation, however large, would not be
considered a violation, no matter where or how detected, because they would not
be considered "debris." Using the other interpretation, such a
seepage would be a violation, if large enough to be detected outside the State
boundaries.</p>

<p class="tab">
Now consider the words
"... to be present outside the territorial limits of the State under whose
jurisdiction or control ..." In order for something to exist in this
context, somebody has to know it's there. If radioactive material did cross the
border of the State conducting the detonation, and someone, with some instrument,
did detect the activity, then the Treaty has been violated. If the material is
not detected outside the territorial limits, for whatever reason, it is
difficult, or impossible to claim that a violation has occurred. Another
document that can be considered as defining containment in the United States is
the Charter of the Containment Evaluation Panel. The relevant passages
concerning containment itself are Articles III, subparagraphs A and C, and
Article VIII subparagraph F. These are:</p>

<br>

<p class="indent"><i>
III A. Emplacement and firing of each nuclear device will be conducted in a manner
that conforms with United States obligations under all Nuclear Test Treaties.</i></p>

<p class="indent"><i>
III C. Each test will be designed to be successfully contained. Special cases
will be referred to DOE/Deputy Assistant Secretary for Military Application
(DASMA), for approval.</i></p>

<p class="indent"><i>
VIII F. Successful Containment: Containment such that a test results in no
radioactivity detectable off site as measured by normal monitoring equipment
and no unanticipated release of radioactivity on site within a 24 hour period
following execution. Detection of noble gases which appear on site at long
times after an event due to changing atmospheric conditions is not
unanticipated. Anticipated releases will be designed to conform to specific
guidance from DOE/DASMA (NV-176, Revision 5, Planning Directive for Underground
Nuclear Tests at the Nevada Test Site (U)).</i></p>

<br>

<p class="tab">
Note that the word
"debris" does not appear. For there to be successful containment, it
is "radioactivity" that is not to be detected offsite, and this term
certainly includes the noble gases. The boundaries of the Test Site are much
closer to the event than the borders of the United States, hence
"successful containment" is a much more rigorous standard than that
given by using either interpretation of "debris" in the Treaty.
Further, there should be "no unanticipated release of radioactivity on
site within a 24 hour period following execution." The implication is that
an unanticipated release of any amount of radioactivity within the 24 hour
period is a failure to achieve successful containment. The monitoring equipment
which might be used to detect such an unanticipated release is not specified.
unlike the case of detection off site where "normal monitoring
equipment," whatever that is, is to be used.</p>

<p class="tab">
What occurred between 1945 and 1963 that led to the Treaty, generally known
as the Partial Test Ban Treaty?</p>

<br>
<p class="tab"><i>
It's almost always true of any organization that there are outside influences that
make that organization change. It seldom comes from within.</i></p>
<p><i>- V. Leimbach</i></p>
<br>

<p class="tab">
And so it was with the Atomic Energy Commission, the Laboratories, and the
field test organizations.</p>

<p class="tab">
Trinity, the first
nuclear detonation, was carried out on July 16, 1945, atop a 100 foot tower.
For the next many years that was one of the basic methods for doing experiments
with nuclear devices. There were variations, of course; the air drop and the
underwater detonations in Crossroads are examples. Sometimes the tower was
short, or non-existent, and the device was detonated on the surface. Sometimes
a plane dropped the device to detonate in the air. Or sometimes a balloon, or
rocket, lifted the device to a desired altitude, there to be detonated.</p>

<p class="tab">
For the scientists seeking
information about the performance of some aspect of the device, there were
trade-offs. The turnaround between experiments could be markedly decreased by
using planes or balloons, but it was not possible to do experiments that
depended on accurately viewing some particular area of the device where
phenomena of interest were taking place. Towers allowed that, but it took a
long time to build the towers, and install the carefully collimated and aligned
pipes through which instruments viewed a particular area, and recorded the data
from there.</p>

<p class="tab">
There were other
differences among the ways in which the experiments were done, and these
related to what happened to the radioactive material that was produced by the
detonation. It was these considerations which gradually shaped the way in which
experiments could be carried out, and eventually led to the firing of all
devices underground in such a way that no radioactivity entered the atmosphere.</p>

<p class="tab">
Initially, the
approach to the radioactive products of the detonation was to disperse and
dilute them, hopefully to a degree that made them of little biological
consequence to people who might encounter them. It was an application of a
belief once commonly held, not only by those detonating nuclear devices but by
those running factories and other industrial sites which produced unpleasant
and possibly dangerous by-products of the materials they produced:</p>

<br>
<p class="tab"><i>The solution to pollution is dilution.</i></p>
<br>

<p class="tab">
With this approach,
if you were dumping waste chemicals into a river, and the river became badly
fouled, what you needed was a bigger river, so there would be more dilution.
The concept of controlling by-products of an activity at the source came
slowly, and only as a result of public concerns.</p>

<p class="tab">
After the end of
World War II the United States conducted nuclear experiments at Bikini, and
later at Enewetak as well. There was the Crossroads operation at Bikini in
1946, and the Sandstone operation at Enewetak in 1948.</p>

<p class="tab">
Crossroads consisted
of two 21 kiloton detonations; one air-burst on June 30, and an underwater
detonation on July 24, 1946. These were weapons effects tests, to investigate
effects of a nuclear detonation on ships and other military equipment. In
Sandstone there were three devices of various yields fired, all on towers, between
April 14 and May 14, 1948. There was a significant difference from the focus on
the effects of the Crossroads detonations - information about the performance
of the devices themselves was an integral part of the Sandstone operation.</p>

<p class="tab">
Crossroads and Sandstone
were basically ship-based with minimal support facilities on the atolls
themselves. By 1951, when the Greenhouse operation was held from April 7 to
June 24, 1951, permanent facilities had been built on Enewetak.</p>

<p class="tab">
Bob Campbell became
one of the Los Alamos Test Directors, and although he did not participate in
either Crossroads or Sandstone, he later had extensive experience in both the
Pacific, and in Nevada, starting with Operation Ivy, in the Pacific, in 1952.</p>

<br>

<p class="tab"><b>Campbell</b>: Enewetak was first
used in '48, for Sandstone, and the whole nine yards of that thing was done by
the Corps of Engineers; U.S. Army types. And there were a number of lessons
learned on that. The AEC made their imprint on Greenhouse. The operation itself
was in '51, but there was well over a year and a half buildup. They had a big
structures program, and all the housing, warehousing - essentially everything
out there that we used for Greenhouse - was built by the AEC. They did a much
better job than the Corps of Engineers, because they had the idea that they
were going to operate these things for ever and a day. It wasn't going to be
done in the style of a Task Force campaign.</p>

<p class="tab">
You can go back and look at the testing. The reason for Trinity was obvious; to see if
the thing would work once. Then there were the Japanese things. Then there was
a big hue and cry by the Navy, and so there was Crossroads. That was a Navy
show; all this Lab did was provide the detonation service. And the Navy did
themselves proud with Crossroads.</p>

<p class="tab">
Then it was the Army's turn with Sandstone, but by that time the Lab had an interest in
it too, because they had some new designs to try. So, it was more or less a
joint venture. In fact, it was a little more than a joint venture. The Army
really acted as support to the Lab on Sandstone.</p>

<p class="tab">
The Laboratory group who did those operations was formed the same way as it had
been in the past. You take somebody from this division, somebody from that
division, and somebody from over here, put together a campaign, and go do it.
Everybody comes back and then goes back to their regular jobs. At the end of
Sandstone, Darol Froman, who had been the senior Lab person there, realized
that wasn't going to cut it. It was going to go on and on, and so in '49, the
year after Sandstone, they formed J Division, a permanent testing division, in
the Laboratory.</p>

<p class="tab">
Froman saw the need of it, and I've seen a fair amount of his correspondence on it. He
wrote some rather persuasive papers on why it would be better if they faced up
to it and said, "Here it is; we're going to be doing this for the rest of
our lives." And I think the AEC was right in listening to him, and going
along with a permanent plant at Enewetak atoll.</p>

<p class="tab">
Operations in the Pacific, at what was called the Pacific Proving Ground (the PPG), were
expensive, time consuming, and required considerable military resources to
support the operation, the civilian construction workers who built the camps,
the bunkers, and the towers, and the scientific teams who came to install the
devices and the diagnostics. The construction started a year to a year and a
half before the actual tests began.</p>

<br>
<p class="tab">
Gerry Johnson, after
a short time as a weapons designer, became responsible for the Livermore field
efforts, and then became one of the Livermore Test Directors.</p>
<br>

<p class="tab"><b>Johnson</b>: Shooting in the
atmosphere required big task forces, and as a consequence we could not have
continuous operations. You had to mobilize, put things together, shoot them all
in an interval, then return to the Laboratories and try to figure out what
happened, rework the designs, and design new experiments.</p>

<p class="tab">
In addition to that, the operations were complicated, unduly complicated, because
there were thousands of people in the field. They were spectacular shows,
people liked to see them, and so they dreamed up all sorts of reasons for being
there. That meant if you were trying to manage the operations, you had several
thousand people to try to keep track of. If anything went wrong, any confusion,
you had a hell of a time getting them out of there, and getting it straightened
out so you could do your work.</p>

<br>

<p class="tab">
After Sandstone there
were no more shots in the Pacific for almost three years, until the first event
of Greenhouse on April 7, 1951. In the meantime there was an exploration for a
possible location in the United States where low yield detonations could be
carried out, without the cost and time required for the Pacific tests.</p>

<p class="tab">
The Korean War led to
the declaration of a national emergency by President Truman on December 16,
1950. Two days after that declaration the President authorized the AEC to
establish a proving ground for nuclear tests on the Las Vegas-Tonopah Test
Range. Various locations had been looked at during the 1948-1949 period. Ultimately
a choice had to be made.</p>

<br>

<p class="tab"><b>Brownlee</b>: The Nevada Test
Site location was selected by Al Graves. He got on an airplane with somebody,
they flew around, and he found this nice area. You could put some boundaries
around it, there was a road to it on the south side, and it looked like it
would be easy to build roads.</p>

<p class="tab">
So, the criteria used for the selection of the Test Site had nothing to do with whether
there would be atmospheric or underground shots. It was just a place we could
get our hands on. And it was a place that had a road to it, and a place where
you could land airplanes; it was an accessible place.</p>

<p class="tab">
And there is another thing. When Al was selecting the Site, he was selecting a place
where Los Alamos could go to do interim kinds of things, and a place where we
could have our failures. We could have a failure there, because if it didn't
work we could come back here, and in a few days have another thing ready to
try. Once we got the various problems worked out, then we would go to the
Pacific to do the real experiment. That was the concept.</p>

<p class="tab">
So, the Nevada Test Site was selected by Los Alamos as a place where you could do
certain experiments before you went to the Pacific to the permanent test site -
the Pacific Proving Ground. When we removed the people from Enewetak, in the
Marshall Islands, that was expected to be, at one point in time, permanent. We
didn't anticipate them going back.</p>

<p class="tab">
The object of the NT5 was to do experiments close to home so you could go over to
the Pacific to do the real thing. So, you did the low yield here, and you'd
find out what wouldn't work. When you got ready to do one that really worked,
you went to the Pacific. That concept was believed, and held, and fostered by
people here at Los Alamos for, I would guess, four years. That was a long time
in those days. And then we realized that Nevada was good enough that we could
do a lot of things there that were not originally intended to be done there.</p>

<br>

<p class="tab">
With the approval to
do continental testing, things moved rapidly. The Ranger operation consisted of
five airdrop detonations which were done in eleven days from January 27 to
February 6, 1951 at the (then) Nevada Proving Grounds. There were two devices
with a yield of 1 kiloton, two with yields of 8 kilotons, and one of 22
kilotons. All were detonated at 1,000 feet or more altitude.</p>

<p class="tab">
There was also the
first of the things which would lead to today's world of "successful
containment." Fallout from one of the Ranger events left measurable amounts
of radiation in Rochester, New York, deposited during a snowstorm.</p>

<p class="tab">
Of course, from 1951,
when the first tests were done at the Nevada Proving Grounds, until 1963, there
was no Nuclear Test Ban Treaty, and from 1951 until 1961 there were no
requirements for any type of containment in the conduct of a test at the (now)
Nevada Test Site. If the concept of containment is considered in a broad
context, it relates fundamentally to a way to mitigate the effects of the
radioactivity produced during a nuclear explosion. These effects can be quite
close to the place of the detonation, they can take place at considerable
distances, they can be global in extent.</p>

<p class="tab">
Such effects began to
be a problem soon after tests began in Nevada. By 1953, in the operation called
Upshot-Knothole, airdrops were used less and less, and devices with yields up
to 32 kt (Harry), and 43 kt (Simon) were fired on towers. Both of those events
caused off site fallout problems. In the case of Simon, some off site cars were
contaminated, and had to be washed down. In the case of Harry, the people of
St. George, Utah were told to stay indoors from nine until noon, to reduce
exposures from the fallout on the community, and the passage of the radioactive
cloud. There was fallout in Troy, New York, deposited in rain which fell. There
were reports (and later lawsuits) that hundreds of sheep in the Nancy and Harry
fallout patterns had died, presumably due to exposure to the radioactive
products of those events. The general public began to be aware of the actuality
of, and the hazards associated with, the radioactive material from the nuclear
tests at the NTS.</p>

<p class="tab">
Worldwide attention
was drawn to the dangers of fallout when the 15 megaton Bravo event of
Operation Castle was fired on February 28, 1954. A Japanese fishing vessel, the
Lucky Dragon, was some 80 miles from the detonation, and was in the fallout
pattern. By the time it returned to Japan several members of the crew required
hospitalization for the effects of the exposures they had received, and one
died during treatment. Some 236 Marshallese and 3I weather service personnel
who were on downwind atolls, well removed from Enewetak and Bikini, were also
exposed, as were personnel on the ships of the Task Force.</p>

<p class="tab">
Bill Ross was a
participant during Castle, responsible for the mechanical hardware that was to
be used for Livermore measurements on the Los Alamos Bravo event.</p>

<br>

<p class="tab"><b>Ross</b>: I was on the
Curtis. We were issued the glasses the night before, told to wear long sleeved
shirts, and that sort of thing. We were about thirty-five miles away. You kind
of wondered, you know . There'd been the orderly room speculation about setting
the atmosphere on fire, splitting the world in half into two pieces, and all
that. And you began to wonder whether they really were seriously talking about
what actually might happen.</p>

<p class="tab">
Of course, the shot point was below the horizon. There was this tremendous light
and heat, although you couldn't feel the heat at first. There was just the
tremendous light. Even with the very dark glasses you were squinting. And then
the heat came as the fireball got above the horizon, and it just g9t hotter,
and hotter, and hotter. We had been warned to hang on because of the shock
wave. By that time it was just so spectacular I'd forgotten all about that
warning, and I was just standing there. All of a sudden it looked like a gauze
curtain coming at you, smoothing out the little ripples of the water. There was
a bang, and from then on there was just a roar, a tremendous roaring that
seemed to go on for a long time. Finally the light got so dim that you were
opening your eyes wide and straining, and then you remembered, oh, I've got
these goggles on. When you took the goggles off it was still very bright. The
goggles were a darn sight darker than welding goggles. It was very impressive.</p>

<p class="tab">
We started to get into the fallout, and the commanding officer of the Curtis got
out from under the fallout. But, the Navy didn't like their ships all going in
different directions, each commanding officer deciding which way to go, so they
were all told to regroup around the Estes, where the task force commander was,
which was right under the cloud, so they all went back into the fallout. We
just had a little bit of fallout and got out from under it, and they washed the
decks down. We were back out on the deck again when they got ordered to
regroup. We went back in, and here it comes down again. Then we were locked in,
and they were hosing down.</p>

<p class="tab">
My stateroom was right near where the swabbies were going out on the deck and
cleaning up, and they had a monitoring station there. These guys would go out
in their raincoats and boots, and they would hose and sweep. When they came in
they would strip and pile the stuff on the floor, step over two feet, and a guy
would go over them with a counter. It was into the showers if you showed more
than 2 mR above background. All this time the pile of clothing background is
growing. At one point they were looking for the difference between 100 and 102
mR per hour. They were doing the monitoring in a 100 mR per hour field.</p>

<p class="tab">
I don't remember how long we had to stay inside, but it was many, many hours. This
thing went off at five o'clock in the morning, and we didn't get fallout coming
down on us until after we had eaten, as I remember. We got a little bit, got
out from under it, cleaned up, and were out on the deck around nine or ten, and
then it was back in again. I don't remember when we got out. Herb Weidner and
some of the other guys who were over on the aircraft carrier Bairoko, they were
in a high field for days. The hanger deck was running, if I remember, a number
of hundred mR per hour for hours, and then they were down around 5 mR per hour
for days afterwards. They got a lot of exposure. In fact, the Bairoko never did
get cleaned up.</p>

<p class="tab">
I didn't see the fallout, but I was told by the guys who were sweeping it up and hosing
it off that it was like a white dust. It was calcined coral. An awful lot of
stuff went up, and it falls out, it definitely does. If you read the story of
the Lucky Dragon, they got caught in the same kind of mess.</p>

<br>

<p class="tab">
After Bravo, and the
Lucky Dragon, fallout was no longer just a local concern, or a U.S. concern.
Prime Minister Nehru, of India, on April 2, 1954 called for a testing
moratorium. Concerns in the United States led to the Atomic Energy Commission
finally to release some information about fallout. Before this there had only
been releases saying, in essence, that whatever exposure people had received
from the fallout from detonations at the Test Site were not large enough to
cause any problems. No mention was made of the levels of possible exposures, of
what radioactive isotopes were involved, or what areas were in the overall
fallout pattern. It was on February 12, 1955 that the Commission released a
report titled "A Report by the United States Atomic Energy Commission on the
Effects of High Yield Nuclear Explosions." This report did talk about both
the Bravo test and the fallout from Nevada tests, but did little, if anything
to reduce the concerns of the public; in fact, it may have exacerbated them.
Commissioner William Libby did make a public statement about the problems of
radiation exposure, and released scientific data about fallout in a talk he
gave in June of 1955 to the alumni of the University of Chicago, wherein he
made the statement that fallout did not "constitute any real hazard to the
immediate health" of members of the public.</p>

<p class="tab">
People working at the Test Site were having their own problems with both
local and offsite deposition of radioactive material.</p>

<br>

<p class="tab"><b>Campbell</b>: After the St.
George business, and after Bravo, it became obvious that we couldn't continue
to have that kind of off site fallout. If we wanted to get our job done, we were
going to have to find different ways of doing things. I don't think it was the
people in Washington. It was really an internal recognition that we had to do
something. And on site it was our people who were getting exposed making the
recoveries. Believe me, radiation readings in the fallout patterns were much
higher in Area 3 than they were in Utah, and we had to go in to get the data.
The rule then was that you could work people forever in 10 mr per hour fields.
In Nevada I don't believe I ever went into a field that was over 50 R. Fifty R
per hour is a lot, but you could get people who had not had much exposure, and
you could say, “The operation is almost over, you're going home, and this is
just for one time."</p>

<p class="tab">
Operationally a number of things were tried, with the idea being to protect our own people.
In so doing there was, of course, a benefit off site. They tried making large
blacktop pads around tower bases, asphalt pads, to keep from entraining so much
dirt. You could keep down quite a bit of the dirt that came flying up
otherwise. And then there were areas where boron was put down, to reduce the
soil activation. That was in about '55, or even before.</p>

<p class="tab">
Towers we bought by the foot; we'd buy pieces for several thousand feet of towers. Then
you take bits and pieces, like an erector set, and put up a two hundred foot,
or three hundred foot tower. We had towers that were triangular in cross
section, and towers that were square in cross section. The triangular things
twisted too easily in torsion, and wouldn't bear enough load either. There was
always the business of Herman Hoerlin wanting more lead, or Ernie Krause
wanting more of something else in the cab. We tried aluminum towers to get away
from the steel, but they didn't work worth a damn Do you want a little steel,
or do you want a lot of aluminum? It ended up that the aluminum just did not
have the strength and rigidity. It wasn't too popular, so we were always trying
to find ways to use the aluminum towers we had in stock.</p>

<br>

<p class="tab">
By 1956 people in the
testing community were beginning to consider seriously the possibilities of
conducting tests underground. This was a major shift in the thinking about the
problem of fallout. Previous efforts had been directed basically to dispersal
and dilution; firing underground would be an attempt to control at the source,
to keep the radioactive material in one place, and not to let it disperse.</p>

<p class="tab">
Edward Teller and Dave Griggs in 1956 wrote a brief paper (UCRL-1659) titled "Deep
Underground Test Shots." In it they concluded:</p>

<br>

<p class="indent"><i>
1. The cost of drilling a hole sufficiently large and deep to emplace and contain
kiloton shots is comparable to the cost of erecting a tower for such shots.</i></p>

<p class="indent"><i>
2. A depth of 3,000 feet is ample to be sure of no surface eruption from 30 kt
and small-to-zero emanation of volatile radioactive elements. One thousand
feet will suffice for 1 kt.</i></p>

<p class="indent"><i>
3. Yield can be determined within 5 to 10% by seismic and time-of-shock
arrival, with suitable calibration.</i></p>

<p class="indent"><i>
4. Radiochemistry of the explosion products may be done by core drilling the
molten sphere. This may be expensive.</i></p>

<p class="indent"><i>
5. Diagnostic experiments may have to be restricted to the determination of
the time-dependent gamma flux.</i></p>

<p class="indent"><i>
6. Using an open hole, visual observation and interesting neutron experiments
may become possible.</i></p>

<p class="indent"><i>
7. The seismic hazard to off-site structures is nil.</i></p>

<p class="indent"><i>
8. The long-term radiologic hazard is nil.</i></p>

<br>

<p class="tab">
And, they recommended
that in connection with the next Nevada test series, (which would be Plumbbob,
in 1957) a low yield shot be detonated at the Test Site, "at such a depth
that it will be contained."</p>

<p class="tab">
At Los Alamos, Al
Graves, head of the test effort, had arrived at the same conclusion; the possibility
of doing tests underground had to .be explored, because nuclear tests were
going to have to be done underground if testing in the United States, at the
Nevada Test Site, was to continue. No such events had ever been conducted, and
the state of ignorance was vast. There were no equations of state for earth
materials, and no codes into which to put them if they had existed, and by
today's standards, primitive computers to run them on if the codes had existed.
No one knew how big a cavity would be formed, or what the post-shot cavity
conditions would be. No one knew what a safe burial depth was. No one knew what
the ground motion and seismic effects would be. And so on.</p>

<p class="tab">
In 1956, Graves asked
Bob Brownlee to look into what might happen if a device were detonated underground.</p>

<br>

<p class="tab"><b>Brownlee</b>: One reason I
admired AI Graves was because he was so inordinately farsighted. He anticipated
problems long before other people. Where he came to have these ideas I have no
idea; whether they came from his colleagues, or whether they came from the sky
I don't know. He was the first one to my knowledge to ask questions of a
far-reaching kind about the hazards of testing. For example, "Is there any
chance that I will knock a piece of the shelf off the reef, which will then slide
down the edge of the atoll and start a big wave of some kind? What's the chance
of doing that?" As people talked it over, they decided that could actually
happen, and so we moved some shots. But those kinds of unanswerable questions
were frequently asked by Al first, at least to my knowledge.</p>

<p class="tab">
One
experience with testing in Nevada which must have influenced him mightily was
that in '55 there was a civil defense test where they sat out over two weeks
before the weather was right. They were very carefully watching where the
fallout would go, and if it was predicted to go over places where there were
people who couldn't be warned, and evacuated if need be, the shot was cancelled
for that day. That shot was scheduled every day, and then cancelled, for nineteen
days, and AI was the one making those decisions. Now, there were a lot of civil
defense people, and press people, and others, whose hotel reservations were
running out and so on, and they were very impatient with all this. And Al was
taking that pressure.</p>

<p class="tab">
He said to me, in 1956, "There isn't any doubt about it. If testing is to proceed,
we're going to have to go underground. It's got to be done, whether we want to
or not. Would you start working on what it might be like to have a fireball
underground?"</p>

<p class="tab">
I was tied up for the '56 tests in the Pacific, but once they were over AI said
again, "Please go to work on underground things. It's inevitable. We're
going to have to do that, and the question is, 'Can you contain anything at
all? If you put the device underground, does it just all blowout, or what?'” It
was a very interesting question, and I began doing some machine calculations.
We were doing work on the IBM 704's, which were quite new then.</p>

<p class="tab"><b>Carothers</b>: You were using, by
today's standards, a rather small machine. You were using a computer that had
less capability than the one you probably have at home now.</p>

<p class="tab"><b>Brownlee</b>: Oh, you can now
carry around, in your shirt pocket, something with more memory than the 704's
had. We coded everything in machine language in order to save memory. And we
had bits in the words which we used as flags, because you never did any
multiplication or division until the end, because that was so slow. The
programs were incredibly sophisticated in adapting anything in the world to a little
bit of memory, and to the machine's characteristics. You spent all of your time
doing that rather than working on the problem. I had this big deck of cards
that I would feed into the machine, and if there was a card upside down it was
rejected. It was a very slow, laborious process, but that's what we had in '57.</p>

<p class="tab">
The earliest work I did was try to calculate the creation of a cavity. I had the
equations of state of four materials; aluminum, uranium, air, and water. I
said, “That’s the old Greek concept of earth, air, fire, and water. Earth was
aluminum, fire was uranium, and there was air, and water. With those four
equations of state I started trying to calculate what might happen underground.
Now, very quickly we began to get more refined equations of state, but from
those four I tried to make an equation of state for some fake material. I tried
to guess in what direction earth might be different from aluminum, and started
to change the various parameters. I finally evolved what I called the equation of
state of NT5 dirt.</p>

<p class="tab">
I look back on it all now in amazement. How could anybody pay me to do such absolutely
worthless calculations? And yet, the fact is, they weren't all that bad. I
created, in my initial calculations, an elliptical cavity; I didn't really get
a round cavity. That was because of the inadequacies of my equations of state.
Of course, I didn't know enough to know what the answer should be, so, just
like every other theoretician, I fudged the numbers to make them kind of match
what I saw. By modern day standards it was an abomination, but for the time it
wasn't all that bad, and we were educating ourselves.</p>

<p class="tab">
Incidentally, I feel very strongly about that. Machine calculations you should use to teach
you how to think. You don't pay any attention to the numbers, but they teach
you how to think, and how to see what is more important than something else.
And that's exactly what I was doing. I was getting a very good education. I
wasn't contributing anything profound to the system, but I sure was getting a
education about how to think about things. That's the real value of that kind
of work.</p>

<p class="tab">
So, I did my first primitive calculations in '56. And I actually calculated one test,
Bernalillo, which we did in '58. That's how I got into the underground business,
and that was strictly due to AI Graves, who recognized the necessity to go
underground. There are a lot of people who don't realize that we were doing the
initial work for underground tests as early as 1956. Now, remember, we didn't do
that until ‘63, totally.</p>

<br>

<p class="tab">
One theme that was
present in the early underground experiments was that there was a definite
self-interest for the Laboratories' test organizations in reducing the fallout
from the shots. There was a need and a desire to reduce the fallout off site,
and to respond to the mounting public concerns, but also there was the need to
reduce the local fallout in the vicinity of the shot itself for operational
reasons.</p>

<br>

<p class="tab"><b>Campbell</b>: The first thing we
at LASL did in a hole was called Pascal-A. It was 500 feet deep, in a cased
hole. We put the bomb in the bottom of it, and we didn't stem it. So, we fired
it. Biggest damn Roman candle I ever saw! It was beautiful. Big blue glow in
the sky. I was up in the CP office, and that was fired from a little handset,
out at the B-J Y.</p>

<p class="tab"><b>Carothers</b>: You mean somebody
sat out there, and as I've seen in Tom Mix movies, pushed the plunger to blow
up the dynamite and foil the Bad Guys?</p>

<p class="tab"><b>Campbell</b>: Well, pretty close
to that, but not quite. He had a little hand firing set. The shot was in Area
3, down by 3-300. The firing point was the nearest timing station of any size
to Area 3, and so the shot was between the people out there and the CP.</p>

<p class="tab">
Bill Ogle was out there, in that timing station. When he saw that come out of the ground
he knew he couldn't come south the way he came north, because he was going to
get into trouble. Bill was more excited that evening than I ever heard him
before or since. He was really excited about how they were going to get back.
They went way out east on roads that didn't exist, came back around into Yucca
Lake, and came in that way. You've heard people say, "His eyes bulged out
like a stomped-on toad"? That's what Ogle looked like when he came into
the J Division office that night. He was really excited, and talked a mile a
minute. They were damn lucky they didn't go right through that cloud.</p>

<p class="tab"><b>Carothers</b>: Why didn't you stem it?</p>

<p class="tab"><b>Campbell</b>: Didn't need to. We
did have a lid on the hole. Nobody's seen that since. We never did find that.
On that lid was one of Johnny Malik's detectors, and we wanted a line of sight
to see if we could measure some of the reactions. There was a kind of plug in
the hole. It was a couple of hundred feet off the bottom, as I remember. All it
was, was a concrete cylinder with a hole through the center of it, so the
detector could look through. And it had an annulus, so it wouldn't bind
anywhere going down. It was suspended from the harness that was holding the
bomb. It was a collimator, not a plug that was supposed to stem the hole. We never
found that collimator either, and it was about five feet thick.</p>

<p class="tab">
We had a half dozen of those holes drilled in an arc around station 3-300, our alpha
station. We were in the business of making the transition from towers that were
looked at from the station. All our scopes were in there, and we were trying to
get something where we could use the same recording gear without having to move it.</p>

<p class="tab">
But anyhow, bad as it was, spectacular as it was, there was only about a tenth of
the radiation on the ground around there that there would have been if we had
done it on the surface. And we considered a factor of ten reduction to be
wonderful. We thought we had made a real gain. A factor of ten meant we could
get back, and get set up and fire again more quickly. We were very happy with
the results, and we did it all over again on Pascal-B. That one doesn't stick
in my mind like that first blue one. That was our initiation.</p>

<p class="tab">
The reduction in off-site fallout was an effect that was appreciated by the AEC,
and the people who worried about offsite safety. What we were worried about was
being put out of business if we had too many people pounding on the gates. And,
we wanted to reduce the local fallout, the contamination of the area that we
were using.</p>

<p class="tab">
Jumping ahead to the moratorium, it turned out that we had a little money, and we
drilled holes against the day that we might come out of the moratorium. We
really thought that was the direction we were going to go.</p>

<br>
<p class="tab">
Bob Brownlee, who had
been asked to look at the possibility of firing shots underground, helped to
design the Pascal experiments, and attempted to approach the problem in an
orderly fashion. That was sometimes difficult.</p>
<br>

<p class="tab"><b>Brownlee</b>: Our first
underground tests were done in '57. There was Pascal-A, and Pascal-B, and Pascal-C.
And there were several others in '58, during Hardtack II. AI asked the
following question, “If I take a 48 inch casing, and I put a bomb a couple of
hundred feet down, by how much will the fallout be reduced?" We discovered
it was a factor greater than ten. And that was just an open hole. So, he then
said, “We put some plugs in the hole, does that cut it even further? And if so,
how much?" So we did that. Then he said, “Let’s put a plug right down on
top of the bomb, and then let's put a plug half way down. Does that make any
difference?" And yes, it does a better job if you put the plug right on
top of the bomb. “Well, suppose we put in some dirt. Does that help?"</p>

<p class="tab">
We started exactly that way. We were still doing atmospheric shots, so the question
was a very simple one. “If you do this, or that, how much will you cut the
fallout?" And we determined that experimentally. The answer to the fallout
question was, “We’ll measure it and see." On the other hand, the
calculations I did calculated the time the shock would get to the top, what
kind of top you might put on the hole to hold things in, what would the
pressures be there, how big might the cavity get, how does it cool, and what
happens to all that pressure? Does it lift the ground? Those kinds of questions.</p>

<p class="tab">
Pascal-B and Pascal-C had plugs, but Pascal-A did not, although it had a concrete
collimator in it for the detector at the surface. The guys had been working
trying to get it ready, and there had been a number of troubles. They finally
got it down hole, by my recollection, about ten o'clock or so at night. There
wasn't much time to go back into Mercury, go to bed, and get up the next
morning to shoot it, so somebody said, ”Why don't we just shoot it now, and
then go in?" And it was the world's finest Roman candle, because at night
it was all visible. Blue fire shot hundreds of feet in the air. Everybody was
down in the area, and they all jumped in their cars and drove like crazy, not
even counting who was there and who came out of the area. Today it would give
the Test Controller and his Panel total apoplexy - they would become totally
insensate.</p>

<p class="tab">
It wasn't done quite as logically as I have indicated, but there was a thread of logic
from shot to shot. We saw what happened on one, and decided what to do next,
but in the meantime we would have another one. So, the chronology is not as
perfect as you'd like to think it was.</p>

<p class="tab">
One of the things we were annoyed about in '57 and '58 - I remember being annoyed, and
I say we because I think there were a number of us - was that we'd do an
underground shot, and the radioactivity from an atmospheric test would be
floating by at such high levels we'd never know what came out. The object of
the underground shot was to see how much we could reduce the fallout, but we
couldn't differentiate that fallout from the fallout of the atmospheric shot,
which was so much greater. So, I thought, "Why in thunder are we doing
this? The whole object is to find out what happened on this underground shot,
and after it's over we don't know whether it leaked or not, or how much. This
is absurd. Why don't those guys knock it off?" I remember having that kind
of an attitude, and I think there were several of us that were annoyed. But the
right hand usually doesn't know what the left hand is doing, and all that.</p>

<br>
<p class="tab">
At the Livermore
Laboratory, stimulated by the Teller and Griggs report, work was being done to
fire a low yield device in a tunnel, with the object of completely containing
all the debris produced. Gerry Johnson was in charge of the Livermore testing
program, and was the Livermore Test Director.</p>
<br>

<p class="tab"><b>Johnson</b>: It was becoming
increasingly difficult to carry out tests in Nevada because of the fallout
constraints, and the public furor over the fallout. There was a rising public
concern that kept growing through those years. In Nevada, from an operator's
point of view, we were only interested in getting the developmental
information. Actually, 1956 was when we began to think about underground shots,
and we were interested from an operational point of view. We felt if we could
go underground and get the data, then we could treat it as an extension of the
Laboratory. We'd go out and shoot whenever we were ready to shoot, without this
big Task Force and large numbers of people, because as you know, underground
shots are pretty dull to look at. And the duller the better.</p>

<p class="tab"><b>Carothers</b>: Somebody said, “Watching
an underground shot is like watching a submarine race."</p>

<p class="tab"><b>Johnson</b>: I've never heard
that, but you're right. That's a good way to put it. One of the big questions
we had was how to seal the tunnel, but out of a lot of stewing around the Rainier
experiment was finally designed, and we fired it in September of '57. And it
did contain.</p>

<br>

<p class="tab">
The Rainier event was
fired in B-tunnel on September 19, 1957. Even by today's definitions, Rainier
was successfully contained. The dragon was caged, and his foul breath no longer
polluted the air. Considering the lack of knowledge at that time about the
phenomenology of an underground detonation, that fact is somewhat remarkable.
After Rainier, perhaps containment even seemed easy.</p>

<br>
<p class="tab"><i>
hubris: n. Excessive pride, arrogance. From the Greek.</i></p>
<br>

<p class="tab">
Meanwhile, two
different paths were leading to changes in the way in which nuclear tests were
conducted. Since the Bravo fallout problems, opposition to continued testing
had been increasing in the United States, with wide publicity given to the
anti-testing or anti- bomb views of Linus Pauling, Albert Schweitzer, Paul
Jacobs, and others. There were anti-bomb demonstrations in England, West Germany,
and Japan. Politically, the issue of testing arose during the 1956 presidential
campaign, and influenced the steps that were being taken to negotiate a
disarmament treaty with the Soviet Union. In August of 1958 President
Eisenhower announced that United States would suspend testing for a year once
test ban negotiations were begun on November 1, 1958, in Geneva.</p>

<p class="tab">
The Hardtack operation had been conducted at the PPG from April to the middle of
August in 1958. With the announcement of a moratorium to begin at the end of October,
Hardtack Phase II began some thirty days after the last shot in the Pacific.</p>

<p class="tab">
During Hardtack Phase
II Los Alamos conducted six safety shots in unstemmed holes, with yields
ranging from zero to a few tens of tons. These events in unstemmed holes were
not designed to be completely contained; the objective was still to reduce
contamination in the immediate vicinity of the ground zero, and to experiment
with various plug and stemming locations and configurations.</p>

<p class="tab">
Livermore did seven tunnel
events during this period. There was one tunnel event which introduced those
people interested in containment to the possibility of an unexpectedly high
yield, or as some people might say, the unreliability of designers. Neptune was
fired on October 14, 1958, as a safety experiment with an expected yield of zero,
but with a possible yield of 10 tons or so. It was fired in a tunnel, with a
working point that was under the sloping face of the mesa, with a vertical
distance of 110 feet to the surface, and a slant range of 100 feet to the
closest point of the mesa. The yield of 116 tons was unexpected, the shot
vented, and produced a crater. The fact that some of the radioactivity was
released was not of real concern; Hardtack II was, after all, principally a
series of atmospheric shots, and the day before Neptune the Lea event, with a
1.4 kt device suspended from a balloon, had been fired. The Livermore people,
showing considerable flexibility in their thinking, promptly called Neptune a
nuclear cratering experiment, and in a future report, (UCRL-5766 The Neptune
Event; A Nuclear Cratering Experiment) discussed the "major contributions
of the data to the theory and prediction of cratering phenomenology."</p>

<br>

<p class="tab"><b>Carothers</b>: In '58 Livermore
fired a shot, called Neptune, in a tunnel. It turned out that it gave somewhat
more yield than was expected, and it vented out the side of the mountain.
People have said to me, "That Gerry Johnson, he was probably the world's
foremost optimist. We don't know how he did it, but he could take a disaster
and convince everybody it was a great success. On Neptune he just didn't pay
any attention to the idea that the shot was supposed to be contained. He said,
'Well, that's our first nuclear cratering experiment.'"</p>

<p class="tab">
Is that a true story?</p>

<p class="tab"><b>Johnson</b>: Yes, that's
correct. I was told the maximum possible yield was ten tons. That was the
absolute tops. So we designed it for ten tons, and it went a hundred or so.</p>

<p class="tab">
It was a lousy cratering experiment. It was on a sloping hill, but it was a point
on the curve. But you're right - you'll find that listed with the cratering shots
in the Plowshare program, and it had lots of analyses done on it.</p>

<br>
<p class="tab">Gary Higgins, at
Livermore, was beginning to explore the possibility of collecting what were
called prompt radchem samples. The thought was that if some kind of pipe could
be designed that would be emplaced in such a way as to look directly at the
device, allow a flow of some very small fraction, but no more, of the device debris
to a collector on the surface, the expense and time delay of the post-shot
drilling for samples of the device debris could be avoided. Dick Heckman was
part of the group that was to field and collect the samples which might be
obtained.</p>
<br>

<p class="tab"><b>Heckman</b>: We started off with
a few of the safety shots. The one incident that I remember in particular was
the Neptune event, in Hardtack Phase II. There was about a one-inch diameter
pipe which ran down into the roof of the room. The hole was drilled vertically,
preshot, and this one-inch pipe was inserted and grouted into place. We had a
plywood box built on top with a two foot by two foot aircraft-type filter
material with the appropriate screen, and with just a discharge on up. With the
yield that was anticipated, everything should really be kind of nice after the
shot.</p>

<p class="tab">
We then backed off down to the Area 12 CP. I requisitioned a pair of binoculars, and
braced myself on my vehicle so I could spot in on the location. With binoculars
I could see the little sampling box, and since our success hadn't been all that
good on safety shots, I thought if something were to happen, maybe I could
follow the trajectory of the box so I'd know where to go and find it. The event
went off, and the yield was quite a bit higher than they expected. As a matter
of fact, that was one of the first cratering shots that the Plowshare program
takes credit for. The binoculars did no good, because the ground shock hit the
surface, raised a dust cloud, and I couldn't see a thing.</p>

<p class="tab">
I got a bunch of radiochemists, and we went up and we saw the filter box was there,
in the crater. I argued like a Dutch uncle, and got permission, which in
retrospect was a dumb thing to do, but I got permission to get a rope tied
around myself, and to be let down into the crater. We were pretty motivated in
those days.</p>

<p class="tab">
So I crawled down, and indeed found the filter box. I tore the filter paper out, but
the pipe had shut off and so we had no sample. Now, when I was given permission
to go down into this crater, it was, "Under no circumstances will you go
into a field which is greater than 1 R per hour," because they expected
this big fallout.</p>

<p class="tab">
Well, going down there with my survey meter, I found out that the activity was
incredibly low - a few tens of mR per hour. In hindsight, as a result of
attempting to do that recovery, we got some very important information that really
excited some of the Plowshare people. When I came back and reported this, Vay
Shelton and Gerry Johnson happened to be down there at the time, and their eyes
lit up. It was sort of, "You've made the discovery, clearly you would want
to publish the paper.” At this point, the sampling system didn't work, so as
far as I was concerned there were other things to worry about. But it was my
crew in that recovery who were the first ones to discover that it was possible
to do a cratering shot and trap the gross radioactivity down in the ground.
Remember that all the previous experience had been with military cratering
shots, which were underburied.</p>

<br>

<p class="tab">
Two of the tunnel
events in the Hardtack II operation were designed to give appreciable yield,
Logan, fired two days after Neptune, produced about five kilotons, and was
successfully contained. Blanca, fired on October 30, 1958 produced 22 kilotons,
and like Neptune, but in a more spectacular fashion, vented out the face of the
mesa.</p>

<p class="tab">
The Logan event was
interesting for several reasons. It was an event in a tunnel, designed to
investigate the effects of the nuclear radiation on various materials. There
was a horizontal vacuum line-of-sight pipe which extended for 150 feet from the
device, opening to two feet in diameter at the far end. From there two six-inch
diameter pipes extended another 75 feet. The design team started with some
money, with very little Laboratory manpower support available due to the heavy
shot schedule already planned, support from some contractors, a pad of blank
paper, a tunnel that was still being dug, and six weeks to design the
experiments and the diagnostics, fabricate the hardware, and have everything
installed for the shot. That is an incredibly short time scale by today's
standards. And, Logan was successfully contained. Arnold Clark was the project
physicist for Logan.</p>

<br>

<p class="tab"><b>Clark</b>: We had six weeks,
because we had to shoot two weeks before, the end of October. We were going to
shoot in a tunnel, which hadn't been finished being dug yet, where an important
shot, Blanca, was going to be shot in another part. So, they had to have two more
weeks after we shot to finish off the cabling for Blanca. They would finish
digging out a side drift place for us, and they'd pull cable for us. Our
biggest problem was that we wanted a vacuum pipe in the tunnel; Here we were,
starting with a blank piece of paper, and we had five weeks to have that pipe
finished, installed, and pumped down.</p>

<p class="tab">
They said, "How long do you want it?" We looked at our blank piece of
paper, and said, II A hundred and fifty feet." "How big around?"
"Oh, about this big," making a circle with our arms. And that was the
process we went through to specify it. So, we had a 150 foot vacuum pipe,
maximum diameter of two feet, made by NRL in Washington. It was flown out,
installed, and evacuated. And it held a vacuum! In five weeks!</p>

<p class="tab">
Lockheed made a very fancy, very strong steel sample holder to put at the 150 foot
station. Then people had second thoughts about that station, and said, "That
is not going to survive. Or maybe it's not going to survive." They didn't
know. "Maybe we better go out farther." So, we extended the pipe by
adding two pipes, 6 inches in diameter, to the back end of the big one, to go
out another 75 feet. And that's all that survived; the 225 foot stuff. We never
saw any of that 150 foot station after the shot. That was where the container
of very special steel, made by Lockheed, had been. It was a huge thing, about
the size of a really good-sized safe, just essentially solid steel. And it was
a very special steel alloy that was supposed to survive. Well, it didn't. There
was very little from that station.</p>

<p class="tab">
We had a quite elaborate closure on the front end. There was a very fine theoretical
physicist, Harold Hall, working for Montgomery Johnson in early '58. They were
worrying about this containment problem, and Harold came up with the idea of a
Box A type closure, as they call it now. This was a brand new idea. Harold Hall
did some calculations, and so did Montgomery Johnson, and they said, “Ah,
yes!" So a Box A type closure was used for the first time on Logan, and it
worked very well. I think the front end was a foot in diameter, which is pretty
big. Maybe it was ten inches.</p>

<p class="tab">
When they were digging back after the shot they also drilled back at different areas
around the zero room, and found that the really highly radioactive area, I
guess you would call it the cavity today, was pear shaped. It wasn't circular.
Some activity had come down the tunnel, but not very far except for a few
cracks that went out as much as 150 feet. So, it did contain completely.</p>

<p class="tab">
However, it knocked in the side of the drift where Blanca was supposed to be, and
there wasn’t time to clean out that drift, so instead of being shot underneath the
mesa where it was supposed to be, Blanca was shot beneath the very steep face
of the mesa, out where the overburden was maybe half of what it would have
been. I watched it, and I thought the side of the mountain was going to come
right towards me and hit me. I was only two miles away.</p>

<br>

<p class="tab">
The days of
unrestricted atmospheric testing at the Nevada Test Site came to an end on
October 31, 1958, at midnight. As midnight came and went, Livermore device,
ready to be fired, hung suspended from a balloon, and there it remained until
the balloon was brought down and the device removed.</p>

<p class="tab">
Duane Sewell, who
later became the Deputy Director of the Livermore Laboratory, was the
Scientific Adviser to the Operations Manager for Hardtack Phase II, and made
the recommendation not to fire.</p>

<br>

<p class="tab"><b>Sewell</b>: We left one device
unfired, and I remember that night very well. I had about fifteen hundred
people who really were upset with me because I didn't tell the AEC to go ahead
and fire that device. I told them not to fire it, because it was obvious we
were going to have trouble, but not from fallout. The wind pattern was in a
direction that was not going to give us trouble, and that last shot was a
balloon shot, so there was not going to be a great deal of dirt picked up, and
local fallout from that. But the wind pattern was such that there was a
potential for a pressure impulse into Las Vegas that was strong enough to
possibly break plate glass windows. We obviously didn't want to hurt anybody,
and didn't want to break windows either.</p>

<p class="tab">
We were testing with shots of a half ton of high explosive mounted on one of the
hills a short distance from the CP. We'd fired a number of those during the evening,
and it was a double bounce. The shock wave bounced down around Indian Springs,
then the next bounce was into Las Vegas, and it was rather sharply focused. We
had trouble getting enough high explosive; I was blowing up all the high
explosives on the site to make those measurements every half hour to forty-five
minutes. The scheduled deadline was midnight on October 31st, Halloween night. I
remember a lot of masks around the place.</p>

<p class="tab">
Dodd Starbird was the Director of Military Applications at the time that operation
was going on. I got on the phone with him, and I said, "That's midnight
Washington time, not Greenwich time when we start the moratorium." We
agreed on that. That gave us an extra five or six hours. When it got to that
point I said, "No, it's really midnight here," and I got him to agree
to that. Then I tried to get him to agree to midnight within the United States,
which would mean Hawaii, but he wouldn't buy that. He wouldn't go that far, so Pacific
Standard Time was what we finally had to go on.</p>

<p class="tab">
We fired the last HE shot about eleven-thirty that night. I was in the microbarograph
room, and we had people out in the field with mobile measuring systems. The
people there called in and said, "My God, what did you fire that time?"
It really shook them. Apparently we had them just at the focus, and I thought,
"Boy, if a half a ton can be heard that far, I'm not going to fire."
The last thing we wanted was to have any sort of damage, or the potential of
harming people in Las Vegas. That's why I made the decision I did. I advised
Jim Reeves not to fire and he went along with it. That's why we left that thing
hanging on the balloon that night.</p>

<br>
<p class="tab">Louis Wouters was one of the Livermore scientists waiting for the shot to be fired.</p>
<br>

<p class="tab"><b>Wouters</b>: We ended up with
one shot, Adams, being The Last, the last of that particular series. It was
going to be shot on October 31st, but something didn't go the right way, and we
didn't fire the shot. If the politicians had any sense at all they would have
let us shoot it, because it turned out that two days later the Soviets went
ahead and fired one more shot anyway, after the beginning of the moratorium.
They weren't as picky about those things as we were.</p>


<a name="ch2"></a>
<br><br>
<h2>Chapter 2: The Rainier Event</h2>
<br>

<p class="tab">
The first nuclear detonation that was designed to be completely contained was the
Rainier event, fired in B-tunnel in Rainier Mesa on September 19, 1957, during
the Plumbbob operation. It had a yield of 1.7 kilotons, and for the first time there
was a nuclear detonation that did not release radioactive material into the
atmosphere.</p>

<p class="tab">
During the test moratorium that started in 1958 there were extensive explorations of
the cavity region and the surrounding materials. It was from the information
obtained during these reentry operations that many of the early ideas of cavity
formation, growth, size, and so forth originated.</p>

<p class="tab">
Gerry Johnson was, at that time, the Test Director for Livermore events, and was the
person who caused the Rainier detonation to take place.</p>

<br>

<p class="tab"><b>Johnson</b>: The
operational constraints, which were increasing each year, were bugging us, and
we were looking for a way out. Then Teller and Griggs did some back of the
envelope calculations and said, "Look, it ought to be possible to shoot a
shot underground, and if you had a thousand feet of overburden, you probably could
shoot a few kilotons or so." I was interested in that, and I said, "Well,
we'll examine that. We'll get some people looking at it and thinking about it,
and see what comes out of it." Which we did.</p>

<p class="tab">
That was in '57. The Teller and
Griggs suggestion was about a year previous. They wrote a memo on it,
describing the concept. Two of the big questions we had were whether you could
contain it, and would the radiochemistry be any good. As usual, we got into big
arguments with Los Alamos on all issues from technical to cost.</p>

<p class="tab">
The chemists here felt
they could do the chemistry. We had questions about the sampling. We didn't
know if we'd have a pool of molten rock, or what we would to get into. Before
the event we had lots of speculation on what would really happen. There were some
calculations made in terms of what you might expect in ground shock, and
surface motion, and so on.</p>

<p class="tab">
We choose the site based
on topography. We decided on a tunnel geometry because we thought that would be
the best way to do diagnostics. And that's how we finally ended up with Rainier
Mesa. We ended up in tuff, which was good stuff to dig in, but we didn't know
anything about it. We didn't know what tuff was when it was first mentioned to
us.</p>

<p class="tab">
But then we began to get
into public information trouble. A number of us were interacting with the
geophysical community, which we always had done, for all sorts of reasons. Dave
Griggs made the suggestion, "Look, if you are going to fire a shot like
this, for the first time we'll have a shot closely coupled to the ground. We'll
know the yield, we'll know the coordinates, and we ought to make this
information available to the geophysical world, so they can take advantage of
it. In fact, you ought to announce it ahead of time."</p>

<p class="tab">
Well, we went through
this, and were told to hold the time of firing to a tenth of a second at some
predetermined time, which we agreed to do. If for any reason we were delayed,
and couldn't meet that time, we agreed to wait twenty-four hours and try again.
And we published this. That was fine. It was very altruistic and lovely, and in
the right spirit of technical cooperation. But about a month or six weeks
before we were going to be ready, an international geophysical meeting took
place in Toronto, and by then this event was getting lots of interest on the
part of the seismic geophysical community. At this meeting some guy made some
statement about Livermore planning to fire an "earthquake maker," and
it hit the headlines, and of course got the Atomic Energy Commission's attention.</p>

<p class="tab"><b>Carothers</b>:
"AEC TO FIRE EARTHQUAKE BOMB!!!" I can see the headlines.</p>

<p class="tab"><b>Johnson</b>: That's
right. Well, that did it. Strauss, who was then Chairman of the AEC, called and
said, "What in the hell are you guys doing out there?" I said, "Nothing."</p>

<p class="tab">
So I went in to talk
with the Atomic Energy Commission, and I said, "We've gone through all the
calculations of what the seismic effects might be. This is a very low yield
thing that we're trying to shoot; 1.7 kilotons." That seemed quite small
to us. "And we've done all these calculations." Strauss said,
"That's not good enough. I'll tell you what you've got to do before I'll
authorize this shot. You have to assure the Commission that the shot itself
will not cause an earthquake. Number two, that it will not trigger an
earthquake, and number three, if a natural earthquake occurs at the same time,
you have to prove you didn't do it."</p>

<p class="tab">
So we put together a
committee. We got Perry Byerly, somebody out of Cal Tech, I guess Dave Griggs
was on it, a fellow named Roland Beers whom none of us knew, and somebody from back
east. They met. And we told them what we were going to do, and the whole thing,
and Byerly's first remark was, "You shouldn't be so presumptuous. One
point seven kilotons? That will do nothing seismically." I said, "I'm
not arguing with you."</p>

<p class="tab">
I called up Strauss an
appropriate time later and I said, "We've gone through this thing. This
board of experts got together, now we want to come in and talk to you."
Strauss said, "Who's on that committee?" I told him, and he said,
"I don't want any West Coast people on it." This was a setback,
because the West Coast seismic mafia was most of it. It turned out that the
only guy who was acceptable to them to be at this presentation was this guy
Roland Beers, whom we didn't know.</p>

<p class="tab">
Beers came to the
meeting. He was a soft-spoken guy, and didn't seem to know what was going on. I
thought, "We've lost the shot." I muttered to my partners, "I don't
think we're going to win this one. I don't know this guy; he didn't say
anything when we were meeting, and I don't know who he is."</p>

<p class="tab">
So we go assemble with
the Commission and have the meeting. I go through my pitch, describing the
experiment and so on, what we were doing, and what the conclusion of this panel
was. Strauss then looked at Beers and said, "Beers, what do you think is
the largest explosion that you could safely fire in Nevada, underground?" I
thought, "Oh God, what's he going to say?" And he said, so quietly
Strauss could barely hear him across this enormous table, "About a
megaton." Strauss said, "What!" Beers said, "About a
megaton, sir." That was all he said, and Strauss said, "You fellows
get out of here. The Commission and I are going into an executive
session." Which they did, and they decided favorably. "Okay, but be
careful."</p>

<p class="tab">
So off we go, and by
then the furor had gotten to the state of Nevada. The day before the test
somebody from the Governor's office came to the Test Site to serve an
injunction on the AEC to stop the shot. The Governor said, "We'll hold the
AEC directly responsible for any damage to public works in the state of
Nevada." He wasn't going to take any responsibility. Well, bless Jim
Reeves, who was the AEC Area Manager for the Site. The day the guy came out to
serve the summons, Jim had to make extensive surveys of the upper end of the
Test Site. He was unreachable.</p>

<p class="tab"><b>Carothers</b>: Well,
he was just doing his job. He has to go see what's going on, once in a while.</p>

<p class="tab"><b>Johnson</b>: Sure,
he's the Manager. And we were going to fire the next day.</p>

<p class="tab">
We had a technical
advisory board, with respect to the containment. These were vulcanologists,
geophysicists, I don't know who all, but distinguished people. The night before
the shot we had a final review. Shall we go ahead, or is there something else we
should do? And the conclusion was everything is fine, go ahead.</p>

<p class="tab">
We arrived at the CP
early in the morning; I forget what time we were to fire, but it was during
daylight so we'd get good photography. I was there, and one of the members of
the advisory group came up. We were about an hour away from firing. This was a
fellow named Fran Porzel, who was an expert in ground shock, and shock
measurements, and so on. He was from Battelle, in Chicago. He came up and said,
"Gerry, I'm nervous about that tunnel, about the containment. There are
only thirteen feet of sandbags in there." I said, "Oh yes, we all
know that." He said, "I'm not sure that's going to hold."</p>

<p class="tab">
And then he began to
pace back and forth. And he kept talking and walking beside me. He said,
"Can't you just hold the shot for a few days? We'll go back in and put
some more sandbags in." I said, "How many sandbags would you put in?
What would you do?" and so on. Well, he wasn't sure. I said, "Well,
Fran, I'll tell you. We've worked on this thing for a year. We've had the best
advice we could get, including last night. If we open that tunnel up to do anything,
we have to start over, repeat all our dry runs, and check everything out again.
We'd have to do everything. I don't know how long it would take us to get it
straightened out so we could get back to a shot day. And this is the end of the
operation. We're holding the operation to get this shot off, and it's an
experiment. We could easily lose the whole thing, administratively, and I don't
want to do that."</p>

<p class="tab">
He said, "You know
if that blows out, everybody here will say they knew it was going to happen,
and it will be your neck that will be out." I said, "Well, that's my
job. But there's just no way that I can see to postpone. We're committed now.
We have to go ahead." I said, "I appreciate your bringing it up.
There really isn't a choice. If we cancel it now we might not get another crack
at it." But he really put the heat on me.</p>

<p class="tab">
And of course, as it
turned out, it worked perfectly, but that's just a bit of history, and he could
have turned out to be right. But we had done everything we knew to do. And God
knows what would have happened if we had shut down. I think if we hadn't fired
at that time we probably would not have gone to underground testing. I think
it's unlikely. The next year we entered into the nuclear test moratorium. We
wouldn't have had time to do a test, set it up, and do enough to learn any more
about it.</p>

<p class="tab">
But we did fire it, and
it was well established by the end of the next year, as a technique. We were
lucky in hindsight, as it turns out. The seal was just a simple spiral. We only
had those thirteen feet of sandbags, and a steel door to stop gases, but the
stemming worked perfectly. We got overconfident later and had some problems,
but Rainier did work very well.</p>

<p class="tab">
And as it turned out, we
recovered the radiochemical samples. The rock had frozen right away because the
cavity collapsed, so we never did find molten rock. But we were concerned about
tapping into molten rock. The question was, "How can we test that
out?" Naturally we went to the vulcanologists, and they told us that no
one ever drilled into a molten zone. The way they got their samples was to wait
for the molten rock to come to the surface so they could scoop it out in a
bucket.</p>

<p class="tab">
About that time there
was an eruption on Kilauea Iki in which a pool of lava some three hundred feet
deep was formed, and later a thin crust about a twenty feet or so thick formed.
So we sent some guys from the Lab to drill through the crust and collect
samples, which they did. They only had to drill through twenty feet of stuff, but
to get to a suitable location they had to walk out on this crusty lava flow for
several hundred feet. Don Rawson headed the group out there. They had a
contract driller and crew, but they were with them. That experience convinced
me that at Livermore you could get somebody to volunteer for anything .</p>

<p class="tab"><b>Carothers</b>: Gary,
when did you first became involved in the containment business?</p>

<p class="tab"><b>Higgins</b>: It was
at the Laboratory, not at the Test Site, and it was almost coincident with the
firing of Rainier. Gerry Johnson, who was then the Division Leader of the test
organization, I think then called Test Division, was working with Bill Ogle and
Al Graves from Los Alamos, who were deeply involved in the conduct of the whole
Plumbbob operation. Gerry went to Chemistry Division, and what Gerry wanted was
someone to look into the question of how you would do a radiochemical yield
measurement on Rainier, or a test like Rainier. I was in the radiochemistry
group of the Chemistry Division, and in the heavy elements part of the group.
My responsibility was the separation of the plutonium and transplutonic elements
from the debris samples from the atmospheric shots.</p>

<p class="tab">
So, I came into this
picture just about the month Rainier was fired. I didn't know a thing about
what the underground effects of a nuclear detonation would be, so I thought I
would go talk to some experts, who obviously would know. And so I began to talk
to experts at Los Alamos and at Livermore. It turned out that all of the
experts had not come to a consensus. There was a range of expectations. At one
extreme was the prediction, or guess, that Rainier would produce a bubble of
molten rock about a meter in radius, and that the debris would all be contained
in that lava.</p>

<p class="tab"><b>Carothers</b>: But
Gary, you can just look at the calories available and know that there will be
more molten rock than a few tons.</p>

<p class="tab"><b>Higgins</b>: You'd think
so. At the other extreme there was the expectation that there would be
something like a 100 meter void, and the debris would be contained in a thin
shell of glass lining that void. This was about the period of time when the
French science fiction writer, Camille Rougeron, who made his living selling
these Jules Vern type ideas to the popular press, published an article that said
if you detonated a nuclear explosion underground, in rock, you'd get a glass
bubble full of steam, and you could then power generators with that steam for a
very long time. That was before we'd ever done anything in the Plowshare
program.</p>

<p class="tab"><b>Carothers</b>: Who were these experts you talked to?</p>

<p class="tab"><b>Higgins</b>: Gene Pelsor was the one in
Livermore that I particularly remember, because his prediction was, within the
uncertainty of the yield, correct about both the size of the void that would be
produced, and the approximate amount of shock-melted material. His arithmetic,
the details of how he arrived at the numbers were incorrect, but with self-canceling
errors there were enough wrong things that his conclusions ended up being
pretty close to right.</p>

<p class="tab"><b>Carothers</b>: If you have enough wrong things
some of them will make the answer too big, and some of them will have the
effect of making it too small, so you might come close to the right answer?</p>

<p class="tab"><b>Higgins</b>: Yes. The guys who were really
far off were the ones who made one mistake and got everything else perfectly to
maybe four significant figures.</p>

<p class="tab">
One of the people who
made an estimate was Stanley Ulam, at Los Alamos, who was a theoretical type
person. He made one very simple mistake, and I'm inferring this from what other
people said, he did not say this to me. His error was to neglect the
vaporization of rock, in that he went directly from a solid to a Fermi gas, and
back to a solid. That neglects the region of condensed molecular gases. Half
the energy of vaporization of rock is in the phase transitions from solid to
vapor. There's another half that takes the rock from vapor to ionized gas. So,
the first half is a very important step function in the pressure-volume
relationship, but it's easy to leave it out because nothing very important
physically is going on except the change of phase. That was the small estimate.</p>

<p class="tab">
The very largest
estimate came from Bill Libby, and his was not very different from Gene
Pelsor's. The reason it was larger was because he did not leave any strength in
the solid. Gene let the solid be an elastic solid forever; what Libby did was
pretend it was a liquid with a back pressure, but no strength. The way to say
that correctly is to say he used a Poisson's ratio of 0.5 instead of 0.3, as it
really is. Which is kind of a dumb thing, but that does make the cavity get bigger.</p>

<p class="tab"><b>Carothers</b>: He would have been correct if Rainier had been fired in water.</p>

<p class="tab"><b>Higgins</b>: Yes. It
would have been precise in water until the rebound occurred. Rebound occurs in
water too, and it causes a recompression, so the bubble rings. It oscillates
with a period that is proportional to the depth, which is a kind of restoring
force.</p>

<p class="tab"><b>Carothers</b>: If the
energy from the device wasn't going to melt much rock, where did they think
that energy was going to go?</p>

<p class="tab"><b>Higgins</b>: Well,
you and I think it's self-evident that there would be a lot of melt. But,
naively, people thought that all of the energy would go out in the seismic
wave. If you fired a kiloton explosion you'd get a kiloton seismic wave. If the
earth were perfectly elastic, that's what would happen. But it's not perfectly
elastic, and that isn't what happens. It's rather fortunate that only something
like one part in ten to the fourth of the total energy ultimately gets into the
seismic wave as energy.</p>

<p class="tab">
Dave Griggs, who has passed away,
was active in the seismic community, and was the author of the first paper that
made an absolute calibration of the seismic magnitudes of earthquakes translated
into energy. It was based on the nuclear explosions carried out in the South
Pacific - I believe it was the 1954 series. If the conversion were not so
small, the convergence of the waves at the antipode of the explosion would have
been sufficient to cause an eruption, like a volcano.</p>

<p class="tab">
That was if all the
energy had gone into seismic energy. The people in the seismic community had
calculated that if all the energy went out around the world and came back into
the same place at the antipode, and none of it were lost, there would be
another explosion. It wouldn't be any bigger than the detonation, but if the energy
went out one hundred percent elastically, it would be as big as - or a little
smaller than - the original explosion. So all you would do then, if you wanted
to destroy a target, was to go to its exact seismic antipode, fire off the
appropriate energy device, and say, "Who, me?"</p>

<p class="tab"><b>Carothers</b>: That
sort of thing sounds like the days of the high altitude tests, where the
thought was that you would detonate a device at some altitude here, and all the
ionized particles would going running down the magnetic field lines and cover
up the enemy's radar over there.</p>

<p class="tab"><b>Higgins</b>: Right.
You got it. But the business of the earthquake, and the elastic world was a
real concern. They still compute the elastic equivalence of earthquake yields
as the absolute magnitude. If you take the elastically coupled value for a
magnitude six earthquake, it's way less than one kiloton. And so there was real
concern that one kiloton, if elastically coupled, would be like a magnitude
seven earthquake. A magnitude seven earthquake, it causes some damage. But the
real world is not elastic, which is of some annoyance to those who like to
calculate things, because it would be much simpler if it were.</p>

<p class="tab">
By the time Rainier was
fired there was a group of consultants who were assembled, ad hoc at first, and
then that group was formalized more or less, to advise the AEC, or the Manager
of the Nevada Operations Office, about such matters as safety. Dave Griggs was
on that committee. He got in by being in the seismic community, and being an
Air Force consultant. He brought George Kennedy along because George had been a
student of George Morey's, and knew about the melting of rocks and so on .</p>

<p class="tab"><b>Carothers</b>: People certainly knew some
things about the response of the earth, because for years and years lots and
lots of people had set off thousands and thousands of explosive charges. All
kinds of sizes, and in all kinds of places, and they knew the earth didn't
respond that elastically. So what were these people in such an uproar about?</p>

<p class="tab"><b>Higgins</b>: Well, precisely the same thing
that they were in such an uproar about on things like Three Mile Island. It was
the unknown feature. And the people involved in the Test Program at that time
really weren't in the same community as the people who had all of this
experience with high explosives. There were a few individuals who carried that
experience over. One was a guy named Roy Goranson, in the very early days at
the Laboratory, who had spent a lot of his life with high pressure steam, and
steam explosions, and equations of state of water and rocks.</p>

<p class="tab">
Gerry Johnson had the experience
of working with artillery in the Navy, and he knew from his experience what the
detonation of a thousand pounds of TNT would do, and how it would scale. He had
HE experiments done prior to Rainier. They tried to produce containment, and
discovered one of the differences between TNT and nuclear, which is the
residual gas.</p>

<p class="tab">
You can't contain high
explosives unless you can also contain lots of residual gas. For every pound of
high explosive, you produce a pound or so of residual gas. In a nuclear
explosion the rock vaporizes and does all of its mechanical work, then as soon
as it cools off it goes back to be some kind of rock again, and the gas
pressure is gone. So, the containment of the nuclear debris is a much simpler, although
more sophisticated, problem than the containment of a high explosive charge.</p>

<p class="tab">
It's really extremely
difficult to contain high explosives. People in oil fields and in mining are
painfully aware of that problem. For that reason they have criteria for safety
and for detonations that are very different from those for the safety and
containment of nuclear explosions. The difference is understood by a few
people, but most people who grow up in one community don't comprehend the problems
that people in the other community face.</p>

<p class="tab">
People who have grown up
thinking nuclear containment cannot understand why the oil field people want
explosives with the highest possible specific energy with the lowest possible
residual gases - they're extremely fond of nitroglycerine, for example, which
is terribly hazardous to handle. So you say, “Why don't you use something like
ammonium nitrate? It's a lot safer.” And they say, “Yeah, but we can't get
enough in there to shatter the rock.” “But why do you want to shatter the rock?
That just makes little tiny particles, and they'll plug up. What you want are
fractures.” They say, “Yeah, but if we do that, it blows out the top of the
hole.” “Well, then why don't you stem it?” “Oh, you can't stem it.”</p>

<p class="tab">
They don't shoot stemmed
shots. They put the explosive down, detonate it, and let it blowout. They don't
try, because they have never been successful in containing the gases.
Therefore, they don't use some of the most valuable products of the explosion.
The high pressure gas would do them more benefit than the shockwave, but they
don't use it.</p>

<p class="tab">
But, back to the rocks.
It was difficult to select which expert to believe, except I could reject there
would be no bubble. All of them shared one thing; there would be molten rock,
and I believed that. The first conclusion I came to was that it was reasonable
from all points of view to expect the debris to be in fused rock. And if the
molten rock cooled, there would be glass. If it stayed molten, then the
question would be how would you sample it., The obvious answer was, you would
need to drill into it. But, without measuring we had no idea how complete or
how good the samples would be, or how efficient or effective the sampling would
be .</p>

<p class="tab">
We had some fused rock
from the ground surface of a number of near-surface bursts, including Trinity,
so we could do the chemistry on fused rock. We had done all of those things
with samples picked up from the surface. But we had no idea what concentration
of debris to expect in the samples we hoped to get. We didn't know whether we
were going to need a gram or a kilogram. And that, of course, depended on how
much rock got melted per kiloton. We did do some sensible estimates, again
using Gene Pelsor's calculations primarily.</p>

<p class="tab">
I believe Gene was asked
to attempt to fully contain the explosion. Not maybe for the reasons that we
want it contained now, but that was his objective. The stemming procedure on
Rainier had been designed as a rather elaborate spiral buttonhook. The philosophy,
expressed in different ways by different people, was that the radioactive
debris would be charging around the tunnel at velocity V, and by the time it
went around the spiral, the seismic shockwave would have come across and closed
off the tunnel, trapping the radioactive debris. The placement of the sandbag
plug, I believe, was to stop jets. The idea that the buttonhook would achieve
containment neglected a lot of things. It worked for all the wrong reasons, but
it worked, that one time at least, very well, and it established that
containment could happen. I believe that a lot of Gene's work was not
recognized as being as good as it was, considering how little anybody really
knew.</p>

<p class="tab"><b>Carothers</b>: Somebody
wanted to try to contain the shot, and that was probably Gerry Johnson.</p>

<p class="tab"><b>Higgins</b>: Yes. I
think it was Gerry, although Al Graves had made the statement, before this was
done, that we weren't going to be able to continue to carry out atmospheric
nuclear tests forever, and we really ought to find an alternative method. He
didn't say it should be underground, or in deep space, or how. There were actually
four ideas that were kicked around in '56 and '57.</p>

<p class="tab">Underground was one,
deep space was two, deep ocean was three. Under the ice cap, either in the
Antarctic or under the Greenland ice cap, was the fourth possible way of
carrying out tests without contaminating the environment in any gross way. We
might criticize the ice cap or the ocean ways as contaminating, but at that
time, in that period, that looked like complete containment.</p>

<p class="tab">Well, Rainier was fired.
The next thing then was to find someone who could drill into it. In the fifties
a lot of our drilling was done by contract drillers, and most of the early
drilling underground was by E. J. Longyear people, and people that they hired.
The Longyear people were having real difficulty, because the drillers had to be
cleared; you had to have a green badge to work with the radioactive debris in
those days. To find drillers that they could get a long enough history on to
get them a Q clearance was not easy. Drillers, by habit, or choice, or
circumstance, don't stay in one place for very many months at a time. They go
from crew to crew, and place to place, wherever the work is good and their fancy
takes them.</p>

<p class="tab">Diamond drillers, who
are a group that we found were experienced in the small drills we needed for
the underground rigs, were used to doing ore deposit definition for the mining
companies all over the world. So, most of the drillers we had were non-U.S. citizens,
which made it even harder to get clearances for them. We had a real problem
getting three men to handle each of the three shifts - actually it means four
shifts because we were going to go seven days a week.</p>

<p class="tab">Finding that number of
drillers who were Q-cleared was really very difficult. Add to that the gossip
that was going back and forth in the union halls, or in the beer halls maybe,
about the possibility of thousands of pounds per square inch of steam, and such
high radiation that they'd be sterilized forever. One fellow told me he was told
that the samples they would recover, if they ever did get to where they were
supposed to, were going to be so radioactive that the whole crew on that shift
was going to be killed. Well, it makes it real hard to get people to do that,
no matter how much you try to convince them, or talk about what to expect. And,
we weren't all that sure ourselves. We knew the business about the
radioactivity wasn't true, but beyond that we didn't really know what the conditions
would be when we got there.</p>

<p class="tab"><b>Carothers</b>:
What was your role on the reentry?</p>

<p class="tab"><b>Higgins</b>: People
didn't have administratively designated roles in those days. My role was sort
of keeping tabs of what was observed, and reporting it, and asking questions. I
talked to the drillers, and the geologists. We had a geologist by then, and the
Geological Survey was involved. And I did chemistry measurements. A lot of
those. I still did that part of it.</p>

<p class="tab">Our first attempts were
to go into the tunnel, establish an alcove, and drill horizontally. I found out
drills don't easily do that; they don't drill horizontally, because the drill
stem droops. So, there was the issue of, well, where is the drill?</p>

<p class="tab">Before we had penetrated
the radioactive zone in the tunnel we had started drilling from the surface,
but that was 860 feet up. For reasons I've never been able to understand, they
cored all the way from the surface instead of just drilling in, and then
switching to a core bit. The communication between ourselves and the
construction people in the field was not good. Perhaps we asked them to core from
the surface, not realizing that they could very easily switch from a spade bit
that would have drilled much faster and have gotten down to the ground zero
zone very early, to a core bit.</p>

<p class="tab">However, the hole from
the surface never intercepted any of the radioactive debris because it came out
in the chimney, and all the drilling fluid ran out of the hole. The drillers
maintained that they could not drill without fluid because the drill bits would
not survive if there was no fluid in the hole. In those days they didn't have
reverse circulation drilling. They only had forward circulation, which meant
that the fluid came out behind the bit. So, if there was nothing around the bit
to confine the drilling fluid, it was not cooling the bit; it was cooling the
rock wherever it ran to. We really had to learn the drilling business before we
could ask the right questions, and we didn't know them then.</p>

<p class="tab">I also found out that
the progress in drilling in the tunnel was painfully slow. The drill would be
turning around and around for days on end, but it never got anywhere. I found
out the reason that it wasn't getting anywhere was that the drillers didn't
want it to. As I said, there were rumors, including the one that this cavity
might contain thousands of pounds per square inch of steam.</p>

<p class="tab"><b>Carothers</b>: Well, Gary, the drillers felt
they were going to drill into a volcano, filled with radioactive steam and
molten rock. Would you want to drill into something like that, which would spew
all over you and kill you and all of the members of your drill crew?</p>

<p class="tab"><b>Higgins</b>: Of course not. So, they would
turn the drill, but they'd never push. We had a huge cavern worn out of the
side of the alcove into the tuff, but it went in only a few feet. I think there
was a lot more gossip and misinformation than we in the Laboratory ever heard.
I do know that there were drillers who would make all kinds of excuses for not
going on that particular drilling crew.</p>

<p class="tab"><b>Flangas</b>: Well, there was always some
concern over the unknown, but for those of us who came out of the mining
business, we were used to some risk. Now, there is certainly a difference between
intelligent risk and recklessness, and some of us know the difference. Gary
Higgins became an integral part of that crew, and I personally had a great deal
of confidence in his judgment and his experience. He didn't try to butt into
the actual mechanics of what we were doing, but he was there to advise us on
the things we didn't know about. It was a very, very close relationship. We
trusted him, and his judgment was good.</p>

<p class="tab"><b>Carothers</b>: His
story is that it took a long time to drill back into the cavity, because the
drillers weren't very anxious to get there.</p>

<p class="tab"><b>Flangas</b>: There
may have been some of that - some of the miners were that way. Occasionally you
would run into somebody who would be a little bit spooked, but once it was
explained to me, and I had a fairly decent grasp of what to expect, and as long
as the leadership was confident in what they were doing, our people just followed.</p>

<p class="tab"><b>Higgins</b>: Well, finally, after a couple
of months of drilling, and I think it was close to a year after Rainier was
fired, because we didn't start immediately, the drillers penetrated,
unexpectedly, a radioactive zone. That got radioactive debris into the tunnel,
and we had to shut down because the rad-safe people said, "You've contaminated
everything here." It was great news to me, but sad news to the drillers.</p>

<p class="tab">I went down and tried to
find some of the debris, along with some of the people from the NTS-LLL
contingent. We finally sorted out a bunch of sand and stuff, and when we took
it all apart a grain at a time we could find some little black pieces of glass
that seemed to be more radioactive then the rest. It was radioactive enough to be
an annoyance, but not a big enough sample to do any kind of measurements on.
Maybe we could have, but we didn't try. But the key thing that had happened was
that we had penetrated into a radioactive zone, and there was no high pressure
steam in it. Now, it was hot - it was hot enough so if they shut off the
circulation water it would almost boil. The water that was coming out was too hot
to hold your hand in. But the drillers then had great confidence it wasn't
going to erupt, and so, within the next two weeks they finally hit a mass of
lava. It was black frothy rock, and they got cores of it.</p>

<p class="tab">We found a piece of core
that was gray and gunky, but it had a radioactive peak in it. And I said,
"I wonder why that is?" So, I put a rubber glove on and squished it.
I found little glass beads that were pendant shaped. From the shape, and the
fact that it was now solid glass, we could infer that it had been hanging from
something at some time. We said, "If it was hanging from something, it
must have been in a void space. It was liquid, and it has the shape of a liquid
drop, so there couldn't have been anything against it."</p>

<p class="tab">And so we began to
reconstruct that after the cavity had grown underground it had stood there for
a little while - at least long enough for these glass beads to solidify. By a
process of reconstruction we worked out about how long that had to have been.
We confirmed that by measuring the ratio of some of the gas-precursed radioisotopes
that were included in those glass pendants to what they
were in unfractionated radioactive debris. It worked out that it was something
between one and a half and four minutes that this glass had been pseudostable.
The whole thing stood there before the roof caved in.</p>

<p class="tab">We also looked at the
amount of water that was dissolved in the glass. Roy Goranson had produced a
table, and published it back in the thirties, of the solubility of steam in
silica glass. If you quenched a glass in water at ten bars of pressure, what
percent of that glass would be water, and how much water would remain as vapor?
He had the whole table of solubility of water in silica glass, and we got the
pressure of the Rainier cavity as being about 45 bars. We observed that 45 bars
was not all that different from the overburden pressure, at that depth of
burst. If one hypothesizes that the steam expands until it's in equilibrium
with the external pressure, then all of the pieces balance. So, that became an
adopted hypothesis for containment; that the cavity size is such that the pressure
would equal the overburden pressure. It turns out that's probably not right,
exactly, but it was a good working hypothesis. We now say stress instead of
pressure, and it is probably even correct.</p>

<p class="tab">The Rainier cavity was
about fifty-five or fifty-six feet in radius. That was the size it would have
been if the material in the first meter or so, around the explosion, were
transformed into steam and other gases, and they expanded until the pressure
was somewhere near the overburden pressure. That was the concept of a balloon,
or bubble, blowing up inside a pile of blocks, with no rock strength involved, and
that was pretty much what the model was that was used for a lot of the early
evaluations of containment. It's wrong, and it's wrong in a lot of different
ways, but it was extremely useful.</p>

<p class="tab">About a year or so after
Rainier the Hardtack II series started, and we sampled several other
underground shots - Logan, Blanca, Evans, Neptune. We did not explore, in any
detail, any of those shots. We simply drilled enough to get rad-chem samples.
We were still going into the tunnel and drilling horizontally.</p>

<p class="tab"><b>Carothers</b>: When
you were drilling horizontally, were you then getting your samples from the
bottom of the cavity, or from the sides?</p>

<p class="tab"><b>Higgins</b>: They
came from the bottom of the cavity. From what we discovered on Rainier we
designed the scaling law that says the radius of the cavity is 55 times W to
the 1/3 feet, with W, the yield, in kilotons. That was where we found the
puddle that gave us a good, big sample. So, the target we drilled for was based
on design yield and 55 times W to the 1/3 feet. We usually aimed a little above
that, with the idea that if we missed it on the high side, as the drill
progressed across the cavity it would go through the puddle on the far side.
And we would carefully log, and almost always saw two blips on the
radioactivity versus depth of penetration plot. And we then said, "That's
the cavity boundary." And on the far side we'd say, "Well, the drill
probably carried some radioactivity along with it, so the far side is probably
a little too far." So you subtract a little from that, and do things like
that.</p>

<p class="tab">Those measurements were
recorded, of course, and people began to say, "My, isn't this interesting
that these things scale together?" Then they said, "What is the yield
that you get from the cavity radius by using the 55 W to the 1/3 feet law
backwards?" It wasn't very good, but it was a number.</p>

<p class="tab">We went through Plumbbob
and Hardtack II without really understanding anything about containment. After
Hardtack there was the moratorium, and during that time we did the post-shot exploration
of Rainier, in great detail. That was to measure accurately the boundaries of
the chimney region and the cavity region, and all of the physical parameters of
the shot. We wanted to measure things like the temperature, integrate the
thermal energy, and locate where all of the energy was deposited permanently. We
balanced the total release, as we measured it from the rad-chem yield, to the
thermal energy to within about 92 percent or so. We inferred that the energy
that went into producing fractures, which we couldn't measure, was in addition
to that. The seismic energy then was some number that was very small, which from
measuring the seismic wave you could also say was true. So, in a sense, we
balanced the total energy of the shot to within the precision of the various
measurements. Which is a satisfying thing for scientists to do.</p>

<p class="tab">We began to understand,
in the course of those drillings, where the radioactive debris was distributed.
Not only the kind we wanted for the rad-chem samples, but also there were, in
these logs of radioactivity versus distance, blips that were clearly at larger
radii than the inferred cavity radius.</p>

<p class="tab"><b>Carothers</b>: You did find cavity material at
some distance from the cavity boundary? Did that material go along bedding
planes, or did you think there were fractures in the rock itself?</p>

<p class="tab"><b>Higgins</b>: Well, we didn't recognize
bedding planes then. We did recognize faults. And there was a huge fault not
far from the Rainier shot point. At the time that the tunnel was mined some
drift in the B tunnel complex - I believe it was 12B-02 - was terminated. It
was designed to go into the mountain a little further than it did, but it ran
into this fault that was so large that you could look down it. You could
literally bend over and look in, and here was this hole in the mountain that
went off in the distance and you couldn't see how far it went. It was a real
fault, not like the things we map these days; it was empty. What we did was
back up from this big open fault and mine the button hook, and they put the
muck from the ground zero room down into the fault. And it just disappeared
down there. We didn't have to haul it out to the portal of the tunnel. That was
a big fault.</p>

<p class="tab">The reason I bring the
fault up is that in the post-shot exploration that we did in such detail, we
found that the center of all of the energy, both the radioactive radius from
ground zero, and the thermal regime, was displaced by a couple of meters toward
the fault. It was clear that the presence of that fault influenced the growth
of the cavity, and there wasn't real symmetry. One would like to say everything
was symmetric about the detonation point, but it really wasn't.</p>

<p class="tab">We also found that if
you looked in detail, this cavity that we were fond of drawing with a compass
as a nice sphere really had bumps and wiggles, and had cracks that went out.
Some of those cracks were filled with various and sundry bits of what had been molten
rock. We also found evidence of enough hot vapor having gone out into some of
the fractures to change the color of the rock on each side of the fracture. It
had boiled water out of the rock, but there was no melt there. So, we knew that
the simple picture of a glass lined sphere, like a Japanese fishing float, the
kind you see hung in the seafood restaurants, really wasn't what the inside of
the cavity looked like. It was really pretty bumpy and wiggly, and probably
very leaky.</p>

<p class="tab">When we had the first
core holes we saw the blip on each side of where the cavity was, but when we
mined that out we found a jumble of slabs. They were mostly planar slabs of
melt-covered rocks, folded over each other. When the geologist identified where
these slabs had come from, it turned out they had come from a hundred or so
meters above the detonation point. Then we began to have a picture that there
was the growth of the cavity, then a pseudo-stable period when it sat there and
nothing happened except some leaking of the high pressure gases pushing out,
and then slabs and bits and pieces falling in, jumbling in helter-skelter, and
the steam being quenched by pieces that were fairly large. It was not a hail of
small pieces of sand, but pretty big pieces that were falling in, and the steam
probably migrated some distance upward. In fact we found evidence for some gas
radioactivities in the rubble three or four cavity radii above the detonation
point.</p>

<p class="tab"><b>Carothers</b>: This
picture you're giving of these slabs of material falling in doesn't fit very well
with the accepted picture of a collapse. “The geophones were quiet, and then it
collapsed, and the collapse progressed upward at whatever feet per second.”
It's not exactly a plug falling in, but it occurs very rapidly, and the picture
is that the layers of rock would still be basically intact, just displaced down
some distance. You don't describe anything like that.</p>

<p class="tab"><b>Higgins</b>: No.
That's right. What we observed, and I would say in an almost differential
sense, was quite different from what we inferred from the readings on the
instruments. And I see still a discrepancy between the detailed reentry mining
observations from Rainier, and from the general picture we get from the
observations of cables breaking and from the surface. I think that discrepancy
still exists to a degree. And you identify it very specifically.</p>

<p class="tab">I would put this point
up, and it's one that has disturbed me and continues to disturb me. We have
only investigated in great detail one event, and that's Rainier. We've never
investigated in great detail any other one event. In the first place it's quite
costly. It cost us about as much to do the kind of post-shot investigation that
we did on Rainier as it did to fire the shot in the first place. So, it like doubled
the cost.</p>

<p class="tab">Now, I must say that in
recent years the line-of-sight pipe tunnel explorations have in some respects
exceeded the information that was learned from Rainier. But it is not so much
about the containment of the shot as about the containment of the pipe, and the
phenomena associated with the pipe closure. When I said we've never explored
another shot in such detail, I meant in all the containment aspects in general.
In other, detailed areas, I think DNA has exceeded Rainier by quite a bit.</p>

<p class="tab"><b>Carothers</b>: Well, you had the moratorium
going for you, Gary. People didn't have anything else to do. We wanted to keep
the miners busy, we wanted to keep Gary Higgins busy, and so we let them go dig
around in the mountain.</p>

<p class="tab"><b>Higgins</b>: Precisely. And keeping the
miners occupied was a very important thing. During the moratorium a number of
professional people decided to abandon the Test Program. That disturbed a lot
of people who felt an obligation to maintain the defense posture that we had
because of our nuclear weapons capability. And so they asked themselves,
"How far can this loss of personnel go before we lose the capability to
resume, should we decide to resume?"</p>

<p class="tab">There were a number of
answers to the question, but among the answers that emerged was the fact that
there were other skills than physics and mathematics and chemistry that we
would be losing, and one of those was our mining capability and our drilling capability.
Both of those skills had evolved well beyond, and different from, the common
industrial practice. In other words, any miner wasn't adequate. Or any driller.
Witness the fact that we'd sat there and turned to the right with no forward
progress on that first Rainier hole for two months or so. It was a question of
having other kind of skills that were as important as the scientific skills.</p>

<p class="tab">So, during the
moratorium, we spent a lot of effort trying to understand what had happened in
the Rainier cavity. The business of what goes on in a cavity went through a
history like that in a lot of technical fields. There was the first evaluation,
and a simple model was generated, or invented, or selected from among a lot of proposals.
That model fit a lot of observations, so we said, "Okay, we understand
this part of the explosion phenomenology. We won't devote much time to doing a
lot more investigations, because they are very difficult to do."</p>

<p class="tab">And they are difficult
because the stress levels within the area where the cavity is formed run not
just to kilobars, but to megabars and above. So, the measurement techniques
must be very sophisticated. The region that's involved is small, and things are
diverging very rapidly in space, so any measurement instrument has to be kind of
tiny. And everything goes on in extremely short periods of time, so getting
signals that are meaningful out from that region is extremely difficult.
Getting a fast signal out means a big co-ax, and a big co-ax means a big void
or something like that in the very small region. That is kind of contradictory
to the idea of measuring what is happening in that region without disturbing
it. There are a lot of contradictory requirements, or conflicting requirements,
when you try to make such measurements.</p>

<p class="tab"><b>Carothers</b>: In your work on Rainier there
were probably several things you wanted to do. Certainly you wanted to do radiochemical
analyses to get the yield. What effort was devoted to trying to understand what
happened to the rock materials themselves under the high pressures and high
temperatures that had existed?</p>

<p class="tab"><b>Higgins</b>: The primary charge we had was
to be able to do on underground shots the same measurements we'd been doing in atmospheric
testing. So, that was the primary purpose of our efforts. In order to fulfill
that primary objective we wanted to know something about the mechanics, and the
chemistry, of how the samples we were recovering had been created. The basic
purpose was still to diagnose the performance of the explosive, not to know how
to contain it. The containment concern really didn't come up until much later.</p>

<p class="tab">We were extremely
curious about what had happened to the native material, and we did a lot of
different measurements. One of the first things we found on Rainier was a lot
of glass, which was the tuff that had been melted and then quenched. We did radiochemical
analyses for a lot of different chemical species to determine how much total
rock had been melted, and how well mixed that melted rock was with the device
components themselves. Those conditions influenced how the device components
would behave after the shot, and what they would be like when we went back and
found the samples. We pretty well knew, from all kinds of laboratory and
atmospheric test experience, what the immediate surroundings were going to be,
and what temperatures and pressures things were going to be heated to. It wasn't
like working in total darkness. We knew that the initial temperatures and
pressures were going to be so high that the material present would be disassociated
into electrons and nuclei, and that there really wouldn't be any material
properties, other than those of a so-called Fermi gas.</p>

<p class="tab"><b>Carothers</b>: That doesn't last long.</p>

<p class="tab"><b>Higgins</b>: It doesn't last even a
microsecond. Some reports on containment describe what's going on in the first
microsecond as if that's a very short time. That's a long, long time compared
to some of the things that go on. The Fermi gas very quickly, in the first tenth
of a microsecond, probably has begun to expand enough so a genuine shock has
developed. That shock is a really strong shock, well above a megabar. The rock
is vaporized by it, and even though the gas may not be fully ionized, it's
still partly ionized, at least once or twice, so the chemistry's still not
important.</p>

<p class="tab">Somewhere out about a
meter or two meters from one kiloton enough energy has been absorbed, and
there's been enough spherical divergence of the shock wave so the pressure
level has gone down to where the kind of rock that's there is important. In the
model, that first simple minded model, what we used to do was say, "Okay, the
first meter that surrounds the explosion is made out of iron." We had a
fairly good equation of state for iron, and we knew what pressures would be
developed if you shocked iron to ten megabars. So, we started all our
calculations, whether the detonation was in limestone, or oil shale, or Nevada
tuff, or alluvium, with iron out to the first meter. We put the whole energy of
the explosion into that. Of course, if you do that, for most of the explosives
we talk about that means the composition of the explosive itself doesn't really
make a lot of difference.</p>

<p class="tab">A sphere of iron with a
one meter radius is like ten times pi tons, so you've got thirty or forty tons
of iron to mix with the device. You mix in a small number of pounds of whatever
and it doesn't make a lot of difference. So, that assumption was very useful
for generating the correct shock out in the rock where we could make decent
measurements and the coaxial cables didn't get banged so quick that we couldn't
get the signals out. They confirmed that what we'd done by putting in the meter
of iron was right. So, okay, what was in that first meter didn't make any difference.</p>

<p class="tab">All of that model is
correct, except that after the material has been shocked, it does something.
It's left behind as very high pressure atoms and electrons, but it doesn't stay
that way. The electrons and atoms that have been disassociated by the shock,
and other things, are going to recombine, and they don't really care what form
they were in before they were disassociated. They go back to a form that is
consistent with their environment at the time they are being born. The
electrons don't care that they were in tuff to start with; they're very happy
going back and becoming methane, for instance.</p>

<p class="tab">The little bubbles that
were frozen inside the glass on Rainier were micro samples of the cosmos in
which they were formed. You don't know in the stage of expansion when that
glass becomes solid and the bubbles were trapped, but you do know that whenever
it did get solid, it was a closed sample. So, the analysis of those glass samples
showed us a number of things.</p>

<p class="tab">We took the glass, broke
it into little chips, and examined them under the microscope to find which had
closed bubbles. We put those in a vacuum system, heated them, and when the
glass melted the bubbles burst, and then we analyzed what the bubbles
contained. It turned out that what was in them was mostly water vapor, which, I
would say, was not surprising.</p>

<p class="tab"><b>Carothers</b>: You refer to the material you
recover from the cavity as "glass." Why do you call it that? It doesn't
look like glass.</p>

<p class="tab"><b>Higgins</b>: No, it doesn't look like what
we think of as glass, but in fact it is glass. We had established that early
through some work with consultants at the Laboratory, in several ways. One was
to take some of the initial material we had recovered from Rainier, and do physical
measurements on it; measure its density, its index of refraction, and so on.</p>

<p class="tab">When you look at it
through a low power microscope, it is just like window glass. The reason, when
we look at it in a gross sense, that it is all black is that it has a whole
range of size of tiny bubbles in it that absorb all the wave lengths of light.
Plus there are some inclusions of metals, and other things. If you look at it
in a thin section it doesn't look black any more. First, it looks sort of dark green.
As you get it thinner it begins to look yellow, and then when you get it down
very thin it's perfectly transparent. You can see through it, with the
individual bubbles in it visible. Those bubbles are remnants of the steam that
was in excess of that required for saturation.</p>

<p class="tab">Professor George Morey
of the United States Geological Survey, who was then in his late seventies or
early eighties, was intrigued with the whole of the phenomenology of the
creation of lava. He had worked for many years as a geochemist, first in the Geologic
Survey, and then after his retirement, at the Carnegie Institute. Then, when
they forced him to retire, he went back as Emeritus Scientist for the USGS.</p>

<p class="tab">He was very intrigued
with the geochemical processes that go on in ground water, and how hot water
around volcanos and fumaroles really transports earth from place to place at a
very large rate - a lot larger than we mortals, who are here for an instant in geologic
time, realize. If that water is flowing from there to here, it's also bringing
along huge quantities of rock. And pretty soon, as the water evaporates and
goes away, the rock will grow here, and it will grow in whatever form best fits
this environment. Professor Morey spent the last twenty years of his retirement
searching out and quantifying these effects.</p>

<p class="tab">Well, what was going on
in Rainier, and the underground explosions in general, was a rapid speeding up
all the processes he was interested in. So, he was intrigued by the kind of
glass we would form from an ash. Volcanic tuff was spewed out of the ground as ash.
But on Rainier it had recondensed, after the shot, as glass. Why did it come
out to be glass, and not go back to being ash? So he got involved in this study
of the glass.</p>

<p class="tab">One of his students,
George Kennedy, from the UCLA Institute of Geophysics, also got involved. And
there was another fellow, named David Griggs, who had been involved in the test
program from before Hiroshima and Nagasaki He was the principal geoscientist
involved with the Air Force advisory panel. Professor Morey, George Kennedy,
and Dave Griggs were involved in not only determining that glass was produced
from the condensation of the molten rock, but also in measuring its index of
refraction, and the amount of water vapor that was dissolved in it. From that,
and the radius of the cavity, we deduced what the steam pressure must have been
to make that kind of glass.</p>

<p class="tab">To form glass you need
some silica sand. As long as the ratio of silica to the other common earth forming
oxides, such as aluminum and calcium and magnesium, is large, the melt when cooled
quickly from its liquid state, or quenched, will always form glass. The rate at
which that glass changes back to being crystal silica, and alumina, and
calcium, depends on how much silica there is. The more silica the longer it
will stay glass, but it will change. That process of changing from glass to
crystalline form is devitrification.</p>

<p class="tab">Glass is a metastable
liquid, but it takes a long time to devitrify, and for silica glasses that time
is measured in hundreds of thousands of years. At the concentration of silica
in the tuffs at the Nevada Test Site, the glass would prefer to be crystalline
quartz plus feldspars, but the process takes around five hundred thousand to a million
years. Those tuffs, as we know from many lead isotope ratio studies, and the
fact that they're there as minerals and not as glass today, are like two,
three, four, up to tens of millions of years old. Even so, there are still
remnant glasses from the original volcanic outpouring. Not a lot, but there are
some.</p>

<p class="tab">A nuclear explosion
converts the rock close around it to glass, with minor, minor exceptions. And so
the generic term is that the “glass” is the initially molten material, from the
shot, that cooled very quickly. The amount of glass produced is like a kiloton
per kiloton of yield, and that's not too surprising. The energy in the nuclear
explosion is just about right so one kiloton of energy will make one kiloton of
molten rock. And that's what we find out.</p>

<p class="tab">Going back to what goes
on the cavity, the other thing we found in those little bubbles in the glass
was hydrogen, and oxygen, and a little bit of carbon monoxide, and a little bit
of carbon dioxide. There really isn't much carbon in the tuff; there wasn't in
the Rainier ground zero area. But, the timbers that held up the tunnel were wood,
and all the electronics had rubber and plastic insulation, and plastic foam as
a dielectric. If you added it all up, there was enough carbon in the environment
to explain the carbon dioxide in the bubbles.</p>

<p class="tab">Now, how did the carbon
get from plastic to carbon dioxide? Well, if you have this big sea of electrons
and atoms, the atom doesn't know whether it came from plastic or rock. A lot of
what's around is water, which is hydrogen and oxygen. So, the carbon has a high
probability of combining with either oxygen, or even more probably with
hydrogen, because there are two hydrogens for every oxygen, so hydrogen is the
major material around. So, when you put hydrogen with carbon, you get methane.
The carbons have some affinity for each other, so a lot of them go around as
two's. And when two's go together, then you get ethane. Sometimes there's an
oxygen, so that makes methyl alcohol, or methyl formaldehyde. A whole suite of
hydrocarbons gets formed, not because they were there as hydrocarbons to begin
with, but because it's probable that they're going to become that in this sea
of mostly oxygen and hydrogen with the occasional carbon.</p>

<p class="tab">More frequently than
carbon there's a silicon, or an aluminum here and there, but not many. For
every four oxygens there's one aluminum, or iron, or silicon. So they go back
together, and then as they cool they continue to react with each other. One of
the things that Russ Duff has noted, and I think he is onto a very important
clue, is that what is happening in the cavity, even at long times, like months,
is that these gases are finding each other and reacting.</p>

<p class="tab">A not very probable
reaction, but an easy example, is where a methane finds a water molecule, a
steam molecule, and reacts with it. The oxygen from the water will go with the
carbon in the methane, and two hydrogens will get formed. This happens at only very,
very high temperatures; as the temperature cools, that reaction goes the other
way. Water and methane are the natural products, hydrogen and carbon monoxide
are the starting reactants. That particular reaction occurs at high
temperatures, but stops abruptly at like 1,300 degrees centigrade.</p>

<p class="tab">If you analyze a lot of
these products, you can look at the ratios of the chemical compounds and derive
a temperature where they must have been "frozen." They call it
"frozen equilibrium," because the rates of reaction are exponential.
There's an old rule of thumb which we chemists use, which is not quite
accurate, but it demonstrates the principle: for each ten degrees increase in
temperature, you double the rate of reaction. So, it doesn't take a very big
change in temperature to have a reaction proceed extremely rapidly, as in
seconds or milliseconds, or extremely slowly, as in hours or days. That change
can take place as the temperature changes a hundred degrees or so.</p>

<p class="tab">The simplest ratio that
gives a temperature is the carbon monoxide to carbon dioxide ratio at a given
pressure of oxygen and hydrogen. If you look at the ratio of hydrogen to oxygen
to water, that gives another method of calculating a temperature. If those two temperatures
disagree, then you have a phenomenon you have to explain. It turns out they
don't usually disagree, and they haven't in the tests where we have made
measurements. They all give a temperature which is consistent with the cavity
sample that we had frozen out in the bubbles on Rainier, which was about 900 to
a 1,000 degrees centigrade. That also turns out to be about where the melting,
or softening point of the rock is. So, all of this holds together, sort of.</p>

<p class="tab">In retrospect it's what
we should have expected, but we still tend to treat the material that the
shockwave traverses near the explosion as if it were iron, or rock, or
aluminum, or plastic. We forget that the world, and the environment around the
explosion, if you average all the stuff together, is almost half water. Normal tuff,
they say, is fifteen percent water, twenty percent water. That's by weight. The
molecular weight of water is eighteen. The molecular weight of rock is like
sixty or seventy. So, if you take twenty percent of something with a molecular
weight of eighteen, and mix it with eighty percent of something with a
molecular weight of seventy, the result is that there are more molecules of
water than molecules of rock. And so, if something is going to react, the odds are
just about even that it is going to react with something from water, and
something from rock. So, anything that's going to happen is dominated by the
water.</p>

<p class="tab">One thing we found on
Rainier was some fragments of glass that were formed by having been blown down
a fracture, which then squished off. We found such a fracture, and again we
didn't recognize its importance. We had this model of a smooth, round cavity
with a glass lining; we ignored the fact that at two and a half cavity radii
was a fracture containing some glass.</p>

<p class="tab">We found this fracture,
and said, "Isn't that interesting? I wonder how that glass got down there.
Well, it must have been a fracture." And, everybody said, "Yes, it
must have been a fracture." But in all of the literature you don't find
mention of the glass-lined cavity having spikes radiating out from it,
containing products from the center. In the model we mentally smoothed the ball
off, and forgot that there were fractures from it.</p>

<p class="tab">The point was that in
those fractures were glass fragments that were frozen out while probably it was
still in contact with the cavity, and they had elemental iron, elemental
copper, elemental uranium in them. These metals are extremely reactive. With
this sea of oxygen atoms we should have said, "They shouldn't be
there." But they were there. Again, we ignored that. It was the exception
that should have said our general model was too gross. Chemically, a sea of
electrons is about the most reducing thing there can be. In fact, you couldn't
get the average chemist to comprehend what a mole of electrons, just
electrons, would do.</p>

<p class="tab">So, the clues were
there. When the cavity forms dynamically, this high stress shockwave goes out,
running way ahead of the material. And we know, for example, that shock
velocity is greater than particle velocity, almost no matter how high the
stress level of the shockwave is. So, as the shock goes out from the explosion center,
it runs ahead of the material, but the material that is behind it is moving at
still a pretty high velocity. The shockwave is irreversible; it leaves a
portion of its energy behind as heat, which causes this ionization-disassociation
that's going on. There are more electrons around than anything else, so
everything wants to be reduced to the elemental state, and then start
combining. Most of the atoms that are present are
oxygen, so most things end up as oxides. It may sound contradictory to say that
oxides are reduced, but carbon monoxide is the reduced form, relative to carbon
dioxide, and elemental carbon, or graphite, or diamond, is even more reduced.</p>

<p class="tab">So, the state of the
cavity is highly reducing, and so, for example, if there is copper around the
copper will stay pretty much as elemental copper. You don't see big globs of it
because it's all vapor, and when it condenses, it condenses a few atoms at a
time, dispersed throughout the glass. The black color of the glass is not due
to radiation, and it's not due to carbon; it's mostly due to elemental lead and
iron in the form of single, or a few, atoms. What we should have learned, and
should have known from the Rainier fractures is that there was a period of time
when the cavity was growing, the boundaries were open, fractures were going
out, and the volume being interacted with was considerably larger than that
which we found when we calculated the steam pressure, and calculated 50, or 55,
W to the l/3rd as the cavity radius.</p>

<a name="ch3"></a>
<br><br>
<h2>Chapter 3: The Moratorium and the Return to Testing</h2>
<br>

<p class="tab">The
1958-1961 moratorium followed Hardtack II. During the moratorium Los Alamos
drilled some stockpile holes in Yucca, and Livermore continued with excavations
in B tunnel and E tunnel, in Rainier Mesa. Considerable reentry work and
explorations were done at the site of the Rainier event. And, little known
until many years later, a series of experiments took place which contributed to
the knowledge about containment.</p>

<br>

<p class="tab"><b>Brownlee</b>: There was something that went
on during the moratorium which used to be super-secret but isn't anymore. There
have been announcements about it, and newspaper stories. That was a series of
one-point kind of experiments, and so we had a rather active underground
experimental program here at Los Alamos. You didn't see towers, and you didn't
see smoke, and you didn't see a lot of things. But out in T A-49 we put things
down holes, and fired them.</p>

<p class="tab">The yields were just the
high explosive yield, essentially, but it was during that period I saw my first
stemming collapses, from a whole series of those things. It always happened.
We'd shoot one of these things off, and a little while later the stemming would
fall down the hole. We were doing them in tuff, so the holes tended to stand, and
the stemming would go down. So, it was during the moratorium that I began to
appreciate chimneys, and stemming falls.</p>

<p class="tab">Bob Newman and I spent
an appreciable time fussing about scaling laws. How big a cavity would we make?
How much stemming did we have to have to keep everything contained? The
difficulty was that the number of people who knew about that program in Los
Alamos was minimal. In J Division there was Westerfelt, Newman, Campbell, and a
few others, including myself. And of course, in W Division there were the
people who were making the devices.</p>

<p class="tab">Because of these
experiments I continued to get an education in containment during the
moratorium, which if you stop to think about it is odd. But it was kept so
close that only Campbell and Newman would talk to me, and they didn't talk to
many others at all. I was not allowed to know very many details. The part of it
that I knew was that we were doing things that required stemming and
containment, and we didn't dare make a mistake. It had to be contained, and we
had therefore to be super-conservative. It wasn't like the Test Site. If
something floats around here in Los Alamos, everybody in town knows it. There's
no way you can escape it. The argument was that we didn't dare go to the Test
Site. I thought that was a bit odd, but that was my understanding. We had to do
it here because the Russians would know we were doing something if we went
somewhere else.</p>

<p class="tab">So, at Los Alamos we
were learning a little something about underground containment. We talked a lot
about scaling laws. We debated whether we needed a depth of burial where there
wouldn't be a crater, or what it was we did need. My recollection is we kept
debating what it meant, but with people like Campbell in the works those kinds
of subtleties were oft times scorned. Obviously what we meant was that nothing
comes out. So, at those very early times we had already, in a way, defined
containment as not one atom out. There was nobody who told us to do it that
way.</p>

<p class="tab">The scaling laws you
could find in the literature were, of course, for chemical explosions, which is
actually what we were dealing with, in a practical sense. So they were
relevant, in away. As a result of all that we came to '61 with the conviction
that 400 feet times the 1/3rd power of the yield in kilotons was conservative,
and worked.</p>

<p class="tab">In summary, I would say
that more happened during that moratorium that's relevant to containment than
you might think. Even though it was hidden, and there weren't very many people
involved, there was a continuation of thought. I think we were more ready to
test underground than people remember.</p>

<p class="tab">There were other
activities, at the Test Site, which contributed to the ability to resume
testing, should the need arise. Interestingly enough, this effort, on the part
of both Laboratories, went into the preparation of underground sites, although
the Nuclear Test Ban Treaty was still several years in the future.</p>

<p class="tab"><b>Carothers</b>: During
the moratorium Livermore had the LRL-Nevada people working at the Test Site.
They got some amounts of money, and I presume the los Alamos testing
organization did too. The Livermore people were digging tunnels against the
time when there might be something to do with them. What were the los Alamos
people doing?</p>

<p class="tab"><b>Brownlee</b>: We
stockpiled some vertical holes. When the moratorium was over we had holes in
which we could shoot, right away. We had made the decision early on, I think,
that our vertical holes would take a 48-inch diameter casing. To my memory they
were all drilled to accommodate such a casing.</p>

<p class="tab">We were in alluvium in
Area 3, and the alluvium we saw was pretty loose. When we drilled a hole, there
were layers of what I call hourglass sand - it would flow like the sand in an
hourglass. Any fool knew that you would have to case those holes, or they would
just fill up, particularly if they were going to stand there for a long time.
And so, there was a policy here that you had to shoot in a cased hole, because
you would lose the bomb and everything else if you didn't. After we resumed
testing we used to have that argument with Livermore, regularly.</p>

<p class="tab"><b>Carothers</b>: Well,
Livermore shot in cased holes for some years. It didn't occur to anybody to
ask, “Los Alamos drills holes and cases them. Why do they do that? We're in a
different area. Is it the same? Should we do that?" So, Livermore cased
holes. Why? Well, because los Alamos did, and that's the way it was done. I
think that is an interesting example of something being done in one place in one
way for a particular reason, and that becomes dogma. In different place at a
different time the same things are done without regard to the fact that it is
different place, and other ways might be better.</p>

<p class="tab"><b>Brownlee</b>: That's
right. Had we started up on Pahute mesa, for example, the dogma would have been
utterly different, I think. In Area 3 we did have the sand flow. In one of the
shafts we put down later, the hourglass sand trickled down between the boards
of the lagging for three or four months. It was a steady little stream, just like
an hourglass. I don't think Livermore has ever seen anything like that in the
north part of the valley.</p>

<br>

<p class="tab">Roy
Miller was the drilling superintendent for Livermore for many years, and had a
different view.</p>

<br>

<p class="tab"><b>Miller</b>: The
problems that LASL had, and we had, on several holes, was that the
alluvium-tuff contact is where they tended to cave in. There are places where
that sand zone acts like a fluid. It just pours in there like sand in an
hourglass.</p>

<p class="tab">We have the same zone,
only it's deeper than in the Los Alamo area. As you get up in the northern part
of Yucca Flat, we've had dozens of holes that caved in at the alluvium-tuff
contact. We've repaired a bunch of them and used them; filled them full of
cement and drilled back through.</p>

<p class="tab">To give you an example
of how massive those cave-ins are, there was a hole called 10r, back when we
were drilling with air-foam direct circulation. We drilled the hole to 1,600
feet, pulled the drilling assembly out of the hole, ran a caliper log all the
way to the bottom, 1,600 feet, and were logging up. When the caliper log was at
about 400 feet - you run the caliper log from the bottom up - it was like an
explosion had occurred. Air roared out of the hole like a volcano. I wasn't
there, but the stories that were told about that... It broke all the arms off the
caliper log, but they pulled it on out. Didn't lose it. They repaired the
caliper log, and went back in to 1050 feet, so they had lost 600 feet of hole.
This was a sixty-four inch hole, and essentially this was instantaneous. They
ran the bit back in, cleaned it out without difficulty, all the way to 1650.
Then we pulled the bit out, went back in with the caliper log, and it stopped
at 1050. It did that two more times.</p>

<p class="tab">It was that hourglass
sand that LASL keeps talking about. The first time it was a massive cave-in.
The other two times it was very slow. They weren't aware it happened until they
went back in. The same thing happened in Area 2 on the west side of the road.
We drilled down to below the water table, and set a liner to have a dry hole.
It caved in above the liner and filled the liner up. We went in, cemented it
up, drilled back down, and fortunately hit the liner. Anyway, those formations
that LASL talk about down there occur up in Area 2 and 10, only at a deeper
depth.</p>

<p class="tab"><b>Brownlee</b>: I think we did cased holes in
Area 3 for perfectly rational reasons, in light of the things we were seeing.
It was only after we had this big quarrel with Livermore, some years later,
after they went to uncased holes and were pointing fingers at us for spending
too much money casing holes, that we really examined the fact that even in the
alluvium in Area 3 the holes lasted a long time if you didn't mess around in
them. That was very hard for Campbell to accept.</p>

<p class="tab">Also, during the
moratorium, there was a doctrine to keep the testing community intact.</p>

<p class="tab"><b>Carothers</b>: You might almost call it a
readiness program.</p>

<p class="tab"><b>Brownlee</b>: Yes, you might. And the way
they planned to keep it intact was to let people work on whatever they wanted
to. We had said, before the moratorium, that during the moratorium we would rework
and reduce all the data we had collected in those frantic years of tests. In
fact that really didn't happen. There were a few people who worked on data, but
there were people they didn't want to lose who didn't want to work on data.
They were allowed to work on other things, so in truth, even though people were
around, they had other interests and evolved to other programs.</p>

<p class="tab"><b></b>And so, when the moratorium was
over and we went back to testing in '61, we really had, it's fair to say, a
different set of people. Not entirely of course, but there were different
groupings of people, and so there was not a lot of carryover from the things we
did in '57 and '58, as far as containment was concerned, into the '61
time-frame.</p>

<br>
<p class="tab">Louis
Wouters, by 1958, was one of the senior scientists in the Livermore testing
program, He remained with the program until his retirement. As with the
comments of John Foster cited after, his remarks do not have to do with
containment, but they are interesting to consider in the light of Bob
Brownlee's words about maintaining a testing, or containment capability when
there is nothing to test, or to contain.</p>
<br>

<p class="tab"><b>Wouters</b>: The day the moratorium started,
L Division ceased to exist in the minds of management. What do we need these
people for? We have no tests to shoot. The general attitude we lived with for
almost a year was, "Well, we're paying them, aren't they happy with that?
We haven't fired them, after all. Good God, what are they complaining about?
They haven't got anything to do except plan, and think, and look a old data.
That seems to us that is an idyllic situation." Well, the kind of guys we
had at that time in Test Division were a bit more motivated and a bit more
ambitious than that, ambitious in the technical sense. They wanted to go out
and do things. They were young men, and they wanted to do things. They didn't
like being cooped up in an office.</p>

<p class="tab">The first year there
were a number of things to clean up. There was data from Hardtack II, and also
Hardtack I, to get into some kind of shape. Only about half of that work
actually got done, because there was no interest from the design divisions,
none whatever.</p>

<p class="tab">I think it was in 1959
that I went over to England to look into a number of things connected with the
Joint Working Group we had with them, and also go to one of the photomultiplier
plants of EMI to see what they had to offer. The people at AWRE were very nice,
and they took me through their test program building and their laboratories. And
let me tell you, you think we were in trouble. Any of the offices that had
anybody in them - and there weren't many, there were a lot of empty offices -
had a zombie. There was just no motivation. There was one guy who was excited,
because he was working on image converter replacements for cameras, and he was
able to use it on HE shots. All the others, they were just sitting there,
waiting for the worm to turn, or whatever. It was dreadful.</p>

<p class="tab">In retrospect, what it
tells you is that it is not unique to us when something like that happens. It
seems to be a universal kind of syndrome. They don't want to spend money on us
because they don't see the point. I, at that time, with a vengeance, came to
the conclusion that if you don't have anything worthwhile for people to do,
close the program down, put them on something else with a long string, and if
the need arises, pull them back. They'll be happier and more useful to you than
if you let them sit and rot in their offices.</p>

<br>
<p class="tab">John
Foster was the Director of the Livermore Laboratory in 1963, when the Nuclear
Test Ban Treaty was signed. One of the things that was considered to be
important when the Treaty was signed was that there should be a readiness
program - a formal program to maintain a capability to resume atmospheric
testing should such testing, for whatever reason, become necessary. The following
words by Johnny Foster relate to that readiness: not to containment.</p>
<br>

<p class="tab"><b>Foster</b>: I can remember, when we got to
the atmospheric test ban, going to the Joint Chiefs of Staff and trying to
argue for the four safeguards that had been worked out with Scoop Jackson. The
day I made this pitch to the JCS was the day that Curtis LeMay was, I think,
Acting Chairman. I went through the four safeguards, and the one safeguard that
LeMay hung up on was the one of readiness. He said to me, “You will never be
able to maintain readiness." I was absolutely thunderstruck. Here was the
guy who had created the Strategic Air Command that had maintained readiness,
and he was telling me, "You will not be able to maintain readiness."
I was too shocked to ask him why.</p>

<p class="tab">He was dead right. Only
a few years later I was working in the Pentagon, (Ed. - as Director, Defense
Research and Engineering) and cancelling the very programs that I had fought
for. I was cancelling them because the plans were made up by people who didn't
understand what they were doing. The people who did had left to go work on
things that would be more productive. And, if the plans didn't make any sense,
you just simply couldn't afford to keep pouring money into them.</p>

<p class="tab">There were some
experiments that could be done during the moratorium. In particular, there were
a number of high explosive experiments done to look at crater formation from
various yields of explosives in various media. One notable such experiment was
the Scooter detonation, which was done at the Test Site. It involved the detonation
of 500 tons of TNT which was stacked in a spherical shape at a depth of 125
feet. One of the problems with Scooter was that when the signal to fire was
sent, the TNT did not ignite and so there was no detonation.</p>

<br>
<p class="tab">Bob Bass, of Sandia, was the project officer for the various ground
response measurements that were to made.</p>
<br>

<p class="tab"><b>Bass</b>: We started
putting the HE in the ground in Mayor June. That million pounds of TNT had to
be loaded down 125 feet. We could never do that today. For example, one of the
problems they're having right now with the Chemical Kiloton is how to have a
safety plan for transporting the ammonium nitrate from Mercury out to Area 12.
Don Larson had one of his people find out how they transported gasoline on the
Site, so they could use that plan. Turns out, there is no safety plan for
transporting gasoline, or flammable material on the Test Site, on the Mercury
highway. That's okay, but you can't move ammonium nitrate, because people have
thought about it. And that's the current kind of stuff we're stuck with.</p>

<p class="tab">Anyway, we transported
all the HE for Scooter, a million pounds, down from Hawthorne in twenty ton
loads on commercial trucks. It came in blocks - it had all been melted and
cast. Hawthorne had so much of that stuff that it was unbelievable. We also had
a whole bunch of spheres made up, and Sandia has used them for containment
tests ever since - two thousand pounds down to eight pounds.</p>

<p class="tab">Well, we put in all of
our instrumentation. We had a trailer nearby that had a revetement around it to
keep the air blast from hurting it, and the rocks from falling on it. In
addition to our instrumentation we provided the electronics and the place to
record and handle the firing system performance, and people's checkouts of all
that. I was not responsible for the firing, but in a sense I was involved
because I helped hook up the firing set. Bernie Shoemaker did it, and I helped
him with that. Scooter was to be fired with a pentalite booster block in the
center of the charge. That block was put in when the sphere was halfway
installed. The detonators were sent up from Albuquerque, and they were
supposedly war reserve detonators to be used with a regular firing set, and the
people who did this were the people who would ordinarily do a regular test, a regular
operation. There were extra dets for backups, and so on.</p>

<p class="tab">The trouble was somebody
sent out sugar loads. They were dummy dets that didn't have any booster in
them. There was no active final little blue booster to set off the pentalite;
they just had the little wires across the back. These were what was put in. Everything
was fine, except there was no explosive in the dets. We found out, after they
were in, and the HE was on top of them, what had happened.</p>

<p class="tab">So, they sent out some
more dets, of the same type. We took them down to our trailer and said, “Let’s
fire these things and see what happens." Bob Burton was in charge of doing
this. The thought was, could we put enough energy in there, to that little wire,
that we would get the pentalite to go. That was the idea, and we tried. And so
we proceeded on. On shot day Neal Thompston, then head of AWRE was there, and
whoever was head of the Atomic Energy Commission at the time was there.
Everybody was there .</p>

<p class="tab"><b>Carothers</b>: What
you're telling me, if I understand you correctly is ...</p>

<p class="tab"><b>Bass</b>: That we knew damn well it
wouldn't go. We would have been stunned if it had gone. That would have been
the surprise of surprises. We knew it wasn't going to go, but we wanted to try
it, because there wasn't anything else to do. The explosives were all stemmed
in, and it would have been a terrible job to try to get them out. And, as we
expected, it didn't go.</p>

<p class="tab">An investigation group
was set up, and Mel Cook, a Utah explosive expert, was called in to head the
committee to see what to do. They met and met and met, and decided there was
only one approach, and that was to melt our way back down. So they set up a
group to do this, and an explosive safety board to supervise it. We could never
do this today, never in a million years.</p>

<p class="tab">What we did was to put a
safety perimeter around the shot, which was established as soon as it didn't
fire. About halfway back toward the Area 10 highway where the access was to the
area, we set up a remote control area to remotely drill back. We moved a drill
rig in, drilled down to the top of the HE, remotely done. When we got to the
top of the HE, then we put in a steel billet, which had hot water piped to it -
I don't think it was steam; I think it was just hot water - to melt our way
back down, through the explosive, to the center. When this was done, the guts
of the billet were pulled out, and a pentalite booster block was lowered inside
this billet, which now sat in the middle of the Scooter charge.</p>

<p class="tab">I was scared to death of
the whole operation, but we were out there monitoring all the time. We were
also worrying very much about our instrumentation cables, because we had all
these storms and rainy periods. We were using white field wire, which was just laying
out on top of the ground. It wasn't waterproof wiring at all, so we ended up
with almost complete shorts in all of our cabling, in addition to the shorts in
all the amplifiers, which were ruined.</p>

<p class="tab">So we sat there, burning
out all our cabling, all this time. And we also had some cabling that went into
the HE to measure the HE burning rate. There were concerns about how much
current we could put into the cables and not be a danger to the HE, and all
that. So, we had to monitor the things very carefully. A lot of thought went
into it. We sat there with low currents, just burning out these cables for
three months. We were in the danger area, burning out our cable the whole damn
time. And they dried out finally. All but the pressure measurements.</p>

<p class="tab">So, what did we end up
with? We ended up with a lot of radial accelerometer data that was outstanding.
We ended up with some good horizontal velocity gauge data. We were using the
old SRI-Sandia DX velocity gauge, which was capable of outstanding
measurements. It's not used anymore, because it's far too hard to use. There
were some surface measurements too. We made some surface velocity measurements,
and there were all kinds of photography done. Scooter was really a very good
experiment.</p>

<p class="tab"><b>Carothers</b>: There were a number of HE shots
during the moratorium.</p>

<p class="tab"><b>Bass</b>: Yes, and Sandia was doing all
of those. There was the Buckboard series in hard rock, for instance, during
that period. And there were a lot at Fort Peck. There is a lot of stuff in the
literature on those, but there is very, very little instrumentation data.
Mostly there are photographs of before and after, and throw-out measurements -
sticky-paper trays, and things like that. Vortman put out beads all over
everywhere, and they counted beads in various samples they took after the shot.
There were a lot of people, including ones at Livermore, who got very excited
about how the crater lips were formed, and that sort of thing. Cratering was a
big thrust. Vortman was digging canals, out on the Yucca dry lake. I stayed as
far away from that program as I could; I wasn't too interested in that.</p>

<p class="tab">The moratorium on
testing ended in September of 1961. Following the atmospheric detonation of a
Soviet device with a yield of over 50 megatons as the first of a series of
Soviet atmospheric tests, President Kennedy ordered the resumption of testing
at the Test Site. There was the proviso that the tests should be carried out underground,
unless a specific exception was approved. The first event at the NTS following
the moratorium was the Livermore 2.6 kiloton Antler test, fired on September
15, 1961 in a tunnel. It was followed by Shrew, a Los Alamos safety test in a
drill hole, fired on September 16, 1961. Both events released measurable
amounts of activity; the activity released from Antler was detected off site,
that from Shrew was not.</p>

<p class="tab">During the next few
months the experience of both Laboratories showed that the containment of the
radioactive materials produced by an underground detonation was not a trivial
task, whether the device was emplaced in a tunnel, or in a drill hole. The
first eleven events all released activity. During the first year there were 43
shots fired in emplacement holes by Los Alamos and Livermore. One, Eel,
released some 1,900,000 curies, and the activity was detected off site.
Twenty-one released material that was detected only on site. Twenty-one are not
recorded as having released activity.</p>

<p class="tab"><b>Carothers</b>: When the moratorium ended Los
Alamos used drill holes for their shots, and Livermore did their shots in the
tunnels. Was there any kind of agreement, or understanding that Los Alamos would
do shots in drill holes, and Livermore would do tunnel shots, so there would be
experience with both ways of doing the experiments?</p>

<p class="tab"><b>Brownlee</b>: I don't know that there was
anything like that. Probably there was no reason for it at all. But, at the
time I thought there was a reason. Our perception at Los Alamos, and mine,
which came a lot from AI Graves, and some of AI's obviously came from Norris,
was that Los Alamos had concluded it didn't make any difference what the facts
were, peaceful uses of nuclear energy would never come to anything. If
Livermore wanted to waste their time with Peaceful Nuclear Explosives - PNE
things - that was Livermore's prerogative. But we at Los Alamos would, as a
matter of policy, not devote any of our thinking to PNE type things, and
tunnels smelled of PNE.</p>

<p class="tab">Our interest was bombs,
and testing bombs, and for that vertical holes were quite sufficient. If you
were going to make harbors and things like that you had to have answers to
certain kinds of questions which tunnels helped you answer. But everybody knew-
Los Alamos thinking - that the best place to test bombs was right where we
were; Area 3. So, don't go near those mountains where who knows what evils
lurk. We'll stay right here, thank you. So, the impression I had was that PNE
was what separated them. Now, in fact, I do not know what Livermore was
thinking, and I do not know whether PNE figured in Livermore's thinking or not.
I don't know. But I think that's kind of how we saw it, early on anyway.</p>

<p class="tab">I would like to
remember, but it's probably totally incorrect, that I was a bit more objective
than some of the other people at Los Alamos. I was never quite so quick to pick
up the party line. I always got along well with Livermore people. But there was
a party line; thou shall not go near Livermore people, because they're all
terribly bad. When I got permission to go to visit Rainier I was the only Los Alamos
person who went and mixed with the Livermore people. I didn't mind that, but
there were other people who didn't approve of that.</p>

<p class="tab"><b>Carothers</b>: I'll tell you a story I heard
about why Los Alamos never had tunnels. I can't vouch for its truth, but it
goes like this. Once upon a time Norris Bradbury visited the Test Site, during
the moratorium. Livermore was busily digging tunnels, having nothing else to
do. As part of Norris' tour of the Site, Livermore people took him to the tunnels.
They got into one of the little mining cars and rattled back into the tunnel,
which was poorly lighted, wet, noisy, dirty, and all the sorts of things
tunnels sometimes are when mining is going on. When they came back out Norris
said, “My people will never work under those conditions." And that was
that for tunnels.</p>

<p class="tab"><b>Brownlee</b>: That's entirely consistent with
Norris. I can believe that. That's the way Norris was. But it's also consistent
with what I told you; tunnels were unnecessary, unneeded, and we would do our
work in vertical holes.</p>

<p class="tab">But I was always very
curious about the tunnels shots. I had seen those sandbags in Rainier that had
turned into rock, and the other things that had happened in the tunnel, and I
thought that was very interesting stuff. I went up and visited whenever I
could, which wasn't all that often. Campbell, for example, didn't approve of Livermore,
or tunnels. If you were going to drive up there you better not let Campbell
discover that you drove one of his AEC cars up there. You had no business being
up there. You were supposed to stay in Area 3. So, whenever I went there I was
either on the q.t., or I had some special dispensation. I don't know that there
was any reason for that. That's just the way it was.</p>

<p class="tab">Well, the Russians terminated
the moratorium. Incidentally, I believe that was done perfectly legally. You
hear that the Russians violated the agreement. I believe the understanding was,
“We will tell you before we shoot again.” And they did. They told us the day
before. I think they did what was perfectly legal in the eyes of the State
Department. We had the same option.</p>

<p class="tab">They certainly didn't
try to conceal it. But Kennedy was irate, and he called here and said,
"How soon can you get a bomb off?” We must have gotten that call the first
week in September, and I believe our answer was, "We can do an underground
shot in one of our vertical holes in a week./I The problem was, that was in no
way a quid pro quo. To do a few kilotons in an underground shot in Nevada was
certainly not equivalent to fifty megatons or so. But, that's what we were
ready to do, that's what we said we could do, and Shrew, our first shot, was
not very long after that.</p>

<p class="tab">The point is, we were
ready to do that very quickly because we did indeed have vertical holes ready.
And, we knew, or guessed, how big a yield we could fire in them.</p>

<p class="tab">So, through '61 and '62
we did some shots, and we were gathering information. Before we had the
underground treaty in '63 we had satisfied ourselves that we could get the
necessary data we wanted by testing underground. We had gotten enough
information to know how to do that. And that was due to AI Graves, and Campbell,
and Newman, in my view. I would name those three people as having done the
necessary thinking and preliminary work to allow us to go that way fairly
easily, and in a straightforward manner.</p>

<br>

<p class="tab">One
of the projects that was significant for containment was the attempt by people
at Livermore to develop a way to collect so called prompt rad chem samples. The
concept was that there would be an open pipe running from the device to some
collecting station on the surface outside the tunnel, or by the top of the
emplacement hole. There a sample of the device debris would be collected, essentially
at the time of the detonation, and returned to the Laboratory for analysis. The
work following the moratorium was basically a continuation of the work Gary
Higgins had started during Hardtack II.</p>

<p class="tab">There
is little question that this effort led to at least two major ventings. Dick
Heckman, a chemical engineer, was in charge of the field effort to design the
pipes and other hardware that were to collect these samples .</p>

<br>

<p class="tab"><b>Heckman</b>: After the moratorium I went
back to the underground sampling business. There was what I called the fast sampling,
which was an attempt to get fast, or prompt samples, where what I was trying to
do was to get refractory bomb debris. In other words, the kind of bomb debris
you would normally get from post-shot drilling, where the activity is trapped
in the melted rock, which is the standard sort of thing. What I was initially
trying to do was develop a competitive process to that.</p>

<p class="tab"><b>Carothers</b>: You did your first tries on the
shots that Livermore did in the tunnels, like Antler? You were the guy who was
ruining the containment on those?</p>

<p class="tab"><b>Heckman</b>: Yes. Well, I didn't have
anything to do with Antler's failure, because we didn't have time to get the
sampling system set up. I think that you have to give Mike Heusinkveld a lot of
the credit for the ideas. In other words, I'm only guilty as being the field
guy who carried out the concepts that Mike had.</p>

<p class="tab">On Gnome there was such
an experiment, a fast sampling experiment. We had a vacuum system with a pipe
ten inches in diameter down to the shot room. It was a beautiful straight,
vertical hole. You could go down into the shot room at Gnome, look up through
that pipe, and at noon you could see stars. It really does work. You could see
stars.</p>

<p class="tab"><b>Carothers</b>: You know, I've heard that
story, and I have done a little simple-minded calculation about the solid angle
and what fraction of the sky you see, and how many visible stars there are, and
the probability of there being a star in that patch of sky is so small that I
don't believe you.</p>

<p class="tab"><b>Heckman</b>: Fine. I understand all your
arguments, and all the rest of it, but I was there, and my recollection is I
saw stars. I'm convinced I saw stars. Anyway, the point is that is was very
straight.</p>

<p class="tab"><b>Carothers</b>: It was straight, I know that.
You could look from top to bottom. Did you ever look down and see the stars
down at the bottom?</p>

<p class="tab"><b>Heckman</b>: I have acrophobia. I don't like
to look down much.</p>

<p class="tab"><b></b>So we had the sampling pipe, and
fortunately, it didn't work. We had enough problems on Gnome as it was, but if
that sampling pipe had really worked, we could have had another Des Moines.</p>

<p class="tab"><b>Higgins</b>: On Gnome there was a ten-inch
diameter hole pointed directly at the device. It went to the surface, and it
was open all the way. It not only sealed up, but we probed the inside of it
with a radiation detector down to within two cavity radii, and were unable to
detect the fact that there had been a nuclear explosion there. There was no
activity, not even gaseous activity. To me that was, and is still, rather
surprising, because there was plenty of tritium tracer around the Gnome
explosion, and it was everywhere else, but not in the rad chern sampling hole,
believe it or not. It certainly went into the tunnel.</p>

<p class="tab"><b>Carothers</b>: Well, there were people, Gary,
and I'm sure you're familiar with this, who believed that the way to ensure
sealing and containment on cables and small diameter holes was to always, on all
drawings, and when discussing them, speak of them as rad chem sampling devices.
Then, the evidence was, nothing would ever come up them. You'd never see an
atom.</p>

<p class="tab"><b>Higgins</b>: Not even one. You're right, I'm
familiar with that approach.</p>

<p class="tab"><b>Heckman</b>: The concept behind all of this
sampling work was that the bomb was going to go off, some of the debris would
fly into the pipe, the ground shock would then squeeze off the end of the pipe,
and now I would have a pressure pulse, and it would be just like a shock tube.</p>

<p class="tab">These were vacuum pipes
that looked directly at the device, and so you put a slug of gas in, and it's
equivalent to puncturing an aluminum diaphragm and allowing a pressure wave to
travel down the pipe. You can very easily show that if indeed it behaves like
that, with the pipe shut off by the ground shock, there's a certain maximum
pressure wave that will arrive at the other end. So you design a system that
will withstand that kind of pressure.</p>

<p class="tab">The chemical engineers
devised several ingenious schemes to keep the pipe open, and Dick Heckman
describes what was done on Eel, in May, 1962, and on Des Moines, in June, 1962.
Both were major ventings. The reported release on Eel was 1.9 megacuries; on Des
Moines, II megacuries.</p>

<p class="tab"><b>Heckman</b>: My good friend Heusinkveld
wanted to use slifers as a way of getting a quick yield measurement, and he
came up with this great idea where he just drilled a satellite hole, filled it
with drilling mud, and stuck his slifer cable in it.</p>

<p class="tab"><b>Carothers</b>: And the mud was going to keep it open?</p>

<p class="tab"><b>Heckman</b>: Well, he didn't think about
what the mud was going to do. He just knew the mud was going to transmit the
shock wave as it went out. On that same shot, which was Eel, I had decided that
maybe I could get an explosive that would get detonated by the shock wave. I
wanted something that would burn pretty slowly, and nitromethane logically
comes to the fore. And so we indeed did that.</p>

<p class="tab">Well, Mike's slifer
cable worked fine, but immediately there was this 150 or 200 foot high column
of mud that spewed out of his slifer hole. Our sampling system worked and we
got samples out of it, but it didn't close off either, so Eel would have vented
even if Mike's slifer hole hadn't been there.</p>

<p class="tab">We were not looking at
the device itself. These were now satellite holes. People said that the device
goes off, and the cavity grows out in this length of time, and our thought was
that if we could connect up with that initial vaporized zone, we'd stay
connected. Then we could build very sturdy systems that would take the thousand
psi or so of pressure, with cyclone separators we could bury underground, and
then we could pull samples out of them.</p>

<p class="tab">So, we tried a straight
nitromethane tube, but what we found there was that when you look at the burn
velocity of the nitromethane, it burned faster than the ground shock coming
through the alluvium. We probably were exploding the pipe; we were putting pressure
inside at the wrong time. So then we had them wind us up a helical pipe, where
the spacing on the pitch changed as you went up, and we tried that. This was
also nitromethane filled.</p>

<p class="tab">We seemed to get a
pretty good sample out of it, but the problem we had was that when the
nitromethane went off, razor blade size pieces of steel just spalled off, and
that ended up clogging up our system. So that clearly wouldn't work. Well, we
got to thinking about it, because Mike had had a spectacularly successful connection
to the cavity on Eel.</p>

<p class="tab">So we started looking
into it, and we ended up going back to the basic viscosity rules and discovered
dilatant fluids. That's something in which the apparent viscosity is
proportional to the rate of shear. To put it in simple terms, if I could fill a
pipe with a fluid so while the shock wave was going through it the fluid had
the viscosity of solid concrete, it would keep the pipe from crushing, and then
as the shock wave went past, the stuff would act like a fluid.</p>

<p class="tab">In looking around we realized
that ordinary starch and water would do this. And we added a gel to it. So, we
did some tests and it all looked good in the laboratory. I remember one
spectacular experiment I did. We had a beaker sitting on the table, and I said,
"Okay, if this is really working, what I am supposed to be able to do is
stick a spatula in it, and if I lift it rapidly, it will set up and I'll be
able to lift the whole beaker up.</p>

<p class="tab"><b>Carothers</b>: Be sure you don't stop lifting.</p>

<p class="tab"><b>Heckman</b>: Well, that was the problem. You
can only lift to as long as your arm is, and that could be right over your
head. However, that demonstration, as far as I was concerned, was a very practical
one.</p>

<p class="tab"><b>Carothers</b>: I recall you and Heusinkveld
had a sampling pipe on Des Moines. What clever scheme did you use there to
breach the stemming?</p>

<p class="tab"><b>Heckman</b>: On Des Moines we built a
section of two-foot diameter pipe, and what we did is we packed it with
polyethylene tubes, polyethylene pipe, and ran it through the stemming. Mike put
a slifer cable right next to our inlet section, and he put a slifer cable over
along the tunnel wall, and then, of course, that part of the tunnel was all
packed with sandbags. Well, as you remember, Des Moines was one of the more
spectacular containment failures.</p>

<p class="tab"><b>Carothers</b>: When you designed this
horizontal pipe for your inlet experiment, and stuffed it with the polyethylene
tubes which would vaporize and explode and keep the pipe open, what was going to
close it? If you had deliberately prevented the ground shock from closing it, what
was going to close it?</p>

<p class="tab"><b>Heckman</b>: Well, Mike didn't really think
that one completely through, and it never occurred to me to worry about it,
because we had that big gas-tight door, right? You were going to get a little activity
out, sure. Remember, this was all kind of back-of-the envelope, and so you
didn't really think about what kind of pulse that was going to be put out.</p>

<p class="tab">Well, when we looked at
the signals from the slifers, the slifer he put by the tunnel we never did get
a signal out of. The one on the pipe just took off, and clearly was moving at
about two to three times the free field velocity. When you tried to look at the
signal that was coming off of the slifer on the side of the tunnel, comparing that
with the free field slifers that they had installed in other locations, it was
just very clear that the shock wave coming out of our pipe was just blowing it
up.</p>

<p class="tab">It became also very
obvious at this point that you don't get just a little bit of the dragon's
breath. Once you connect with the dragon, he keeps blowing. So, as you
remember, the blast door that was sealing the tunnel came flying out.</p>

<p class="tab"><b>Carothers</b>: Richard, everything came flying out.</p>

<p class="tab"><b>Heckman</b>: Yes. And
it's just very clear that Mike Heusinkveld and I were responsible for the Des
Moines fiasco.</p>

<p class="tab"><b>Carothers</b>: Well,
you can't really claim all the credit. There was a vertical rad chem sampling
hole that looked from the top of the mesa down to the device, and pictures from
the fast cameras show that vented immediately, in less than a millisecond. I do
believe that your attempt to keep the pipe in the tunnel open succeeded, and
led to the venting out the portal. But even if that hadn't happened, Des Moines
would have had a big release due to that vertical sampling pipe. So, maybe we
should give Des Moines to the chemists in general, rather than to you in
particular.</p>

<br>

<p class="tab">The
following pictures of the Des Moines venting, on June 13, 1962, were taken by
the author with a hand-held camera. The pictures were taken at irregular time
intervals; the elapsed time between the first and last is probably about ten
minutes. The total release is recorded as 11,000,000 curies, which is one of
the largest releases from any underground event. Regardless of what definition is
chosen, Des Moines was not successfully contained. It is instructive to observe
the amount of material ejected from the tunnel by the energy release from what
was a rather low yield device.</p>

<p class="tab">In
the pictures there are three distinct venting paths that can be seen, The first
is from the rad chem sampling hole that led to the mesa top. As was mentioned
above, material was released there within the first millisecond. The second
release occurred through a hole that ran from the the face of the mesa down to
the tunnel, and can be seen as a plume that appears before the venting from the
portal develops. The purpose of this hole was basically to protect the
diagnostic film in the trailers near the portal. The thought was that if there
was venting into the tunnel, the pressure would be relieved by having an open
hole from the tunnel to the mesa face. Hopefully, such pressure relief would
allow the door near the portal to remain intact, and so prevent radioactive
material from blackening the diagnostic films in the trailers near the portal.
The third, and major release, was from the portal after the gas-seal door had
been forcibly ejected.</p>

<p class="tab">However,
neither the Des Moines venting, nor that of Platte (about 2 megacuries) in
April of 1962, nor that of Eel (about 2 megacuries) in May of 1962, caused
significant problems to the overall test program. They were significant
problems to the people at Livermore, particularly the people trying to collect
data on film, but there was no stoppage of testing while the causes of the
ventings were explored, there were no changes in field procedures, and so on. Des
Moines was detonated on June l3, 1962, and the Dominic operation was actively
being carried out in the Christmas Island area. In the week preceding and the
week following Des Moines, there were a total of seven airdrops of devices of
intermediate or low megaton yield. If 10 megacuries is taken as the H+ 12 hour
activity from I kiloton of fission, the Des Moines release was about that of a
1 kiloton atmospheric shot. That was trivial compared to the activity being released
in the Pacific, and perhaps that influenced the AEC. On the other hand, it was
close to home, and the people whose data were lost were not happy.</p>

<p class="tab">In
all, Livermore fired seven tunnel events after the resumption of testing in 1961,
and only one, the Madison event, was contained. The last Livermore tunnel event
was Yuba, fired on June 15, 1963. It was not contained and released material
that was detected off the Test Site.</p>

<p class="tab">It
was in 1963 that the Nuclear Test Ban Treaty, widely known as the Limited Test
Ban Treaty, or the Partial Test Ban Treaty was signed. As observed in the first
chapter, the Treaty did not say any event had to be designed to contain all the
radioactive products that were produced - only that the radioactive debris
should not cross the border of, in this case, the United States. For example,
nuclear cratering experiments continued until December 8, 1968, when the 30 kt
cratering event Schooner was fired, presumably under meteorological conditions
that would retain the vented activity with the boundaries of the United States
for some indeterminate time.</p>

<p class="tab">Containment
failures, as defined today, occurred both before and after the Treaty was
signed. Most of them were minor seepages, but some were major failures,
particularly for the experimenters trying to collect information from the
detonation. There were a variety of reasons for the ventings, and it was not
always easy to determine the cause of those failures.</p>

<br>

<p class="tab"><b>Brownlee</b>: There was Bandicoot, in 1962,
in about the first year. There was nothing wrong with the containment design, nothing
wrong with the emplacement, or anything like that. I think that was all done
right. We had everything placed assuming the yield we were told it would go
would in fact be the yield. The hole was deep enough for that yield, but I
believe there's no doubt it went well above that. We had enough hydrodynamic
data that we were convinced of that. And so, the hole was just too shallow, and
it vented. It was just that there was this enormously surprising yield. Now,
why was the Bandicoot yield so surprising? Well, it was a type of device where
nobody can estimate yield very well. Of course, what we should have done was
put it much deeper, just to be conservative. But, you see, we took the
designers word for it; what the yield would be, and what the
max cred was.</p>

<p class="tab">That as one of the few
times when the yield was, in effect, dictated by a committee, which paid little
attention to data that didn't fit the desired results. It was designed to be so
many kilotons, so that is what it was. And it wasn't. It just wasn't .</p>

<p class="tab"><b>Carothers</b>: I have noticed, at the CEP
meetings, that you are often skeptical of numbers we get from the designers.</p>

<p class="tab"><b>Brownlee</b>: You've noticed that?</p>

<p class="tab"><b>Carothers</b>: I have noticed that. Perhaps
that's because of your experiences with Bandicoot and Pike.</p>

<p class="tab"><b>Brownlee</b>: It's more than that. We've had
a number of times where I have seen idiocies promulgated as fact. And it's done
for political reasons. You understand how that goes; we have promised the Navy,
or the Army that this thing is going to be so many kilotons. And, that's what
they are going to get. Never mind what the yield really looks like.</p>

<p class="tab"><b>Carothers</b>: Well, Bob, you must realize
that having promised a particular yield, over the course of this many year development
through the Phase 3 and into the stockpile, there has been lots and lots of
money and time spent on targeting plans, training manuals, and so forth, all
based on that yield. Now, you're not going to come in at some late date and
tell them the yield isn't what you promised them, are you?</p>

<p class="tab"><b>Brownlee</b>: Yes, if it is different. I do
understand the cycle you've described, but I do believe that the quicker the
country finds out that something is different from what they thought it was,
the better off the country is.</p>

<p class="tab">I was bitter about
Bandicoot. I had done what I had been told to do, which was to contain this
shot where the yield was going to be thus and so, and that's it. After the fact
they insisted that's what it was, and it was just a lie. I had my own
hydrodynamic yield measurements, and those measurements gave a much different number,
and I have no reason to take them back today; they were good measurements. Now,
we have relooked at Bandicoot. We went back and drilled for more samples. This
was during Eric Jones' stay. Eric reviewed all my data, and when he got all
through he said, “The hydrodynamic data are correct." By this time we had
gotten rid of the guy who was the problem, and so we got them to concede that
the yield really was a lot higher than it was originally reported.</p>

<p class="tab">In early 1963 an
informal meeting was held between Los Alamos and Livermore test principals to
evaluate individual tests. The intention was to share procedures, plans, and
lessons learned, but containment was not a major part of the discussions. After
the Limited Test Ban Treaty was ratified in October in October, 1963, the Eagle
event vented. Considered as a probable violation of the treaty, the event
triggered additional discussions on containment at various levels in the
Laboratories, and in the AEC. From these, the Test Evaluation Panel was
formally established in December.</p>

<p class="tab">The Panel consisted of
consultants, and persons furnished by LASL, LRL, Sandia, DOD, the Public Health
Service, and the AEC. The USGS furnished the geologic information. The purpose
of the Panel was to "review all data pertinent to the containment aspects of
each planned nuclear test; then, based on these data, to assign the test to one
of the risk categories defined below."</p>

<p class="tab">The TEP had three categories,
much as the CEP does, but there the similarity ends. The TEP Category A, in
1966, was "Underground nuclear tests which, on the basis of experience,
should not release a significant amount of radioactive material. It must be understood
that, even in this category, unforeseen conditions may develop which result in
the release of detectable levels of radioactivity at the border." The NYO
Planning Directive for 1964 said, "The emplacement and firing of devices
will be designed to result in containment in all
cases where this requirement is not inconsistent with the technical
objectives."</p>

<br>
<p class="tab">Cliff Olsen, long time Livermore containment scientist, made these
comments about the TEP:</p>
<br>

<p class="tab"><b>Olsen</b>: The people who tended to be at
the TEP meetings were the Test Group Directors, and they presented the shots.
The presentations were very rudimentary. There was a data sheet, and maybe a
line-of-sight pipe layout, or a stemming drawing. Often there was no stemming
drawing, because we had generic stemming plans. There was LASL 5, or LASL 2 at
that time. We would have our stemming plan, which was pea gravel with fifty
feet of sand halfway up, and fifty feet of sand at the surface, and that was
our stemming plan. So, there was no need for a drawing, because they were all
the same. The TEP got into reviewing the designs of particular features a lot
more than the CEP does. In a sense, they would suggest changes, and they would
actually review mechanical designs - why don't you do this, why don't you do
that. And design changes to the hardware were made as a result of the TEP.</p>

<p class="tab">One of the things with the TEP,
which I guess was sort of indicative of the climate at the time, was there were
three categories, A, B, C, and C was, "Underground nuclear tests which are
expected to release a significant amount of radioactive material." There
was no particular onus to getting a C. It simply meant that you made different
notifications before you shot it. It had nothing to do with whether you were
going to execute the event. It wasn't that somebody in Washington or Germantown
was going to have a hemorrhage when he saw it. It was just the design of the
event.</p>

<p class="tab">One venting in
particular, from the Pike event, fired March 13, 1964, has had a major and
continuing impact on the Test Program. The fallout projections for following
events have been based on the "Pike Model," which means that the
possible fallout from the proposed shot is scaled to the readings that were
obtained in the Pike fallout pattern according to the yield ratio of the two
events. The basic assumption is that the proposed shot will release the same fraction
of the activity that Pike did.</p>

<p class="tab"><b>Brownlee</b>: Pike has cost all of us
enormous amounts of time, and effort, and money, and I think needlessly. That
is a thing I have never been able to communicate to NVO in modern times. You
see, one of the things everybody forgets is that we had a line-of-sight pipe on
Pike. It didn't come to the surface, so people forget that it was there. And,
since it didn't come to the surface, although it went a substantial distance,
it had no closures or anything. That pipe was one of the key factors. Another
was that Pike was expected to have a maximum credible yield of a certain value
- not very large, but definitely not a safety shot. Well, it went over one and half
times the max credo And then, it was in a very shallow hole; 400 feet or so.</p>

<p class="tab">What I knew about it was
that it had this predicted max cred, and the pipe was so long and so big. I
said, "A lot of energy is going to come to the top of that pipe." I did
not realize that there was any chance that the yield could go higher than what
I was told, or I would have hollered. I knew that it was in a shallow hole, so
that bothered me as it was. Another thing I did not know was that when they
drilled that hole they had run into what I called hourglass sand. And guess where
that layer of sand was - which I found out after the shot. It was right at the
top of that pipe.</p>

<p class="tab">Now, there's no chance
in the world we will ever duplicate Pike. First of all, we won't shoot anything
at 400 feet. Secondly, we won't have a pipe on it like that. Thirdly, in a
medium where the sand was running like water - we'll never do that. And
finally, having a max cred yield as bad as that is kind of unthinkable. I say, "Kind
of unthinkable.” When you combine all those things, Pike was a lead-pipe cinch
to be spectacular.</p>

<p class="tab">My argument is that to
treat every shot like Pike is absurd. It's just absurd. There isn't anything
that's going to vent like Pike, because we don't do those things anymore. We
will never duplicate Pike, and yet we pretend to the world, and to society, and
to the President of the United States, that this shot we're considering could
come out like Pike did. We don't intend to communicate that message, but that's
what we do, and it's just not true. It's not going to come out like Pike,
because Pike had too many great oddities.</p>

<p class="tab">Pike is what really
brought us to every detail going through the hands of the containment people.
We said, "No more are we going to take anybody's word for anything.” The
Pike experience was profound for us, because that's when we realized that no
one person was knowledgeable about everything on a shot. I was responsible for certain
things, but not everything. After Pike we began to function in what I'll say is
a modern way. We had a meeting in which the bomb designer had to come and swear
he knew what the yield would be. That really came as a result of Pike. Before,
it was by chance. You knew what you knew by who you happened to talk to, but if
people were on vacation, or you were on vacation, you didn't talk to them, and
you didn't know whatever it was they could have told you. I learned a bitter
lesson on Pike, which was that I thought I knew what the shot was and I didn't.
I didn't know the yield, I didn't know the geologic setting, and I didn't know
about the sand. All these things came out in the wash.</p>

<br>

<p class="tab">Bob
Bass, Sandia, Albuquerque, was doing instrumentation work on the hydrodynamic
yield measurements that Los Alamos was doing at that time. He also had
information that Brownlee didn't have.</p>

<br>

<p class="tab"><b>Bass</b>: Pike could have been foretold.
I was on the instrumentation crew. We were doing hydrodynamic yield
measurements on Pike, and we had three satellite holes. Our job was to
instrument these satellite holes. We had a guy named Jim Greenwald, and he liked
to play with TV. He was our installation engineer when we were lowering these
slifers and/or time of arrival gauges down these holes. Pike, of course, wasn't
very deep. Well, Jim called me and said, "You've never seen such a mess in
your entire life. I lower my TV camera down there, and it's a cavern. I've got
communication between every one of my satellite holes, all the way down. I go a
hundred feet down and there's no sand pile down there. There's nothing but a
labyrinth of tunnels."</p>

<p class="tab">Well, we tried to put in
enough stemming to fill up that cavern, but we didn't get it done. We flat
didn't get it done. We got it done for a while, but then it would start again.
We knew that site was Swiss cheese. That shot was sitting there waiting to
vent.</p>

<p class="tab"><b>Brownlee</b>: The first political fallout was
about the fallout. It was on Las Vegas, and it also went straight toward Mexico
City. I think somebody in the embassy read something and didn't know what he read,
and it never really did get reported in a sensible way. I don't believe you'll
find any record of a measurement having been made in Mexico City, but I believe
there was.</p>

<p class="tab">Then Al Graves had a
meeting, and I went, and Westerfelt, and for the first time we put together all
the things that were wrong. And I was appalled. So we, at the second level,
bared our breasts and said, “Well, we had done this, and we had not done that,
and the yield was quite a bit higher than we were expecting, etc." Then Washington
came down hard on us on all those points, but they knew these things because we
told them about them.</p>

<p class="tab">The thing they knew was
that it had crossed the border. We made lots of promises of brand new
procedures, which indeed we did initiate. And we really changed our working
relationships after Pike, between the people at the Laboratory, and the people
in the field doing the engineering and drilling. I remember that as being profound.
We said, "This will never happen again."</p>


<a name="ch4"></a>
<br><br>
<h2>Chapter 4: The Beginnings of Containment Programs</h2>
<br>

<p class="tab">
As time went by, the tolerance of releases of radioactivity from the underground
detonations at the NTS diminished until it became obvious to the Laboratories
and the DNA that serious effort must be given to all the questions that such
releases raised. And the list of questions was daunting. What was it that
prevented such enormous energy releases from rupturing the ground and thereby
releasing the gases, steam, and radioactivity to the atmosphere? Obviously it
was related to the amount of material over the detonation. In what way did the
necessary amount of material depend on what the material was? How was it
related to the chemical composition of the material, the strength of the
material, which in turn is related to the amount of water in the material? How
does the material react to pressures of millions of atmospheres, and to
temperatures of many tens of thousands of degrees? Does it matter if the
material is fractured or faulted, and if does, how? What pressures and
temperatures actually are created in the material, and how do they decay with time?</p>

<p class="tab">The
original thoughts about doing experiments underground arose from pressures to
reduce off-site fallout, and desires to make the operations easier to carry
out. Contamination of the shot sites, and radiation exposures to people working
in the field gave additional incentives to the Laboratories to find different
ways to conduct the tests. In a similar way, the releases that occurred on some
of the underground shots were a problem to those trying to collect experimental
data. At first, political pressures to achieve better containment were minimal,
but by the time of Baneberry in 1970 they became controlling.</p>

<br>

<p class="tab"><b>Olsen</b>: It must have been late' 65 that
I started to do things in containment. There had been several leaks, but the
political climate of the time was sort of, "So what?" But the Test
Program people really didn't like getting trailer parks exposed, because virtually
all the shot data was on film, which turned black if it got irradiated, and
there went the data. If you put the trailer park upwind, nobody really cared if
you leaked a little bit. But the AEC people eventually began to think that we
ought to be a little more careful. The straw that broke the camel's back was a
thing called Diluted Waters, which was shot in Frenchman Flat in June of '65.</p>

<p class="tab">I remember I was working
on something in Yucca at the time. I was driving over the old Burma Road, and
heard the countdown for Diluted Waters on the net, so I parked the car and
watched it. At zero time there was a little dust, and a few seconds later a big
cloud came out. A few other cars had stopped, and the guys watched for a while,
and then we decided, “Oh well, another one," and we started our cars and
went out to Yucca Flat.</p>

<p class="tab">After I got back to Livermore,
my division leader, Jim Carothers, called me into his office, and asked me if I
would be interested in something called containment. It seemed the AEC had
gotten a little worried that we were having some problems, and Diluted Waters
had kind of sensitized enough people that the AEC was going to form an
investigating committee to look into it, because we had guaranteed we had
solved the problems. We were involved even though it was a DASA shot. Now, we
thought we had solved some of the line-of-sight problems on earlier things,
going back to Eagle, in '63.</p>

<p class="tab"><b>Carothers</b>: Mr. Olsen, since Eagle released
enough energy to create an explosion at the surface which completely destroyed
the surface structure and the experiments thereon, I cannot say that I would
use Eagle as an example of how you had solved things.</p>

<p class="tab"><b>Olsen</b>: Well, no, but it led us to
things that needed solving, let us say.</p>

<p class="tab"><b></b>So, in '65 this Jim Carothers
asked me to look into containment, and it turned out at that time it had to do
primarily with line-of-sight shots and the diagnostics thereof. So, we went
scrounging for recording equipment for slow diagnostics, as compared to
reaction history. We were looking at tens of microseconds, and millisecond response
rather than nanosecond things. We got help from EG&amp;G, primarily Santa
Barbara. And some from EG&amp;G Albuquerque, which at that time existed.</p>

<p class="tab">We were looking
basically at flow in the pipe itself; time of arrival, pressures, as well as
radiation coming up the stemming and the pipe itself. We were looking at how
you could attenuate flow in a pipe. I f you want to do that you obviously have
to look at what's going on.</p>

<p class="tab"><b>Carothers</b>: How
did you do that? Pipe flow is still an interesting, difficult problem.</p>

<p class="tab"><b>Olsen</b>: That is
true. We tried lots of things, some of which worked, and some of which didn't.
We used ordinary pin switches, and pressure pins. We used pressure transducers.
We used optical time of arrival things, slifer cables both inside and outside
the pipe. We used radiation detectors.</p>

<p class="tab"><b>Carothers</b>: And lo
and behold, you discovered that indeed there was a lot of pipe flow, and it
often came right out the top of the pipe.</p>

<p class="tab"><b>Olsen</b>: That's
right. And it got to where we were measuring differential pressures, we hoped,
across closure mechanisms. If you saw zero above, and a lot below, it said that
thing really closed, and really worked. These were man-made closures, as
opposed to ground shock driven. There were high explosive driven, and mechanically
driven, closures. And there were lots of varieties of those. There were ball
valves, and flapper valves, and so on.</p>

<p class="tab"><b>Carothers</b>: Did any of them work?</p>

<p class="tab"><b>Olsen</b>: Yes, some
of them did, although some of them didn't. In fact, some of them were probably
worse than if they hadn't been there. Probably the worst one we put in was a
thing called HE flaps. They were dimples that had been cut in the pipe at
alternating spots. You put little pads of HE on them, and shoved pieces of the
pipe in, rather than trying to close it symmetrically. The idea was to obscure the
pipe by pushing things in. One version of these flaps was to cut the pipe at
the bottom of the flap, and shove this flap in so that something coming up the
pipe would come to the area of the pipe where this piece had been pushed
across, and the flow would then just go out into the stemming.</p>

<p class="tab"><b>Carothers</b>: Say, that sounds clever.</p>

<p class="tab"><b>Olsen</b>: That was
really clever. Unfortunately, this thing weakened the pipe so much that what it
did was put a tab of material out in the flow, and that tab could rip off very
easily. So, the whole thing went right on up the pipe.</p>

<p class="tab"><b></b>We had a few other disasters on
line-of-sight pipes. Some, like Tapestry, weren't too bad. The reason it leaked
was that some valves at surface ground zero jammed a bit and didn't close all
the way.</p>

<p class="tab"><b>Carothers</b>: Did you ever have a successfully contained pipe shot?</p>

<p class="tab"><b>Olsen</b>: Oh yes.
Probably the best ones were Crew and Flax. They were unusual in that the pipe
terminated underground, and we had the things there that we wanted to expose
and follow for a time. Obviously you had to close the pipe, or there wouldn't
be anything there to look at. Both of those events were quite successful. Packard
was another one where we had exposure stations about halfway down the pipe, and
we wanted to pull them up the pipe to recover them. That was quite successful.
We closed everything off below the exposure stations.</p>

<p class="tab">By then we knew about
things that didn't work, like the HE flaps that just put more mass into the
flow. We knew not to put an HE closure, even though the closure worked, in too
close, because the ground shock could simply go around it, as if it weren't
even there, and still have enough energy to pour energy into the line-of-sight pipe.
So, you have to put even a fast HE closure far enough out so the ground shock
doesn't just envelop it and keep going. We learned that closer isn't
necessarily better. We learned how to build valves that would seat in the
environment. We learned how to decouple them, if necessary, with joints and
things like that, to modify the environment so they would survive.</p>

<p class="tab">We had a better
capability, by then, to look at the energy in the front end, and to look at
things where we could limit the energy going in. Often, in the early shots the
experimenters wanted everything they could get. So, they wanted bigger and
bigger apertures.</p>

<p class="tab"><b>Carothers</b>: That's
still true. The experimenters always want more than they can have.</p>

<p class="tab"><b>Olsen</b>: That
wasn't always true though. On Flax, for example, we put a segment of a pie-type
collimator in the front of the pipe to cut down on the flux. That, of course,
made it easier to close, because part of the path was already plugged. When the
experimenters got to be a little less grabby about wanting everything it sometimes
made things easier. But a lot of it was trial and error.</p>

<p class="tab">The Livermore Hupmobile
event, fired on January 18, 1968, released activity that resulted in a major
loss of data, and radioactivity was detected off-site. It did not result in the
kind of long-lasting operational changes that Pike did, but it did lead to the formation
of a separate group, responsible for the design of the containment plan, at
Livermore. Cliff Olsen and Billy Hudson became two of the first members of that
group.</p>

<p class="tab"><b>Olsen</b>: In those
days I think ninety percent of the reason for expending effort on containment
related to data loss, rather than pressure from Washington. That begin to
change probably around '67 to '68. It may have been as a result of Hupmobile,
because the people in Washington who supplied the money, even though they were
not so worried about the loss of data as the experimenters, got antsy about
dumping money into these things and not getting anything in return. Hupmobile
was quite expensive for the time. I think that may have been the first thing
beyond strictly experimenters wondering why their film was black.</p>

<p class="tab"><b>Hudson</b>: Hupmobile turned out to be a
containment fiasco, in that a lot of the film data was lost due to the
radiation release. The decision was made at the Associate Director level to
form a containment group, and to try to put some serious effort into understanding
containment and saving the film. Jim Carothers asked me to join that group, and
it appeared to me to be an offer I couldn't refuse.</p>

<p class="tab">I believe it was in late
1968 that happened. For about the first two years Bill McMaster and I used to
have some words now and then about how this surely wouldn't be more than a two
year problem, and then we could get back to doing some science. "We'll figure
this out, won't take more than two years, then we'll get back to interesting
physics." Fortunately, it got more and more interesting, because it turned
out to be much more than a two year problem.</p>

<p class="tab"><b>Carothers</b>: I'm
surprised that the containment group came along so late, because there were a
number of Livermore events earlier that had been, by today's standards, quite
catastrophic containment failures.</p>

<p class="tab"><b>Hudson</b>:
Personally, it was my impression that we became interested in having a
containment group because so much data was being lost on experiments like
Hupmobile. On the earlier events there weren't that many experiments, so it was
a relatively small loss, even though they perhaps lost a major fraction of what
they had on the event. It was a small loss compared to the loss on Hupmobile. And,
programmatic people decided that since this was the direction they wanted to
go, bigger and more comprehensive experiments, something had to be done about
containment so they would have some confidence that after spending all that
money on the test they would get the data back. The primary problem then was to
protect the film so the prompt diagnostics folks could go back to the Laboratory,
read the film, and tell the bomb designers what they did right or what they did
wrong. It was not to protect the environment; it was to protect the data.</p>

<p class="tab">The Partial Test Ban
Treaty had been signed in 1963, several years earlier. The Treaty said we were
not to do any experiments where radioactive material would go beyond the
national boundaries of the U.S. That was a primary guideline; no radiation
across our international borders. But in fact, measures had already been taken
to pretty much limit the escape across the border. Just by the act of putting a
few hundred feet of dirt over the device you almost always eliminated radiation
getting to the border. There were a few events after the early sixties that
released material that may have gone across the border, but they were very few.
It was mostly a local problem, because the radiation leakage would be confined
almost to the site of the event itself, or maybe a little larger. But, it was
that local radiation that was causing the damage to the film containing the
data, and that was the kind of problem most often encountered.</p>

<p class="tab">If we had a release that
got up to the neighborhood of ten thousand curies there was a possibility of
activity getting off site. Less than a thousand curies was of little or no
concern to the general public, or the people in Washington. However, it was of
great concern to the people whose film was in the recording trailers.</p>

<p class="tab">In the late 1960's,
early 1970's, they were doing some exposure experiments, with an open
line-of-sight pipe to the surface. It took a few tries before the hardware was
properly designed to stop the rush of hot gases and refractory products to the surface,
but that problem was pretty well solved by the time the containment group was
formed. I don't think people realized it, but we didn't see much more of the
Hupmobile type releases on our line-of-sight shots after we formed the
containment group.</p>

<br>

<p class="tab">The
Baneberry event, detonated on December 18, 1970 with a yield of 10 kilotons,
was the watershed in the history of containment. It was fired in an emplacement
hole in Area 8, and had a vertical, non-divergent line-of-sight pipe. It vented
spectacularly through a fissure, a little over three minutes after the device
was fired. The cloud of dust and debris rose some 12,000 feet, and was reported
to have been seen by people at the NVO offices in Las Vegas. The total release
is today given as 6,900,000 curies (H+ 12 hours). Interestingly, almost all of
the activity was the volatile and gaseous elements, so there was little fallout
deposition from Baneberry. The integrated total activity in the fallout
pattern, on the ground, was a small fraction of that in the Pike pattern.</p>

<p class="tab">The
wind patterns before the shot indicated the transport of any effluent to the
northeast, and so the Area 12 camp, to the west of the shot site, had not been
cleared of the people staying there. However, surface winds carried some of the
activity to the west. During the time it took to alert the people in the camp,
and to clear the area, a number of people received radiation exposures, and
some of those filed lawsuits in the following years, alleging damage to their
health and longevity.</p>

<p class="tab">The
AEC allowed no more detonations for some six months while a committee, called
the Vinceguerra Committee, after the Chairman, examined the causes of the
venting, and the method of operations at the Test Site. In the report of the
committee several recommendations were made for changes in the way future test operations
should be carried out, and how improvements could be made in the way the
containment aspects of an event were evaluated. One of the recommendations was
that the Test Evaluation Panel should be reconstituted, and a new Charter
developed for the new Panel. The Containment Evaluation Panel, as the new Panel
was called, consisted of a Chairman, one member and an alternate nominated by
each of LASL, LRL, Sandia, DNA, USGS, and the Desert Research Institute. In
addition, provision was made for the Manager, NVO, to appoint one or more
consultants. Members nominated by particular organizations, or consultants
recommended by the Chairman, were formally appointed by the Manager, NVO, to serve
on what was an advisory Panel to him.</p>

<p class="tab">Carter Broyles, Sandia, was one of the first members of the CEP.</p>

<br>

<p class="tab"><b>Broyles</b>: I think
the members of the Panel all recognized there was a political need to be met,
to prove to the nation that we were paying attention. And clearly it was
evident in the series of proposed charters, and hassling that went on between
Nevada and the Labs and Washington on just what the charter should say. I think
I viewed from the very beginning that the CEP took it's role as a technical
judgment body seriously, and more than just political window dressing.</p>

<p class="tab">In fact, I think some
members perhaps were over-enthralled. Not so much over-zealous, but perhaps
they did not have a full appreciation of the limits of our technical knowledge,
and therefore tended to give themselves more credit for how sure they were of
any technical facts than we really were. They didn't necessarily recognize the
technical limitations, and the lack of knowledge of geophysics and
geo-engineering, and what the characteristics of the real world were, how
variable they were, and the limitations of the calculations.</p>

<p class="tab">Clearly various parts of
the structure looked different from different perspectives, and the CEP, I
think, was many different things to many different people. But the Panel
itself, from the very beginning took its role seriously, and took it as a
technical challenge to do the best job they could, because it was obvious that
the world was going to be different after Baneberry.</p>

<p class="tab">The Livermore
containment group had been in existence for some two years when the Baneberry
venting occurred. During those years they were supported as part of the overall
testing effort, but their authority to affect a particular shot was
questionable. That changed significantly after Baneberry.</p>

<p class="tab"><b>Hudson</b>: Following
Baneberry the Test Program was shut down for six months, and the people who
designed bombs and wanted to get data back were suddenly aware that containment
was a very important factor to be considered. It was the beginning of a movement
directed toward the idea that we shouldn't have anything out at all. If it was
above background, it was too much. It was clear that was where people were
headed.</p>

<p class="tab">There were about a dozen
people in the containment group at that time, as I
recall, and I would guess that two-thirds of them were involved with
calculations. This is when the major effort was directed at adapting the codes
that first had been used for bombs, later to describe what's going on in the
pipe, to describing what's going on in the earth. It was clear that the interaction
between the bomb and the ground might be the ultimate worry, not just the interaction
between the bomb and the pipe.</p>

<p class="tab"><b>Carothers</b>:
Clearly demonstrated by the Baneberry venting. Why didn't the containment group
prevent that?</p>

<p class="tab"><b>Hudson</b>: Well,
that is an interesting question. At that time the containment program was
really under the umbrella of the Test Director and the operational folks. We
didn't have a Containment Evaluation Panel. In those days we had the Test
Evaluation Panel, and the Test Evaluation Panel was more concerned with having
a successful experiment than they were with containment. As a result, when
containment aspects of an event were considered, they were presented by the operational
side of the program.</p>

<p class="tab">We in the containment
group were operating in a support mode. If they wanted to pay attention to us
they did. If they thought that the concerns we had wouldn't lead to an
expensive loss of data, then they didn't. The objective was still to bring back
the data. And as a matter of fact, they brought back data on Baneberry.</p>

<p class="tab">What we did say was that
we should run some logs in that hole, and find out what kind of densities and
velocities we really were shooting in. We did ask for them, but we didn't get
them, because we couldn't make a good enough case for it. We couldn't say,
"Hey, if the velocity is below this, or the density is below this or above
that, we're going to have a release problem, or a vent." We just knew there
were questions we would like to have had answered before the event. We knew
there were some things that were new and different, and that we didn't
understand.</p>

<p class="tab">If we could have said,
"Hey, you're going to lose a lot of data," then we would have gotten
their attention. But as far as containment per se is concerned, we didn't have
a lot of leverage. And, we didn't know we were going to have a horrific containment
problem. We just knew that there were some things about the site that were unusual,
and that was our cause for worry. But we didn't have any theory as to why we
were worried. We were just worried because it was new and different. Without
having a really logical, well thought out reason for delaying things, it was
hard to give credence to our fears.</p>

<p class="tab"><b>Carothers</b>: You
might contrast that with today, almost twenty-five years later. Today if the
containment group said, "We have fears and we don't know the
answers," you would be listened to more, I believe.</p>

<p class="tab"><b>Hudson</b>: I think
there's no doubt about it. The attitude today is that we have to demonstrate
why somebody's fears aren't really a problem. In those days somebody had to
demonstrate why a fear was a problem. Today we're almost in the position of
having to prove negatives. Just the opposite was true in the past. Then we had
to prove that there was a problem. Today we have to demonstrate that there's
not a problem - as well as we can.</p>

<p class="tab">Recognizing the changes
that were taking place, and the strong requirements that were being developed
for complete containment, Los Alamos organized a formal containment group in
1970. Bob Brownlee had been working on the containment of underground events
since 1956. In 1966 he was joined by Carl Keller, and they did a number of
calculations and experiments related to line-of-sight shots, but it was not
until after Baneberry that a containment group, per se, was formed.</p>

<p class="tab"><b>Carothers</b>: When
did there get to be somebody working on containment besides you, or when did
there get to be a defined containment activity?</p>

<p class="tab"><b>Brownlee</b>: It was
at Baneberry time that we actually formed a containment group, and I became the
group leader. We finally decided that between Baneberry and when we started
testing again. The first step in that direction was actually back in 1966, when
Ogle said, "Get somebody and teach them." So, I hired Carl Keller. He
was young then. I'm the same age now as then, but he's older for some reason. I
hired Carl, and just spent time with him. We started going through things, and
learning, and doing things, and I started transferring jobs to him. Before that
some people were named as doing containment. That is, there was somebody in
J-6, and there was somebody somewhere else, there was me and Carl. These people
stayed in their own organizations, but they were supposed to work on
containment. In effect we had a very small containment group scattered around
the Lab.</p>

<p class="tab"><b>Carothers</b>: When
you say, "formed a containment group," does that mean these people
now physically came to work in one area?</p>

<p class="tab"><b>Brownlee</b>: Yes.
J-9 was formed at that time. Jack House was in J-8. He had a little training in
geology, so I latched on to Jack right away, and got Jack into the group. Then,
after we had that group, I hired Fred App. I started hiring people for the
purpose of containment. Bob Sharp and Tom Weaver were both in J-9, the containment
group. And so we had some pretty good guys, and for the first time we had some
geologists.</p>

<p class="tab"><b></b>So, the containment effort, as
you see it now, is really derived from that containment group, J-9. That's when
we started down that path.</p>

<p class="tab"><b>House</b>: I had
never actually heard anything about containment until that December morning in
1970 when Baneberry vented. I happened to be in Mercury in the J-3 operations
group office, waiting to ride into town with Bob Newman, who was then one of our
Test Directors, to get a plane back to Los Alamos. There was this ominous gray
cloud rising up over the Gate 200 pass. I didn't know what it was, but Newman
proceeded to tell me that LRL had a really bad leak. We could see the cloud all
the way into town. I happened to be sitting on the left side of the aircraft as
we flew towards Albuquerque, and I could still see that cloud when we were clear
out over the Grand Canyon, until the sight angle became diminished to the point
where you could no longer see it. That was my first introduction to
containment.</p>

<p class="tab">About two months later I
got a call from Ogle saying that I was being temporarily reassigned to a new
group that was being formed under Bob Brownlee. It was to be a containment
group called J-9. Apparently Ogle told Brownlee that he had to form up a
purpose-oriented containment group, and he could pick any of the J group numbers
not in use, and Bob picked J-9.</p>

<p class="tab">The people who were in
J-9 were Brownlee, Bob Sharp, Carl Keller, and a few other folks, probably less
than ten, that Brownlee had assembled from other groups in the Laboratory. So
we had this little cadre of dedicated personnel who were to do “containment,"
whatever that was. I didn't know anything about containment except probably how
to spell it.</p>

<p class="tab">At that time, in early
1971, we were in the six months test moratorium mandated by the Atomic Energy
Commission post Baneberry. Now we were supposed to have information, geological
information, about the shot sites. All the emplacement holes that Los Alamos
had in inventory were cased. How can we do site characterization and examine
the material properties in a cased hole? So, we initiated a drilling program
for exploratory holes, in close proximity to the emplacement holes, that could
be sampled and logged.</p>

<p class="tab">We initiated our program
of exploratory drilling, and sampling, and so forth. Because we didn't have the
necessary expertise to do the geologic analysis, the data went to the USGS at
Denver, where Evan Jenkins and Paul Orkild and their people did the analysis.
The USGS would then put together a site characterization package - the cross
sections and the whole nine yards. Livermore at that time was able to do those
kinds of things in-house, because they had the necessary personnel. Billy
Hudson and Cliff Olsen had been doing containment work for a few years, and they
were our distant colleagues in this new, for me, world.</p>

<p class="tab">It was a real circus in
those early days of 1971 while we were still learning the containment business.
We didn't have any designated presenter for the events that came before the new
Containment Evaluation Panel, as Livermore did. As I recall, Billy Hudson was
the designated presenter. And we had no containment scientists as we know
today, or event managers, as some people call them when they're trying to
figure out what a containment scientist is. Well, how do we do this thing,
which we had never done?</p>

<p class="tab">The very first event
that was presented by Los Alamos to the CEP was a shot in Area 3. Bob Brownlee
sat at the CEP table and read the prospectus to the Panel. I was sitting in the
audience along with essentially all the rest of J -9, there being only a few of
us, and that's how the presentation was made. The USGS sat in the audience and
responded to whatever geological or geophysical questions were posed by the
Panel. Bill Twenhofel was on the Panel, and he was the USGS representative.</p>

<p class="tab"><b>Carothers</b>: No.
Bill was on the Panel, but Jack, there aren't representatives of organizations
on the Panel. There are independent experts. They may make their living by
working for some organization, but they don't represent that organization.</p>

<p class="tab"><b>House</b>: Yes. I do
understand that you do work hard to try to maintain that distinction.</p>

<p class="tab">Anyhow, Brownlee soon
became dissatisfied with this mechanism of reading the prospectus to the Panel,
and he concluded that Los Alamos would need a designated presenter. He also
decided that we needed individuals who would be assigned to prepare the prospectus.
They were to pull everything together from all the different venues, like the
engineering folks who were doing the diagnostics rack design, and the
operations folks who were drilling the holes, and backfilling them, and so
forth. Carl Keller had been writing the prospectuses. Then one day Brownlee
came to myself and Roy Saunders, and said, "Okay, we have a couple of
these one-point safety tests, and they're in these little shallow holes, and they're
not very complicated. Roy, you write one up, and Jack, you do the other
one." And so we did.</p>

<p class="tab">Carl made the
presentations for a while. Then, I guess he decided that really wasn't his cup
of tea. So Brownlee called me one evening at home, and dropped this little
nugget in my lap, saying that I was going to start presenting all the events. I
was not real comfortable with that. Bob prevailed, as Bob always has, at least
in my case, and 10 and behold, not too terribly long thereafter I was standing
at the podium presenting an event to the CEP. Lacking any experience, I mimicked
Billy Hudson in my presentation. As time evolved, the containment prospectus
preparation and presentation became my task, with a lot of support from my
colleagues.</p>

<p class="tab">We continued on with the
USGS supplying our geologic packages until about 1974 or 1975, somewhere along
in there. That relationship was not always comfortable for the USGS people up
in Denver, because we didn't know, in the early days, what we really wanted or
needed. So, those guys didn't know quite how to respond to our needs. As a
result, we had some interesting meetings, hosted by the Lawrence Radiation Lab,
about things like grain density - what did we need to measure in grain
densities, and how should we do it? Should we use the air pycnometer, or should
we use this other kind of trap, or what? And what should we expect in alluvium,
and what should we expect in tuff? And how about the lavas in Pahute Mesa? So,
there were problems in determining data needs.</p>

<p class="tab">Then, in late 1974 the
USGS made an incredibly gross error in the assessment of a Paleozoic scarp
location near a hole in Area 4. That caused us to have to drill a special
exploratory hole, do sidetracking, and so on. The J Division management,
Brownlee in particular - as an aside, Brownlee had been moved on from being the
J-9 group leader to being an associate or assistant division leader in the J
Division office - decreed that J-9 should hire a geologist, and diminish our
dependency on the USGS.</p>

<p class="tab">Where were we going to
get a geologist who knew anything about the Test Site? Well, we had Fenix and
Sisson geologists who supported Los Alamos as our “well-sitters." They sat
the emplacement holes, or the exploratory holes, as they were being drilled on
the Test Site. So we thought, “Let’s pick the guy assigned to Los Alamos, and
let's hire that guy. He's got to know something about the geology of our test
holes."</p>

<p class="tab">We hired a young man
named Mike Ray from F&amp;S. Mike came to work with me, and we then hired a
geophysicist to do well-log analysis on the Birdwell logs supplied to us.
Gradually Los Alamos developed enough of a geoscience capability that we were
able to tell the USGS that we didn't need their geologic packages anymore, because
we were going to do that in-house.</p>

<p class="tab">We, I think, separated
ourselves from the USGS without acrimony. I think, quite frankly, the Survey
was relieved to get out of that production mode. That's not their cup of tea.
They are primarily a research organization, and they don't like to be called
and told, “Look, we needed this yesterday. Where is it?" And then to be
called back and told, “Well, we got it, but it's not right. Now you need to do
this, and that." There weren't many of those occasions, but still, that
didn't fit the Survey's view of themselves.</p>

<p class="tab">So, here we are in the
mid-seventies now, and we have our own geosciences capability. House is making
all the presentations and writing all the documents, and so forth. That went on
until 1979, when we changed Lab Directors. Harold Agnew left the Laboratory, and
Don Kerr, a former J Division staffer from years before, took over as Director.
One of the very first things he did was to dissolve J Division, the field test
organization. He spread out the groups that were in J Division to other
divisions, such as WX, weapons engineering. Then they looked at the containment
group and said, "What shall we do with these guys?" Well, Brownlee
was then the geosciences division leader, and that seemed like the right place
to be. We do geoscience stuff, and Brownlee is known in our Laboratory as the
father of containment at Los Alamos, and so let's put these guys, the J-9 guys,
over there in G Division, and call them G something or other.</p>

<p class="tab">I've forgotten why they
chose to dissolve J Division. It was much to the dismay of the people in J
Division. We all ended up working for other existing divisions in the
Laboratory. The diagnostic guys were all put in the Physics Division, and they
were called the weapons physics guys. The field engineering and rack design
guys were put in WX, under a management they had not previously been associated
with.</p>

<p class="tab"><b>Kunkle</b>: I was
hired by J-9, but when the paperwork was done the group called itself G-6. By
the time I showed up in 1980 it was calling itself G-S. According to rumor that
was because Don Kerr, the then Director, decided to get rid of J Division, the
field testing division, in the fall of 1979 because he was concerned that a comprehensive
test ban would soon be enacted, and a field testing division would be something
easily clipped out of the budget. So he decided to - I wouldn't say hide -
submerge those activities in other divisions. One of the divisions created, an
artificial division, was G, the Geology Division, and Bob Brownlee became the
division leader of that.</p>

<p class="tab"><b>House</b>: Actually, J-9,
the containment group, came out best, because we were re-associated with our
former boss, and that worked out reasonably well for us, and for the
containment organization.</p>

<p class="tab">There were three
supporting groups, discipline oriented. There was geology and geochemistry,
geophysics, and something called geoanalysis, which we just called computer
jocks. So we were in some common organization which has metamorphosed through being
called Geosciences, then Earth and Space Sciences, to now being called Earth
and Environmental Sciences.</p>

<p class="tab">Then the Containment
Project Office was created, and I was named as the Deputy Project Leader. In
late 1980 the gentleman who had lasted but eight months as the Principal
Project Leader decided to seek other employment, so he bailed out and went to another
division which had nothing whatsoever to do with containment. As a result of
that Bob Brownlee called me into his office one day and said, "I intend to
make you the Containment Project Manager." I was either too stupid, or too
stunned, to say no, and so that became my task, in addition to making the presentations,
and writing the documents, and all this other large load of responsibilities.</p>

<p class="tab">After two or three months,
maybe as many as six, I went to Brownlee and said, "I can't do all this.
It's too much." He said, "Well, what do you want to do then? How do
you want to structure this?" I said, "I want to follow Livermore's
model of having containment scientists, or event managers. I want to make a selection
of people, and for openers I'll pick Fred App, who's one of our CEP members,
and Eric Jones, and Nancy Maruzak, and we'll make them into containment
scientists. They will be responsible for the event from the time I assign it to
them, and we layout the parameters for it, with the yield and the location. And
they'll carry it through the presentation, and ultimately the post-shot report,
to the Panel." Brownlee said, "Okay, we'll try it," and so we
did.</p>

<p class="tab">And that's where we are
today. except with far fewer people. At one time in our glorious past, which,
as I recall, was fiscal year 1984, the Containment Program had 34 FTE's, which
represented about 42 to 45 actual personnel. That was pretty big, and it was pretty
much paralleled by our colleagues at Livermore in their containment program.</p>

<p class="tab"><b>Brownlee</b>: When
the containment groups were large, and even before, there were a good many
opportunities for Los Alamos and Livermore to work together toward common
goals. There were also many opportunities for disagreements. At any given time,
both kinds of activities were on-going. It was therefore possible to believe
that no cooperation ever occurred, or that good togetherness was possible,
depending upon just where one happened to sit. I happened to have one foot in
each activity, and remember a few occasions when Los Alamos asked certain
questions that caused some difficulty for Livermore in public meetings, yet the
result enhanced certain arguments that Livermore's containment people could not
win at home. So, some debates were based on what I will call a "non-obvious
agenda".</p>

<p class="tab"><b>House</b>: A sidelight that I would like
to bring to your attention is the incredible acrimony that existed between
Lawrence Livermore guys and Los Alamos containment guys in the early, if not
almost all the way through, the seventies. It seemed to be initially precipitated
by two adversaries across the table, who shall remain nameless, who got into a
shouting match one day at a CEP meeting . I remember it as well as if it were
last week. Those two gentlemen were summarily removed from the Panel by the
Chairman. One of them, by his choice, no longer works at Livermore, and the
other one, by his choice, is retired from Los Alamos. But for a long time there
was an incredible acrimony; there was a real bad - them guys at Livermore, and
vice versa - attitude.</p>

<p class="tab"><b>Carothers</b>: I know
the two gentlemen to whom you refer. I remember the situation, and I did remove
them from the Panel. I must say I had a little difficulty with Los Alamos. I
talked to Brownlee first, and he was understanding of my position. Then I got a
call from Dr. Charles I. Brown, who informed me that the Los Alamos Scientific
Laboratory would decide who would be their representative on the Panel, and that
was not something that was within my purview. I explained to Dr. Brown that Los
Alamos did not have a representative on the Panel; that was not the way the Panel
was constituted. The Laboratories, and other organizations, nominated people
they felt were reasonably expert in the field, and subject to the Manager's
approval, and mine, those people could serve on the Panel. Anyway, I won.</p>

<p class="tab"><b>House</b>: Yes. I
noticed that you did, and I have remembered that. And, quite frankly, the
tension level was reduced dramatically as a result of that change of personnel.
Anyway, to carry on with this, and not to beat a dead horse, it wasn't until
Larry McKague became Livermore's containment project leader, then succeeded by Frank
Morrison, that we started working together to try to reduce this tension and
acrimony. I remember Carl Smith sitting at the CEP table one day and commenting
about the acrimony that apparently existed between the two Labs. That caused me
to think about how we could defuse this. We were viewing the attitude of our containment
colleagues at Livermore as a "hassle LASL" attitude. I thought that
was no good, and that we ought to do something to fix that.</p>

<p class="tab">The first real case of a
friendly gesture was when the late Frank Morrison invited me out to sit in on a
Livermore pre-CEP meeting. This was absolutely unprecedented! Sit in on a
pre-CEP? That's inviting the enemy into your camp; the fox into the hen house.
But I went, and it was great, although I was a little uncomfortable, needless
to say. Then after the pre-CEP, that evening I was invited to Frank's home, and
he had some of the Livermore containment folks over for dinner. That was what
really broke the ice, I think. After Frank's tragic demise I continued to work
with his successors, up to and including Norm Burkhard, the current program
leader. We have, I think, maintained a much better attitude. We don't hold hands,
per se, but we do talk to each other, and when the Laboratories independently
review each other's containment prospectuses prior to presentation to the CEP
we try to air all our dirty laundry, behind the scenes and before the CEP
meeting, so we don't get in there and have one of these acrimonious activities.</p>

<p class="tab"><b>Carothers</b>: Do you
think that's proper?</p>

<p class="tab"><b>House</b>: The
reviewing of each other’s shots? I think that's a very important part of the
checks and balances that seems to be built into the containment community. And
of course you must understand, it doesn't exist just between the two
Laboratories. We get comments from the USGS, whose primary focus is on the site
characterization package. When Russ Duff, of S-Cubed, was on the Panel, he
would call me up with a concern, and we would discuss it. Sometimes it was a
simple question that needed explaining, and perhaps Russ didn't feel he might
want to raise it in the forum of the CEP, but he really wanted an answer. As
far as the two Laboratories looking over each other’s shoulders, and as one wag
has been known to say, "keeping each other honest," I think it's a
very important part of the way we do business.</p>

<p class="tab">There have been
occasions when either Lab has served notice on the other one's event, via the
prospectus mode and response. "Maybe you guys ought to look at this,"
or "Have you really calculated that, and do you really believe those
numbers?" So I think it's incredibly important, and it's been something
we've continued. The way it works is quite simple. We transmit the prospectus
to the containment community, and of course the other Laboratory is included,
and we expect a response within a week or two. It usually comes as a FAX, and
is prepared by one of the principal containment members of the organization. In
many cases it's the CEP member, like Cliff Olsen at Livermore, or Tom Kunkle at
Los Alamos. And there will be questions and comments on the event. And then we
interact, and it's most helpful.</p>

<p class="tab"><b>Carothers</b>: Then
why do you need a CEP? And I do not mean that as a frivolous question.</p>

<p class="tab"><b>House</b>: No, I
don't take it as such. Why do we need a CEP? The Panel represents a rather
broad scientific experience base. Hydrologists, geologists, radiochemists,
people who are well versed and have expertise in the calculational side of the
house, and people we might refer to as phenomenologists. These folks are
looking at the sponsoring Laboratory's containment plan from, hopefully, an
independent viewpoint. So you have nine or ten individuals reviewing and
discussing and questioning the plan of the sponsoring Laboratory. It provides a
review that is, in my experience, unparalleled for plans of operations that are
going to go forward, especially with something as critical as an underground
nuclear test.</p>

<p class="tab">The Containment Panel
review has a distinct ES&amp;H aspect to it. Back in the days before Admiral
Watkins we didn't call it ES&amp;H, but it certainly is environment, safety,
and health oriented, and it's a big part of the whole thing. There have been
occasions when the sponsoring Laboratory had an event reviewed by the
Containment Evaluation Panel, and has had to step back and say, "Well,
maybe we didn't do this quite right. Maybe that hole isn't suitable for that event."
And so, appropriate steps and responses are taken. Once again checks and
balances are in play.</p>

<p class="tab"><b>Carothers</b>: There
are some people who feel that the process has gotten to be pretty cut and
dried, and that it has become a kind of ritualistic process that you have to go
through. And that the CEP doesn't really do much, other than providing a public
facade of reviewing the Laboratories' and DNA's activities.</p>

<p class="tab"><b>House</b>: I think
you would find, if you ask any seasoned member of the containment staff at
either Los Alamos or Livermore, or at the DNA, they would strenuously object to
that. To some it may seem like a rote process, where you go to the Panel, and
you stand up and you present the standard set of viewgraphs, and you make the
standard apple pie and Chevrolet arguments. But the fact remains that you are
having your containment plan reviewed by, not a peer group, but a group of
experts in the field of underground testing. While it may seem like the same old
stuff, every time we go to a Containment Evaluation Panel presentation, granted
it is repetitive, you will find that each containment scientist is extremely sensitized
and concerned about the design they have put together. And not just to get it approved.</p>

<p class="tab"><b>Carothers</b>: When a
person does a presentation, in front of friends and peers from his or her own
Laboratory, and people from a couple of other, may I say possibly competing
organizations, and from various other places, there are going to be questions
about various aspects of the plan. Basically that person doesn't want to look
stupid. I wouldn't want to stand up there and make a fool of myself.</p>

<p class="tab"><b>House</b>: I know
what you mean. I've been there, Jim. But consider this. Both Laboratory
containment staffs have what we call pre-CEP meetings. Or you could refer to
them as dry runs for the presentation. The way we like to view it is that it's
a heck of a lot easier to take flak here at home, from your peer group, and be prepared,
and be able to answer the majority of questions that presumably might be posed
to you, versus doing it in front of the Panel. I likened the CEP presentation,
to Brownlee, and mind you this was back when I was doing them all, in many
cases one a month, especially during the high yield test series in '76, to be
like defending your doctoral thesis once a month.</p>

<p class="tab">It's a pretty stressful
situation, and sure you don't want to look bad, and sure you'd like to get your
event properly categorized and approved. But by golly, when push comes to shove
and the Panel, as a whole, or as an individual Panel member, finds something
that is unsuitable, whether it isn't understood, or what have you, we better to
step back and take another look rather than try to move forward with something
that might cause a problem at shot time.</p>

<p class="tab">And, you don't want to
present something that might not make it through the detonation authority
process. I can remember one time when the Chairman's recommendation to the
Manager, and the Manager's subsequent forwarding of the detonation authority package
back to Germantown didn't guarantee the event was going to get approved by
Headquarters.</p>

<p class="tab"><b>Carothers</b>: It has
happened once only that the DOE Headquarters has refused the Manager's request
for detonation authority. That was for the Kawich event, and I consider that to
have been an embarrassing failure on my part. I went to the Manager and apologized
for having put him in that situation.</p>

<p class="tab"><b>House</b>: Well, it
is an awful feeling, and as I said, I have been there, to stand up in front of
the Panel and get put on the run. Once I got a post-presentation viewgraph from
my Livermore colleagues about the “wounded rabbit" syndrome. Or, to have
an event come up to categorization and have someone on the Panel give it a dissenting
vote. It stops everything dead in the water.</p>

<p class="tab">The DNA took a different
route than the Laboratories In approaching the problem of containment. They
were doing both vertical and horizontal line-of-sight shots, with limited
success in containing the radioactive products of the detonation. And, like the
Laboratories, they were losing experimental data. Joe LaComb, DNA, had much of
the responsibility for the way the events were designed and constructed, but he
had no person designated as responsible for containment.</p>

<p class="tab"><b>LaComb</b>: By 1966
we cared about containment, and I cared about it, because it was the same as it
is today. If we don't keep all the detonation products in close we don't
accomplish what we want to accomplish. We lose our experiments. On Double Play,
which was in June of '66, after we had problems with Red Hot in March, Discus
Thrower in May, and Pile Driver in June, Jack Noyer came out and said, “How long
will it take you to build an overburden plug?" So, we built an overburden
plug in five days. We put that plug in because our containment record wasn't
very good. We already had a gas-seal door in the drift, so when we ended up we
had, in general, the same kind of configuration we do nowadays, although we
didn't have a lot of the things we do now, like cable gas blocks. That plug was
strictly for public safety and health. It wasn't going to help our experiments
at all.</p>

<p class="tab">I don't think at that
time DASA had anybody who was designated as the person to be concerned about
containment. There wasn't really anyone who was given that responsibility,
other than Jack Noyer. Being the kind of person he was, he tried to worry about
it all. A person I listened to was Wendell Weart, from Sandia. He was the one
who came out when we had questions regarding how should the stemming be placed,
should the hook drift be left open or should it be backfilled - those kinds of
things. Mel Merritt was another one who helped.</p>

<p class="tab">It was about that time
that they started doing calculations with a bunch of folks who were with
General Atomics. It started out with some GA folks involved, and there was,
right after Double Play, some RAND people involved. For Door Mist, in '67, it
was those contractors who were doing the calculations, and were saying we want
this kind of grout with this kind of strength, and so forth. As far as the
overburden plug and the gas-seal door went, that was more or less our
engineering problem. There were no real criteria.</p>

<p class="tab">So, there wasn't anybody
in DASA, in the Door Mist time frame, in 1967, saying it was this or that, that
DASA wanted. The contractors were saying, and saying more or less directly to
myself and the Test Group Director, "This is what DASA wants."
Somebody said they wanted a plug, or particular kinds of grout, but it wasn't
my job to define those things, only from the standpoint that I tried to make
sure we got the materials that the" experts" thought they wanted.</p>

<p class="tab">Right after Door Mist,
where we had more problems, Noyer told me, "That won't happen again.
You're going to take care of this." I said, "Yes sir." We could
see we were going to have to pay some significant attention to protecting the
experiments, and to stopping leaks. So, after Door Mist, for every test I sat
down, and I wrote out the criteria for the grouts; what the velocity should be,
the strength should be at least this, and so on. And I set down criteria as to
how things were going to be done, and what should be done. I worked fairly
closely with the people doing the calculations, although I didn't understand
what they were doing, at that time.</p>

<p class="tab">It was, in our program,
always a constant threat that the people funding the experiments would decide
that the possibility that they would lose a lot of their data was too big to
take a chance on. That's one of the reasons DASA tried to turn things around so
rapidly after the four in a row in '66. I don't think it was so much a big
concern about the fact that we were releasing a little radiation to the atmosphere.
It was the loss of the experiments, and our credibility. I think that has
always been a factor, and still is.</p>

<p class="tab">About that time we
formed what we called the Stemming And Containment Panel Junior, or SACPAN
Junior, which was a working group. It was a real mixture. There was Court
McFarland from headquarters DNA, who was an aeronautical engineer, but very interested
in materials behavior. There was Ben Grody, who had a doctor's degree in
geology, and Bob Bjork, who was, and is, an excellent physicist, myself, and
Jerry Kent. That group, in my opinion, really turned our containment program
around. I think that group was the real foundation of the DNA containment program.</p>

<p class="tab">When Baneberry happened
we were working on Misty North. We were also getting ready to field Diagonal
Line. We had to go and present a risk-benefit analysis for the Diagonal Line
shot to get permission to fire it, because some guy named Jim Carothers, on the
Panel, said it was going to leak. Actually that turned out to be good, because
it did leak, and we had gone through it, and they had okayed it with that
possibility in mind. So, they weren't surprised. We also had to do that for
Misty North, because there wasn't a whole lot of confidence. Fortunately, that
one contained.</p>

<p class="tab">We also had the
presentations we had to make to the CEP, and there were problems with some of
the early shots when we presented our material, in getting our ideas across
about what we were trying to do. I was talking to Carl Keller one day, and we
were kicking ideas about this problem back and forth. He said something about
vessels, and I said, "You know, it might be worth thinking about
that." So, it was when he and I were talking that the seed was planted, I
think. I decided there had to be a logical way to present this material, so you
could say, "That will be coming in this section here." So, I sat down
and I said, "Okay, we've got three vessels, nested together, and each one
backing up the ones inside it." So, I started writing up the presentation
based on the three vessel concept. I made out the outlines, and then went back
and started writing how you would do it. They're still using some of the same
words today.</p>

<p class="tab">In '74 DNA hired Carl
Keller to be the Containment Scientist, and early on he began to develop an
experimental and calculational program to try to understand some things about
what was going on. Through the years, thirty to forty percent of our effort
with Pac Tech and S-Cubed has been in research, to do something new and different,
to find out something. We've got to do our production work that's associated
with the test, but it's essential to me that we still keep enough effort in
there to try to find out if there isn't something there, something we're
missing. I always have the feeling there's a shadow lurking around the corner.</p>

<p class="tab"><b>Keller</b>: When I
came to DNA I think the title of the position was Containment Scientist, and
there was a job description associated with that, as the Civil Service
requires. That job description had been developed by Jay Davis, my predecessor
at DNA by more than a year, and by the Director of the Test Directorate. This
was a new job description, with their new concept of what the Containment Scientist
ought to be doing.</p>

<p class="tab"><b></b>At that time DNA had numerous
problems, and they had decided that they needed a heavier gun in the
Containment Scientist position. They upgraded the position from a GS-14 to a
GS-1S, which meant they could offer more pay. I know that they had solicited
several senior people in the containment business to take that job - people far
more senior than I was. Those people, I suspect, were already above that pay
grade, and probably well established in the Laboratories. I wouldn't say I was
the bottom of the barrel, but I was certainly not their first choice for the
position.</p>

<p class="tab">It was an interesting
environment at DNA. They hadn't had any recent leaks, but they had had some real
encounters with the Containment Evaluation Panel. I remember one of their
presentations to the Panel where they had decided not to present any of the mechanical
closures, because they felt those were only relevant to sample protection.
Therefore, the DNA people who were presenting the event refused to present any
details about the closures, because that was irrelevant to containment. Well,
the Panel refused to categorize the shot, because they thought the closures
were relevant to containment. Then Phil Opedahl, who was the Test Group
Director on that event - I believe it was Husky Ace - stood up and said,
"Just a minute. Mr. Chairman, could we have a short recess?"</p>

<p class="tab">After the recess it was,
"We'll provide you with any of the information you want." It was
pretty clear where the concept that the mechanical closures were not
containment features came from, because for many years thereafter Joe LaComb
still insisted that the MAC's were not containment features. I never agreed
with him on that point, and so we always described them fully in the CEP documents.</p>

<p class="tab">One of the concerns was
that it handicapped the Test Director to have all these non-containment
features included in the containment presentation. But it was decided by the
Panel that those features were important to containment. And the Panel was right.
You can say with confidence that after Mighty Oak those features were thought
to be very important. So, that's an old concept that's been abandoned, but I
don't think DNA totally abandoned it until a couple of years ago.</p>

<p class="tab">When I came to DNA their
containment program was really being managed by S-Cubed. There was no
Containment Scientist, and had not been one for over a year. DNA was doing as
well as they could with the few military people they had, some of whom were quite
new to the business. I wouldn't say they were desperate, but they were really
being controlled by the contractors. DNA had very little in the way of
technical capability in-house, so they really relied almost completely on their
contractors, and S-Cubed was happy to step in and supply all the advice the DNA
needed.</p>

<p class="tab">For me it was a totally
new environment, dealing with contractors, because when I was at Los Alamos
contractors were considered second-class citizens; rude, mercenary, science-for-hire
kind of people. They are still mentioned with a sneer. It was at DNA that I
discovered that contractors did offer far more than you'd ever believe from the
way they were considered at Los Alamos. I found they really were responsive,
partly because you controlled the purse strings, but also because they were
very capable. My whole staff was essentially contractors, and over the next ten
years I gained a great deal of respect for them.</p>

<p class="tab">The whole concept of
contracting for support does isolate you a bit from your staff, but you do
define what the deliverable is to be, and what the price will be, and what the
schedule will be. I found that I got results from the contractors much more
predictably than, say, a program manager at Los Alamos would get from his
staff. That's because his staff might be scattered all over the Laboratory, and
he was always competing with other programs in the Laboratory for the attention
of those people he needed.</p>

<p class="tab">I found I very much
enjoyed the contracting process as a way of doing a program. It really worked,
and we got a lot of good results, though I was always worried when the
contractors agreed with me. Was it because I had control of the money, or was
it because they thought I was correct? And I was never sure.</p>


<a name="ch5"></a>
<br><br>
<h2>Chapter 5: The Nevada Test Site</h2>
<br>

<p class="tab">
During 1948 and 1949 a committee headed by Lt. Gen. E. R. Quesada developed a list of
five potential sites that might be used for continental nuclear tests. The
candidates were the White Sands Proving Grounds in New Mexico, Pimlico Sound in
North Carolina, Dugway-Wendover Proving Grounds in Utah, an area between Fallon
and Tonopah in central Nevada, and the Las Vegas-Tonopah Gunnery Range in
Nevada. In 1950, after the approval by President Truman of continental testing,
some 1360 square miles of the Gunnery Range were turned over to the AEC for the
conduct of nuclear tests. The Nevada Proving Grounds, now known as the Nevada
Test Site, currently has an area slightly larger than the state of Rhode
Island, and lies some 70 miles northwest of Las Vegas.</p>

<p class="tab">There
are various criteria which could be used in the selection of an area to be used
for nuclear testing, the importance of each of which would depend on the
judgment of the person or persons making the selection. Remoteness from
populated areas, availability of air, rail, and highway transport, security,
and so on are important criteria. Another thing that would be of importance is
the type of nuclear tests to be conducted, or which might be conducted,
although that did not appear to be a factor in either the selection of the
Pacific Proving Ground, or the Nevada Proving Grounds. Enewetak and Bikini, for
instance, were too small to do experiments to explore the effects of the
detonations on structures or military hardware, Crossroads notwithstanding. The
possibility of underground detonations was not considered when the selection of
the Nevada Proving Grounds was made.</p>

<p class="tab">What
would be the geologic characteristics of a suitable site, where underground
detonations were to occur, and the radioactive products were to be contained?</p>

<br>

<p class="tab"><b>Brownlee</b>: I'm of the opinion that we have
not actually had to address that problem, thanks to the fact that we are where
we are. In other words, we were blessed, in a sense, by being put down in a
place not of our choosing; the Nevada Test Site. We have made the best of that
without having the freedom of choosing where in the world we'd like to go to do
the best underground testing.</p>

<p class="tab">As we've understood from
the Soviets, and from the French, and from anybody else who's tried to test,
we've had a wealth of different sites and different media, with opportunities
for different kinds of tests. If we want to test in granite, we can; we don't
have to go to North Africa. If we want to test below the water table, we can.
If we want to test above the water table, we can. We can test in various kinds
of alluvium, and in various kinds of tuff. Most places in the world are not
blessed with all of those opportunities. So, without having had any opportunity
to select the site, we have been lucky, if lucky is the right word, in being
able to find a great variety of media within the confines of the Test Site.</p>

<p class="tab"><b>Carothers</b>: Do you
mean that if in the fifties someone had said, "We want you to test
underground. And, not one atom out. Pick a good spot, in the United States, and
you can have it,” we probably wouldn't have picked a place as good as the Test
Site?</p>

<p class="tab"><b>Brownlee</b>:
Absolutely. If we had used our heads we would have been in terrible trouble. We
were very slow to learn all of the different opportunities we had for the
different kinds of tests that we wanted to do. For example, did we want to mine
a big room? At the Test Site we could. Did we want to do something and throw a
little dirt on it? We could. Did we want to lay something out on the surface
and shoot it? We could. We could do that because in those very early years we
were sufficiently removed from anybody that we essentially had everything
around us, and a long way around us, under our control, with a few exceptions.</p>

<p class="tab">When we went underground
the number of milk cows in the fallout pattern we might have would sometimes be
three, or six. The number of people for whom you would have to provide the
means of evacuation, were that to be needed, would be twelve, or twenty. What's
happened with the Test Site since those days is that people have moved right to
the boundaries of the Test Site, and there are literally hundreds and thousands
of everything and anything. But people see the Test Site as it is, and they
don't understand that it was selected as it was.</p>

<p class="tab">Early, it seems to me,
we had an emplacement hole and we used it. Even after Baneberry we still used
the hole that was there. We had them stockpiled, and we tended to use them. It
took us quite a little while after Baneberry before we really selected a site
we wanted for the shot. I think it's only in relatively recent times that the
containment people have had some input, really, as to which hole they wanted
for a given shot. There are times when we will have a deep hole, and shoot near
the top of it. That deep hole was drilled for something else, but we make use
of it. I can find all kinds of examples, still, where we don't select the site
as logically as we are able. We do things in tuff that might better be done in
alluvium, and so forth.</p>

<p class="tab">There is one other
thing, and that's the water flow. I think it's bad business to get plutonium
into an aquifer. It happens that at the Test Site the water doesn't go
anywhere. To the first approximation, it just sits there. Al Graves didn't know
that either, when he selected the Test Site. And so from a radiological point
of view, a hydrologic point of view, the Nevada Test Site is peculiarly able to
support testing.</p>

<p class="tab">On the other hand, on
two or three occasions we've found debris from shots at places that we had no
expectation of it being. That tells me it's entirely possible that things are
going on down there for which we have only had an occasional whiff. And that we
are not anything like as knowledgeable about the water flow as we think we are.</p>

<p class="tab"><b>Carothers</b>: I have
talked with the folks who calculate what might occur in different types of
rocks, if you were to shoot in them. They don't like very hard rocks like
granite because of the tensile cracks that show in the calculations. And they
don't like very weak rocks because they don't sustain the residual stress
fields thought to be important for containment. Something like tuff or alluvium
turns out to be just about the best you can do. Isn't that surprising? Believe
the calculations or not, they imply that if we were in some other site it
probably wouldn't be nearly as good.</p>

<p class="tab"><b>Brownlee</b>: We
couldn't have possibly done as well, because I don't think there's any other
place that could be as good. Now, that's said out of ignorance too, but let's look
at Pahrump, which was actually considered. The whole history of the world would
have been different. The water table there is so high that all of our testing would
have been different, and we would probably have had the Russian experience of
having something come out from each test. Or we'd have spent so much money that
we couldn't have afforded it. I bet you anything that if we had started out
testing in Pahrump either we would have abandoned it, or we would have still
been there and, for example, we would never have had room for the British. All
kinds of things would have been different. It's really true, I think, that the
selection of the Test Site actually was a branching point in history. We took
that new road without ever knowing why or what we were doing, but I feel it was
a very fundamental action.</p>

<p class="tab">As an aside, we are in
the process of losing the Test Site for underground testing, and no one seems
to know or care. The majority of the NVO budget is now devoted to things other
than underground testing. And their interests are in Waste Management and
various other kinds of things. They don't mind bringing in all kinds of people,
and building new things, and doing new experiments. They would sell off any
part of the Test Site to keep NVO green, and they have so cluttered up the Test
Site with other kinds of activities, which are now sacred, that it's
increasingly difficult to get a shot off.</p>

<p class="tab">And you haven't seen
anything yet. I actually challenged one of the Assistant Managers at NVO a few
months ago, and said, "I believe the biggest threat that we have to the
Test Site is NVO. It's not the people on the borders. It's not Las Vegas. It's
not the anti's. It's ourselves. We're our biggest enemies." I didn't know
whether I could get away with saying that, but he pondered it a while and said,
"I see what you mean, and I believe you're right. We really have plans for
doing all kinds of things." They're preparing for a moratorium, and so
they're going to do all kinds of things.</p>

<p class="tab">They imported a lot of
activities during the last moratorium. And when we go into another test
moratorium, which I figure will come one of these days, I don't believe we'll
ever go back to being able to use the Test Site again. I've said what I think
are the characteristics of the Site that are to our advantage, and I believe that
there is hardly anybody in NVO who understands them. They do not appreciate
what they have. They do not appreciate what it means to have such a place.</p>

<p class="tab">I believe that as long
as there's a nuclear stockpile we have to have the ability to address questions
which may arise. That might be continued testing, or it might not. It might
mean a nuclear test, or it might not. I'm talking about questions which may
arise, and we have to have a place where we can go to answer them. Nowadays, I
visualize that being underground. Even chemical experiments could be
underground, and not on the surface. We need a variety of ways to be ready to
answer a variety of questions. So, we need alluvium, and granite, and tuff, and
shale, and dry, and wet, and space, and mesas, and valleys. We need it all,
because we do not know which part of it we can give up. I believe we will have a
nuclear stockpile for at least the next four decades. Forty years. I can't
conceive of getting rid of it in less than forty years’ time. I would like to
think we can, but I can't believe that we'll be able to do that.</p>

<p class="tab">If you look at what's
happened at NTS in the last forty years, it's an exponential curve. And if we
have any kind of a moratorium it will get worse. With Baneberry we stopped
testing, and at the end of six months, every week we delayed it was harder to
start. We almost didn't get started up again; it got harder and harder as time went
on. I think that if there is any kind of a moratorium, it will be that way
again. And so, I almost despair over the loss of our Test Site, because I think
it's happening, and NVO couldn't care less because they have no appreciation of
what I've been trying to say.</p>

<p class="tab">I shouldn't say,
"no appreciation" because I've been lecturing to them, and waving my
arms at them, and writing things down and showing it to them. But it doesn't
take. After all, we don't have to pay any attention to what Brownlee's saying.
We've got this waste management program, and the President has said, Secretary Watkins
has said, "We've got to clean up. That's the urgent thing." So, NVO
is no longer interested in stockpiles and testing; that's just way down on the
list. You noticed in the memo we got from Watkins, where he outlined all the
things DOE did, that he never once mentioned nuclear tests at all? It's not
listed in his long list of things that had to be looked at. Nuclear test is not
mentioned. So, the DOE has little appreciation of what I'm saying.</p>

<p class="tab">And what's worse,
neither do the Laboratories. This question that you've asked me about the Test
Site I think is an exceedingly important question. We ought to recognize what
the Site means to us, and I think we don't. Notice that I've said,
"Despite all the opportunities we've had to use it cleverly, we
haven't." And now I'm saying, "Even though we've learned as much as
we have, we're getting ready to throw it away."</p>

<p class="tab">That's the reason why I
spent quite a few months writing a document on the preservation of the Test
Site. And I got Troy Wade to finally enunciate the DOE policy on the
preservation of the Test Site, which in effect says to NVO and ALOO that any
decision made about the day-to-day operation of the Test Site has to be made with
the idea that we're going to preserve it for testing. I was hoping by that
means to get something down on paper which then I could wave in NVO's face,
saying, "When you bring in these rug merchants, that is contrary to
the policy of the preservation of the Test Site."</p>

<p class="tab">But doggone it, there is
something kind of sacred about the Test Site nowadays. Put away the
conservationists, and the preservationists, and the purists. We have done some
things there that are special in history. They are. In the history of the
world, a thousand years from now, that's going to be something kind of special.
We ought to have that in mind as we act, but our concern is only this year's
budget. That's all. And we ought to be bigger than that; we ought to be
thinking more broadly than that. I'm saying, "Here we have the Test Site.
We could use it much more cleverly than we do, but we're only interested in the
current budget with this fiscal year's shots. That's our only concern, and
therefore, we just do things as they come." I think that's a grave
mistake. I doubt that we will ever do it any other way because that's the way
our government is, and that's the way we are. But I wish it were otherwise, and
I would like to really understand more about containment by doing things of various
kinds at the Test Site.</p>

<p class="tab">Another point I want to
make. I only learned in recent years that when it comes to space you don't need
a nuclear test to affect it. You can seriously affect space with just a little
bit of energy. If you have what the United States government assumes is empty space,
a vacuum, it doesn't take very much mass there to change it. Actually, the
United States government is mistaken, because it's not empty at all. It's
already cluttered up with a lot of things, and so when we put something else up
there and put a little energy there, it interacts with the stuff that's already
there that we've put there. This is not appreciated. Well, I believe it's a
grave mistake to do experiments in space that can be done underground, or in
tanks, or in other places. And the NTS has the capacity to allow us to do many
space-like experiments. Now, they say, "Oh, you can't have a
mountain that will hold a vacuum." A lot of the key questions that you
need to answer in space are not those questions, and they could be answered
easily in Nevada. So, I think we ought to preserve the Test Site for space
research, strangely enough.</p>

<p class="tab"><b>Carothers</b>: That does seem strange.</p>

<p class="tab"><b>Brownlee</b>: But let
me use this analogy: I said we originally thought of using the Test Site on the
way to the Pacific. I think we ought to use the Test Site on the way to space.
And so I'm not really talking about space experiments, I'm talking about some
stepping stones on the way there. And for reasons that are lost to me, there's almost
nobody who understands that yet, although I think they will in time.</p>

<p class="tab">DNA is leading us there.
I think they're leading us in that direction, and eventually these things will
occur to people. Now, when they do, will the Test Site be available? I'm afraid
it won't be, and so that gives me grave concern.</p>

<p class="tab">What I'm doing here is
taking an exceedingly broad view, and I know that. Let me summarize all this up
by saying, "I think we need to look at the Test Site with much broader,
much wider-angled glasses than we have the habit of doing." I feel very
strongly about that, but unfortunately I can't convert anybody.</p>

<br>

<p class="tab">From
the first detonations at the Test Site in 1951 until 1957, when the first
underground shots were fired, the geologic structure of the Test Site was of little
importance. There were a number of air drops, devices were placed on towers,
suspended from balloons, fired on the surface, and two that were emplaced at
the modest depths of 12 and 67 feet. The only information about the geology that
was required was enough to allow the design of the footings for the towers.</p>

<p class="tab">In
the Plumbbob operation in 1957 the first underground events were fired. It
began to matter what lay beneath the surface, for the tunnels that were being
dug and the emplacement holes that were being drilled.</p>

<br>

<p class="tab"><b>Twenhofel</b>: In the early days there were
two aspects of Survey work here. One was ground water contamination. What was
the water table like, and where was it. So there was some drilling done, and
ground water testing. The contamination of water was the impetus for that. The
other thing was mapping. There were some early explorers who came through the
country, and there were geologists attached to them sometimes, so there was a
general knowledge of the Test Site area. There had been some mining in this region,
but there were no geologic maps. The first overall report on the geology of the
Nevada Test Site was done by two geologists named Johnson and Hibbard, who were
assigned out here with the Army. That was probably in about 1952. No
comprehensive study had been done until those two Army guys mapped the Test
Site.</p>

<p class="tab">On their map they
plotted the kinds of rocks that occur at the surface. If the rocks dip at an
angle, you plot on the map that dip. You end up with a map that shows the
occurrence of the various rocks that you can see at the surface. You have to
have a good base map so you know where you are, so you can be relatively
accurate about where the various formations are. The U.S. Geological Survey
published that report later, (Geology of the Atomic Energy Commission Nevada
Proving Grounds Area, Nevada, Geological Survey Bulletin 1021-K) when the
interest in underground events began to grow.</p>

<p class="tab">The first thing that
happened when the underground program began to materialize was that the USGS
said, “Well, we've got to have modern topographic maps." Those are the
quadrangle maps that are used today. So, that part of the USGS which is called
the Topographic Mapping Division flew the area for aerial photographs and then
made the topographic maps. Those were done, and the next thing was to map the
surface geology on the new topographic maps. It was in the late 1950's to early
1960's when the geologic mapping was done. And, they're the maps that are still
used today.</p>

<p class="tab"><b>Orkild</b>: In '58 we
opened an office in Denver, and that same year they said, “Ah ha, you're a
photo-geologist. We have this big Nevada Test Site out there. We want you to
analyze the western part of it, using photos." I said, “All right,"
never having looked at volcanic rocks before, but sure, we can do anything. If
we can find uranium, we can find volcanic rocks. So that's how I got involved
in Test Site work. In 1961 I joined what they called the Special Projects
Branch, which was formed to do work on the Test Site. And then I took over and
started doing photo-geologic techniques for the mapping of the Test Site.</p>

<p class="tab">The USGS had been
involved in '57, '58 in the tunnel work out in the Rainier Mesa area doing some
of the pioneer work for doing shots in tunnels, and containment in tunnels.
Prior to Rainier the USGS did two high explosive shots in tunnels in Rainier
Mesa. Those were right where the miners' camp is now. They were in east Rainier
Mesa; not Rainier Mesa proper. They were a little to the west of the Area 12
camp.</p>

<p class="tab"><b>Twenhofel</b>: The
Survey shot the first contained high explosive tests at the Test Site. There
were two; ten tons and fifty tons. They were done in Rainier Mesa, in what were
called the USGS tunnels. As far as I know, those ten and fifty ton shots were
the only high explosive tests done at that time. They were done entirely by the
USGS, for containment purposes. They were steps in scaling up to Rainier.</p>

<p class="tab"><b>Carothers</b>: Do you
recall how the USGS become involved in detonating rather large amounts of high
explosives?</p>

<p class="tab"><b>Orkild</b>: I guess
they were sitting there, minding their own business, and one day got called by
somebody in the AEC who said, "We need somebody who has experience in
mining. You dig holes in the earth, so you must know something about it."
Of course, nobody knew anything about it. Including me.</p>

<p class="tab">But the first reason we
got involved with the Test Site was to understand what the rocks were. And
that's how the mapping started up in the Rainier Mesa area. The USGS started
mapping in quadrangles, so to speak. The Rainier Mesa was done first, and then it
expanded from there. During the moratorium was when we did most of the geologic
mapping in the northern part of the Test Site; Rainier Mesa, and over toward
Oak Spring Butte, and the Climax Stock. That's when the quadrangle series
mapping started; it started out to be three quadrangles. I think they're called
Tippapah, Rainier, and White Rock Spring. When we finished that we had a big
celebration and said, "Hey, we're done with the Test Site. We'll never
have to come back. We finished all this mapping, and we're done." That was
in '60 or '61, and then, lo and behold, the moratorium was over, and things
picked up very actively.</p>

<p class="tab"><b>Carothers</b>: Do you
know how it was that Rainier Mesa was chosen for the Rainier event? Do you
think it just that the mesa happened to be there, or was there a particular
geologic reason to pick it?</p>

<p class="tab"><b>Orkild</b>: Well, I think both. I think it
was there, it was a nice mesa, and it had very mineable rocks. I don't think
anybody worried about the physical properties of the rocks; it was just a place
to put a hole in the ground. The tuffs are easy to mine; they're very competent,
they hold up quite well, and you can make a tunnel in them very easily. It's
easy mining really, better than mining in very hard rock.</p>

<br>

<p class="tab">By
1957 the USGS had a role at the NTS that has continued to the present time.
Both Los Alamos and Livermore have had a continuing involvement with the Site,
and both of the Laboratories established organizations with people permanently
stationed in Nevada. However, the USGS did not.</p>

<br>

<p class="tab"><b>Twenhofel</b>: None
of us ever moved to Las Vegas. There was a lot of pressure from the AEC to move
the USGS group, because it was a fairly sizable group as things developed in
underground testing, but we resisted that. Jim Reeves was the Manager, from Albuquerque,
and he tried to exert pressure to have the USGS group move here. Studies were
made about the costs of air travel, and per diem, and so on, but the move never
came about. It was not the people who resisted; the organization resisted. The
USGS is somewhat paranoid about becoming beholden to outside money. We do take
it, but we're going to keep our independence and our objectivity. There was a
real fear that if this group, assigned to work at the Test Site, would go there
and be officed near or in the AEC, the people in it might lose their
independence and their objectivity. That's a strong feeling in the USGS. So we
never moved down here; we commuted and lived at Mercury.</p>

<p class="tab">At one time we had one
person stationed here, and we rotated. We had a liaison office, you might call it.
The guys would come down here for a month and be in the liaison position, but
it just didn't work. That person had no authority.</p>

<p class="tab"><b>Jenkins</b>: Since
1966 I have put my roots down on the Test Site. I think the geologic work at
the Test Site is fantastically interesting. There are very few places where so
much drilling has been done, and so much data have been collected. There are a
lot of concepts being developed as a result of the exploration at the Site.
That is what makes it a really fascinating place to work.</p>

<p class="tab">In the Flats there are
about nine hundred holes that have given information we can use. Up on the
Mesa, perhaps a hundred. Nowhere else in the world do you have a buried
volcanic caldera with that much exploration. It's just unreal. Nobody else can afford
it.</p>

<p class="tab"><b>Carothers</b>:
Probably not. Well, the Department of Energy hasn't done that just for you
geologists, out of the goodness of its heart. Do you get a good amount of
information out of those holes?</p>

<p class="tab"><b>Jenkins</b>: Oh yes.
And as time goes on, more information is gotten out of them. When I first got
here we were getting caliper logs and drill-hole bit cuttings; occasionally
some core. That was about it. Now we know something about the magnetic
properties of the rock. We have good information on the density of the units, in
situ, and of course the electrical resistivity logging has developed as time
has gone on, but we don't really use all that we could of that. We can get the
in-situ water contents now. There's the thorium-potassium ratio from the logs,
and in our work that helps in determining which units have clay. The technology
has developed by leaps and bounds since I got here. It's a real opportunity.</p>

<p class="tab"><b>Carothers</b>: From
the point of view of the person selecting a site for an event, it appears that
you could consider the Test Site as made up of three general areas. There's the
Yucca Flat area, which is deep alluvium over tuffs, there's Rainier Mesa, which
has extensive layers of tuffs, and then there is Pahute Mesa, which has various
lava flows throughout.</p>

<p class="tab"><b>Orkild</b>: That's correct.</p>

<p class="tab"><b>Carothers</b>: How would you describe Rainier Mesa?</p>

<p class="tab"><b>Orkild</b>: It's a
mesa of layered volcanic rocks. They were laid down essentially horizontally;
some by water and some by air, and compacted into a very cohesive mass of rock.</p>

<p class="tab">Off to the west there
were a couple of volcanos, and they were spewing ash and debris out. Some of
that was flowing with the wind and settling out as dust. Other material that
was blown up further came down as big clots, and some came down as hot glowing
ash. These volcanos were to the west of the Test Site proper, over in what we
call the Timber Mountain area, but the actual source for those rocks we don't
know. There were never actual lava flows on Rainier, because it's too far away
from the sources.</p>

<p class="tab">The later rocks, like
the Rainier Mesa tuff, came from the Timber Mountain Caldera. The Grouse Canyon
tuffs came from the Silent Canyon Caldera. Those calderas are very close - only
ten, twenty miles away. On Pahute Mesa you're very close to the sources of all
of the lavas, so you do have flows and pillows - one going out to the west, one
going to the east, some going to the south, some going over the top of others,
and so on.</p>

<p class="tab">What you're looking at
in Rainier are the outflow sheets from those volcanic features. Some of the
material rolled and surged down the mountainside, and came to rest in the place
where Rainier Mesa is today. Time went on, and some thirteen, fourteen million years
ago, maybe ten, Yucca Flat started to subside, and left Rainier Mesa as a high monolith,
essentially as you see it. Its formation was accelerated by erosion, and the
cliffs formed, and the rocks from the face fell into the flats. In Yucca, the
faults that go down through the valley occasionally move over time, and form
scarps, and the valley spreads a little more and settles some more. It is still
moving today.</p>

<p class="tab"><b>Carothers</b>: On
Rainier Mesa there is a layer of hard rocks - the cap rock. Is that why Rainier
Mesa is there?</p>

<p class="tab"><b>Orkild</b>: That's
right. It has preserved Rainier Mesa itself, being a hard rock. Essentially
what the Rainier Mesa cap rock is doing is protecting the very vitric, soft
Paintbrush Tuff beneath it. Now, that cap rock, the Rainier Mesa member, has a
lot of vertical fractures in it, due to the way it was formed. As it cooled, it
shrunk and formed into square blocks and polygonal blocks, and that's very typical
of that type of rock unit deposit. You see the same thing on Pahute Mesa. You
would see the same thing beneath Yucca Flat, if you could see through the
alluvium. It is what happened to any of the units that are welded, or have some
form of welding. They start as a very hot layered mass, which sticks together
and compacts, and then as it cools it cracks.</p>

<p class="tab"><b>Carothers</b>: There
have been a number of tunnels that have been mined into Rainier. Are they all
being put into the same block of material?</p>

<p class="tab"><b>Orkild</b>:
Essentially. They're all in the Tunnel Beds. There are very different units in
the Tunnel Beds, but essentially they are all the same rock types. Except P
tunnel, which is much higher in the stratigraphic section. It's up in what we
call the Paintbrush, which is above the Tunnel Beds. But I don't think those
tuffs are very different. The physical properties are very, very similar. The porosity
might be higher in some of them, especially as you get into the upper units
that are not as welded, not as altered. This is also true of any event down in
Yucca Flat, or in Pahute.</p>

<p class="tab"><b>Carothers</b>: What are Paleozoic rocks?</p>

<p class="tab"><b>Orkild</b>: They are
the older rocks that form the basement of the Yucca Flat, and the whole Test
Site, essentially. They are the limestones, or the dolomites, or the shales.
They were there before the volcanos - many, many millions of years before the
volcanos.</p>

<p class="tab"><b>Carothers</b>: There
might have been a time when I could have walked around on them. What would they
have looked like?</p>

<p class="tab"><b>Orkild</b>: Just like
the Rocky Mountains. And then there were the eruptions which filled the various
valleys and troughs.</p>

<p class="tab"><b>Carothers</b>: In
Yucca Flat, are the tuffs below the alluvium the same rocks that are in Rainier
Mesa?</p>

<p class="tab"><b>Orkild</b>:
Essentially. The tuffs have exactly the same stratigraphic sequence on Rainier
Mesa as ·you have on Yucca Flat. Once upon a time they were connected. The
Grouse Canyon was a layer that was deposited probably all over Yucca Flat and
Rainier Mesa. Now you find it on the top of Oak Spring Butte, and also many thousands
of feet below in Yucca Flat.</p>

<p class="tab"><b>Carothers</b>: So,
most of the things that you say about the tuff units on Rainier Mesa should
also be true of the tuff units in Yucca.</p>

<p class="tab"><b>Orkild</b>: That's
correct. The alteration is very much the same. The physical properties are
very, very similar. And very likely there are blocks just like those in Rainier
Mesa.</p>

<p class="tab"><b>Jenkins</b>: Right
under the alluvium in Yucca Flat is the Rainier Mesa member, which is the same
ash flow tuff that you find on Rainier Mesa and on Pahute.</p>

<p class="tab"><b>Carroll</b>: With one
exception, which is the alteration phenomenon. That stuff has been there for
twelve, fourteen million years. Having been there that length of time, there's
another imprint that goes upon the rock. That's the effect of moisture, and of
heat. There is water coming down and creating accessory minerals - the clays,
and the zeolites. And although one argues in certain places that this is Tunnel
Bed A, and that is Tunnel Bed A, in Area 3 it may not be altered as opposed to
the bed in Area 9. Stratigraphy to me has always been a problem, because I
don't like people to tell me the name of a rock. Like "metasediment,"
which is a popular term, I think, in the Soviet Union now. That name means
nothing to me as a geophysicist. What is it? Tell me the density, tell me the porosity,
tell me something more than a name you've made up.</p>

<p class="tab"><b>Rambo</b>: In terms
of material properties, those rocks beneath the alluvium in Yucca may have had
a whole different experience than the ones in Rainier. It's the same ashfall,
but from the materials properties view I think there are some differences. If
you do shear strength measurements on the tuffs in the tunnels, they will look quite
a bit different from the measurements we do out in the Flat. And take the
Grouse Canyon layer. Out in the Flat that means something highly porous, and
usually to us means something very weak. In the tunnels it is a very strong,
highly welded member, and I wouldn't say it had anywhere near the same
gas-filled porosity as in the Flats. But it's the same low density unit.</p>

<p class="tab"><b>Miller</b>: I never
did consider the tuff directly beneath the alluvium in Yucca to be the same as
Rainier Mesa tuff. It drills differently. The Rainier Mesa tuff you run into in
Area 12, and Areas 19 and 20, is one hard rock. Whatever is underneath the alluvium
in Yucca Flat is not a hard rock. It's not that much more difficult to drill
than the alluvium. The fact is, often times the penetration rate was not that
much different than the alluvium. In Yucca, where you usually hit the hard
drilling is when you hit the Paleozoic; when you hit the limestone or dolomite.
The tuff underneath the alluvium in Yucca Flat is a different rock than you find
in Area 20.</p>

<p class="tab"><b>Carothers</b>: In Yucca,
how thick is this layer of Rainier Mesa tuff?</p>

<p class="tab"><b>Jenkins</b>: It's
quite variable. On the east side of the valley it's quite thin - maybe a
hundred feet. In the thickest part of the Flat, where the unit is thickest,
probably close to five hundred feet. And on Pahute Mesa it's very much a
thousand feet thick all over. The Rainier is the surface unit there.</p>

<p class="tab"><b>Carothers</b>: If I
were to go to some place in Yucca Flat, and drill down through the alluvium, I
might be able to drill several hundred feet into this Rainier Mesa member, and
have the working point in it?</p>

<p class="tab"><b>Jenkins</b>: Right. It's been done often.</p>

<p class="tab">Carothers: Well, it
would seem that with the number of joints, or cracks that is in that rock,
there would be a lot of pathways for gas to get to the top of that Rainier Mesa
layer.</p>

<p class="tab"><b>Jenkins</b>: It's true they could be quite convenient pathways.</p>

<p class="tab"><b>Carothers</b>: Yucca
Flat and Pahute Mesa are two very different regions, aren't they, in terms of
structure? Pahute is composed largely of lavas, and Yucca is mostly tuffs of
one kind and another, covered by the alluvium.</p>

<p class="tab"><b>Jenkins</b>: Yes, I
agree with you, but the same generic units, from the same volcanic centers, are
in both places. And you have almost the same rock on Rainier as caps a lot of
Pahute Mesa. Now, the stratigraphic section on Rainier is rather compressed as
compared to that on Pahute Mesa. In other words, there are units on Rainier
that are very lithologically similar to those we find in Pahute Mesa, but they're
compressed. They aren't quite as thick. There was not as deep a hole to fill,
if you will.</p>

<p class="tab"><b>Carothers</b>: Pahute
was added to the original Test Site in 1964. Why was that area chosen, aside
from the fact that it was directly adjacent to the existing site?</p>

<p class="tab"><b>Jenkins</b>: I think
the biggest factor that led to the identification of Pahute Mesa as a testing
area was the gravity data work. That work identified low density material, at
depth, in this big circular situation. And of course, the good thinkers could
look to the south and see Timber Mountain, which is an exposed caldera. And the
good thinker said, “Well, this must be another caldera. Therefore it has a
variety of volcanic rocks at depth, instead of the Paleozoic rocks which we
find underneath Yucca Flat".</p>

<p class="tab">There were a number of
exploratory drill holes that the USGS did. Pahute Mesa 1 and 2, Ue20f, Ue20j -
the water well, Ue19c, - and Ue19b. All of them were quite deep. Ue20f was
fifteen thousand or so feet, and a lot of them went greater than five thousand.
And so, we got a pretty good picture of what we were dealing with there.</p>

<p class="tab"><b>Carothers</b>: I
think of Pahute as being a different type of containment structure from Rainier
Mesa, or Yucca Flat, because it has layers which are very hard rock.</p>

<p class="tab"><b>Jenkins</b>: The
lavas. Well, the lavas are probably the only difference, because you have
densely welded ash flow tuffs in all areas. The Grouse Canyon in the Flat is
probably airfall or nonwelded ashflow. Of course, it's thin. Under parts of
Rainier Mesa, and under Pahute Mesa, it's densely welded.</p>

<p class="tab"><b>Orkild</b>: Pahute
Mesa is where the lava was molten, and flowed out from an active volcano, which
was very, very close - within miles. Normally the hot lavas don't go more than
ten miles away from their source. Being a viscous, gooey mass, they stay very
close. They went in one direction, then that would clog up, and then they went
in another direction. That's what really generated some of the blob bier
structures.</p>

<p class="tab"><b>Carothers</b>: What's between the various lava flows on Pahute?</p>

<p class="tab"><b>Orkild</b>: Generally
material that was ejected out of the volcano as ash or brechiated rock, rock
that is broken up. Ash is hot volcanic material that is blown into the air and
then cooled. The molten rock comes out, and when it gets to the atmosphere it
vesiculates into a nice big frothy ball that becomes disaggregated, and falls
back to the surface.</p>

<p class="tab">The deposits that are
what we call airfall, dropping onto the ground, will form a very thin rind.
Normally what you will see if you have any extreme topography between various
flows is that the rains have washed this airfall material into gullies and
other low spots. Many times you can see peculiar dips on the Mesa, and they are
on those slopes where the material has been deposited, and then washed off.</p>

<p class="tab"><b>Carothers</b>: There
would be considerable differences in the properties of the material in the lava
flows, and in those places filled with the ash, wouldn't there? Density
differences, for example.</p>

<p class="tab"><b>Orkild</b>: Sure. The
lavas could be very dense, and the ash flows could be very low density. There
are a number of density contrasts, especially going out of the very dense lavas
into the very vitric tuffs, back into dense rock, back into soft rock, and then
back into hard rock.</p>

<p class="tab"><b>Carothers</b>: In
Yucca, which in a sense is a somewhat less complex structure, people took a lot
of logging data and sample data, but in the first years they didn't do all of
that on Pahute. The geologists would say, "Well, the properties are
extrapolated in." How can you go to a structure like Pahute, which has
pillows of lava, and many kinds of layers, and do that?</p>

<p class="tab"><b>Jenkins</b>: Because
on Pahute Mesa the units have better identification, and therefore a unit
there, a subunit, whatever, can be projected much better under Pahute Mesa than
it can be on the Flats where you really don't have that good a handle on what
the units are.</p>

<p class="tab"><b>Carothers</b>: Is
that another way of saying that the units on Pahute Mesa are so different, one
from the other, that you can see them readily?</p>

<p class="tab"><b>Jenkins</b>: Yes. The
units are so different, one from another, that they can be easily distinguished
one from another. That's a good statement. In the Flats you have the fallout of
all of this volcanic activity, and it's just very hard to distinguish among
them. Now of course, that depends on what kind of a scale you want your
physical properties on. If it's a very wide scale, then the whole unit between the
Timber Mountain tuff and the Paleozoic rocks could be generalized. On Pahute
you'd have to have parts of it here, and parts of it there, and other parts of
it over there in order to make that statement.</p>

<p class="tab"><b>Orkild</b>: I think
that, as far as we're talking about the physical parameters, there's no longer
a difference in the data gathering. It's true that most of the physical
properties were extrapolated from the key fifteen exploratory holes that were
drilled up there. You saw the same type of unit in the next hole, and said,
"All right, this is very similar. Therefore we'll extrapolate." And
there was really nothing wrong with that. It was very successful for
thirty-four events.</p>

<p class="tab"><b>Carothers</b>: That
depends on with whom you want to argue. There are some who might say,
"Yes, but all of those events were high enough in yield to be the kind of
shots that don't leak. You're just lucky that you only shoot high yield shots
in that very complex, little known, variable density medium. You try to shoot
low yield shots, as you do in Yucca, who knows what would happen? At nine hundred
feet or so for a ten kiloton shot, it might not be the same.</p>

<p class="tab"><b>Orkild</b>: I would
be very nervous with something like that, because of the Rainier Mesa tuff unit
that's at the surface there. That Rainier Mesa material has cooling cracks all
through it. It cooled as one unit. It came out in multiple flows, but it all
stacked up, very thick, and compressed. As it cooled, the cracks formed in the
vitrophyre in maybe a different pattern than they formed in the upper part of
it, but those cracks are essentially through-going. That layer is about a
thousand feet thick, and that means those fractures go down that far. Once you
drop below that layer, unless you're near a fault you have very few fractures
of that kind.</p>

<p class="tab"><b>Carothers</b>: Then
if I shoot at sixteen hundred feet or so, I'm only a few hundred feet below
that layer. I don't have to go very far to get to those fractures. And then the
gases can move rather freely through the fractures, even if any single one
doesn't extend all the way through the unit.</p>

<p class="tab"><b>Orkild</b>: That's
right, if you only have the Rainier Mesa member as the rock at the top. That's
in Area 19. When you go over into Area 20, you have other units above the
Rainier. The events where you see late-time gas seepage are mostly over in Area
19, and they are directly related to whether the Rainier Mesa layer was near
the surface. West of there, other units, the Thirsty Canyon and the other ash
flows, sit on top of it, and those cracks are essentially sealed off at the
upper part. Late-time gases certainly came up into them somewhere, but they
didn't get to the surface because they could disperse into those thin, very
porous layers that were intertongued with denser units.</p>

<br>

<p class="tab">One
of the features of the Test Site that has been considered as possibly adversely
affecting the probability of successful containment are the faults that occur
throughout the site. Generally the faults with substantial displacements are
avoided - when they are known. Some faults, such as the one known as the
Carpetbag fault, are not detected until some movement occurs as a result of a
nearby detonation. How dangerous faults are with respect to containment is
largely unknown, and is a matter of individual judgment. </p>

<br>

<p class="tab"><b>Carothers</b>: At the
Test Site there are many faults, cracks that show that movement has taken place.</p>

<p class="tab"><b>Orkild</b>: Yes, many
of them, some with up to forty meters of displacement in Rainier Mesa, where we
can see them in the tunnels. That's a large fault for Rainier Mesa, and it
would probably be the largest that you'll see there. And you do see
displacements down to inches in the tunnels. In Yucca there are faults with
much more displacement than that, but on those the displacement has to be inferred
from seismic surveys and exploratory holes. Normally when you see a fault it's
not one fault plane, but a series of fault planes that might make up a total
displacement of maybe ten feet, distributed on five or six of these faults .</p>

<p class="tab">These faults are held
very tightly together by the overburden. There are no open standing fractures.
They are a plane of weakness, but I don't think they're a plane of transport. I
don't think faults necessarily have to be bad for containment, but I think the
system should be aware of them, and plan accordingly.</p>

<p class="tab">It would be nice to be
able to try a shot on the Yucca fault. Many years ago, on Pahute Mesa, there
was an event very close to a structure over in Area 20. That was back in the
Rae Blossom days. He said, “Let's try it. Let's see what happens." Nothing
happened. The fault moved very nicely, very handily, something like five or six
feet. But there was no reason to think it affected the containment. There was
no release.</p>

<p class="tab"><b>Carothers</b>: The
closest shot to the Yucca fault that I can remember was in '72. It was called
Oscuro, which was a Los Alamos shot fired on the east side of the Yucca fault,
fairly close.</p>

<p class="tab"><b>Orkild</b>: And close
to a very large northeast fault. My personal feeling is that it would have
vented if it hadn't collapsed when it did. I remember going out and looking at
the post-shot effects, and I said, “I don't know how this thing stayed in the
ground." Everything was standing open. The fracture that broke to the
northeast was standing open a good foot and a half or two feet at the surface, beyond
where the collapse had occurred. That northeast fault is in tension, and that's
the thing that would stand open, because there's nothing to close it up. (think
that was a very, very close experience. The only thing I think that saved it
was the collapse. If that had sat there for any length of time, I think we'd
have been hit.</p>

<p class="tab"><b>Carothers</b>: How do
you know whether a fault is under compression or is in tension?</p>

<p class="tab"><b>Orkild</b>: In certain cases I think we know
based on the overall structure. When we look at some of the northeast trending
faults off the Yucca Fault, we can say that very likely they are in tension -
they're pulling apart. That's how the basin-range formed in the first place.
There are areas within the Test Site that are under those conditions. That's
based on the physical parameters that they have found on drilling on the Mesa,
finding out the principal stress.</p>

<p class="tab"><b>Carothers</b>: You
mentioned the east side of the Yucca fault as an area that is in tension. Does
that mean the west side is in compression?</p>

<p class="tab"><b>Orkild</b>: No. They
both could be under compression, because one side is coming up, and the other
is going down, and they're both pushing together. It's the subsidiary faults
that come off of the Yucca fault that are being pulled apart.</p>

<p class="tab">The upside of the Yucca
Fault has always been steered away from because you see all of these open,
standing fractures, which means that something has to be under tension and it's
pulling apart. You would assume that some of the downside would be under compression
because it's being pushed down. But there's another wrinkle to the Yucca Fault
- it also has lateral motion. One side is moving laterally with respect to the
other, and as you have that motion you can have tension along those northeast
fractures.</p>

<p class="tab"><b>Carothers</b>: Would
this same situation obtain up on Rainier Mesa, where you might have tension and
compression areas? It's not a very big block.</p>

<p class="tab"><b>Orkild</b>: It's not
a very big block, and probably what it's doing is that all of it is moving
radially toward its edge. That's the way you would think it would happen - that
it would move toward the open-faced surface, toward Yucca or toward Pahute
Mesa.</p>

<p class="tab"><b>Carothers</b>: Bill,
you have said many times over the years that you don't see that faults really
cause a containment problem, and they don't concern you particularly.</p>

<p class="tab"><b>Twenhofel</b>: I
don't think faults are a problem unless they move on the shot.</p>

<p class="tab"><b>Carothers</b>: How am
I going to know whether that will happen or not?</p>

<p class="tab"><b>Twenhofel</b>: Well,
we don't really know that too well, but we know which ones have moved on past
shots. The Yucca fault, for instance, moves quite a bit, and there are others.
We try to avoid those because we have the concept, and I think it's valid, that
a fault isn't a perfect plane, so when they do move there may be openings created,
and that's a possible release path if you're near enough.</p>

<p class="tab">So I concur with the
idea of avoiding the Yucca fault, because it moves. But many of the faults are
not going to move. There are two kinds of faults. There are tectonic faults
that are created by earth stresses, and they tend to be big things. Then there
are a lot of subsidence and compaction faulting that only occurs because the rock
is compressed a little bit here by the weight of the overlying rock, and so it
subsides a little bit - there's a little fault. Those things don't move, and I
don't think they're a factor.</p>

<p class="tab">I think that if a fault
goes right through the stress cage it's going to be compacted and tightened
right there, so it can't possibly be a path. When it's farther out where it can
move, I think it can be a factor, but I don't get alarmed by many of these
faults. But we can't be very quantitative about it. It's very subjective.</p>

<p class="tab"><b>Weart</b>: Well, Pin
Stripe was an early vertical line-of-sight pipe shot that vented through a
fault. It was conducted in Area 5, and rather than being in a drill hole, it
was in a shaft that had been excavated. It had the latest in closures, ball
valves, HE closures, everything. But, as we found out when we did an
investigation after it vented in a very massive way, all those features had
been circumvented. There was a fault that came into the shaft below these
features, and it provided an easy release path to the surface.</p>

<p class="tab"><b>Carothers</b>: The
release was through the fault itself?</p>

<p class="tab"><b>Weart</b>: Yes, we know it was. It was a
very clear example. When we reentered the top of the line-of-sight pipe the
seals were closed, and it was clean. And we could trace the fault path on the
surface of the ground.</p>

<p class="tab">It wasn't a fault that
released material directly from the cavity, and I'm not sure that the Baneberry
fault did either, although on Baneberry the fault was much more closely
associated with the cavity than the fault on Pin Stripe. Whether or not Pin
Stripe would have contained if the fault hadn't been there I can't say for
sure, but it certainly was the easiest path. The shaft was clean above that point.</p>

<p class="tab"><b>Carothers</b>: There
are people who say, “The geology at the Test Site really doesn't matter as far
as containment goes, except in exceptional circumstances. We have fired so many
shots that we've probably encountered just about every kind of material and
situation that you can imagine. If it mattered it would have got us by now."
I emphasize they mean that statement only with respect to the Test Site, not
the world in general.</p>

<p class="tab"><b>Orkild</b>: I agree
that if you bury shots deep enough you don't have any problems.</p>

<p class="tab"><b>Carothers</b>: Well,
that's true, I think. If you have all the money you want, and all the time you
want, you can certainly do that. But coaxial cable is expensive. Casing is
expensive. Drill holes are expensive. And when you get down below the water
table it begins to get very expensive. So, that's the kind of statement that is
true, but it's not very helpful in the real world. But certainly we have encountered
many different kinds of geologic situations, wouldn't you say, on those many
shots that haven't leaked?</p>

<p class="tab"><b>Orkild</b>: Yes, but
there are certain combinations of geologic conditions that can get you.
Baneberry is an example.</p>

<p class="tab"><b>Rimer</b>: Take
Barnwell. There was a case where the containment lore about geology doesn't
matter came close to being disproved. John Rambo was the containment scientist.
It scared him enough that he had people go there and take cores, and measure
strength. I'm sure he got a lot of flak. He did a number of calculations, and we
did hydrofracture calculations, and everything said that the thing was going to
be contained. We came to the CEP with that information, and I forget who, but somebody
said, “We’ve never had a problem with a shot of this size at that depth of
burial. Therefore, we don't need to listen to these calculations."</p>

<p class="tab"><b></b>The bottom line was, the thing
was going to be contained, but it was going to be contained with the potential
for a hydrofracture going much higher in the section that we had ever
hypothesized before from a tamped event. I emphasize tamped event, rather than
a cavity event.</p>

<p class="tab">Based on drilling rates
John knew there was something funny, and what was funny was, you had this
strong material right above the shot, which kept the cavity size small, and
therefore kept the cavity pressure up. Above that material was a layer of
weaker material which wouldn't support a high residual stress. So you had high cavity
pressure, and low strength rock above. That's the worst possible case you could
have, other than an open fracture leading to the surface. The empiricist said,
“Why should this matter?" Well, when it was shot, radiation got very
quickly up to the last plug.</p>

<p class="tab"><b>Carothers</b>: Higher than we've ever seen it on a shot of that yield.</p>

<p class="tab"><b>Rimer</b>: And you
know what? It wasn't a coincidence. Geology mattered.</p>

<p class="tab"><b>Brownlee</b>: I think
what I've learned is that the geology is only important when I'm on the edge.
Then it becomes important. But if I've got normal margins of safety, the
geology can be almost anything. I know that's true, because we've shot in
almost any geology, safely. If you've done your containment right, you don't have
to hang on the geology to determine what happens. But if you've done things wrong,
a trivial thing in the geology can make all the difference.</p>

<p class="tab">Now, don't misunderstand
me - I just believe that we ought to be so conservative that geology never
matters, and most of the time that's true. We are so conservative that the
geology doesn't matter. And so, I get very bored when they go into details that
are of no importance to this shot; none whatsoever. But they go into it because
after all, they've done this work, and they've got this geologic business to
talk about. Well, they don't understand why it isn't important, and there's no
way I can teach it to them. They have to learn it themselves.</p>

<p class="tab"><b>Orkild</b>: Many
times, I agree that you could ignore all the geology; many, many times the
geology is benign. That is, you have flat beds, you have low water content, you
have good porous rock. There is no nearby structure that would affect the
containment. And, a rock type where we have a good handle on the physical properties,
and they are well within the range that we are familiar with. And the water
content, the same thing; it's within a range that we know for this particular
lithologic unit that's being tested in. And that there's no large body of clay
at the working point.</p>

<p class="tab"><b>Carothers</b>: We've never seen a large body
of clay, except for the Baneberry site, have we?</p>

<p class="tab"><b>Orkild</b>: There was
the site for the Stutz event that had a pretty large volume of clay. I think
there has to be a particular set of circumstances to get a big pod of clay. On
Baneberry there was opportunity for a large amount of water moving through the formation,
and the right lithology that could alter, and a thick zone. You've got to have
water, and you've got to have a vitric tuff that will readily turn to clay, and
the right chemical conditions to start the process.</p>

<p class="tab">We've seen that situation
twice. I don't think that any other time we have drilled into a situation like
that. Normally the clay we see is at the interface between two units, which is
stratigraphic, and very, very thin. Theoretically, in a long strike it could
get thicker, but not more than ten feet or so.</p>

<p class="tab"><b>Carothers</b>: On
Baneberry that clay was what, a few hundred feet thick?</p>

<p class="tab"><b>Orkild</b>: Yes. It
would be very nice if we could excavate that and see what it really looked
like. We've looked on outcrops and looked for situations like that. Where would
you go to look, to see if you could find a situation like that? There should be
an analogue at the surface somewhere. The closest we could find to something
like that was in what they call a chinle formation on the Colorado plateau. That
was essentially volcanic ash that was deposited in a shallow ocean or pond, and
altered. It's hundreds of feet thick. But we never have we seen anything like
that on the Test Site.</p>

<p class="tab"><b>Carothers</b>: With
data from the hundreds of drill holes that are on the Test Site you must be
able to plot everything everywhere, from hole to hole.</p>

<p class="tab"><b>Orkild</b>: Yes, we
have 2-D and 3-D programs where we can do that. We call up the data base and
plot the holes. That's how we do the siting. The program looks at a site and
plots the geology, the water table, the lithologic units, and plots in the
known faults, and their distance.</p>

<p class="tab">The Laboratory people
come in with a set of coordinates, and the parameters for the hole. We plug
that into the program and crank out what they call a prediction report. And
then we do the same thing with the gravity. We show what the configuration of the
Paleozoic surface will be, and send it on to the Labs. That eventually gets
incorporated into the prospectus and the presentation.</p>

<p class="tab">Sometimes we reach a point
where we do not agree. Or we might point out certain problems, like a lava mass
being close to the site. We went through one of those in Area 20, where the two
exploratory holes drilled did confirm there was a blob out there. It turned out
that it wasn't really any problem, because it turned out to be far enough away.</p>

<p class="tab">Of course, as the hole
is drilled you develop more data. It's an ongoing process. Now, I think,
they've gone overboard, and collect data that nobody seems to understand.
Especially water content. We here still think something's fishy between the
results of the two water content logs - the epithermal neutron logs that Livermore
is showing these days, and the one they used to show.</p>

<p class="tab"><b>Carothers</b>: Why?</p>

<p class="tab"><b>Orkild</b>: It has to
do with the bound water. It's hard to tell which standard to use, because the
Lab seems to pick the one that fits best. Which is okay, I guess, but that
really doesn't solve the problem of understanding why you have this bound water
and additional water. The water contents on Pahute are up what - ten percent
more? - than we ever used in the projections. On some of the recent shots where
they're using the new logs, the water contents are up in the twenty's -
twenty-five percent, twenty-four percent. Which might be real, but we really
don't know. This is one of the outgrowths of all the data gathering that's been
going on.</p>

<p class="tab"><b>Carothers</b>: These
new numbers are coming from the neutron log aren't they?</p>

<p class="tab"><b>Orkild</b>: Yes, and
I think it's a positive step. But I think it's going to take a lot more work
before they really understand it, and everybody agrees with it. Of course,
getting everybody to agree will probably never happen, but you could certainly
get to where a majority agreed.</p>

<p class="tab"><b>Fenske</b>: Hazelton
Nuclear Science Corporation got a contract to do hydrologic studies on the Test
Site in 1962. Hazelton had two labs for work with radioisotopes; a pretty high
level lab, and a low level one. They were doing all kinds of things for the
Atomic Energy Commission, and the National Institute of Health, and people like
that who were interested in radioactivity. They were hiring people, and in
about 1965 I went to work for them. The program was to find out whether
underground testing was going to contaminate ground water in such a way that it
would cause a serious problem. I don't recall what a “seriousproblem"
would have been at that time, but I think it came out that it would be if any radioactivity
would leave the Test Site.</p>

<p class="tab">Where was the water
going to go? Nobody really knew very much about the transport of radioactivity
in ground water, and not too much was known about hydrology, in that sense. At
that time hydrology was centered around how much water could be produced from a
well. So, hydrology was drilling a hole into an aquifer, and producing water so
you could water the livestock, or irrigate the field, or something like that.
That was the hydrology the USGS was steeped in at that time. It was always
drilling holes and finding out how much water could be produced.</p>

<p class="tab">To do that, in the final
analysis what you really do is pump on the well. In a nice isotropic,
homogeneous medium the production is an exponentially decreasing curve. You
plot it on semi-log paper, and it's a straight line. When the line comes out so
many years in the future going to zero production, you know that's it - that's
the end of that well, probably. Of course that assumes things are isotropic and
homogeneous and all those nice things. Which they never are, but that's about
as good as you can do. The longer you run the pumping test the more confidence
you have in the results, but, as on some of the wells at the Test Site that the
USGS tested, you can find that the slope of the curve changes. It goes along nicely,
and all of a sudden it starts diving. It has what they call a boundary effect.</p>

<p class="tab">So, hydrology was a
developing field, from the point of view of transport of water for a long
distance. It started out with the idea that there is an aquifer, there's a
gradient in the aquifer, and therefore the water is moving down the gradient at
a certain rate. Essentially you drill a couple of holes, and if the water comes
up to a certain level in one hole, and comes up to a lower level in another, you
figure there's a hydraulic gradient in that direction. Early on, people tried
to figure what the hydraulic gradient was, and what the direction was, and what
the permeability was so they could say, "This contamination is going to go
in that direction, and will travel this far in so many years."</p>

<p class="tab">As things progressed,
people realized that the hydrology in an area wasn't that simple. The Test Site
is not at all simple; it has a very complex hydrology, and we still don't know
much about it, really. And, radionuclides are adsorbed on rocks. Then we found out
that the process isn't really symmetrical; they weren't desorbed at the same
rate they were adsorbed, and things like that. All kinds of problems like that
occurred, but it didn't change the basic conclusion. That was, except for the
tritium, the radionuclides just weren't moving very much. At least that was so
for the rocks we were dealing with.</p>

<p class="tab">Now, the carbonate
aquifers are different, because things like strontium and calcium are ionically
similar, and strontium will move in the carbonate aquifers. In the alluvium you
just didn't find any real movement of that material. In alluvium we never have
found movement, except for the tritium, which moves as fast as, or maybe faster
than the average velocity of the ground water.</p>

<p class="tab"><b>Carothers</b>: How
can something in the water move faster than the average velocity of the water?</p>

<p class="tab"><b>Fenske</b>: Well, you
try to calculate the velocity of the water on the basis of the pore structure
and the permeability, which are the two things you have to have to get the
velocity of the water. That's an average value for the movement of the water in
the aquifer. Now, that aquifer extends over a broad region, and there may be localized
regions where the pore structure is different from the one you used to
calculate the average velocity. An old, buried stream bed, for example. If you
happen to drill into that when you are measuring the movement of the tritium,
you might find a faster velocity than you have calculated as an average. So,
it's not that easy. The velocity of diffusion depends on pore size, and the
pores can be of different sizes in different places, so it gets to be complex.</p>

<p class="tab"><b>Carothers</b>: One of the things I have heard
about the Test Site, which is said to be unusual, is that the water table is
very deep, that there are very few places where you will have to go down 1,600
feet before you get to the water. Is that true?</p>

<p class="tab"><b>Fenske</b>: Well, if
you're talking about Yucca Valley, yes. If you're talking about Pahute Mesa,
no. On Pahute the water is pretty far down, but very often in regions at higher
elevations you will find deeper water. In lower regions, like Yucca Valley, you
find shallower water. In fact, a lot of valleys in Nevada have swampy areas in
them. Ruby Marshes is a good example. Or they have springs; Hot Creek Valley
has springs. That would be the normal situation. But in Yucca Valley it's
different.</p>

<p class="tab">I had one of the fellows
at DRI, a number of years ago, draw a map of the elevation of the water in all
of the valley bottoms in Nevada. The reason for this was because I felt if I
had the elevation of the water in all the valley bottoms I would have an idea
of what the regional flow structure looked like in Nevada. Well, you find everything
is very regular, and it all moves down towards Death Valley - until it hits the
Test Site, where Yucca Valley is. Then, there are very steep gradients going
into Yucca Valley. There's something else going on; Yucca Valley is underlain
in many areas by the carbonate rocks, which are fractured, and transmissive of
water.</p>

<p class="tab">Another thing you have
in Yucca is that the alluvium has a higher water saturation, higher in the
section, than you would expect in a dry valley. All the way to the surface you
have some water saturations that are higher than you normally would expect. In
some places you find 20, 30, 40 percent water saturations; much higher than you
would expect to see if the water was always down at the level where it is now.
The impression you get is that at one time the water was up near the surface,
but now it isn't any more.</p>

<p class="tab">What I think has
happened is that the carbonates which underlie the valley have acted as a huge
drain. So, the water is basically moving down to the carbonate, and out to the
springs in Amargossa. The water in all the rest of the Nevada area is moving in
sort of a normal fashion; in Yucca it's being drained, and has been drained, so
it's not up near the surface anymore. It's down closer to the level of the
water in the Amargossa.</p>

<p class="tab">If you look at the
vertical gradients in the carbonate, they are much less than the vertical
gradients in the alluvium, so the normal direction of movement would be
downward through the alluvium into the carbonates in the Yucca valley. Then the
water moves south through Frenchman out to the springs in the Amargossa Desert.</p>

<p class="tab">Some of the water
beneath Pahute may be draining into Yucca, but whether it is or not is the
subject of some argument. The Survey, which has done most of the work on that,
think that the Eleana formation, which comes along the side of Yucca Valley, on
the east side of Pahute, is a pretty effective barrier to movement into Yucca Flat.
Everything that comes off the west side of Pahute Mesa goes down underneath
Forty Mile Canyon toward Lathrop Wells. So, not much of any water gets into
Yucca from Pahute. Some probably does, but I think it would be small.</p>

<p class="tab">I don't think there's
any recharge at all in Yucca. We ran an investigation there once where we
looked at tritium in the dirt. It's pretty dry dirt, and it's pretty hard to
dig it. I guess about the farthest they could reach was about as far as you
could reach with your hand to grab a handful of dirt. We found that the amount
of tritium pretty well decreased with depth, so there doesn't appear to have
been any recent recharge there. By the time you got down about a meter you just
didn't find any tritium any more, in the dirt. There was a lot of tritium in
the rain in the sixties from the atmospheric tests; there was a peak during
those years. You don't find that at depth when you look at it in Yucca valley,
or on the slopes around the valley. So, I don't think there's much recharge going
on there. I don't think it's going from the surface of the valley down 2,000
feet.</p>

<p class="tab">Now, it may reach an
equilibrium point where the gradient around the sides of the valley is
increased enough to replenish the water about as fast as it's running out.
There are steep gradients going down into the valley, and the lower you make
the water, the steeper those gradients get, and the more water you bring into
the valley from the sides. It may have reached an equilibrium point, but I
don't know if it has or not. You'd have to watch for a long time, a hundred
years, or two hundred years, to be able to tell.</p>

<p class="tab"><b>Carothers</b>: A few
years ago, in the LAN L area, radioactivity was found when they were drilling
an emplacement hole. There was the thought that perhaps this activity had been
transported from the expended Sandreef or Aleman sites, to the north. If that
was so, it had traveled laterally a lot further than people had expected. What do
you think accounted for the transport that was observed? It did happen.</p>

<p class="tab"><b>Fenske</b>: Yes, it
did. There are a lot of things we can't explain that we see once in a while.
The only thing I can think is that there was pressure in the cavity, and
material was driven down a fracture that momentarily opened up. As I recall,
there were some radionuclides out there that had gaseous precursors, and they wouldn't
have gotten that far if they hadn't been shoved over by a pulse of gas, or
something like that.</p>

<p class="tab">Generally, the water above
the carbonates, in the alluvium and the tuffs, drains down. It is when it gets
into the common aquifer that it drains to the south. I would think that the
amount of lateral transport, above the carbonates, is pretty small. That
doesn't mean there can't be some, but I think it's pretty small.</p>

<p class="tab"><b>Carothers</b>: On another subject, what is perched water?</p>

<p class="tab"><b>Fenske</b>: Well,
it's something that you may well have in Yucca valley, if once you had a higher
water table and now you have a lower water table. Say that a thousand years ago
you had a water table close to the surface. If that water table drops, there
will be water left in various places - on top of layers of less permeable material,
for instance. That water is just sitting up there - perched up there. It is not
like a lake; it's just a more saturated region of the rocks.</p>

<p class="tab">In the conventional
sense of perched water, you'd be in a more humid region than the NTS, and you'd
have a water table at some level. The water that's deposited on the surface
infiltrates down. But, there may be some fairly shallow little clay lenses. So,
some of that water sits on top of these clay lenses. Then it runs off the edges,
and down to the water table, but there's a time delay. In that situation, given
a certain amount of rainfall on the average, there's always a lens of water
that's perched up there on top of this clay lens. It's in equilibration between
the amount of water that's running off the edges of the lens, and the amount of
rainfall that deposited.</p>

<p class="tab"><b>Carothers</b>:
Perched water was one of the things that was discussed in the first report
about what happened on Baneberry. The impression was given that the explosion
cracked a rock layer, and a lot of water ran into the cavity. In the situation
you describe, that couldn't happen .</p>

<p class="tab"><b>Fenske</b>: No, it
couldn't. At least not rapidly, not in minutes. It might do it in months, or
years, or decades, or something like that, depending on the permeabilities of
the materials.</p>

<p class="tab"><b>Carothers</b>: What
about “water mounds," that are thought to be produced by nuclear detonations?</p>

<p class="tab"><b>Fenske</b>: You will
get Fenske's version, which is that I don't really believe in water mounds. I
do believe in potential mounds. What I mean by that is, in material which has a
low permeability, such as the alluvium, the water maybe moves ten feet a year
when it's moving laterally. I don't think that, instantaneously, you can move
huge volumes of water up meters in height over big areas. I think that what
happens is that the relationship between grain pressure and pore pressure is
changed.</p>

<p class="tab">Say you drill a hole
down into the formation, and measure the water level. After the shot you have a
higher pore pressure there than you had before; so the water comes up to
equalize that pore pressure. And so, every place you drill a hole you have
water coming up to higher levels than it did before the shot. You can say you
have a water mound there, but it's not the water that's a mound - it's a
potential mound. What you are really measuring is the potential of water in
that formation at that point. Now, the water's flowing, because of the
gradients and the higher potentials, from one place to another. But it's not a
real mound of water. The holes you are drilling are really acting as
piezometers; they're measuring the water pressure at that point, which is
higher than you would consider at that depth, or higher than it was before.
There really isn't any more water there than there was before. It's just that
the pressure, in the water, is higher than it was before the shot, so the water
just comes up higher in the piezometer tube that you have put in there. And
that's because, in shaking the ground, you have transferred the grain pressure
to pore pressure.</p>

<p class="tab">The material is
originally in an equilibrium situation, where all the sand grains are impinging
on one another, and they hold the pores open to a certain degree. If you took
'all the water out, there would still be some pores in there. Now, if you shift
the sand grains a little bit, they can go together and reduce the porosity.
Then, because you have reduced the porosity, there isn't the space for the water
that there was before, but there's still the pressure of the overlying rocks.
By reducing the porosity you have increased the pore pressure, or the water
pressure in the rocks.</p>

<p class="tab">The same thing happens, incidentally,
in a landslide. You have a water saturated material. A little shift of the
grains, for one reason or another, will start increasing the pore pressure, and
decreasing the grain pressure. When you do that you decrease the resistance to
flow; the material becomes liquefied, and downhill it goes. Spontaneous
liquefaction is basically that kind of a mechanism. You've been to the beach
and patted the sands?</p>

<p class="tab"><b>Carothers</b>: Sure. And water comes up to the top.</p>

<p class="tab"><b>Fenske</b>: Yes.
You're compacting the sand, and the water comes up. When you compact it, that
material becomes liquefied; it becomes mushy.</p>

<p class="tab">If you start calculating
the amount of water that would have to be in a water mound, given a reasonable
porosity, and how much you had to move in a fairly short period of time, that's
a lot of water. And then you have to ask, "Where did it come from?"</p>

<p class="tab">We have run into
situations where perched water was a consideration, and it has caused all kinds
of problems. They were not necessarily containment problems; they were problems
with emplacing the device, just getting the thing down in the hole. For example,
there have been cases where the Labs have put down a liner, and the water has
come over the top of the liner. That has to do with hydrology, and you ought to
understand more about it. Sometimes that's a perched water problem.</p>

<p class="tab"><b>Carothers</b>: No
it's not. It's a stupidity problem. They say, "And the water level was
tagged at 636 meters. So, we've put in a liner whose top is at 636.5
meters." They seem to think that all they need is a liner that is an inch,
or a foot higher than their tag, and everything will be swell. And then they
say, "Oh my gosh, the water is running over the top. How
distressing." What I think is, "How expensive to fix. Fire
them."</p>

<p class="tab"><b>Fenske</b>: Well,
there are other cases where water has run over the top for other reasons. There
is the possibility that there really is perched water. When you go through a
zone where there is water, and it's not all necessarily held in by capillarity,
it can run out. And there are cases where there is excess pressure in the
water, as in the ground water mound. There was one shot where the water
pressure was high enough to collapse the casing, due to ground water mounding,
or the pressure in the water, as I think of it.</p>

<p class="tab"><b>Carothers</b>: So,
suppose I am drilling down through the alluvium, and the tuffs, and it's dry. I
am careful to stay above the standing water level, but I notice water running
into the hole. As I understand it, that could happen because there's perched
water, or as you would say it, there's a high pressure zone. If I case that hole,
the casing has to be able to withstand a pressure that is at least equal to
whatever the pore pressure of that water is. If it can't do that, it could
collapse, even though that casing is above the standing water level.</p>

<p class="tab"><b>Fenske</b>: Yes.
There's another way you could have perched water, and at the Test Site it would
be water running into the valley. If you happen to have a tongue of something
like clay, that's lower permeability, which extends into the Valley, water may
run along the top of it rather than run down to the water table. It may run along
the top, and then drip over the edge. Up to that point you may have perched
water. Around the valley sides, more than around the center, you could possibly
have perched water. You have a source that keeps on running, because it's
recharge water from, let's say, Pahute Mesa that's coming through the system.
It's just taking a little different path. A good example of that is some of the
springs that you see. They're basically perched water. Water enters the system,
flows down some impermeable layer, and comes out in the form of a spring where
the layer intersects the surface.</p>

<p class="tab"><b>Carothers</b>: Do you
think we've made any difference to the flow of the water, or the drainage of
the water? Have we upset the hydrology of the valley?</p>

<p class="tab"><b>Fenske</b>: I don't
think so, except locally. around the cavity, and for some small distance out
from that. I looked at one thing though, at one time, which was the number of
un cased bore holes that went into the Paleozoics. There turned out to be a
fairly large number. At some level those holes enhance the flow of water from
the alluvium down into the carbonates. Of course, you have to start with how
much water is leaking through there, without the holes, to see what that
enhancement might be, and we don't know that.</p>

<br>

<a name="ch6"></a>
<br><br>
<h2>Chapter 6: Earth Materials and Their Properties</h2>
<br>

<p class="tab">The geologic materials in which a
device is detonated determine the details of the phenomenology that occurs.
Hence, the properties of these materials are required as input for any of the codes
used to calculate the expected cavity size, hydro fractures that may occur, the
various stresses that occur, the ground motions, and so on. Unfortunately, many
difficulties beset the determination of these properties.</p>

<p class="tab">In emplacement holes there is no
access to the materials, or to information about the geologic materials around
the shot point, other than that provided by logging tools, or various tools
which can retrieve small samples. In the tunnels samples can be taken fairly readily,
and laboratory measurements can be made on them to determine various quantities
such as density, porosity, and water content. However, such laboratory
measurements cover only a small range of the conditions the material is
subjected to near the detonation, and tell nothing of how the material will
respond to a shock pressure of 500 kilobars, for example, or to simultaneous radial
and tangential stresses.</p>

<p class="tab">Laboratory measurements are made
on small, competent samples of rock, while the energy of the detonation
interacts with the entire mass of the surrounding earth, which can include
fractures, faults, and layers of different materials of different composition and
properties. The behavior of the overall surrounding materials may be quite
different from what would be expected from the properties of a small laboratory
sample.</p>

<p class="tab">Rocks that have been subjected to
the high shock pressures generated by the energy released in the detonation can
be damaged, to various degrees, depending on the shock pressure, and their properties
are not the same after the shock wave has passed as they were before.
Therefore, they do not respond as they did before, but things important to
containment are still occurring.</p>

<p class="tab">There is not agreement among
those working in the field of containment as to what the properties important
to containment are.</p>

<br>

<p class="tab"><b>Carothers</b>: Los Alamos had drilled some
holes during the moratorium, and after the resumption of testing in 1961 that activity
picked up considerably. What sort of logging did you do, or what kind of
geologic information did you look for? Or did it just accumulate peripherally
to the actual drilling?</p>

<p class="tab"><b>Brownlee</b>: Well, I hate to go on record as
saying this, but when I was dealing with the engineers those kinds of questions
had nothing to do with it at all. They picked the sites, and told us there was
a hole there. We could ask whatever questions we chose about it, but they were
not obligated to tell us anything. The truth is, they didn't know anything
about the site.</p>

<p class="tab"><b>Carothers</b>: If you asked, "What are
the rocks like at the bottom of the hole?" Or "What sort of layers of
rock have you drilled through?"</p>

<p class="tab"><b>Brownlee</b>: No answer. Now, they very well
may have had some information, but they certainly didn't feel obligated to
share it with a non-engineer. The one fact they acknowledged was that it was
possible to hit water. And so, I usually knew if we had gotten to the water
table.</p>

<p class="tab">I knew the depth, of
course. And if they were in tuff, they would tell me that as opposed to being
in alluvium. But I didn't know much about tuff, because the alluvium in Area 3
is very deep. So, tuff was not a common kind of occurrence until we got toward the
edge of the valley.</p>

<p class="tab">But logging was not a
requirement. The only requirement was to drill a straight hole, and so they did
a lot of worrying about not drilling crooked holes. All the emphasis was on the
mechanics, on the engineering aspects of the drilling. That's the way I
remember it.</p>

<p class="tab">I finally derived
four standard materials, based on how close I was to the water table. I had
very dry, dry, wet and very wet. The very dry was for the top of the alluvium
in Area 3, and the very wet was at the water table. And, I had a couple of
other standard curves. So, I found that the equations of state were some
strange function of depth, but it wasn't depth from the surface, it was really
distance from the water table.</p>

<p class="tab">So, the question I
would ask was, "Where is the water table?" And Rae Blossom would fume
and say, "You don't have to know that. There's no reason why we should
spend a dollar to find out where the water table is. Just knock it off. What
difference does it make to you anyway? We tagged the water table at such and
such a depth over there, so that is what it is. How could it be any different here?"
And so, my questions always ended in big arguments about non-relevant things
like budgets, and time, and money, and "You're bothering the engineers.
Get the hell out of here."</p>

<p class="tab">I'd go have these
terrible arguments with Rae, and shout and wave my arms, and we were enemies
forever, and then Rae would go out and get the answer to my question because he
would recognize I really was serious. You see, if you didn't persevere, you weren't
serious. But if you persevered, he'd go get the information you wanted. So, I
have to admit that on a number of occasions Rae did make an attempt to get
answers to some of my questions. He was in a position where he could order the
rest of them to do it, but it was always like pulling teeth to get that done.</p>

<p class="tab">So, I'm afraid that
in those very earliest times we knew next to nothing about the medium or its
properties after the hole was drilled. The guys who drilled would record that
the drilling rate changed, but you didn't know why. I only found out about some
of these things when we were actually doing the tests. Livermore did a better
job than we, because when they were doing the tunnels they were asking the
right kinds of questions. I did get permission to go out and see what was
there, and I was educated more by Livermore guys than by people here, in the
very earliest times.</p>

<p class="tab"><b>Carothers</b>: Pre-Baneberry there was,
apparently, no real requirement at Los Alamos to take logs and samples.</p>

<p class="tab"><b>Scolman</b>: I don't recall that there was.
My feeling is that to the extent that there was logging done, or we studied the
lithology of the hole, it had to do mostly with drilling. How do you best drill
it? Anything that came out in terms of geologic information was almost
incidental to that procedure. We did run some logs. We ran caliper logs, for
example.</p>

<p class="tab"><b>Carothers</b>: Because you wanted to put the
casing down the hole, and you wanted to know how much cement you would need.</p>

<p class="tab"><b>Scolman</b>: Exactly. Because you had to put
the casing down, and, of course, we ran cement logs, so we could say, “Yes, it
is cemented." We calculated how much cement we should have put in and then
made sure that it was reasonable with regard to that.</p>

<p class="tab"><b>Carothers</b>: What attention did the
Livermore people pay to the medium the event was in?</p>

<p class="tab"><b>Olsen</b>: That really didn't come until
Baneberry. There were some of us in the containment group, in '69 and '70, who
started to appreciate some things. In particular, what we looked at was C02
content, because there was a shot that conventional wisdom said, at that time,
was deep enough, and had enough yield that it shouldn't have leaked, but it
did. That was Nash. Well, the obvious thing about Nash was that it was in high
carbonate rock. As soon as you think about it, if you make a lot of C02, it
doesn't go away, so it just keeps pushing. So, one of the things we started
thinking about early, when there came some sensitivity about seeping, was carbonate
content. We didn't go much beyond that, although we started to, until
Baneberry.</p>

<p class="tab"><b>Carothers</b>: Was there any logging or
sampling program to look at the various media you might be shooting in?</p>

<p class="tab"><b>Olsen</b>: We did some. It was not much. I
don't remember that we did downhole sampling. We took cutting samples, as they drilled.
One of the problems, in that era, was that there were not big-hole logging
tools, which are now the standard. If you wanted to do any geophysical logging
you had to drill a small diameter hole, so there was a lot more exploratory
drilling then than there is now. We did take cores, and we had, basically, oil
field geophysical tools to measure density and things like that. So, we had
some logs then, and there were a few people who were beginning to look at those
things. The cratering people, who were still in business at the time, were
interested in knowing densities and things like that as input to their
computational models, but they weren't interested in containment, obviously, if
they were interested in blowing a crater.</p>

<br>

<p class="tab">One way to determine something
about the material properties in the emplacement holes is to obtain samples of
the rocks at various depths, and to do various tests on them, in the
laboratory. Such samples mayor may not be representative of the actual
material, but they are a start. Obtaining such samples is not an easy, nor inexpensive
matter, as the drillers see it.</p>

<br>

<p class="tab"><b>Miller</b>: One thing I'd like to tell you
is about all the sampling deals that came up after Baneberry. I was thinking
about that when you called and said you would like to talk with me. I thought,
"I wonder if he ever heard some of my tirades about all the sampling we
did, back then."</p>

<p class="tab"><b>Carothers</b>: All the sampling? Just those
few little side-wall samples here and there, you mean?</p>

<p class="tab"><b>Miller</b>: Yeah, just a few. In fact I
wrote a technical paper on it. It was years ago when they were designing the
tool to go out and take a side wall core, not a side wall sample. I said,
"You've got to find a way of getting this information with logs." And
they finally did. I was happy about that, because they caused us so many problems
with that sampling. Drilling the hole is difficult enough.</p>

<br>
<p class="tab">Preshot measurements of material
properties are important in the prediction of the behavior of the surrounding
medium when the shot occurs. Measurements on cores and samples taken after the drilling
of a hole, and downhole logging data from emplacement holes provide some
information. However, there is not uniform agreement as to the value, or
necessity, of the various kinds of data that can, or should be obtained.</p>
<br>

<p class="tab"><b>Carothers</b>: Bill, you chaired a committee
to look at various material properties to make recommendations about which ones
were important, or how they should be measured.</p>

<p class="tab"><b>Twenhofel</b>: It goes back to Baneberry, when
the properties of the medium had a contributory effect in the release. So the
system said, "We've got to have some way to find out what's down there. And
we want to have that in numbers, we want to quantify it."</p>

<p class="tab">There were certain
measurements that could be made at that time. You could get samples, and you
could measure the water, the grain density, the bulk density from either
samples or from logging tools, and you could measure the carbon dioxide. Those
measurements are relatively easy to make. They're cheap, they're routine, and
they tell you something about the material down there. Then you can calculate
other properties, some of which may be related to containment, like gas-filled
porosity. You can do that, and it's cheap, so you do that.</p>

<p class="tab">There was a committee
set up at that time, and then there was a report that said, "We are now
going to collect these data, and make these measurements. At the very least, if
there are any more surprises which are likely to cause another Baneberry, these
measurements will probably tell us about those surprises."</p>

<p class="tab"><b>Carothers</b>: You make it sound as though the
measurement of material properties started along the lines of, "Well,
we've got to do something. Here are some things we can do, so let's do
those."</p>

<p class="tab"><b>Twenhofel</b>: Pretty close. That's the
impression I'm trying to give. And that wasn't foolish. We were scared. And
there was another thingi the physicists liked it, because they had numbers now.
And again I'm being a little facetious, but not completely.</p>

<p class="tab"><b>Carothers</b>: Well, Bill, what is a physicist
going to do with information like, "At 1326 feet there are fossilized tree
trunks mixed with gravel and sand." How do you put that into a code to calculate
anything?</p>

<p class="tab"><b>Twenhofel</b>: I know. I realize that. But
anyway, that's how it got started. Then the next thing that happened was that
some years ago you appointed a Data Needs Subcommittee for the Panel, and I was
the Chairman.</p>

<p class="tab"><b>Carothers</b>: Well, there had been a certain
amount of grumbling, among some Panel members, who would occasionally say, "Why
are you showing me all this?" And then there was grumbling on the part of
other people who said, "I think it's absurd that you show me data that
shows a water content of 100% and a saturation of 120%. How can there be 120%
saturation? That just tells me you don't know what you're doing. Why are you
doing this?"</p>

<p class="tab"><b>Twenhofel</b>: Yes. So, that subcommittee was
appointed, and it's purpose was to look at what data was' being collected to
see whether there was additional data that ought to be collected, or whether we
could stop collecting some of it. Well, we expanded that charter a little bit
to include, "What kind of data ought to be presented to the CEP." One
of our recommendations was that we add a section on phenomenology, and a
section on a discussion of the containment aspects of the event. So, I think we
made a pretty good contribution .in terms of what data ought the CEP see, and
what ought to be in a containment package.</p>

<p class="tab">In my personal
opinion, I think we badly goofed when we failed to eliminate much of the data
we're collecting on material properties. We failed to do that. I tried, and
some other members of the Panel tried, to get some of that data eliminated, and
the Labs would not stand still for it.</p>

<p class="tab"><b>Carothers</b>: What, for example, do you think
are some things that don't need to be collected?</p>

<p class="tab"><b>Twenhofel</b>: Grain-density. Bulk density.
And consequent calculations based on them. I just don't think they are directly
relevant to containment. I think that those data do not need to be collected.
I've always thought that.</p>

<p class="tab">Now, I think that the
electrical log is a really valuable tool because it tells you something about
whether the rock is different from the norm, whatever the norm is. There's a
norm for alluvium, and there's norm for tuff. If there's something different,
when the electric log tells you that then you can go and look at the samples very
carefully and see whether there is a bunch of clay or not, for example.</p>

<p class="tab">I think we know
enough now about Yucca Flat and Pahute Mesa that we can drill a hole, take a
few simple logs, and treat those areas just like the Sandpile. In certain
places along the edges of the valley there may be another Baneberry surprise,
but we'd catch it with simple logging. Then we could go into it in detail. This
concept didn't prevail in the Data Needs Subcommittee because of the opposition
of the Labs.</p>

<p class="tab"><b>Carothers</b>: What sort of arguments did the
Labs make? You'd think they would latch onto that and say, “Here’s our chance
to save a few bucks."</p>

<p class="tab"><b>Twenhofel</b>: Well, they didn't. I think
there were two reasons. If you have numbers, and you have data, that gives you
some appearance of having done a good job. You've gone to the best of your
capabilities. Also, the calculators do like to have some of those numbers. I'm
not trying to downgrade their attitude at all; they had a good attitude. It
just differed a little bit from mine. I think it's time to reopen the whole question
of what's needed, and to look at it again.</p>

<p class="tab"><b>Carothers</b>: Which properties do you think
do matter to containment?</p>

<p class="tab"><b>Twenhofel</b>: You ought to know the carbonate
content. You don't have to know it precisely, but you ought to know if it gets
over six or seven percent. I think you ought to know if there are some big
acoustic interfaces. The Paleozoic location is only of concern because it's an
acoustic interface. I don't see any reason to give water content, I really
don't, unless you want to know it for coupling, and placement of instruments.</p>

<p class="tab">One more thing about
physical properties, or material properties. I think the histograms that are
presented are probably unnecessary. We now have such a wealth of experience,
since Baneberry, with all those grain densities, water content, gas-filled porosity,
and all that, that what we say is, “Well, they're within experience. They're
within successful experience, every property." Well, of course they are.
We've covered a span now from 5% water to 27% water, so any value we get is
going to fall within our successful experience. We're deluding ourselves with
the magic of these numbers and the histograms, in thinking that they are
relevant to anything. Again, I'm making an extreme statement to make a point.</p>

<p class="tab"><b>Carothers</b>: Or, I could put it as, “We’ve shot
in just about every kind of geologic medium there is at the Test Site, and so
the material properties of a new site are almost sure to fall in the range
you've observed before."</p>

<p class="tab"><b>Twenhofel</b>: And many of them don't matter.</p>

<br>
<p class="tab">As contrasted to the measurement
of the material properties preshot, either in-situ or in the laboratory,
measurements can be attempted of the response of the material to the shock
pressures and motions produced by the detonation.</p>
<br>

<p class="tab"><b>Bass</b>: There was a program at Sandia
that was beginning to get started during the moratorium. Luke Vortman, Lou
Perret, and Al Chabai had a very nice program set up. They asked me if I would be
willing to go to work with AI Chabai on this, as his assistant. I said, “Sure,”
and I got involved with Hugoniot determinations for earth materials. The main
thing we were going to do was write a report on close-in effects of buried
underground explosions, be they nuclear or chemical made no difference. We
wanted to look at the pressures generated close by, the temperatures generated,
whatever was there.</p>

<p class="tab">Livermore was heavily
involved in this kind of work through the PNE program. Dave Lombard was doing
this at Livermore. He was doing a lot of very good Hugoniot work. Bob McQueen
was doing it at Los Alamos, and AI Chabai and I were doing it at Sandia. We
said, “Let's measure Hugoniots, let's measure elastic waves. Let's look at
granite, let's look at alluvium." Nobody wanted to look at alluvium very
much. We looked at tuff a little bit; nobody really wanted to look at tuff. We
were much more interested in oil shales, sandstones, and things like that.</p>

<p class="tab">Anyway, we got going
on it. We did explosive work out at Coyote Canyon, behind Manzano. We had an
explosive site out there that I was in charge of, and I had a crew of about
eight or ten. It wasn't a big facility; it was sort of an ad hoc thing that we
put together. So we started doing this, and we were chugging along merrily,
measuring shock velocities and things like that. Mainly we were doing Hugoniot
work, and gauge development.</p>

<p class="tab"><b>Carothers</b>: What shock pressures were you trying to reach?</p>

<p class="tab"><b>Bass</b>: My job was to get as high as we
could. We wanted to get to a megabar. At that time Altschuler's work was coming
out, and Altschuler was getting up toward a megabar. Everybody said, “How in
the world is he doing it?" The answer was obvious to us all what he was
doing, but it was never in the literature. It has been finally admitted he was
using nuclear sources. He was ahead of everybody, there's no question about
that. He did some great work, and I think he's still around and still doing
some pretty good work. McQueen had started doing some flyer plate work at Los
Alamos, where he was getting up towards a megabar.</p>

<p class="tab">It's no problem at
all to get to a couple of megabars in brass, or steels, or maybe even aluminum.
Getting a geologic material up there is a little tougher, because its impedance
is so much lower. We did the best we could; we would run flyer plates five or
six inches, and planarity was going to hell on us; we were generally using
eight inch flyer plates as plane wave generators. We evacuated the path between
the flyer plate and the target, trying to cut down on the air shock that would
build up and screw up our instrumentation. So we would fire the things in a
vacuum. We would have to glue the plates to the explosive to keep them from
bowing away when we pumped them down. It wasn't a very good vacuum, but you
certainly could bow an eight inch plate; eighty mils was a typical thickness
for the flyer plates. We followed Mcqueen's work on this directly. I'd say we
were getting up to a megabar. The other high pressure work that was being done
was being done by Bill Isbell, at General Motors at the time.</p>

<p class="tab"><b>Higgins</b>: The results of the Livermore
work on Rainier, and that work was very much focused just on Rainier, caused us
to modify our experimental measurements program. We had three or four people who
were spending a lot of time on designing measurement techniques for the
megabar, or many hundreds of kilobars, pressure regime, and we dropped all of
those except one confirmatory measurement that was done on the Antler
experiment in 1961 . That was done by Dave Lombard, and it is the only megabar
level active measurement that's been done on a shot.</p>

<p class="tab">I can remember
standing up at a meeting at Rand Corporation, in Santa Monica, and making an
impassioned plea. “Please stop spending all this money on ten megabar equations
of state because it doesn't make a bit of difference. It's all electrons
anyway." And I wasn't the only one making that argument. That point of
view prevailed, and so all that work stopped. And that was wrong. It was a
terrible mistake.</p>

<p class="tab"><b>Carothers</b>: And you talked them into it?</p>

<p class="tab"><b>Higgins</b>: Well, I was one of those who
did. I've thought of things I've done wrong, and that was certainly one of
them. The consequence of that decision was that the measurements program centered
on the things like Bob Bass has done for the last thirty years, measuring
stress levels in the tens to low hundred kilobar range, where plastic failure,
and brittle failure, and that kind of thing is happening. Of course, that
region is important not only for containment purposes; it's important for
structures effects purposes. It's a region where the mechanical engineers are
very uncomfortable designing things like bunkers, and missile silos, and very
crucial elements of an offensive or defensive system. Whether the stresses come
from nuclear or not nuclear things, that stress region is important. So, it
wasn't totally a mistake, but it was a mistake from the standpoint that we
would today understand more about what goes on in the explosion than we do .</p>

<p class="tab"><b>Bass</b>: I did not go to that meeting in
Santa Monica. I was in Rio that week, and if I had a choice, I would be in Rio
de Janiero. I would say that where Gary now feels we are lacking is not necessarily
in the megabar region, but in the hundred kilobar, two hundred kilobar regime.
That's because the phase changes that are going on in all of our native
materials have been terribly handled theoretically. The various contractors who
have worked with that have really botched that job badly.</p>

<p class="tab">When you get into a
porous geologic material, apparently the phase change can move down in
pressure, down into the seventy or eighty kilo bar region, because of the
temperature that's involved. Alluvium does funny things. Alluvium starts
expanding when you get above a hundred kilobars when you hit it. On a Hugoniot
plot of pressure versus volume, it starts expanding when you get up there,
because you're moving back in the temperature curve. It's a mess, and I don't
pretend to really understand what's happening there.</p>

<p class="tab">It would be nice to
have data in the megabar region, but I'd rather have them in the hundred kilo
bar regime. Shell Schuster, who used to be at Livermore said, “Don’t measure me
another Hugoniot, for God's sake. I can draw them." And I think he's
right. You can draw the Hugoniot, but you can't write the equation of state.</p>

<p class="tab">I think we've got a
better handle on some of these things than a lot of people realize. There have
been two decent sources of data in recent years. The containment program has
provided a wealth of data. Frankly, I think most of it recently has come from
DNA, and Sandia. I think that's because of where they test. The DNA tunnel events
give you the opportunity to make a decent measurement, because you can get
there. You know exactly where your gauge is, you know exactly where it's
pointing, you can orient it with a transit. You don't have to dangle it down a
hole, or put it in a satellite hole.</p>

<p class="tab">The other great
source of data has been the hydrodynamic yield program, and this a tremendously
overlooked source of data. We got seventy-five pressure measurements in tuffs
and alluviums in the period when Los Alamos was making hydrodynamic yield measurements.
Individually they're pretty damn bad, but as a whole they're pretty good.
There's a wealth of data in there in the 500 kilobar to 10 kilobar pressure
regime. There are awfully good data on events in alluvium up to 500 kilobars. I
know they're good because I made the measurements, and I'm very happy with
them. They were not measurements of wave shape, however. They were measures of
peak pressure, and at 500 kilobars what else can you have?</p>

<p class="tab">Another batch of data
came from Livermore. Clyde Seismore came up with a marvelous pressure gauge
that worked in this pressure regime. It was a bulb of plexiglass; it turns out
that when you shock plexiglass it puts out a charge. So, Clyde put this bulb of
plexiglass downhole, and he made some outstanding measurements.</p>

<p class="tab"><b>App</b>: DNA has the best opportunity to
look at material properties in-situ, and at what material damage has been
caused by the shot because they can go into the tunnels preshot, and can reenter
after the shot. On a reentry they can go back in and obtain core samples of
rock that has been shocked to a kilobar, or five kilobars. They can obtain the
damaged samples, send them to Terra Tek and have them measure the residual
strength.</p>

<p class="tab"><b>Carothers</b>: And it's different from the
strength of rock that hasn't been shocked.</p>

<p class="tab"><b>App</b>: Yes it is. For the cases I have
seen on reentry, the tuff appears to damage more than the grout. Preshot, both
the rock and the grout give off a ringing sound when hit by a rock hammer.
Postshot, the grout still rings, but the tuff gives off a dull thud. The
postshot tuff can be pulled from the walls by hand, and it crumbles.</p>

<p class="tab">DNA has taken cores
from damaged rock to Terra Tek, and the failure properties they measure are
way, way down. Of course, it's a function of range. At five kilobars the damage
is severe, at one kilobar it is just beginning, and at five hundred bars it is
virtually nonexistent. Damage decreases significantly with increasing range.</p>

<p class="tab">As a practical
matter, on the vertical shots we can't obtain such core, so we have to estimate
damage based on the tunnel rock observations. Or we can try to pseudo-damage
rocks in the laboratory them by straining them, and determine how they weaken with
strain. You can do that up to a point, but you can't get the really large,
twenty percent type shear strains that occur in an underground test. And, you
can't replicate the strain rates either. So, we're not really replicating what
is going on in the ground with laboratory tests.</p>

<p class="tab">However, with
laboratory tests we can get some feeling whether a material is going to damage
easily or not. DNA has gone to a lot of effort to try to simulate damage in the
lab, but with a lab sample, once you get a through-going shear failure, you've
lost your experiment. They can't achieve twenty percent strains, although the
people at Waterways and Terra Tek are trying. They're coming up with new
schemes, and who knows? They might be successful; it would be very valuable to
the calculational community if they were.</p>

<p class="tab"><b>Carothers</b>: Suppose you get a sample from a
tunnel location, and you send it to Terra Tek. They say its compressive
strength is such and so. There are folks who would say, "That's the value
for a small, competent piece of material. The region the device energy is
interacting with is much larger, and that much larger volume will have things
in it like fractures, changes in porosity, and so on. Therefore the lab
measurements are not really representative of the world the device energy is
going to interact with."</p>

<p class="tab"><b>App</b>: That's right. But, for certain
types of rocks apparently that measurement is fairly representative. The Tunnel
Beds tuff in the tunnels is perhaps one of those rock types. The DNA modelers feel
that the in-situ fractures don't modify the overall properties much from what
one obtains from the small samples. The reason they believe this is that they
can put the Terra Tek test results into their models, and replicate the
outgoing shock wave fairly well. Now, I said outgoing shock wave; late time
residual stress is a different story.</p>

<p class="tab">Other rock types such
as alluvium and welded tuff also are a different story. For these materials,
what you're saying is absolutely right. You cannot go from the laboratory
measurements to a calculation that agrees with the field data. This is a big
problem for us, and the approach we have taken is to start a systematic study
of events that have had a lot of free field measurements associated with them,
and inferthe response properties of the rock mass from them. Merlin alluvium is
an example. The Merlin event was heavily instrumented by Sandia. There were a
lot of working point level gauges, some horizontally out, and some vertically
up from the working point. Unfortunately, the Merlin samples are the only ones recovered
for alluvium core properties measurements, so that's the only case where we can
make direct comparison to the calculations.</p>

<p class="tab">We're trying to
create a library of properties based on inferences made from modeling, as
opposed to from core. I don't know what else to do. This approach does take
into account the larger volume. Exactly what you've said is what prompted us to
take this course of action. We do not get a unique solution from these calculations,
but the more measurements we have, the closer to unique it becomes. So, we now
have a standard equation of state for Area 3 alluvium. It's not based on
mechanical measurements, because you can't obtain core in alluvium. If you do
get core it's only the more competent parts of the material, so it comes back
to your argument that it's not representative.</p>

<p class="tab">What is
representative is what we see in the wave forms, and if we can infer properties
by using forward modeling techniques, then we can come up with an equation of
state for Area 3 alluvium. When we have our next shot in Area 3 we will take
those properties from Merlin, look at the comparisons of the physical
properties, such as density, and perhaps make a few adjustments, but keep the same
basic response model. Then we will use that in the new location where we're
trying to do a site evaluation.</p>

<p class="tab">We're currently
taking this approach with granite, for the verification program. We have the
same problem for verification. And so,we're trying systematically to
calculate a number of events. We've been doing this for years now, as time
permits. It is not something we have recently started. There are three of us
working on this; myself, Wendee Brunish, and Jim Camm. We've calculated some
Pahute Mesa tests, and in Yucca Flat we've done a lot of work on the Hearts
event.</p>

<p class="tab"><b>Carothers</b>: I would think that Pahute Mesa
would be your most difficult area. On Pahute you have fairly soft layers of
ashfall or ash flow rocks, and you have pillow of lavas, so you have hard
layers and soft layers. All of those presumably interact with the outgoing wave.
How do you handle that?</p>

<p class="tab"><b>App</b>: It's a difficult problem, and
we're not happy with our Pahute Mesa results in comparison with the
experimental data. We've been able to model certain aspects of them; we're able
to see the same kind of rarefactions, in the model, coming back from the hard
to soft transitions that we see in the measurements. But they are only
qualitatively similar. Quantitatively, no. I said something about uniqueness
earlier. When you have a layered situation, it is extremely difficult. From the
modeling standpoint what we'd really like to be able to find is a Pahute Mesa
site that doesn't have any soft layers, but then we'd be afraid to conduct the
event, from a containment standpoint, because the site would be different from any
we've used before.</p>

<p class="tab"><b>Carothers</b>: When we talk about differences
in the materials, over what physical dimension do things have to be different
to produce changes in the response?</p>

<p class="tab"><b>App</b>: The size of the feature
compared to the wavelength is probably the most relevant thing. If a feature
that is different is quite small compared to the wavelength, it may not be very
important. This is not always true, however. It would not take a very large
open fracture to seriously attenuate the signal. The wavelength is going to
increase with increasing distance, so by the time you get out to where the wave
becomes elastic, it's going to take a fairly large feature to cause a serious
perturbation.</p>

<p class="tab"><b>Carothers</b>: Let's consider closer to the
device. There is the thought that it doesn't matter much what's close to the
device, because the energy release is so large that it just overwhelms any minor
geologic features. Some folks think that's not a very good argument.</p>

<p class="tab"><b>App</b>: I'm not one of those people.
Close in, in the true shock regime where the wave is supersonic, I don't think
response properties of the solid rock much matter. For rock that is vaporized, it
does make a difference. Now, again, these opinions are based on modeling. I
think properties do matter beyond where the eventual edge of the cavity will
be, at the few kilobar level and below. The exact range would be somewhat
material dependent.</p>

<p class="tab">Two and three dimensional effects are important, but our serious
difficulties lie with material response.</p>

<p class="tab"><b>Carothers</b>: But that's something you cannot
find out in the laboratory with the tests that you can make today.</p>

<p class="tab"><b>App</b>: You're right. Not to the degree
that we need to. I think we need more measurements in the field, and from that
data, backing out the response models would be the way we would go. These would
be inferred properties, and once again, there is a uniqueness problem. But, if
you get enough data, using reasonable assumptions about how a material behaves,
augmented by mechanical tests in the laboratory, you might be able to back out
how particular classes of materials behave.</p>

<p class="tab">That takes an
experimental program, and in fact that is part of the emphasis right now in
verification, to do more well controlled in-situ experiments. Modeling plays an
important role in the experimental setup. In order to maximize our ability to
infer bulk response properties of the rock, instruments must be located well into
the inelastic zone, and at numerous locations.</p>

<p class="tab">To characterize
various classes of rock in this way will be an expensive process, but once
having developed a library of properties, we should have more confidence in
modeling, and understanding the more important effects of layering, such as
exists at Pahute Mesa. Currently it is very difficult to sort out the effects
of layering.</p>

<p class="tab">The Pahute Mesa event
named Houston was a rare example of a site where there's considerable thickness
of hard rock without softer interlayered rock. The soft layers are halfway up
the hole. If we can have another shot in that area, where we can get
instrumentation strings deep, and study the propagation of the initial outgoing
wave, then we can learn something about the properties of a heretofore
difficult material to characterize.</p>

<p class="tab"><b>Carothers</b>: Carl, when you make the
measurements you're making, I'm sure you must need to know properties of the
materials. Where do you get that information?</p>

<p class="tab"><b>Smith</b>: DNA sends cores to Terra Tek
principally, where they are squeezed. The data from that goes principally to
Pac Tech, where Dan Patch does most of the stemming calculations for DNA. The
other big source of information is Maggie Baldwin and the people at DNA,
because they're the ones who have done the exploratory geophysics work in those
holes.</p>

<p class="tab"><b>Carothers</b>: Carl you have said, when
talking about the equation of state work, that measurements in the field are
not necessarily at all like those made in the laboratory on samples. Couldn't
the same criticism be made of the data from the cores?</p>

<p class="tab"><b>Smith</b>: It's a question of economics.
With a fixed pot of dollars you could spend it all on investigating one little
area, and know more and more about less and less until you know everything
about nothing. Or you could take that fixed pot of dollars and explore a larger
area with selected measurements. This question has always been a bugaboo for
DNA; you've got all these variations on the core measurements, but everyone
wants to treat the material as uniform, because you do all your calculations
with one material.</p>

<p class="tab">Actually, for years
DNA has been very successful in treating all this shot area, this material they
excite, as roughly uniform material with some faults and fractures through it.
But now, as you go to smaller and smaller shots, and maybe go into a new
tunnel, and maybe get into places that are not zeolitized, now maybe these variable
things come back to haunt you, and you can't treat them as a single element.
The scale is no longer the high yields where you overwhelm the geology. If the
scale is that for only half a kiloton, maybe that fault is going to eat you
alive.</p>

<p class="tab"><b>Carothers</b>: Instead of taking all these
cores, which means you have to drill a hole, why don't you run logging tools?
That's cheaper.</p>

<p class="tab"><b>Smith</b>: Logs give you one type of
information, the cores give you different types of information. Cores give you
information up to four kilobars, and the calculators like very much to have
that.</p>

<br>

<p class="tab">Calculations of many kinds are
done. One of the important questions for containment is how the gases in the
cavity, originally at very high temperatures and pressures, flow out into the
surrounding medium. Central to that is the permeability of the materials in the
earth itself, and in the column of stemming materials. One of the first efforts
to measure, and to calculate that was made by Carl Keller, then at Los Alamos,
in the early seventies.</p>

<br>

<p class="tab"><b>Keller</b>: The flow paths of concern were
the stemming column, the chimney, the hypothetical hydrofracture, and that was
about it. The characterization of the medium required for hydrofrac
calculations was never done. The permeabilities were not measured. The in-situ
stresses were not measured. There were no serious measurements even of stresses
near the events. There were serious efforts, but the data certainly weren't of
the quality that there is now. Cavity pressures were not measured. They were
inferred from LOS pipe measurements of pressure, and those weren't too bad. Now
they seem to be what they were thought to be then; a lower bound on the cavity
pressure.</p>

<p class="tab"><b>Carothers</b>: How could you run a gas flow,
or hydrofracture code? You just listed a number of the important parameters and
said you didn't know them.</p>

<p class="tab"><b>Keller</b>: Cowles and Yerba were the first
two line-of-sight pipe events after Baneberry. Yerba was in a shaft, and so we
had access. So, one of the things we did, having that state of ignorance, was
that I designed a permeability measurement scheme for the Yerba shaft, and the
J-6 folks built the hardware, installed it, and made the measurements. Every
hundred feet in the Yerba shaft we made permeability measurements, and those
are still the only permeability measurements with that kind of resolution in
existence.</p>

<p class="tab">Those were done with
two drill holes. One was the air injection hole, and you measured the flow rate
and the pressure history at the bottom of the hole. They were essentially
packed off so you only had a small volume at the bottom, which was the gas
source, that was free to leak into the medium. And given the pressure history and
the flow rate, you can determine a permeability. The second hole measured the
pressure of the flow field. That's a check, a redundant check, and from that
you can also deduce a permeability. And so with that over-constrained system we
could tell whether or not it was really spherical flow, and we could tell
whether it had come to equilibrium, and some of those kind of things.</p>

<p class="tab">The Yerba
measurements have been invoked countless times as characteristic of alluvium.
Well, alluvium is a highly variable material. One of the most glaring examples
of the differences in alluvium are the Agrini crater, which was 200 feet deep
and bigger at the bottom than at the top, versus Pike, where the alluvium just fell
in like a big sand pile. Some of the alluviums crater very gracefully; they
just fall in and there's a big flow, a big slump down to the bottom.</p>

<p class="tab">There have been other
permeability measurements made by other people. Frank Morrison and the Livermore
folks tried to deduce permeabilities from pressure histories measured during
the stemming process, which is kind of a clever way of doing it. It's pretty
complicated, but in principle you can do it with enough math, and get a measure
of the permeability.</p>

<p class="tab">Another way was to
measure pressure histories in drill-back holes, and from that try to measure
overall permeabilities. I think those are fine for a real gross measurement,
but there are serious problems with them. For one, the volume of the hole can be
a real problem because you have to fill the hole. It's not like you have this ideal
pressure probe which does not influence the flow. You have to fill the hole,
and these flows are very small with that kind of driver, so it takes time to
fill the hole. And then the hole can actually leak off, because they're not all
cased, and most of them are not grouted even if they do have a casing in them.
And so you never know, because you can get strange flows. You can come up in
this hole, and run down to the bottom of that one, and shortcut the medium.
There are a lot of problems with those measurements. So, it gives you a very
gross measure. There are better ways of making measurements.</p>

<p class="tab">You can even infer
permeabilities. If you presume that you know the noncondensable gas source,
then you can, from the arrival times at the surfaces for those that have
leaked, infer chimney permeability.</p>

<p class="tab"><b>Carothers</b>: Well, along these same lines,
in the CEP you often hear somebody say something like, "Well, you may get
a fracture to here, or there may be gas transport to there, but this layer has
a lot of permeability and porosity, and so it will just soak everything up.</p>

<p class="tab"><b>Keller</b>: Yes, you do hear that a lot.
The people making those statements are not very quantitative in those areas, but
they could be. Those kinds of statements could be supported completely with simple
noncondensable gas flow calculations. Or you can even do hydrofrac
calculations. Generally people infer that if you have a high porosity, high air
void content, then you have a high permeability. That's sometimes true, but not
necessarily so.</p>

<p class="tab">And the permeability
is never measured; it's always inferred from other characteristics. That's
bothered me forever. There have been some pretty strong statements about pore
space available, but it is the permeability that determines whether it's really
available. Some air voids are not available; they're in pumice shards, for instance,
and they're sealed off.</p>

<br>

<p class="tab">Near the detonation point the
shock pressures, the stresses and the strains the material undergoes, and the
time scales on which they occur are beyond those that can be created in the
laboratory. Data from instruments located in the material near the shot point
can give some information, but the environment is severe, and such experiments are
extremely difficult to do. Carl Smith has done extensive work on developing
ways to make such measurements in the field, on both nuclear events and high
explosive experiments.</p>

<br>

<p class="tab"><b>Smith</b>: I have principally done gauging
work, working on gauge development techniques, trying to make in-situ equation
of state measurements. Equation of state measurements typically are made in the
laboratory on small samples. Of course, if the sample breaks you discard it,
and get an intact sample. But field work invariably involves fractures, and
faults, and things like that, and so the big push for many years was how to
develop techniques, and how to make measurements for in-situ equation of state
type work.</p>

<p class="tab">The equation of state
measurements principally revolve around the area from the near elastic into the
shock wave regime, so you're through the yield range of soft rocks, like tuffs.
That's from like half a kilobar up to the ten kilobar regime, where the yield
effects take place, and that's where the unknowns are in the equations of
states.</p>

<p class="tab">In such work you need
measurements of both motion and stress, because of the three dimensionality of
the meaurements in the field. In gas-gun work you have one dimension, and you
can take stress measurements and get the motion measurements out of them, through
the Hugoniot equations of state. On a gas-gun type of shot you slice the rock,
put in these material gauges, which can be as thin as mils, and then glue all
the layers back together. The shock passes through the rock from one end to the
other, and so it's one dimensional.</p>

<p class="tab">In measurements in
the field, because of the spherical divergence, you need the hoop stresses, the
radial strains and the radial stresses, and particle velocity measurements. And
so, very quickly, you become aware that the Achilles heel of all that work is
in developing instruments to make viable measurements.</p>

<p class="tab">The seventies were
the days when we started developing the so-called ytterbium gauge. Ytterbium is
an odd-ball element that sits off the periodic chart, and has a very strange
electronic structure. As discovered by Bridgeman and others, it has a very wild
stress-piezoresistive effect. In other words, as you squeeze, it changes it's resistance.</p>

<p class="tab">On a field event you
don't have the ability to build an in-material gauge, as you do on a gas-gun
shot. You have to drill holes, insert the gauges, and put in grouting material.
The concern then is, does the grout material match the host in some way. In particular,
you want a measurement that is representative of the free-field stress in the
rock, in a material that is not the rock itself. That's the so-called inclusion
problem that people have worked on for numerous years.</p>

<p class="tab"><b>Carothers</b>: You say you want the grout to
match the rock in some way; which characteristics are most important?</p>

<p class="tab"><b>Smith</b>: Compressibility. In other
words, does the grout deform in the same way as the host rock.</p>

<p class="tab"><b>Carothers</b>: When you get into the ten
kilobar range, you're in the region where the tuffs are plastic. That means
you're near the edge of the cavity, where it's still growing. How do you make
things survive?</p>

<p class="tab"><b>Smith</b>: They don't. Principally it's
the cables and electrical leads that are destroyed. Sometimes we can go in on a
mine-back and find these gauges. When we find them, the first thing we do is see
if the gauge is still intact. Almost invariably it is, but the leads that have
been severed, or torn off the package, or somewhere something like a fault has
moved differentially and sheared the cables.</p>

<p class="tab">What we're getting
out of the gauges now is the arrival time, a rise to peak, and then a little
bit of unloading, enough stress wave unloading so we can say that we have
indeed captured the peak, rather than having it go up and stop before it
reaches the top. One of the efforts nowadays is to enhance those recordings,
and to incease the recording times by building armored cables, and so on.</p>

<p class="tab">To build stonger
cables we're now using a technique that uses wire-rope. The first time we did
that we took a wire rope, took off the outside strands, replaced the center
core with the electrical cable, and then wrapped the outside wires back on the
rope. Now we've gotten sophisticated, and we're going to a wire-rope
manufacturer to have the cables built that way. At the end of a production run
on something of about the right size, we stick our spool of cable at the back
of the machine, and have the wire-rope made with our electrical cable as the
center.</p>

<br>

<p class="tab">The shock wave damages the
materials through which it passes, and changes their properties. Those
properties are of importance in what occurs in the later time processes around
the cavity. Attempting to reproduce in the laboratory the damage that occurs
due to the shock loading is extremely difficult to do, and the material
properties measured on such damaged rock samples as can be produced may be
quite different than those of materials near the detonation. Persons attempting
to develop models to predict the ground response must often infer the material
properties by trying to match their calculations to data such as arrival times,
peak values, and decay times of the pressure pulse.</p>

<br>

<p class="tab"><b>Keller</b>: One of the really interesting
experiments we did was on one of Sandia's shots called One Ton, which was done
by Carl Smith. We obtained, from the working point region of One Ton, big,
twelve inch core. We took that to SRI, cut it, machined it, and put it in our
HE charges with the wires, to measure the response of that tuff from the
working point of the One Ton HE shot. We also took core to Terra Tek, and
measured, in the laboratory, the strength properties of that same material.</p>

<p class="tab">Both S-Cubed and Pac
Tech did calculations of the SRI test, and of One Ton. This was before the
shot. Then Sandia shot One Ton, and made good stress measurements all around
it. I asked Sandia not to tell the calculators what the results were.</p>

<p class="tab">I had asked the
calculators to take the properties of the cores that Terra Tek had measured,
and calculate the SRI test. Then they could see the SRI test results, and they
could take those results and modify their equation-of-state if they wanted to,
and then they were to predict the One Ton results.</p>

<p class="tab">We met at S-Cubed,
and they had their viewgraphs of the stress histories at the various ranges,
which had been pre-selected on the SRI tests and on the One Ton tests. We had
pre-selected the scales to use in the plots of the results, so you could
overlay them. Sandia would put down the measurement from One Ton, and S-Cubed would
put down their stress history, and then Pac Tech would put down their stress
history, right on top. The correlation between the predictions and the
measurements was really quite good. It wasn't equally good at all ranges. The
calculations were better close-in than they were far-out.</p>

<p class="tab">We discovered, out of
that series, that the way Terra Tek was measuring the pressure versus volume
curve was not good. They just put the sample in the holder and squeezed it.
From that they would get a pressure versus volume curve. However, if they put
the sample in the holder, squeezed it up to the overburden stress, where the
samples had been obtained, and let it sit there for a while, it would creep to
a lower volume. Doing that sort of replaced the sample in the mountain, and now
when they ran their pressure versus volume curve they got much lower
compaction. It turned out that you needed lower compaction in order to match
the results. That was a really instructive series, where we compared our predictions
and our procedures to reality. Sandia was very helpful on that.</p>

<p class="tab"><b>Patch</b>: The most important things that
go into the models are the mechanical test data that are done in the
laboratory, on cores. And those tests have some serious limitations that
everybody understands. The people doing the tests certainly do, and the users do
as well. One of the most serious limitations is that they are limited in the
total amount of strain, because they can only squash the rock so much. Nuclear
bombs, near where the bomb is, have a way of scrunching the rock a whole lot.
That strain path is just not accessible in the laboratory.</p>

<p class="tab"><b>Carothers</b>: My impression is that they can
go up to about four kilobars.</p>

<p class="tab"><b>Patch</b>: Yes, they can go to about four
kilobars. We have gotten up to six kilobars at Terra Tek, and I think eight
kilobars is doable in a Terra T ek type test. They can go up to twenty-five
kilobars, but the problem is, you don't get out the data you need. What you're really
looking for is the response of the rock in terms of its deviatoric response,
and so on. Just pushing on a rock and measuring how much it squeezes gives you
some data, but there are many other things you want to know. So, it doesn't
help just to go to some high stress level.</p>

<p class="tab">The other factor is
that you can load the core to four kilobars by loading it axially, but you can
only deform it so much before you reach the limits of the machine. The problem
is that in the ground, rock that's squeezed to four kilobars subsequently moves
out a long ways, and undergoes a lot of strain. It laterally stretches and it compresses
axially, and that occurs at much less than four kilobars. A great deal of that
motion might be at only a quarter or half, or maybe three-quarters of a kilo
bar. A lot of that deformation goes on at low levels, and one could track that
in the laboratory, except that there are mechanical limitations on the machinery.</p>

<p class="tab">The other problem we
have with mechanical test data, and in some ways it's almost more serious, is
that in the ground, when the material is deformed there is a funny kind of
lateral constraint. To first order the material is forced to move out spherically
symmetrically. Maybe block motion happens later on, and other funny things, but
by and large, if you go in and look at any given piece of material, you can
pretty much convince yourself that it's been homogeneously moved out and
stretched. To the zeroth order it's an isovolumetric strain path. If you try to
do that on a sample in the laboratory, you can do the compression part of it.
Once you try to mimic the part of the strain path that amounts to stretching it
laterally, and taking up that so it is kind of isovolumetric, the rock wants to
fracture along a shear plane. It wants to form these shear planes, and now
suddenly it's not a continuum material anymore. You're doing a friction test in
a way, and you get data out of the test that looks reasonable. The only problem
is, it doesn't have any relationship to the way the material is behaving either
in the field or in any kind of continuum sense. That's one of the serious problems,
and we have to finesse our way around that.</p>

<p class="tab"><b>Rimer</b>: I've been working for a number
of years, trying to understand how the rock gets damaged. I have not been able
to get data in tuff, because its permeability is so low, for effective stress modeling.
So, I assume the laboratory data we have has the pore pressure built into it,
because the strengths are lower because of the saturation. I am still trying to
get measures of how much of the material is damaged from the shot.</p>

<p class="tab">We tried to do a
laboratory material properties test at Terra Tek that would go along the strain
paths. Unfortunately, you cannot confine the material in the laboratory like it
is underground. Underground it's confined by adjacent material doing the same thing.
You have membranes around it in the laboratory, with pressures on them, but you
can only measure the strains in a couple of locations around the circumference.
And, you don't even know what path you're on. As you start to unload the
material, you get a through-going fracture, so those samples are worthless for
material tests after that. So, that work was unsuccessful.</p>

<p class="tab">There is another set
of data on reentries and core samples taken at the time of Hybla Gold, which
was near Dining Car. These show that the samples that were near Dining Car were
damaged greatly. Their strengths were extremely low, much lower than we can reproduce
in the laboratory by damaging the material to the same peak stress levels. So,
my hypothesis was that the total shear-strain the material has seen is greatly
different, based on calculations, than with any model. And that's the difference;
we should make the damage that we see a function of shear-strain.</p>

<p class="tab">In late 1990 I and
Bill Proffer, who did the calculations for me, used that Terra Tek data to do
some residual stress calculations. Those calculations give grossly different
residual stresses. The peak in the residual stress is further out, but it's
still considerably higher than the cavity pressure. Even though the material is
now much weaker, peak stresses are the same as with the other model. So are peak
velocities, so are cavity pressures, and cavity size. The material goes out
more, comes back more, and ends up at about the same place. But, it undergoes a
lot more plastic work. It gives low peak residual stresses further out, but
gives almost no residual stresses out to, let's say, the range of the FAC, the
Fast Acting Closure. The other model would say a third of the way from the
cavity to FAC you've got strong residual stresses, much higher than cavity
pressure.</p>

<p class="tab">I think that's why we
see radiation as far as the FAC on many of the DNA events. There's a nice
closure, but it's permeable, and the residual stresses aren't there to keep it
closed. And so, you get a little seep of material through that grout to the F
AC. It doesn't influence containment because there's a gas-tight closure
further down, but there's a little seep. Operationally it means we can't examine
and take out the FAC anymore. But I think that's in line with the new
calculations I've been doing with this new model.</p>

<p class="tab">We know that
post-shot we have much lower strength in the material. When this strength
reduction occurs is anyone's guess. My guess is that it doesn't occur when the
peak stress is reached. The material continues to strain all the while it's
moving out, and the strains it gets to may be a factor of three higher than the
strain it sees at the peak stress of the shock wave.</p>

<p class="tab">I recently saw some
interesting data. Terra Tek had taken preshot samples from Disko Elm, and they
did the normal tests on them. Then they did SEM tests, the scanning electron
microscope tests. Then they used what they call a Wood's Metal approach, where
they use melted metal, which gets into the open pores and fractures of the
sample. They shine a laser on the sample, and they get marvelous color pictures
of the microstructure at different scales, even better than they get from the
SEM pictures.</p>

<p class="tab">They did the same
thing to materials they took post-shot, at the same stress levels. The pictures
are totally different. At two kilobars, from samples that were damaged in the
laboratory by squeezing, you see some signs of pore crush-up, but just a little
bit. Once in a while you see a little fracture. At two kilobars, in the in situ,
shot damaged material, there are fractures throughout it. It looks like a
totally different process has occurred.</p>

<p class="tab"><b>Carothers</b>: Well, sure. The material near
the shot doesn't get just compressed. It also gets stretched tangentially,
because it's moving out.</p>

<p class="tab"><b>Rimer</b>: That's right. Exactly. And
that's true even at two kilobars. That's what I mean by the strain test. I'm
using shear-strain, because mathematically it's a principal invariant. The
lateral strain is tensile, the radial strain is compressive. They add together,
and you get four percent, roughly, at four kilobars peak stress. That's almost
all radial strain, but then it keeps stretching as it moves out almost
incompressibly. The strain is enormous; you can get twelve percent strain, and
that's what I'm trying to model. I don't know the numbers, the parameters, but
when it reaches ten percent strain I think it's mush. And we've seen plenty of
mush near the cavity. These results that Terra Tek showed are another confirmation
of that.</p>

<p class="tab"><b>Ristvet</b>: You get into totally
microfailed material as you get about a quarter of a cavity radius away from
the cavity boundary. You start seeing isolated pockets of this material from
about two cavity radii in, and it is basically like cohesive silt. I would say
its unconfined strength is only a few hundred psi, as a result of the microfracturing.
We've documented that at Terra Tek and USGS, and we see it in the shear wave
drop, and so forth. It's for real.</p>

<p class="tab"><b>Rimer</b>: Terra Tek also did uniaxial
strain, and triaxials on those damaged samples from Disko Elm. They have much
lower strength, and the strengths get lower and lower, within the scatter of
the tuff, as it's been hit harder. I don't know if strain is the right thing to
use, but it's much better than stress.</p>

<p class="tab"><b>App</b>: In the effective stress there
are theories that the pressure of the water, after it has been shocked and some
unloading has occurred, exceeds the stress in the matrix. Then, essentially the
response of the whole aggregate is determined by the response properties of the
water. And the more water you have, the more that's going to occur. In an
effective stress model, the strength, after the material has been loaded up to
a certain point, comes back to zero. There's no strength left, and it is the
water in the pores that determines the response of the material.</p>

<p class="tab">One reason the
effective stress models have not been adopted universally is their extreme
sensitivity to small changes in mechanical behavior such as dilation, porosity
increase due to shear induced micro fractures. Pore pressure, and therefore
shear strength, is very sensitive to such increases in porosity. Yet, in the
field, we do not observe huge variations in observed phenomena from site to
site, at least not at the scale that is suggestd could occur due to dilation.</p>

<p class="tab"><b>Carothers</b>: In P tunnel there was a small
change in something that made a big change in the response of the ground.</p>

<p class="tab"><b>App</b>: Well, yes. DNA does have a
prime example that is contrary to what I was just saying. Why was Mission Cyber
so different from Disko Elm? Those were two shots that were very similar. If
I'd thought of that a minute ago when I started on that little spiel about not
seeing much difference, I might not have said it. There is apparently some
change so hidden that nobody's been able to identify it. Thus far, the only
difference that has been identified is the minerology, and we cannot determine
how that would alter the phenomenology. One site has been altered to zeolite,
and the other hasn't. The mechanical properties from both sites are about the
same. There is no known answer at this time.</p>

<p class="tab"><b>Rimer</b>: With the things we usually
successfully measure, the free-field ground motion, the calculational results
do not tell you which model is better. Residual stresses would, and we're still
trying to measure them; real hard we're trying to measure them. The problem has
been gauge breakage, and cable breakage.</p>

<p class="tab"><b>Carothers</b>: How about a self-contained,
hardened instrument that you recover after the shot?</p>

<p class="tab"><b>Rimer</b>: Great idea! We tried that with
the SCEMS, the Self Contained Environment Measurement System, a big heavy piece
of equipment that does that. And the batteries went dead on it.</p>

<p class="tab">There's a paper by a
guy named Starfield, in which he talks about the limits of our ability to
understand rocks, and classifies calculations by how much data is available on
the material; how much data is available to isolate the physical models that
are important. It's a very interesting paper. It really tells you how limited
you are in rock mechanics, in your understanding. That's not to say you don't
learn anything about how materials behave by looking at measurements, and
trying to match measurements. You need to know as much as you can about the
properties of the rock, and I get very exercised every time I'm at a CEP,
because they go into enormous detail about sonic velocities, and physical
properties, but they don't talk about strength. And containment is, to zeroth
order, a strength phenomenon. Water matters, for cavity pressure, and it
has an effect on strength. Gas porosity matters in attenuating peak motions,
and surface velocities. Why anyone cares about surface velocities for these
deeply buried shots I don't know. I guess it's easy to measure.</p>

<p class="tab"><b>Carothers</b>: I don't think anybody knows how
to measure the in-situ strength, un fortunately.</p>

<p class="tab"><b>Rimer</b>: That's true. Now, Bob Schock
looked at how you could determine strength from the measurements we have. He
found a strong correlation with the shear modulus, the modulus of rigidity, the
shear wave velocity. Anyone of those, because they all use the same quantity,
really. I always thought an improvement would be to measure the in-situ shear wave
velocity, because you can get a shear modulus, and from that maybe get an idea
of the strength. Not the full story, but a feeling. Now, John Rambo, at
Livermore, looks at drilling rates as a measure of strength. He's come up with some
interesting correlations.</p>

<p class="tab"><b>Carothers</b>: But the drilling rate depends
on a lot of things you don't know. How sharp is the bit, how much weight is on
it, are the drillers pushing today, or taking it easy.</p>

<p class="tab"><b>Rimer</b>: I understand. But it's
something that's worth looking at.</p>

<p class="tab">Another thing we
spent a great deal of time on was Pile Driver. I must have done thirty or more
one-dimensional calculations, and a number of 2-D calculations, to develop a
model for the in-situ strength of the Pile Driver granite. The intact rock was
very strong, but the pulse width measurements that Perret and Bass, at Sandia, did,
and SRI did showed wider pulse widths, which shows weaker material. By pulse
width I mean velocity versus time.</p>

<p class="tab"><b>Carothers</b>: There are folks who might say,
"The rock is very strong. We've taken good, intact cores to the lab,
checked them out, and it's strong rock all right. No doubt about it." And
there are other folks who might say, "That's all very well, but that's a mountain
there, which is not intact. It's full of cracks and fractures which weakens the
rock."</p>

<p class="tab"><b>Rimer</b>: A one-foot joint spacing.</p>

<p class="tab"><b>Carothers</b>: For example. And so, you have
all these numbers from these unfractured cores, but you've got deal with all
this fractured rubble, to exaggerate a little.</p>

<p class="tab"><b>Rimer</b>: I spent a considerable period
of my life dealing with that. Ted Cherry's idea, and he first thought of it
back at Livermore, was that there was water in the fractures. At this point I
think it's more likely there's clay there. Either way it results in a weaker, lubricated
joint system. Ted modeled that with an effective stress model. We tried a
number of things, and that's what I spent a lot of time on. What could we do
that was reasonable, where we used the laboratory strength of the granite,
which was superstrong, and then brought in some physical process to reduce the
strength? We used the effective stress model, and ran 2-D calculations which we
calibrated to pieces of data; Perret's underground particle velocity measurements,
the geologic structure, which was a weak weathered layer, then a layer where
Perret measured the wave speeds to be slightly less, and then the working point
material.</p>

<p class="tab">We were able to match
all the ground motion measurements, both underground and free surface, with
that model. The peaks were a little different, but the SRI data is from a
different azimuth than the Perret data, and that may explain it. We were able
to match, with a 2-D calculation, that data, but I don't believe it. I don't
believe that effective stress is the true model. I think it's more something
that happens in the joints, and that could be tied in with the pore pressure in
the joints. We had a program, which DARPA funded, that’s consisted of
small-scale explosive tests at SRI, using 3/8 of a gram of HE, to look at this.</p>

<p class="tab">These were in granite
cylinders. I was doing calculations, supervising the experiments that Alex
Florence was doing up at SRI, and having special laboratory material properties
tests done by Chris Schultz, at LaMont Dougherty Geologic Observatory at Columbia
University. In these experiments SRI was measuring particle velocities, looking
at wet versus dry, where they measured the pore fluid pressures preshot.</p>

<p class="tab">We had overburden
pressures on those cylinders. We put everything in a balloon, pumped up the gas
pressure, and then blew the balloon. The granite just splintered into pieces.
Then we put lead shot around the cylinder to let it go out slowly, and the
granite microfractured. That fracture spacing, when the cube root of the yield
was scaled up to Pile Driver, gave us, within a factor of two, that one-foot
joint spacing. We were trying to get to the bottom of this question, and we
spent three or four years on it.</p>

<p class="tab">I finally concluded
that the strain rate effects in the small scale experiments were too great.
They decreased the strength so much that they were not relevant to Pile Driver.
However, they still showed an effect of water, but not as strong an effect as I
believed to be in-situ.</p>

<br>

<p class="tab">As the number of events increased
more and more information accumulated about the events that were taking place.
New people joined the program, perhaps an old-timer or two left, and there was increasing
difficulty in relating a current shot to the experience on an earlier one. What
previous experience had there been? Had there been a similar geologic setting
for a shot, similar material properties, a similar yield at a similar depth?
Eventually there was recognition of the need to bring together in some accessible
fashion what was beginning to be a large amount of data.</p>

<br>

<p class="tab"><b>Rambo</b>: In the late sixties, while I
was still involved with slifer measurements, I and a lady by the name of Mary
Lou Higuera were set together in a nice large room in Building 111, and told to
start collecting all the data on our shots. So we started collecting data, and
I wrote a simple version of a data base that would work. I decided what the
logic should be, and interestingly over the years that piece of logic has still
remained as one of the ways of getting the data out.</p>

<p class="tab"><b>Carothers</b>: What sort of things did you
have in your data bank?</p>

<p class="tab"><b>Rambo</b>: Yield mostly, at first. The
groups that I was working with were very interested in yield, because seismic
happened to be a big thing at that time. So we had different kinds of seismic
yields in there. The old slifer yields were put in there as sort of a comparison,
and there was some thought of going back and reworking all of the old seismic
data. And, it went further than that. We tried to put a little bit of geology
in also.</p>

<p class="tab">Then, after
Baneberry, the tone of it changed dramatically. Then it became very interesting
as to what caused things to leak, and were there any clues that could be put
together to extrapolate to serious problems of that sort. I recall the day
after Baneberry happened, of looking in the database, and gee, there seemed to
be a definite correlation of shooting shots shallower than six hundred feet and
leakages showing up. So I wrote a very limited memo to about four or five
people. Billy Hudson then took some of that data and extrapolated it in a more
formal sense, and that became policy. Some of those data bank runs that we did
in those early days really did cause the development of some of the procedures
that we use nowadays.</p>

<p class="tab">That data collection
is still being carried on. Now Los Alamos information is included as well. The
two Laboratories do trade this information to update both of their data banks.
Los Alamos independently started a data bank about the time of Baneberry, and did
find some similar correlations to what we found.</p>

<p class="tab"><b>Keller</b>: One of the things I did before
Baneberry was to develop a library of shot data. So, I evolved the first data
bank at Los Alamos, and I got it to print out in regular book format so I could
trim the printouts and bind them. Then I had a data book in which I had all the
shot names, and the dates, and the depths of burial, the yields, and everything
else that was known about them. That was one of the things that was picked up
very quickly, and they decided to expand that data book to include all the Lab
data on the shots. The device designers also had their own shot data book, but
it was more crude; it had been developed much earlier.</p>

<p class="tab">At that time, as I
remember, there were like 72 underground events, total. And there were only Los
Alamos events included in the data. We didn't even think about Livermore;
somehow that was irrelevant experience. We were really pretty parochial. And
the Livermore data wasn't readily available either. So, I only put together
those Los Alamos events, and I remember the highest yield event I had was Halfbeak,
and the lowest yield was Solendon.</p>


<a name="ch7"></a>
<br><br>
<h2>Chapter 7: Logging and Logging Tools</h2>
<br>

<p class="tab">Paul Fenske, before he turned to
hydrology, spent several years working for oil companies, doing logging on
holes thought to have penetrated an oil bearing formation. These were small
diameter, cased, fluid-filled holes often drilled to depths of many thousands of
feet. Here the problem was not to obtain the kinds of data about rock
properties needed for code calculations, but to determine where, if at all, the
oil bearing regions were so the casing could be perforated there, and the oil
pumped out.</p>

<br>

<p class="tab"><b>Fenske</b>: There was a standard set of
geophysical logs; there was a resistivity log, a neutron log, and what was
basically a conductivity log. It was one of those logs where you had two coils,
and we transmitted from one coil to the other. The ability to transmit from one
coil to the other was given by the conductivity of the formation. We would run
those induction logs, I guess they would call them today.</p>

<p class="tab">The neutron log was a
porosity log, essentially. We looked for the hydrogen content of the rocks. If
you have a real clean formation you would find a difference between the gas in
the well, and the hydrogen content, but most of the time you couldn't depend on
that, because most of the time the formation wasn't that uniform. It wasn't
isotropic or homogeneous, and so you couldn't depend on that. There have been a
lot of advances made in the logs, how you interpret the data, and what kind of
logs you use since that time. This was in 1952, and we had, by today's
technology, some rather simple logs; induction logs, neutron logs, resistivity
logs.</p>

<p class="tab">We used those for the
purpose of defining what the structure was in the area, and also interpreted
them in terms of where the pay zones, the high porosity zones, were. Basically,
we were trying to determine if there was porosity there or not. At that time
the logs were not good enough to determine if there was really oil there or not.
You could tell if there was porosity, and you could tell if you were dealing
with a shale, or dealing with limestone, or sandstone. You could tell where the
formation tops were, and the formation bottoms, and things like that. But you could
not really tell, from the logs, where you had oil. What you can do, because you
also run the resistivity log, and oil is essentially a nonconductor compared to
water, you can by a combination of those logs make a pretty good guess as to
whether you have oil, if you have a combination of high porosity and high
resistivity.</p>

<p class="tab">The gamma ray log,
which we also used, will show you that you are not in a shale, because shale
has higher radioactivity than a limestone, for example. And, the neutron log
will show you that you have a rock that has a lot of holes in it - high
porosity. The resistivity log will show that there is something in those holes
other than just water. Basically, the induction log was better for that than a
resistivity log. When you had the induction log you could do pretty well in
wells that you knew something about. If you were in an area, and you knew
something about the area because you had taken cores, and had measured the
porosity, you could do pretty well.</p>

<br>

<p class="tab">Joe Hearst has been a central
figure in the development of logging tools and methods at the Livermore
Laboratory. The initial impetus, at the Test Site, for ways of determining the
various in-situ properties of different materials encountered in drill holes
came from the Plowshare program. In particular, the use of nuclear explosives
to form craters of different sizes was envisaged as a means for creating
harbors and canals. To predict the yield of the explosive required at what
depth in a particular formation to produce the desired result required both the
development of computer codes, and a means of obtaining the properties of the
rocks involved as input data for those codes. The oil companies had developed
various tools to measure properties associated with the presence of oil when an
exploratory hole seeking an oil-bearing formation was drilled, and it was from
this base of experience that the development of instruments that could be used
in the nuclear programs came.</p>

<br>

<p class="tab"><b>Hearst</b>: When I was working on the
Plowshare program I had to calculate an event; I think it was Danny Boy, a
cratering shot. One of the things you had to put in the code as one of the rock
properties was the sound speed. Well, I discovered when I was given the sound
speed from laboratory measurements, the calculated signal arrived at the
surface in about half the time it did in real life.</p>

<p class="tab">I thought perhaps
something was wrong with the numbers I'd been given. So, I decided I should go
to the field and measure the sound speed. I went to the field, and I reinvented
what is known as the uphole survey. What you do is you make a noise like an explosion,
underground, and you time the signal coming to the surface. I also reinvented
the refraction survey. There you hit a hammer on the ground and listen to the
signal coming back.</p>

<p class="tab">Of course, refraction
surveys had been standard for years, but I didn't know that. I invented it
again out of ignorance. Then I decided maybe I didn't believe the density
numbers either, and I believe that I reinvented the density logging tool, or
re-conceived it, using gamma ray reflection, or gamma ray back-scattering. That's
how I got into the logging business. I had all these numbers that I didn't
believe, that didn't work, and so I started reinventing some of these things.
And then I discovered, first of all, that there was a logging group at the Test
Site, which I hadn't known about. And, secondly, that there was a logging
industry, but I didn't know that either, at the time.</p>

<p class="tab">Then, one day - I was
in a ride pool with Don Rawson, who was at the time the head of geology in K
Division - Don said, "Joe, how would you like to take charge of logging
for K Division, and be in charge of the logging effort in Nevada?" I
almost said, "What's logging?"</p>

<p class="tab">But that's how I got
into it. I needed the data. I don't remember when I found out about the logging
group in Nevada, but at first I didn't even know about them. They were
developing seismic measurements, and improving on them, and they were using commercial
logging companies, which I had never heard of, like Birdwell, and Wellex. I was
reinventing all this stuff in a vacuum.</p>

<p class="tab"><b>Carothers</b>: One of the things researchers
are supposed to do is look at the literature, Joe.</p>

<p class="tab"><b>Hearst</b>: I didn't even know there was a literature.</p>

<p class="tab">The logging people
that I knew in Nevada were in support of Plowshare, because the Plowshare
people were interested in breaking up the rocks, and when or where the signal
came to the surface. They were doing cratering shots, and they were worried
about damage, and earthquakes. The Panama Canal effort was what was funding all
this, so that was what the Nevada group was working on.</p>

<p class="tab"><b>Rambo</b>: In the Nevada group we were
trying to develop new logging tools. And, we were evaluating the commercially
available tools from Birdwell, and I think Wellex. We weren't very happy with what
we were seeing, because those tools were all borrowed from the oil patch, and
those people were not interested in the same things we were, at the time. We
were interested more in physical properties than in blips on an electric log.
On the cratering events we were able to drill a lot of holes and pull out
samples, and make measurements on those, and get material properties in that
way.</p>

<p class="tab">So, during this time
we were developing logging tools to measure these unknowns, and density was one
of the big items we were looking at. We had just gotten one of the old 1620 IBM
computers, and that was a miracle machine at that time. I learned all about
programming that. We bought the second version of the Rand Tablet, which was a
digitizing device, which had etched lines on it. I had a stylus, and you could
digitize logs with this electronic pencil. For every point you got, it would
punch a number in a piece of paper tape. So, I wrote programs to do this
translation, and I wrote the programs for the IBM 1620. We would put on a reel
of paper tape that was maybe about eight to ten inches in diameter, turn it on
just before we went home, and this thing would run all night long digitizing a
density log. Then we'd process it in a Cal Comp plotter, which was an old
version of a plotter, and convert what was kilocounts at one time to density,
which was the real thing.</p>

<p class="tab"><b>Carothers</b>: What was the source of the
input data? What kind of an instrument were you using?</p>

<p class="tab"><b>Rambo</b>: What it was for the density log
was a cobalt 60 source. The gammas would backscatter from the formation after
the source was held up against the wall of a hole at various locations. It was
a gamma-gamma density; the backscatter was the indication of the density. I
forget whether there was two or three feet of separation between the sensor and
receiver. You couldn't get the receiver too far away, or you wouldn't sense
anything; if it was too close you'd only sense the source. You then had to go
through various calibrations to get the density.</p>

<p class="tab">We were also dealing
at that time with a firm called Birdwell, which was big in the logging field,
and which did the Test Site logging. We were trying to do our processing
in-house, and to develop a whole logging program. That eventually became the modern
logging programming we now have. Those were the early days of developing those
sort of things.</p>

<p class="tab"><b>Carothers</b>: Why didn't the Lab use the
commercial tools? Why build up an in-house logging capability? There were
companies that had logged hundreds of miles of holes.</p>

<p class="tab"><b>Hearst</b>: Because the conditions were
different. The commercial tools were developed for deep, small holes that would
be f1uidfilled because they were below the water table. We were logging in emplacement
holes, so first of all, we were logging above the water table, and almost all
commercial tools were, and are, designed to work in water-filled holes, or
liquid-filled holes.</p>

<p class="tab">When we were trying
to do seismic surveys, at first we tried to couple them with water. We'd drill
an eight-inch hole, dump a truckload of water into it, and it would flush like
a toilet. We learned you can't do that. Even for seismic surveys we had to
develop a new method of stemming with sand and things like that, because the commercial
methods wouldn't work in the holes we had.</p>

<p class="tab">So, we needed methods
for a dry hole, and a big hole. First a dry hole. For Plowshare we didn't need
big hole tools, we needed dry hole tools. And so we developed dry hole methods.
We also needed higher accuracy for many of these things than was available from
the commercial tools at the time. First of all, velocity; our first paper was
on an uphole survey, which was a standard procedure, which was an order of
magnitude higher accuracy than industry used. For the short distances which
were used on the cratering shots, we needed the higher accuracy. Or, at least
we thought we did. For density, we had rough, dry holes, and we had to develop tools
that would work in them.</p>

<p class="tab">The first thing we
worked on was a lock-in geophone, to get better accuracy in measuring
velocities. I didn't work on that much; that was done by Dick Carlson and the
people in Nevada. We used that for downhole surveys rather than uphole. The
geophones would lock into the borehole, and measure the travel time from an HE
shot on the surface. We were measuring the sound speed for the code
calculations. One of the reasons for that is that laboratory measurements on
samples, especially for sound speed, have nothing to do with field
measurements.</p>

<p class="tab">For laboratory
measurements you take a core sample, a nice solid core which doesn't have any
cracks in it, and which doesn't fall apart. In the field things aren't like
that. I remember the Sulky event, where you could look down the hole and see
cracks you could put your arm into. And of course, the acoustic signal has to
come through that broken up, fractured material. The Test Site is very nasty
that way. And, the fractures at the Test Site are not filled with water -
they're filled with air, which gives a tremendous attenuation for acoustic
signals. That's why we had to make those measurements with the geophones. There
is that factor of two that I mentioned, between the laboratory and field
measurements. People still fall into that trap sometimes.</p>

<p class="tab">Don Larsen developed
some very thin velocity gauges, and we then could look at the velocity history
of rock samples in the lab, using very small HE charges. We also worked a lot
on stress gauges, and we're still working on them. Checking calculations with
actual measurements is a lifetime program.</p>

<p class="tab"><b>Carothers</b>: The Buggy event, which used
five simultaneous detonations, was a great success, in that it made a real
ditch. It demonstrated that you could actually calculate these row charge effects.</p>

<p class="tab"><b>Hearst</b>: Before Buggy was Palanquin,
which demonstrated you couldn't calculate everything.</p>

<p class="tab"><b>Carothers</b>: The only real work that was
being done was being done for Plowshare, and basically being done for the
cratering shots. Now, the Plowshare people had various other ideas, such gas stimulation.
Did you do any work on those kind of things?</p>

<p class="tab"><b>Hearst</b>: Logging was logging, but for
most of the other things commercial logs could be used. Another thing was
verification. There was Salmon, in Mississippi, and Dick Carlson especially did
a lot of logging work on Salmon. In the second place, on Salmon, if you recall,
the ground shock caused much more damage to buildings than people had anticipated.
It was a real surprise. We then started bringing seismic people into our group,
and we started getting involved in what we would now call verification work. We
then did logging for that, as well as calculations and lab experiments.</p>

<p class="tab"><b>Carothers</b>: On device development shots, as
differentiated from Plowshare events, were there samples or logs taken?</p>

<p class="tab"><b>Hearst</b>: I don't think the test program
people did much of that. We didn't get involved with the test program until
Baneberry. Plowshare was vanishing, and the Lab also had the first big
reduction-in-force. Just about that time, very providentially, along came Baneberry,
and that put us back in business, logging for the test program. I was still
doing calculations at that time.</p>

<p class="tab"><b>Carothers</b>: What logs could you do at that time?</p>

<p class="tab"><b>Hearst</b>: We could do almost anything
that we can do now. There were very sophisticated acoustic things, which
weren't useful at the Test Site, but as soon as we started working on
verification, then we could use the conventional stuff for things like Salmon
and Sterling, and so on. I recall doing lots of seismic surveys on Pahute Mesa
events, and I think it was pre-Baneberry.</p>

<p class="tab">Now, the quality
wasn't as good. The measurements weren't as sophisticated as they are today,
but the techniques were available in the sixties. There's very little new that
has come along since then. The only thing, really, is borehole gravity, which
was conceived in the fifties, but not used in the field until later. And it's
still not very commercial. You could, in the sixties, do acoustic, density, electrical
logs.</p>

<p class="tab">The epithermal
neutron log was a commercial tool; we just used it. We did invent one density
logging tool, which was for Plowshare, and we subsequently stopped using it. It
was a rugosity insensitive density logging tool. When we got into bigger holes
we stopped using it, and started using commercial tools, and calibrating them,
and living with the rugosity effects.</p>

<p class="tab">So, it was all
commercial tools, and we had to make them work. That was the switch from Plowshare
to verification and test. We started making commercial tools work. The only
tool we developed that is still in use is the dry-hole acoustic log. The other
tools could be made to work; basically, they had to be calibrated for dry
holes. The thing that I did with the epithermal neutron tool was, after many
years of effort, and learning to run Monte Carlo codes, and things like that,
was to convince management to build me a calibrator for dry holes. It was boxes
of carefully mixed materials, and those boxes are expensive.</p>

<p class="tab"><b>Carothers</b>: Boxes with dirt in them?</p>

<p class="tab"><b>Hearst</b>: They had to be big boxes,
because the neutrons go long distances. And the dirt had to be carefully
designed to give you what you wanted, and to give it uniformly and accurately.
Actually, that calibrator didn't work very well.</p>

<p class="tab">What we ended up
doing, because of engineering and money constraints, was, we made cells a foot
square and six feet high so we could put them together to make a rectangular
parallelepiped, to be technical, which was six feet high, by three feet by five
feet. Basically it was a slab.</p>

<p class="tab">We put carefully
measured amounts of material in each one of the boxes, and shook them to get it
uniform. We calculated what materials we needed, and mixed them. We used sand,
and marbles - we actually had a million marbles, a whole truck load of marbles -
and aluminum oxide. Among other things we had to control the density, and so we
had to make mixes of materials of different sizes to get it dense enough to do
what we wanted. We used marbles, and sand to get higher densities. And aluminum
oxide, to get even higher densities. To a neutron, aluminum looks very much
like silicon. Then we poured in water, and we also had some activated alumina,
which could soak up some water.</p>

<p class="tab">We did all that, and
it was still not well done. Part of the problem was that the mixes were made
here, and they were sealed in these aluminum cans, and then they were trucked
over the Sierra. That made the cans expand, because of the low pressure as they
went over the mountains. And so, when the cans got to Nevada they were
bulging. Consequently, they never fit well together.</p>

<p class="tab"><b>Carothers</b>: All you had to do was to put a little pinhole in them.</p>

<p class="tab"><b>Hearst</b>: They didn't think of it.
Remember, they were sealed to keep the water in there. There were actually
reinforcing rods in them, but that didn't work well enough, and so they bulged.
When you put them together and squeezed as hard as you could, they still weren't
flat; they had gaps, and bumps, and wiggles. And so, they were never satisfactory.
But it took a lot of persuasion to get management to let me build that
facility, and that was what I contributed - the calibration facility.</p>

<p class="tab">There were problems
with our first calibrations. We did two procedures. Our main effort, which was
to simulate a big hole, was this three by five foot wall. And, we took one box
out of the middle of the fifteen boxes to mock up a small hole; that hole, of
course, was square.</p>

<p class="tab">Those results are
quite different from those in the small cylindrical hole we now have in our in
our new calibrator. A logging tool is cylindrical, and is up against a wall
that is either cylindrical or flat, and the major effect is right in the front
of the tool. One of the things we discovered was that even in a 72-inch hole
there is a hole-size effect on a neutron log. That's why we had to build this
ENS - the Epithermal Neutron Special, instead of the ENP - the Epithermal
Neutron Porosity - to take care of the hole-size effect. The Geologic Survey
people are unhappy because we almost always get higher values with the ENS.</p>

<p class="tab">The ENS was special
because it had more shielding. We put that bigger shielding on to compensate
because we were up against the slab. The slab was to simulate the big hole -
infinite radius. But because it wasn't right, wasn't really effectively
infinite, we had to put in this extra shielding. We also pulled out one of the
boxes in the middle to simulate a small hole. Now that we've built our new system,
we've found that neither of those simulations is particularly good.</p>

<p class="tab">Our new calibrator is
two cylinders, fifteen feet in diameter, with a six foot diameter hole in the
middle. They are vertical cylinders, six or eight feet high,-and somewhere
between twelve and fifteen feet outside diameter, with a six foot diameter hole
in the middle. They are made of pie-shaped wedges; each of the two cylinders
has six cells fiIIed with the material. It cost us like a quarter of a million
dollars to fiII them - REECO prices. You have to fill them very, very
carefully, and we did a lot of studying of the mixing of solids. We even sent
our engineer to a meeting on the subject, in Southern California. We came to
the conclusion that we could not make uniform mixes of the solids we wanted to
mix. The technology does not exist to make good uniform mixes of solids of different
sizes, or even of the same size.</p>

<p class="tab"><b>Carothers</b>: My mother can do that when she
makes sticky buns with raisins in them. She gets a pretty uniform mix.</p>

<p class="tab"><b>Hearst</b>: Well, probably on that scale
you can do it. But we concluded that we just could not guarantee a uniform mix,
with dry particulates. So what we did was, we made layers. Each cell has fifteen
layers, and we know what's in each layer, so we know that at least on that
scale the mix is uniform. We use fifteen layers of the same mix. The layers may
not each be completely homogeneous, but the neutrons see more than one layer.</p>

<p class="tab">The layers are all
the same recipe, mixed in a concrete mixer. The problem is that the concrete
mixer may not necessarily get things uniform, but it makes it uniform on the
scale that the neutrons see. We put these mixes in place, and then vibrated the
cells to get the right density, because we had to have a known density as well
as a known water content. So, we vibrated these huge cells each time we put in
a layer, to settle it to get the right density. We did all sorts of experiments
on that sort of thing. We did experiments where we would pour stuff into a
container after we mixed it, then shake it to settle it to get the right
density, and it would separate.</p>

<p class="tab"><b>Carothers</b>: Well, sure. The heavy things
fall down to the bottom. It's the shaking that's doing it.</p>

<p class="tab"><b>Hearst</b>: Yes, but otherwise you can't
get the right density. So, it's probably still not uniform. Afterwards we made
all kinds of measurements with logging tools, and other things. I've got a book
an inch and a half thick describing these mixes. How to mix solids is an
unsolved problem, and there are conferences on the subject. It's important to
places like cookie companies, and places like that.</p>

<p class="tab">I think the solution
is that you put in liquid, and then you can mix it. If you make a slurry you
can mix it, apparently. But as long as it's a dry solid, you can't. That seems
to be the story. This was a major problem that we spent a lot of time and money
on.</p>

<p class="tab">There are calibration
facilities at places like Bendix, in Grand Junction, where they tried to make
mixes of radioactive concrete to calibrate gamma ray logs. It took them years
to discover that they got it wrong. There are American Petroleum Institute test
pits in Houston that are not right, because they couldn't mix it well; they're
not uniform. Mixes just don't do very well, and these test pits where they
tried to mix radioactive concrete don't work. And so, when we built our gamma
ray calibrator we used six foot high, three foot diameter pieces of granite.</p>

<p class="tab">Commercial tools are
calibrated in American Petroleum test beds in Houston, in saturated limestone,
and things like that. They are small, water-filled holes, and we have dry big
holes, and dry small holes. And so, we had to simulate that. And also, we have a
much bigger range of water contents and densities. One thing that I did invent
was the idea that you had to compensate the neutron log for density. That's not
a problem in the oil industry, because any time there's a density change there
is also a water content change, because everything is saturated. The holes they
log are deep, and also they're in places where there is a shallow water table.</p>

<p class="tab">So, we had to develop
calibrations to account for that, and we did. We developed ways of correcting
for all those features they don't worry about in industry. We didn't have to
develop tools, we just had to develop calibrations and corrections; ways to use
those tools. That saved lots of effort.</p>

<p class="tab"><b>Carothers</b>: This new calibrator you have is
bigger, better, and so forth compared to the old square cells. Presumably it
was more expensive also. How was the management persuaded to spend that quarter
of a million dollars?</p>

<p class="tab"><b>Hearst</b>: Actually, it ended up being
more expensive than that. But, partly it was the DOE management that spent it.
I think we succeeded because there is still the tradition of getting better
data, and because there was money in the budget, the DOE budget, to do these
things.</p>

<p class="tab">When I was working
with Frank Morrison I was in charge of research for the containment program. I
had lunch with Frank one day at the bowling alley at the Test Site. I said,
"Frank, we don't need any more research in the containment program. We're
doing our job, and we're not hurting. We have a budget, and there lots of
interesting things we could do that would give us more accurate measurements -
nicer, warmer fuzzy feelings - but they don't improve the containment of the
event one bit."</p>

<p class="tab"><b>Carothers</b>: I was wondering if there was
something new that had occurred; if for some reason better numbers were needed.
For instance, perhaps the verification folks needed better numbers.</p>

<p class="tab"><b>Hearst</b>: No. There was available money,
and we could show the things that were wrong with the existing calibrator. So,
we have better data now. This business of the correction for the bound water,
that's an improvement in the correctness of the numbers, even though it's not
very important.</p>

<p class="tab"><b>Carothers</b>: Your epithermal neutron log
doesn't really measure water; it measures the hydrogen that makes up the water.
And you assume that alI the hydrogen is associated with water.</p>

<p class="tab"><b>Hearst</b>: That's correct.</p>

<p class="tab"><b>Carothers</b>: Well, your measurements seem to
bother the geologists, because you measure not only the free water, but the bound
water. As far as I know, they measure the free water. They never measure the
bound water.</p>

<p class="tab"><b>Hearst</b>: That's correct, but they could
if they tried. They measure the water in samples, and if you heat the samples
hot enough the bound water will come off.</p>

<p class="tab"><b>Carothers</b>: But the problem is that alI the
data in the data banks that we have that relate to the Test Site only report
the free water. Now you're reporting free water and bound water, and so there's
always more than there is reported in the data bank.</p>

<p class="tab"><b>Hearst</b>: Not always. Only in places
where there is water that is bound, and that's in zeolitic materials, as far as
I know. Or clays, or things that have some clay in them. But yes, the neutron
log seems to give higher values than the sample data, and generally it should.
That should only happen where there's bound water. But, we have a method for
correcting for bound water. We can measure it with nuclear magnetic resonance -
from samples only, which is a little bit cheating, as a reviewer from a journal
pointed out to me. It's cheating to interpolate between samples. There is
nuclear magnetic resonance logging, but it's never been successful. I recently
read a proposal for something that might work, but they aren't there yet. That
tool has also existed since the sixties, but it's never been very good, and it
certainly wouldn't work in big holes.</p>

<p class="tab">But there is a
problem there, and I'm not sure the solution is complete; that is, that we can
explain away all the differences between the sample measurements and the log
measurements. But, we think we understand most of it, and yes, the data bank
does have just the free water, and we can now compare free water measurements if
we wish.</p>

<p class="tab"><b>Carothers</b>: But you do that by cheating a little bit.</p>

<p class="tab"><b>Hearst</b>: Yes. Incidentally, the
epithermal neutron log was a Birdwell tool. It was abandoned by the industry,
because it didn't get enough signal, until very recently. Now epithermal
neutron logs are coming back into fashion in industry, and they are using them in
creative ways. Maybe it's just more recognition of neutron poisons, which is
the reason we used epithermal neutrons - the fact that there are things out
there that absorb thermal neutrons. And maybe it's that industry is getting
into more materials where they care about it. But also they've found
constructive ways of using the tool.</p>

<p class="tab">The problem, with the
neutron log in particular, and the density log, is that our calibration at zero
gap, and even at a small gap, is excellent. But the correction for gap, when we
measure some gap, is still very poor, because we're doing that badly, somehow.
I don't know why. I think it's poor because I'm measuring the gap at some place
other than the spot where I'm making the neutron measurement. The hole is
rough, and we're making the measurement a foot away from the source, because
the gap measuring device is somewhere else on the tool. That isn't right, but
we don't know how to do it otherwise. We're probably getting the water content wrong;
we're probably overestimating it in many cases.</p>

<p class="tab"><b>Carothers</b>: There are members of the Panel
who have said that they really don't care about all those numbers, and the
geology, unless there is something unusual about it. For instance, they, and I,
feel that the histograms of material properties that are presented are
meaningless, because there have been so many measurements taken that what is at
the Test Site has been bracketed, and what you measure always falls within
those limits.</p>

<p class="tab"><b>Hearst</b>: Yes. Of course. Norm Burkhard
gave a paper at the containment symposium before last about the rockpile
concept - you should just assume these numbers. I think that's quite reasonable.</p>

<p class="tab"><b>Carothers</b>: In 1978 there was a session of
the Panel called to consider the question posed by Ink Gates, the then NVO
Manager, as to whether there were ways to reduce the containment related costs.
Without compromising the probability of successful containment, of course.</p>

<p class="tab">One of the
suggestions that was made in 1978 was that Livermore should regard a large
section of the areas they used in Yucca Flat as LANL regards the Sandpile -
call it the gravel pile, or whatever. There is plenty of data to do that, and
when a new hole is drilled, just extrapolate in the data from adjacent holes.
The Livermore Laboratory, for whatever reason, has not chosen to do that.</p>

<p class="tab"><b>Hearst</b>: In 20ax, the containment
scientist wanted to do that, and suggested that we look at the 20ax data and
compare them to the data from nearby holes. We did actually try that for that
event. Well, it turned out that in many of the lithologic units the error bars for
the measured 20ax data lay outside the error bars for the nearby data. They
didn't agree. But, so what?</p>

<p class="tab"><b>Carothers</b>: I don't believe, these days,
that the CEP is the organization that drives the data collection. You've got
people who do calculations, and to do calculations you have to have numbers, and
if you don't have numbers people criticize you for having so many knobs to
twiddle in your code that the results are meaningless. And so, you have to have
numbers. And to get the numbers you either have to have samples, or logging
tools. Samples are expensive.</p>

<p class="tab"><b>Hearst</b>: And they're not very good anyhow.</p>

<p class="tab"><b>Carothers</b>: So, we have to have logging
tools, so we have to have people to do that.</p>

<p class="tab"><b>Hearst</b>: I consider it a ritual, but I
earn my living at it, and it's interesting work. As long as you're going to do
it you might as well try to do it well. Although, we wouldn't use the tools we
are using if we were starting now, we'd use higher technology. We're
still using 1960's technology in much of our stuff at the Test Site.</p>

<p class="tab"><b>Carothers</b>: With a logging tool there are
two things you can do, and presumably you could do them both at once. One is,
you might not care what the absolute value is; you might only care about where and
how the value changes. The other is that you really want to know what the
absolute value is. How do you deal with that?</p>

<p class="tab"><b>Hearst</b>: Well, in the first place, you
should actually design the tool differently for the two different uses. For
almost any tool, the larger the source-detector spacing the further you're
averaging over, so the more accurate number you're going to get, but the less definition
you're going to get of a boundary. There is a basic problem, before you start a
logging program, of deciding what you want, and why. There's always a balance
between accuracy of the value and accuracy of the depth, which compete, and
cost.</p>

<p class="tab">For the Soviet test
site a U.S. committee got together and decided what logs they wanted to verify
Soviet tests. There was this list of logs that were wanted, and we made
decisions about the necessary logging tools to send over to Russia. This committee
would say, "We want these logs." And maybe, "We want them to
this accuracy," but usually not. But not, "We want them
because." The cortex people wanted them for one thing, the Geological
Survey wanted them for another thing. The first time people went over there
they spent a great deal of money, and effort, and time getting these data. And,
nobody has ever used the data, as far as I can tell.</p>

<p class="tab"><b>Carothers</b>: Why do you think that is?</p>

<p class="tab"><b>Hearst</b>: I don't know. Probably they
didn't think it through. Dick Carlson is the guy who went to Russia to do it,
and the last time I talked to him nobody had ever made any use of his work. And
he does a very good job of getting good data.</p>

<p class="tab">It's very difficult
to persuade people, including the CEP, to think hard about what numbers they
want, to what accuracy, and why. You can say, "I want the density to two
percent accuracy over the range." Then I come back and say, "Why?
What are you going to do with those numbers? That's very expensive. If you
really mean you want that accuracy, I probably would want to run three different
tools. But, you probably don't really mean that, because you're not going to
use those numbers that accurately."</p>

<p class="tab">Each person, each
organization will say, "I need this measurement," and they will
always specify some accuracy which is good as they could possibly use, without
ever thinking how difficult they make it to get the data, and how much more costly
it is, and how it's competing with someone else's desires. You really have to
think about what you're going to do with those numbers.</p>

<p class="tab">Let me say, the CEP
doesn't need accurate numbers. They're just talking about how their grandfather
did it, and 10% accuracy would be wonderful for them. We put big error bars on
the data we present, and nobody cares.</p>

<p class="tab"><b>Carothers</b>: Well, in defense of the CEP, I
constituted a subcommittee of the CEP a number of years ago, chaired by Bill Twenhofel.
It was called the Data Needs Subcommittee. That subcommittee came back and said
the CEP didn't need various kinds of data. The Laboratories paid no attention
at all, and continued to get those data anyway. Why? Well, they've got guys
like Joe Hearst, and John Rambo, and Fred App who are calculating various things,
and they want numbers.</p>

<p class="tab"><b>Hearst</b>: That's right. Calculators need
numbers. But I think we are getting data that are too accurate. Or too precise -
they are probably not that accurate. I think we are wasting time with too many
decimal places which nobody uses.</p>

<p class="tab"><b>Carothers</b>: You now have a tool that
measures the hydrogen in the rock, and you assume all the hydrogen is there as
water, so let's say you measure the water in the rock. Why did you develop a
tool to do that?</p>

<p class="tab"><b>Hearst</b>: We didn't. We hired it. That's
the tool that was available. But also, one of the important parameters for
containment is the total water. That's one of the key parameters, and if you
need to know numbers at all, that's one of the numbers you need to know. When
we first started we looked at the available methods of measuring water content,
and decided this was the best. But we didn't want to measure only free water.
We'll continue to report total water and these other parameters, the porosity
and saturation, which the whole world tries to measure, by the way. The
objective of the industry in running all these logging tools is to measure porosity
and saturation. That's what the tools are built for; that's what they were
invented for. All those methods assume that the formation is saturated with
some conductive liquid.</p>

<p class="tab">We looked at density
tools, and we just demonstrated that these tools are worthless in the
seventeen-inch holes for the groundwater characterization program. We've shown
that they're not good. For 20ax we had problems with a density tool in a seventeen-inch
hole, and we had to build a new calibrator for it. This was blocks of various
metals like aluminum and magnesium. That's the way you calibrate a density
tool, and that's one reason density tools are much easier to calibrate. We
discovered that these automatic, two-receiver compensated density tools get
wrong answers if they are tilted ever so slightly in a seventeen-inch hole. They
work all right in an eight-inch hole, which is what they were designed for, but
they have to be recalibrated for the bigger holes. That's still being worked,
but we have now demonstrated what we surmised on 20ax; the logs are coming out wrong.</p>

<p class="tab"><b>Carothers</b>: The first log I see at the CEP
is the density log. You measure that with a gamma ray logging too/. What
happened to the dry-hole acoustic log?</p>

<p class="tab"><b>Hearst</b>: It is used, and in fact you see
it, but you just don't pay attention. It's the DHAL, and it's shown every time
we show logs. It's the acoustic velocity. First comes the caliper log, and then
comes the dry hole acoustic. That's something we invented ourselves, because
there were none in the world. We needed it for Plowshare at the time, because
we had no way of measuring acoustic velocity except by seismic surveys.</p>

<p class="tab">We went to Don
Rawson's back yard one day, with a couple of acoustic transducers. Dick Carlson
and I had thought of attaching cones to transducers that we had bought. We put
them on Rawson's fireplace, and sure enough, we got a signal through the
fireplace, horizontally. Then we tried it on trees, as well. We got acoustic signals,
and we had invented a dry-hole acoustic log. The reason nobody in the world
uses it is because it's not continuous. A logging tool to be useful in the
industry, where drilling costs are immense, must run continuously as you pull
it up the hole. There are now a couple of logs that do that, but there weren't
at the time.</p>

<p class="tab"><b>Carothers</b>: Why isn't your acoustic log continuous?</p>

<p class="tab"><b>Hearst</b>: Because it has to dig into the
wall of the hole. You have to push it hard up against the wall, and push these
points into the wall. That's why nobody else ever invented it. It wasn't that
we were these brilliant geniuses; it was just that nobody else could use it in
their business.</p>

<p class="tab">Then we discovered a
problem with it, which is why we call it a relative measurement. In a small
hole it agrees quite well with seismic measurements of velocity. In a big hole
it usually gives us velocities that are too low. The reason for this,
apparently, is that the material near the wall of a big hole, or any hole, is
broken up by the drilling process. In the case of a big hole the depth to which
it is broken up is about the same as the depth to which the acoustic signal
goes, so we're just measuring the region which is broken up by the drilling
process.</p>

<p class="tab">The least time path
is what you measure. So, the higher velocity material gives you less time, but
if you have to go through a large amount of low velocity material to get to the
high velocity material, that doesn't work. The way we proved all this was to
build a tool with two receivers, which is the standard way done in the industry.
If we used the measurement between the last two receivers, it was faster than
between the source and one receiver. That's because the passage through the
broken up material is cancelled out. Actually, in the industry now they may use
up to twenty receivers.</p>

<p class="tab">So, we get the
acoustic velocity, and then the density, which we get from the gamma log, and
then we show the acoustic impedance, which is the product. And that's probably
why we still show that log - to show the impedance mismatches.</p>

<p class="tab">For the water content
we use the epithermal neutron log, and correct for gap between the neutron
sonde and the wall of the hole. Los Alamos does not.</p>

<p class="tab"><b>Carothers</b>: So you ought to get different
answers, in the same hole.</p>

<p class="tab"><b>Hearst</b>: Not only that, but if you look
at the calibration curves, they're different.</p>

<p class="tab">And, we also show the CO<sub>2</sub> content, which is still measured 
from samples. And we show the clay content, which is done with x-rays, occasionally.</p>

<p class="tab"><b>Carothers</b>: You also show the resistivity log. How do you do that?</p>

<p class="tab"><b>Hearst</b>: Well, resistivity is the
standard log in the oil industry. That was the first log invented, and it was
the only thing available for many years. You put a source of current at the
surface, and you look at the voltages generated by it, downhole. Nowadays I
think some of them have a source of current and voltage detectors in the hole.
Some of them use induction instead, because then there's no contact problem.</p>

<p class="tab">Again, it's very
difficult to do in big holes. In the big, dry holes none of the standard
methods work. We did one time develop an induction tool - huge coils for a big
hole - but we never made it standard. What we have for our dry hole resistivity
log, which is the only thing we can use in big, dry holes, is a bunch of wheels
- padded cloth wheels - saturated with copper sulphate solution . They roll up
the wall of the hole, and they're saturated with conductive solution. They make
contact with the wall of the hole. The basic problem is that sometimes they
make good contact, and sometimes they make bad contact as they roll up the
hole, and so you get indifferent results. That's our attempt at duplicating the
standard things that are used in liquid filled holes. The current source is in
one of the wheels, and you measure the voltage between the two wheels.</p>

<p class="tab"><b>Carothers</b>: Why is it useful for the CEP?</p>

<p class="tab"><b>Hearst</b>: Well, clay is conductive
because it's has water in it, and it's got all kinds of ions in it. So, clay is
more conductive than alluvium or tuff. Supposedly a resistivity log tells the
CEP if there is clay, but there have been a number of studies done, and none of
them link resistivity to clay. There have been a number of papers which show
there is really no connection. Nevertheless, since we care very much about clay
because of Baneberry, it is traditional to present a resistivity log, and to
worry very much if there is a very low resistivity somewhere. Then you have to
go get a sample, despite the fact that Gayle Palawski has written a couple of
papers showing the lack of connection between log resistivity and clay content.</p>

<p class="tab">The log resistivity
is proportional to the conductivity of the rock, which depends, among other
things, on the amount of water, the amount of clay, and the kind of rock. But
it depends even more, I believe, on the amount of contact between these wheels
and the wall of the hole. There are many brand names of these resistivity, or
electric, or E logs. And there are many configurations of the electrodes,
depending on who does it.</p>

<p class="tab"><b>Carothers</b>: How about the seismic velocity.
How is that measured?</p>

<p class="tab"><b>Hearst</b>: I got into that when I first
got into logging. The way it's measured now is with an air gun. There has been
a lot of work on that, and I don't know too much about how it's done today. There
are problems with getting good contact between the air gun and the rock. The
air gun puts a big pulse into the ground, at the surface, and you have
detectors clamped into the hole, downhole, and they sense the signal. So,
you're measuring the entire depth of the hole, down to the detector.</p>

<p class="tab"><b>Carothers</b>: So if I want to know the
velocity in a particular layer I have to subtract out all the others above it.
It sounds as though the deeper I go the worse the measurement would get.</p>

<p class="tab"><b>Hearst</b>: Well, this is an acoustic
signal, not going through liquid, and you measure the arrival time of this
acoustic signal, The signal has to be some amplitude that you can see.
Therefore, the arrival time really depends on the contact between the detector
and the wall. You look at the analog trace, and you pick the arrival time. If
you have less sensitivity you will see the signal later, because the signal is
not a step function; it rises from zero to full value in some amount of time,
and when you can see the arrival depends on the sensitivity of the detector.
It's a smoothly rising signal, and you pick the time when you can see it.
That's the trouble with automatic picking procedures; they depend on the
amplitude.</p>

<p class="tab">So, from all this,
the measured velocity depends on the contact between the detector and the wall.
Again, this is a problem with our dry holes, which is not much of a problem in
industry, where they have liquids and the contact doesn't matter.</p>

<p class="tab"><b>Carothers</b>: There are other logs, one of
which is presented to the CEP as the gravimeter. Tell me about that.</p>

<p class="tab"><b>Hearst</b>: A gravimeter is a device that
measures gravity, and it's used routinely in the industry to make subsurface
maps. I got interested in borehole gravity when it was first being thought
about in the 1950's. The first paper was published in 1950, and I was one of
the first people to use it for anything.</p>

<p class="tab">The tool measures
gravity in different places, and you attribute variations to changes that are
underground. The idea of measuring rock density with borehole gravity was very
intriguing to me, and as soon as a borehole gravity meter became available I
started using one to measure density that way. You put the tool downhole, and measure
at various stations at various depths, and you can calculate the density of
uniform slabs, if you assume the world is made up of uniform slabs.</p>

<p class="tab">That's exceedingly
uninteresting, but if you measure the difference between the gravity
measurements and the density log, and you believe them both, you can infer
things about the structure of the earth, underground. And that's what it's used
for. There's now a fair industry; I was at a large meeting in Chicago last year
where people were talking about improving the measurements. There were maybe
twenty or thirty experts there.</p>

<p class="tab"><b>Carothers</b>: The changes you are looking for
in the gravitational field must be very small, and so the instrument must be
very sensitive.</p>

<p class="tab"><b>Hearst</b>: It is a very sensitive
instrument. One of the questions raised at this meeting was, "Do we need
greater sensitivity?" The conclusion was that the instrument is sensitive
enough to do the job. Basically, it has a mass on an arm, and it measures the
angle of the arm as the field changes. That's the physics principle; the trick
is to get it to work in real life. People have done this, and there's one company
that does it well. The interesting conclusion of that meeting was that what
they wanted was to make the measurement faster, and make the equipment more
rugged and more reliable. But they didn't need more sensitivity.</p>

<p class="tab"><b>Carothers</b>: How do you infer things about the structure?</p>

<p class="tab"><b>Hearst</b>: You make a calculational model
of the structure, calculate what the gravity would be with that model, from
that calculate the difference in gravity that you would see at different depths,
and compare that to what you observe. There are, of course, infinitely many
structures that would give you the same result, and all you can do is to use
the measurements to choose between proposed models.</p>

<p class="tab">It has apparently
worked very well in the oil industry to find oil some distance from a hole.
Again, their density logs are much more accurate than ours, because they
satisfy all the assumptions - good contact with the hole, no gap, and it's a
small hole. They can use very small density differences to infer useful things.
We can't, because our measurements aren't that good because of our big, rough
holes. But that's what we use it for.</p>

<p class="tab">There is also a thing
called a gravity gradient measurement, where you're measuring the change in
gravity with depth. You can build instruments which measure the gradient, but
it turns out that gravity measurements are sensitive to one over R squared of
the mass. The gradient measurement is sensitive to one over R cubed, and the
gradiometer is so sensitive to changes in the hole configuration and things
like that, that you don't buy anything by building a gradiometer.</p>

<p class="tab"><b>Carothers</b>: What's the free air gradient
that is always measured when you're doing gravity measurements?</p>

<p class="tab"><b>Hearst</b>: If you calculate the density, using
a gravity meter, there is a constant term, an additive constant, that is in the
formula for the gravimetric density. It is the change in gravity with depth which
is caused by the fact that you're getting closer to the center of the earth.
It's called the free air gradient because originally it was the change in
gravity measured as you got closer to the surface of the earth, in the air.
When we started working with this, we decided we ought to measure this free air
gradient by making gravity measurements on a tower. Well, a lot of people in
the field said that was a bad way of doing it, because that measurement is very
sensitive to things that are close to the surface. In fact, that measurement is
now used to look for tunnels and things like that which are near the surface.</p>

<p class="tab">You get a much better
measurement of the free air gradient by measuring the gravity at the surface
over a wide area, and doing a transformation to calculate the free air
gradient. Norm and I finally got persuaded by a number of publications by other
people that is indeed the correct way to do it. We were not doing it right, and
so we now do it that way. We no longer measure it directly. If you're making
measurements near the surface, yes, you should measure it above the surface.
But when you're measuring at depth, as we are, in general you're better off by
calculating it from a number of surface measurements.</p>

<p class="tab">Incidentally, one of
the things you have to correct for is tide, and the first time I asked for tide
tables for the Nevada Test Site people thought I was crazy. If you set a
gravity meter out on the ground, it changes with time, because the sun and the
moon affect it. There are earth tides, and that's what you have to correct for.
That's automatic now.</p>

<p class="tab">The seismic survey
business is another huge industry, and it's been a very successful one. The
surveys show you where reflecting layers are, below the surface. I have never
been able to interpret the measurements with any comfort. I think it requires a
great deal of imagination to interpret those surveys, but people do it
successfully, and get paid very well for it. It is a universally used
procedure, and that's how all this information we get about the structure of
the earth comes to us.</p>

<p class="tab">It is another
technique which is standard in the oil industry, but which is exceedingly
difficult to use at the Test Site. The highly porous rocks near the surface are
highly absorbing for the acoustic signals. We used to hear stories of how some
world expert in seismic measurements would come to the Test Site and go out
with our technician. The expert would start setting off small explosions and get
no signal. Finally our technician would say, "You have to use two sticks
of dynamite instead of one detonator to get a signal here." For many years
companies would come out and produce thick reports about why they failed .</p>

<p class="tab">Norm Burkhard got his
Morrison Award because he was the first person to do a successful seismic
survey at the Test Site. He used a procedure which I don't quite understand,
where he used a fairly small charge. He got it to work; it had to do with using
the right source-detector spacing, and the right type of charge, and all sorts
of things like that, which he said he learned in school.</p>

<p class="tab">It is difficult
technique to use at the Test Site, but we do have seismic surveys now, and they
are used usually to look at cross sections, to interpret them. A number of them
have been done, but nothing like the number that have been done in the oil
patch. They're quite expensive, but you can call in a crew, and they'll do it.
My problem is in interpreting them, but people do it. You can see things, but
figuring out what they mean is another story. Now again, there's a huge amount
of software that's been developed to improve these things, and there's all kinds
of difficulties converting time, which is what you measure, to distance, which
is what you want.</p>

<p class="tab">By the way, another
way people in the industry measure porosity is velocity. These velocity logs in
industry, in the right circumstances, get porosity from velocity, if you make
the right assumptions. In a clean, water filled sandstone, all you need is the velocity.
As far as I know, every formula that's used assumes clean, water filled
sandstone. So, a velocity log is called a porosity tool, and that's what it was
developed for. There was recently an issue of one of the journals published on
the use of velocity logs to infer porosity and permeability and things like
that in rocks like granite. Now people are starting to measure fractures with
velocity. You can do all kinds of neat things with acoustic signals, in a water
filled hole. You can actually make a picture of the wall of the hole and look
at the fractures, and things like that. You can even see some depth into the
wall, and see fractures.</p>

<p class="tab"><b>Carothers</b>: One of the things people on the
Panel, from time to time, ask about is the stress state of the rock, and about
the shear strength. What can be done there?</p>

<p class="tab"><b>Hearst</b>: We are, in fact, developing a
method of measuring strength, compressional strength. I have spent a fair
amount of time, from time to time, trying to figure out how to do that downhole.
I have not yet found a method we could field. There are methods that I have
looked at that are used, even some that are done in the tunnels, that are very
difficult to do remotely. For example, putting two pins in the wall of the
hole, measuring the distance between them very accurately somehow, then taking
a saw and making a slot in the wall between those two pins, and then measuring the
distance between them again. We've spent some money looking at things like
that. One of the major problems is that the borehole causes a major change to
the in-situ stress, and so whatever you measure in the wall of the borehole may
not have a great deal to do with what's out in the rock. But we've looked at a
number of methods for that.</p>

<p class="tab"><b>Carothers</b>: I think of it because one of
the things people are touting these days, maybe correctly, maybe not, is the
following argument. There isn't, necessarily, any residual stress field around the
cavity. There would be in a uniform medium, or world, but we don't shoot shots
in such a world. Blocks move, here and there, and what really contains shots is
hydrofractures, which drive out into the rock a short distance, dump a lot of
steam, cool the cavity down, and that's it.</p>

<p class="tab"><b>Hearst</b>: That's quite possible. Now, we
have worked on measuring shock induced stress. In fact, we just had a failure
on the Bristol event, where we got numbers that were mostly strain. It is exceedingly
difficult to measure shock induced stress. Part of the problem is that the
shock damages the gauges. The biggest problem is that it's very easy to measure
a stress in the stress transducer, but relating that to the stress in the rock
is very difficult indeed. If you could, in fact, put the transducer in direct,
intimate contact with the rock, you could do it. But you can't. You have to
drill a hole, you have to put the transducer in a package, you have to put the
package is some kind of stemming material, and all of that makes a big difference
in the measurement. We've worked quite hard on that. We've developed procedures
for reducing the data, and they haven't worked very well either.</p>

<p class="tab"><b>Carothers</b>: How about measurements where
you could say, "Yes, there is a residual stress field, because before the
shot I measured the stress in this region, and thirty seconds after the shot, here's
what that stress field was, and it was different."</p>

<p class="tab"><b>Hearst</b>: We've had some little hints of
that in these measurements, but one of the major problems is that every stress
transducer you can build is also affected by strain. You can't distinguish between
stress and strain easily, and so we have not been able to prove that what we
have seen is actually residual stress. We have seen signals that have stayed up
for long periods of time, but we can't prove what they are.</p>

<p class="tab"><b>Carothers</b>: As contrasted to post-shot
stress, there is a lot of interest, by people who are interested in the
hydrofracing model, in in-situ stress.</p>

<p class="tab"><b>Hearst</b>: Attempts have been made, and
papers have been published, even about work at the Test Site. Again, it's
something that's done routinely in small holes in mines, where you can get at the
rock, where you can drill a small hole and put an instrument in it. Even then
there are difficulties.</p>

<p class="tab">While we have not
developed a method for measuring in-situ stress remotely, we are developing a
method to measure strength. It's very difficult, again, to calibrate. It is
known that the penetration of a projectile into a material, such as a rock,
depends on the strength of the rock, among other things. We did a series of experiments
in concretes, and things like that, where we demonstrated this. And, there's
been a great deal of work done on it because of penetrating weapons, by Sandia
and Waterways Experiment Station. They have developed a whole bunch of
complicated formulas for calculating the penetration.</p>

<p class="tab">I discovered that a
formula developed in 1765, or something like that, by Euler, was much better
than any of the formulas developed in modern times, and he used very simple
math. At any rate, we now have a device, built, which is capable of being put
down hole. It fires a projectile into the wall of the hole, by remote control,
measures the deceleration, and then retracts. It can then be used to repeat.
This device exists, but the equipment to lower it down the hole doesn't exist.
There are a lot of difficulties with it.</p>

<p class="tab">One of the major
problems, of course, is in calibration. You can calibrate it in concrete fine,
and that's what we're working on. Calibrating it in rock is extremely
difficult. We're going to take it down to the tunnels, and we've done this once
before with a kluge. Now we're doing it with the real apparatus. The problem,
of course, is knowing the right answer. When you fire it into a rock, and measure
the deceleration, what is the strength of that rock? You get a core sample, and
you measure the strength of that core sample. You hope that if you measure it
six inches from the place you're measuring with the tool that it is at least
similar. But if you take two or three core samples, and you measure the
strength of them, they're wildly different. And if you shoot in two or three
places in this piece of rock, you get different penetrations. I think we'll be lucky
if we get a factor of two accuracy; we'll be happy if we get a factor of two
accuracy. But this tool I am very pleased with. It's calibrating pretty well in
grouts, and I'm looking forward to doing it this summer in the tunnels. It's a
lovely piece of apparatus.</p>

<p class="tab"><b>Carothers</b>: Maybe the strength varies by a
factor of two over short distances.</p>

<p class="tab"><b>Hearst</b>: Quite possibly. At any rate, we
have actually built this apparatus, which is on wheels at the moment. We have
designed a device to lower it. It's designed to work in a big hole, to clamp up
against the wall of a big hole and fire the projectile into the wall.</p>

<p class="tab">John Rambo uses the
drilling rate as a measure, of some kind, of the strength, but it also measures
other properties. Among other things it depends on how the drillers are
working, and how much weight is on the bit, and how sharp the bit is. But it is
another measure.</p>

<p class="tab">John also believes
that the velocity is another measure of the strength. Remember that I told you
that the velocity depends on how much the rock is broken up by the drilling?
Well, if it's broken up less, it's stronger, and so the velocity is higher. A
lot of other things will make the velocity higher also. We may have to use all
of these methods together to infer a strength. But since strength makes a great
deal of difference in a calculation, it's important to get it.</p>


<a name="ch8"></a>
<br><br>
<h2>Chapter 8: Energy Coupling and Partition</h2>
<br>

<p class="tab">A nuclear detonation produces ten
to the twelfth calories per kiloton, by definition. All of that energy is
deposited in the earth, and ultimately, over a long period of time, results in
making the earth as a whole somewhat warmer. Over the short term, the energy deposition
can cause many different things to take place. The question of what that energy
deposition does, and what fraction goes into each phenomenon is an open one, subject
to many variables. Some amount causes surrounding rock to vaporize and to melt.
Another amount causes the surrounding material to move, giving rise to motions
in the ground. Some causes open pores to collapse, some gives rise to stresses
in the rock, some is carried away by elastic waves that propagate to large
distances. The amount of the energy that goes into each of the various channels
determines the phenomena that are produced by the detonation. Some are easily seen;
that which goes into the seismic wave can be detected worldwide. The amount
that melts rock stays close to the origin; the rock cools, solidifies, and can
only be seen if a costly reentry is made to the vicinity of the detonation
point.</p>

<br>

<p class="tab"><b>App</b>: When you are looking at the
coupling of the energy, and ground motions, there is the issue of how much
energy actually gets coupled into the rock, as opposed to what remains behind
in the cavity. This deals with the shock Hugoniot and the release properties of
the vaporized rock. Butkovitch, in 1974, determined that there are large
differences in the kind of energy coupling between low and high density rock.
He looked at the refractories in the melt puddle and assumed perfect mixing,
and from that inferred how much melt had been generated. That gave a value for
how much energy had stayed behind in the cavity. What he showed was that for a
dense rock you get twice as much, or maybe more than twice as much, of the
energy into the shock wave as you do for a shot in low density, like 1.6 grams
per cc, rock. And so, starting off one looks like a bigger bomb than the other,
but it doesn't really change the waveform characteristics, just the amplitude
of the signal. It looks like a bigger bomb.</p>

<p class="tab">Now, the porosity,
and a number of other things change how large the bomb appears to be; how much
energy goes into the solid rock. One can make the argument that there could be
a factor of two in how much energy goes into the stress wave, just from the Butkovitch
work. We should be able to go back and systematically look at cortex data to
determine the hydrodynamic coupling for different materials. That's essentially
what cortex is sampling - the energy that goes into the shock wave. If we could
combine that with additional rad chem analyses of melt puddles, we might be
able to come up with some relationship between such coupling and the working
point material.</p>

<p class="tab">The other part is, as
we move farther out, there's this other phase of coupling, where the strength
of the materials comes into effect and changes both the wave shape and the
amplitude. That's the regime where the properties of the rock can modify the
wave form to make it look like maybe something else, another type of source.</p>

<p class="tab"><b>Carothers</b>: Does that matter to containment?</p>

<p class="tab"><b>App</b>: I think it matters. Anything we
can learn about how much energy gets coupled into the ground, and how it gets
coupled in, I think is relevant to containment. If a bomb is going to put twice
as much energy into ground shock because it's in this material rather than in
that one, that's relevant. It's relevant to containment because we worry about
the yield of the bomb, and that's the yield of the bomb, as far as the ground
shock is concerned.</p>

<p class="tab"><b>Higgins</b>: There was a recent tunnel
experiment that was identical in almost every respect to a test that had been
fired six months before. The results show that the same explosive yield, in the
same configuration, created a seismic signal that was one-half as large, or
even a little bit less than half as large, in one case as in the other. That
doesn't disturb anyone, because everyone knows that the seismic wave is kind of
a vague and various thing. But when people began to examine the close-in strong
motion measurements, they too were half as large, or less. And, as were the
accelerations, as was the tunnel damage. If you went to a distance like a
hundred meters from each of these two explosions, in one case there was nearly
total destruction of everything. The tunnel was collapsed, and so forth. In the
other case there was almost no observable effect; there were displacements, but
they were modest.</p>

<p class="tab">As the data are
examined, one of the suggestions, and it looks now to me to be the most likely
suggestion, is that the mechanisms for coupling energy, in that region where
melting and vaporization was going on, was very different in the two cases. If
you think of the total explosion, very close to the explosion rock is melted
and heated to extremely high temperatures. So, there is a part of the total
explosion energy that goes into heating the immediate surroundings, and that
part goes into forming the cavity. There's another fraction of the total energy
that goes into deformation of the rock in an elastic-plastic sense. And
finally, way out at longer distances, there's an elastic wave which creates a
seismic wave.</p>

<p class="tab">We've long said that
about fifty percent or so of the total bomb energy goes into the thermal cavity
region, that another large fraction, also about fifty percent, goes into the
plastic deformation region, and a very tiny part - one percent or less - goes
into the seismic signal. What these two shots, and the measurements since then,
suggest is that this roughly equal partition between the molten and the plastic
deformation is variable, and a lot more variable than we thought. And that, in
turn, affects the one percent or so that's left over for the seismic wave by a
rather large factor.</p>

<p class="tab">For example, look at
the amount of energy that is stored in what we call the containment cage. Take
from one cavity radius to three cavity radii and say that is the containment
cage region. That's a very crude set of definitions, but if you put two bars of
stress in that spherical shell, that amounts to thirty percent of the initial
device energy, using the compression curves that we are measuring. That amount
of energy in the containment cage is a significantly large fraction of the
device energy, and things that go on to perturb it are big things, not little
things.</p>

<p class="tab"><b>Carothers</b>: What would lead to variability
between the ratio of device energy that goes into cavity formation and the
elastic-plastic type of deformation?</p>

<p class="tab"><b>Higgins</b>: There are quite a lot of
things, it turns out. We have started to look at that, but I don't think the
subject has been adequately studied, certainly not exhaustively. The most
obvious thing that changes the ratio is irreversible pore collapse. Suppose you
built the test medium out of fiberglass foam, or frothy pumice-like blocks,
with fifty percent air-filled void. The crushing of those voids would consume
huge amounts of energy. Of course, the material gets very hot when it's
compressed, but we don't measure temperature from a distance, so we don't know
how hot it gets. All we know is how much of the compressive wave got
transmitted, and if you're crushing the material, you're not transmitting any wave.</p>

<p class="tab">So, air-filled voids
are one thing that can change the ratio. There are other kinds of things, such
as phase transitions. Everybody is familiar with the ice cube in the drink, and
the fact that you have a phase transition going on. It keeps the drink cold
even though there is almost no volume change. The same thing happens in an even
more pronounced way in some solids, like rocks. There are phase transitions
that go on where minerals hydrate, or dehydrate, or melt, or vaporize, or
change from loose open structures to dense compact structures. A common one is
the transition of carbon to diamond, where there is a big density change.
Silica does the same thing. It goes from an orthorhombic eightfold symmetry to
cubic symmetry at very high pressures, and the volume change that accompanies
that is like a factor of two. So the amount of energy that can be stored, just
by going from an open loose structure to a high density structure is huge.</p>

<p class="tab"><b>Carothers</b>: You mean that just to
generically call the Rainier Mesa rocks 'tuff' doesn't tell you what you need
to know?</p>

<p class="tab"><b>Higgins</b>: Right, and it doesn't even tell
you what you need to know if you identify it as being Tunnel Bed Four, because
it turns out that the degree of zeolitization, the minerals of Tunnel Bed Four,
are quite different in different places.</p>

<p class="tab"><b>Carothers</b>: So, to say that you have Tunnel
Bed Four here, and in a different location you also have Tunnel Bed Four, as
the geologists do, is not adequate to determine what's going to happen when the
device goes off, at least close-in.</p>

<p class="tab"><b>Higgins</b>: That's a conclusion that
appears to be true. I've got an analogy, which isn't exact. The business of
containment, the interaction of a nuclear explosion with the earth, is somewhat
like atomic physics was at the turn of the century. People were beginning to
discover the difference between the orbital electrons in the various atoms.
Then they discovered there was a nucleus, and there was the atomic structure.
Then there is the nuclear structure, and they discovered that makes a difference;
all nuclei aren't just the same nuclei. There are levels in those nuclei and
there are particles in there. And then, there are particles in the particles. I
think that going from the picture of the earth as homogeneous is just like the
transition when they said, "You know, the atom isn't a pudding. It's more
complicated than that."</p>

<p class="tab">We're at the point of
knowing things are more complicated, but not exactly what all of the
complications are. That is still an open question. It's not open to the degree
that we don't have some pretty good containment rules, but it is open to the
degree that we can't say we can test in every conceivable situation with
complete certainty. There are questions that have to be answered in every case.
I think we can answer them. I don't see any insurmountable technological
problems, but it's more complicated than we first thought, by quite a bit .</p>

<p class="tab">The amount of melt is
one of the interesting numbers to look at. I really do believe, and I think
most of us in the business believe, that energy is conserved. Ten to the
twelfth calories in a glacier, or in the Greenland ice cap, will melt a fixed
amount of ice, and it doesn't make a lot of difference if it does it by
crushing or whatever. One of the rules of thermodynamics is that the paths are
not important; the end states will be the same no matter what path you take.
There is a certain amount of ice transformed into a certain amount of water. If
you know the total energy, you know the total amount of water regardless of the
path.</p>

<p class="tab">When you consider
those kinds of things, and then you observe such different results in the
seismic signal from two different events, you have to say, "It's clear
that there have been differences in the thermodynamic path, and that must be
related to the materials involved, and in the structure." We know that the
total has to be the same.</p>

<p class="tab">Take the differences
between P tunnel, and N and T tunnel. N and T turn out to be almost twins, but
P is different. When we ask the question, "Well, what is different?"
what turns out to be different is the degree of zeolitization, although the
stratigraphic units are the same. That's a fancy way of saying to what degree
the original volcanic glass has been transformed into some kind of a clay mineral.
There are units in both tunnels that have the same amount of clay formation,
but the clay occurs at different levels in the stratigraphic section. In other
words, the geologists have layered the cake differently than the physics does.</p>

<p class="tab"><b>Carothers</b>: There was a man, Rick Warren,
who gave a presentation at one of the CEP meetings about identifying the rock structures
by mineral analysis. He felt that was the way you should identify the layers.
His didn't correspond to the conventional units, but his point was that he
could tell you that the rock at this depth in this hole is like that rock at a
different depth in that hole.</p>

<p class="tab"><b>Higgins</b>: Right. DNA
had him to do a special set of examinations, and it was through his work that
this analysis of the P tunnel versus N tunnel came out. There are like fivefold
differences in the amounts of some of the minerals.</p>

<p class="tab"><b>Carothers</b>: Might one
say, “Over and over again we learn that the earth is an inhomogeneous body of
materials. There's no reason to be surprised by differences in the response of
the rocks to shots in different locations, because if you don't think of the
rocks just as Tunnel Beds Four, and instead look at their mineralographic
makeup, you're in a different medium in those locations?"</p>

<p class="tab"><b>Higgins</b>: That's
right. That's what you would conclude. And that has to do with the history of
the two areas we've been trying to understand, and their history with water.
One is closer to the edge of the old original pile of ash.</p>

<br>

<p class="tab">In the first years of underground
testing the radiochemists had a difficult time determining the fraction of the
yield that resulted from the fusion reactions. The samples obtained from the
post-shot drill-backs sufficed for measuring the number of fission reactions, but
the number of fusion reactions was difficult problem. In this circumstance
other methods of measuring the yield, or energy release, of the device were
sought.</p>

<p class="tab">The yield could, in principle, be
determined by measuring the velocity of the outgoing shock wave in the earth
materials surrounding the device. Small diameter holes drilled near the
emplacement hole were used to place various instruments in, hopefully, known locations
with respect to the device so the shock velocity could be measured. information
about the behavior of the medium itself could also be determined by instruments
placed in the same satellite holes to measure the pressures and accelerations
produced by the shock as it passed</p>

<p class="tab">Two of the important tools for
obtaining information about shock velocities are what are called the
"slifer," and the "corrtex." In the slifer, a long length
of coaxial cable acts as the inductance in an oscillator circuit. When the
cable is placed in an environment where the cable is progressively crushed, and
thereby electrically shorted by some external pressure, the frequency of the
circuit changes. Measurement of the frequency of the oscillator as a function
of time will then give the rate at which the cable is being electrically
shortened. In the corrtex there is also a long length of cable, whose length is
determined by sending short electrical pulses down it and measuring the time it
takes for them to reflect from the shorted end.</p>

<p class="tab">SLIFER - Shorted Location Indicator by Frequency of Electrical Resonance.</p>

<p class="tab">CORRTEX - Continuous Reflectometry for Radius versus Time Experiment.</p>

<br>

<p class="tab"><b>Bass</b>: I first got involved with
underground measurements when I was asked to head an instrumentation section to
make the close-in earth motion measurements on Scooter. We had stations at 25
feet, 50 feet, 100 feet, 200 feet, in vertical drill holes at shot depth. Then
we had some instruments above them, making some vertical measurements, and then
we had a few surface measurements. Scooter provided absolutely fantastic data
that probably is not equaled today.</p>

<p class="tab"><b>Carothers</b>: Were these the first attempts
at such measurements?</p>

<p class="tab"><b>Bass</b>: No. There were very good
measurements on Rainier. Bill Perret did those. Rainier was an outstanding
experiment and it was very well measured. Actually, some of the measurements
were fantastic. Go back and look at the work that Fran Porzell did. He had left
Los Alamos, and was at Armour Research at that time. He was attempting to
measure hydrodynamic yield. and he had measurements that are now on what I am
going to say is the cutting edge of what Los Alamos is now trying to do. There
was a Doppler system radar on Rainier to measure the shock wave arrival which actually
was as good, or just as far advanced, as Los Alamos is doing on the
hydrodynamic yield programs today.</p>

<p class="tab">Also, on Scooter we
tried to make pressure measurements, and we got next to nothing. We put in a
few hydrophones, which are underwater pressure gauges, which we tried to adapt
to underground, in soil, measurements. These hydrophones, which were made by
Atlantic Research Corporation, were all Navy type equipment. They were a little
batch of barium titanate crystals, I think, in a sack, and they drove a cathode
follower, which was an emitter follower which drove a line driver. We tried to
put those in a pressure chamber, and tried to calibrate them. We then put the gauge,
which looked like your finger with a little bulb at the bottom, in a plastic
sack of sand. We then put this in a metal frame, lowered it down the hole, and
poured matching grout around it. The idea was that we would activate the
crystals in the chamber. The return was zero.</p>

<p class="tab">The reason the return
was zero was that during the long period of time when Scooter misfired, and
then finally went, we had snows and rains and everything else on the Test Site.
The emitter-follower boxes were right at the surface, and they all got wet, and
shorted out. As project officer I was at" fault for not having them moved.
That shot went about the first week of October, I believe, instead of July, for
reasons we have talked about.</p>

<p class="tab"><b>Brownlee</b>: Right after the moratorium I
was doing hydrodynamic yield measurements in satellite holes. Ray Blossom
picked the site for the shot, and Bob Newman told them how deep to drill the hole,
using his little scaling law. Then I came along and said, "Okay, let's
drill a hole here, and a hole there, and a hole over there, so for that yield
range I can measure the hydrodynamic yield."</p>

<p class="tab">In order to do that I
would go talk to the designers, and spend time with them. I would say,
"You've got this down as 10 kt. What's the chances it will go 15 kt?
What's the chances it will go five? What's the chance it will only give us a
hundred tons?" I would listen to everything I was told, and I would say to
myself, "Well, they say it's going to go ten, but it's clearly not going
to do that." So, I would locate the satellite holes so if it went three
kilotons I could get a good yield measurement. So, I'd have one or two in
close, and do the third one farther out. I would put the holes where I was guessing
would be right for the yields. We didn't have a design yield or a max cred
yield then. We had a design yield in the sense that they were hoping it would
give ten kt, or whatever. Newman would have the hole for that. But that's not
necessarily the yield I would use to place the satellite holes.</p>

<p class="tab"><b>Carothers</b>: If you were trying to get the
yields hydrodynamically, that must have made the question of what the material
around the shot point was important to you.</p>

<p class="tab"><b>Brownlee</b>: Oh, yes. That's where I came up
with the four standards. There is a supersonic part of the arrival time curve,
then it becomes sonic. And so, the shot would tell me what the sonic velocity
of the material was. I had these curves, four altogether. I would say, "Is
the sonic velocity most like this one?" Then I would use that one to
derive the yield.</p>

<p class="tab">On one shot the curve
would go sonic at this place, and then I could say, "This is very
wet." On another shot it would curve over at another place, and I could
say, "This is very dry." So, when I'd gotten enough facts I could
say, "There, that's what it does. The shot itself is telling me the sonic
velocity." So, I was able to construct a particular curve. Now, after
you've done that, you can go back and restructure all the other curves and say,
"Well, I can have any kind of equation of state here, depending on how much
water is there." Then you do the trial and error fitting, and let that try
to tell you the yield. I abandoned the four standard curves in time, but I
needed data to show me that.</p>

<p class="tab">But you're exactly
right. The reason I got interested in the water content, and what the rocks
were like, and the porosity, and whether the porosity was filled with water or
not, was in order to determine the yield. Hindsight says we were doing a better
job of determining the yields than we had any right to expect. They were really
pretty good, but I didn't know that. We finally stopped because the rad chem
people said they were getting the yields well enough. It costs money to drill
those satellite holes, so we finally stopped it. On the other hand, it's a good
way to get the yield, and you really can do a pretty good job in a medium that
you understand.</p>

<p class="tab">But remember, it's
the shot itself, when you shoot it, that tells you what the medium is like. We
never measured, ahead of time, the correct sonic velocity. We determined it from
the shot, and it was always different from the pre-shot measurement .</p>

<p class="tab">That was the point I
was trying to make at one of the CEP to these lads who were sitting there, who
persist in believing that what they measure is the truth. They insist upon
that, but it's never been true when you find out what the truth really is; it's
never right. But there's the, "That's what I went to school to learn. I
did all the things they told me to do, so this must be the number." So,
you're quite right. It was the hydrodynamic yield measurements for those earliest
shots, more than for containment, that forced me to understand something about
the material.</p>

<p class="tab"><b>Bass</b>: After the moratorium Los Alamos
was drilling a lot of holes in Nevada. They would drill a hole, and we would
locate three satellite holes for making hydrodynamic yield measurements. Bob Brownlee
had a formula to locate them, and we were working in the sonic region, because
we thought that was the only place we could really understand. Also, in that
region we were far enough away that the range errors - the errors in distance
between where we thought the device was and where our instruments were -
weren't killing us. But, every now and then something would happen, and they
would end up putting a higher yield device down than they had originally
planned. So, we would be in the hydrodynamic region, and we started getting
some hydrodynamic data out of our first satellite hole, which was supposed to
have been at around ten kilobars. Sometimes we were getting up to a hundred kilobars,
or even two or three hundred kilobars.</p>

<p class="tab">When Bill Ogle said,
"Let's start this hydro yield program," he gave Sandia carte blanch.
Sandia and Los Alamos started their program, and Sandia did all the
experimental work on that. The people in Livermore went off on their own, and
started their own program. At one time Johnny Foster came to Sandia and asked Sandia
to get involved in the Livermore program, but it never got implemented. It was
probably a good thing, because I think there was too much work to be done as it
was.</p>

<p class="tab"><b>Carothers</b>: It was expensive to drill those
instrument holes, and Livermore gave up such measurements as the chemists
developed their own methods for better yield measurements.</p>

<p class="tab"><b>Bass</b>: Los Alamos quit it too, because
we got into a medium that was badly layered and we weren't getting decent
results. The results were garbage, so we all quit the thing. But, before that
we did get some useful data. Our agreement was this - we would provide Los
Alamos with time of arrival information, if they would let us make, in their
facility, pressure measurements. Chabai and I wanted the pressure measurements.
They wanted the time of arrival data. Art Cox, Bob Brownlee, and I worked on
this constantly. I was at Los Alamos every week during that period.</p>

<p class="tab">We were also working
rather closely with Fred Holzer at that time, on Madison. He had a big
containment program there. Madison had a huge room, and a drift off to the
side. He wanted to find out how the energy partitioned down that, and could you
close off the tunnel with that drift. He courteously invited us out to look at
the whole thing, and go over all his data.</p>

<p class="tab">Then he came up to us
at the CP one day and said, "I've got something you ought to get involved
with," and he handed us a drawing of the slifer that they had come up
with. We looked at it and said, "This is outstanding," because at
that time we were using peizoelectric crystals, rather than a cable. That's the
same thing the Russians are using today, although they finally went to a
slifer.</p>

<p class="tab">We immediately
started putting down slifers. I think the first one went down within a week. I
took the drawing down to our trailer area, to an electronics guy, and said,
"Hey, build us one." He said, "I'm not going to put those tubes
down there," because it was a hard-tube oscillator. In about twelve hours
he had one working with two transistors. There's just an oscillator and a line
driver; that's all there is to it. That is still the same slifer design that
Sandia uses to this date. We have never changed that design, from that day in
the CP in 1962. When the Soviets looked at that they said, "You guys are
kidding. Is this how you measure hydrodynamic yield? You use this?" because
the transistors were circa '62.</p>

<p class="tab">We put slifers down
right away, and we loved them. We used them ten times as much as Livermore ever
did, and we still use them to this day. There are two slifers installed on the
outside of the pipe on all DNA events, to measure pipe flow.</p>

<p class="tab">Brownlee and I put
them on the inside of a pipe one time only. Al Graves gave us Mataco, and said
we could do anything we wanted on Mataco, because he wanted to know if they
could do these line-of-sight experiments. One of the things we did was to put a
slifer cable inside the pipe, and one outside. We found that they read exactly
the same thing .</p>

<p class="tab">So we started using
these slifers. Taking the slifer data, and the Hugoniots of the earth
materials, you can do the integrations, and put them all together, and you will
end up with a beautiful pressure-distance curve. And it matches the pressure
data. The whole thing falls together. It really falls together when you do it
for granite. You can end up with a pressure curve from two megabars down to two
hundred kilobars, in granite, from the slifer cables, that match the pressure
data. It's a very good test, and the sanity check is solid. Those all go
together, the pressure data, the slifer data, and everything else we've ever
put together.</p>

<p class="tab">So, we were making
these time-of-arrival measurements on Los Alamos events, and compiling the
data. That's one thing I've always done through the years. I say, "All
these individual data are poor, but when you put them together, there's some
sense to them." And Brownlee's a real advocate of this; you better believe
the data, because they're telling you something. They're always telling you something.</p>

<p class="tab">We started putting
together the data we had taken on the LASL shots where we were in the
hydrodynamic region and we discovered, 10 and behold, it didn't make any
difference what we were shooting in. There was a straight line function in
everything. If we were in granite, if we were in alluvium, if we were in tuff,
it made no difference in the strong shock region. All these materials worked the
same way. What we had found is now called the Universal Relation. Now, marble
is an exception. There are exceptions always to rules like that.</p>

<p class="tab">And this has been
ignored, I think for one reason. The Livermore jealousy concerning the Los
Alamos hydro yield program has been incredible. Livermore has been very negative
on that program from the very beginning, because they have been oriented more
toward seismic measurements for yield. So, they have not been much in favor of
the cortex measurement program and the slifer program.</p>

<p class="tab">Incidentally, I think
cortex is the greatest sales job in the history of the program. If the Lord
above had told you how to do this, he would have said, "Cortex first, and
then slifer is the improvement over cortex," because slifer is continuous,
and cortex is discrete, and not too solid. Now, the new cortex gets rid of this
problem by looking for the phase change of a standing wave on a cable. Fran Porzell
had done that on Rainier. It didn't work on Rainier, but it was the same thing.</p>

<p class="tab">We first started the
idea of using slifers for hydrodynamic yield on the PNE and the Threshold Test
Ban Treaty, using this Universal Relation. It says that shock propagation in
most geologic materials can be described by one power-law formula. It's called
the Universal Relationship, or the Los Alamos Relationship. AI Chabai and I
developed it, and Los Alamos has used it ever since.</p>

<p class="tab">We were pushing this
as the way to measure the yield of PNE events. The reason you have to use the
Universal Relationship on PNE's is that you don't know where the source is. The
treaty we had, and still do have, with the Soviet Union says that the canister can
be, then ten meters long, now twelve meters long. And, they can put the device
anywhere they want in those twelve meters.</p>

<p class="tab"><b>Carothers</b>: You mean, you don't know where
the center of energy is.</p>

<p class="tab"><b>Bass</b>: That's right. That's a better
way to put it. So, your system has to tell you where the center of energy is.
This is where you use the Universal Relation, because you know what the slope
of the function must be. All you have to do is make a measurement in the
emplacement hole, although it also works in a satellite hole. In the
emplacement hole you don't need to know where the source is below you, but you
do know from the Universal Relation that the slope of the shot curve has to be
a certain value. Theoretically it should be 0.4, on a log-log plot. It turns
out it 0.459, or something like that, because theory doesn't work here. It's
just strictly accidental empiricism, or quackery. That's a proper dictionary definition
of an empiric, isn't it - a quack? Anyhow, the Universal Relationship works
beautifully for this.</p>

<p class="tab">So, that's where PNE
monitoring became possible, because we could, through the use of the Universal
Relationship, and with the proper spacing of the cable above the canister so we
would know we were in the hydrodynamic region, get the yield for any event we wanted
to measure. If you had a satellite hole that went deeper than the device
emplacement, that would tell you directly, but at that time there were not
going to be any satellite holes. Everything on the PNE treaty was main hole,
because it costs a million dollars to drill a satellite hole.</p>

<p class="tab"><b>Rambo</b>: I was hired on, in November of
1963, by John Ellis, who was then in charge of a small group developing, as a
group, how to measure slifer yields for the nuclear test program. As I got familiar
with the operation I would design where they would be located. I was one of the
first people to say, "We've got to run the cable below the working point,
so we can see the first crush on it." We wanted the first arrival because
the elevation of that first arrival is where we thought the shot horizon would
be. That was of interest for us because it would tell where the working point
was, and there was a lot of uncertainty in that.</p>

<p class="tab"><b>Carothers</b>: You know where the emplacement
hole started, on the surface, and it may wander a bit, but not much. Then you
know where the device itself was put, rather accurately.</p>

<p class="tab"><b>Rambo</b>: Fairly accurately, although in
the early days it wasn't always stated if they changed that location, and other
times that information did not get back to us. On the satellite holes we
thought the location accuracy was about two feet per thousand feet of depth, on
the average. The Sperry Sun people did those surveys. They would run two or
three runs, and we'd get different answers from each run. Two feet per thousand
feet was average, but it could exceed that. You could get systematically bad
information. Occasionally you'd get one survey that was five or six feet
different from the others.</p>

<p class="tab">So, there was some
uncertainty there. There was also some uncertainty in the depth, and there was
the distance from the emplacement hole to the satellite hole; you had to make
sure that was correct. One time I discovered that my data wouldn't fit no matter
what I tried to do to it. So I went back to an aerial photograph, found the
size of the pad, and then was able to determine how far away the satellite hole
was. The surveyors had made a ten foot error. Then I was able to analyze that
data. That was the kind of thing you could run up against from time to time.</p>

<p class="tab">In those days we were
usually using one satellite hole. There was one or two shots that had three
holes, but it was usually just one, and we didn't always know where the
satellite hole was. So, there were surveys, and sometimes there were errors in
where the cables might be located. So, we would make corrections after the fact
to our data.</p>

<p class="tab"><b>Carothers</b>: After people told you what the
yield was supposed to be?</p>

<p class="tab"><b>Rambo</b>: I've been accused of that quite
often, so that question doesn't come as a surprise.</p>

<p class="tab">The results were
quite sensitive to separation. A few feet made a difference. At the low yields
we were doing in those days, it was very sensitive. In fact, I could easily be
in the thirty to fifty percent range sometimes, certainly thirty percent. When
you made the statement that if I knew the yield I could determine a good slifer
yield, sometimes I did that, but more or less to determine what went wrong with
the experiment. I was looking for systematic problems. I'd look back at the
yield, and I'd say, "In order to get this yield, what would I have needed
to change?" And so I would learn something about the experimental
procedure, hopefully, to improve it. But I can't say I was completely oblivious
to the fact that I sometimes knew what the yield was before I published the
yield that I had gotten.</p>

<p class="tab"><b>Carothers</b>: If you were going to do that
kind of measurement, you needed to know something about the material properties
of the medium in which you were shooting - whether it was tuff, or alluvium, or
below the water table, or whatever. How did you get that kind of information?
When you started the slifer measurements they weren't logging the holes were
they?</p>

<p class="tab"><b>Rambo</b>: We weren't getting anything.
The geologists would go down, look at the cuttings, and say things like,
"There's rocks down there," or, "This is highly porous
stuff". They weren't very good descriptions for what I needed.</p>

<p class="tab">We had four or five
curves that we would compare our data to, to get the yield. It's called similar
explosion scaling. These curves were labeled Wet, Damp, Dry, Very Dry. The tail
of these curves would fold over flatter if they were dry, and they would be
steeper at the end if they were wet. I would take these curves, and I would compare
the tails of these things after the fact, and with some knowledge that we were
in a wet hole or a dry hole area, I would ask the geologists for what specific
information they had. From that I would try to figure out which curve was the
one I was to use. It is not the best way, and it is certainly not as good a way
as we do nowadays.</p>

<p class="tab"><b>Carothers</b>: Bob Brownlee did measurements of that sort for
some time for Los Alamos. Did you have any contact with him at all?</p>

<p class="tab"><b>Rambo</b>: No, I don't think so; not in
those days. The curves I was just mentioning came from Los Alamos, and they had
come from calculations they had done. We inherited those nomenclatures. We were
at least self-consistent in terms, between the Laboratories.</p>

<p class="tab"><b>Carothers</b>: Why did you use satellite
holes, which are expensive? Why not put the slifer cables down the emplacement
hole?</p>

<p class="tab"><b>Rambo</b>: We did. We did them in both
places, but what was happening during those days was we were usually measuring
fairly low yields, and there were often large diagnostic line-of-sight pipes, at
that time. Close in to the device, where you needed to be with the slifer
cables, there was a lot of radiation and energy that was going up to hit
doghouses and things like that. Often what I'd see on the slifer cables was
doghouses exploding. I could see all this detail going on, but it wasn't very
conducive to doing a good yield measurement. So, I kept pushing for satellite
holes. That was an additional expense, and I think toward the end of this early
era they were trying to save money, and the other methods of yield determination
were getting better, so slifers sort of ceased to exist at Livermore, probably
around 1964 to 1965.</p>

<p class="tab"><b>Carothers</b>: What's the difference between a
slifer and a cortex measurement?</p>

<p class="tab"><b>Rambo</b>: Really nothing, in terms of
what the data looks like. In a slifer, the cable is the inductive leg of a
tuned oscillator. When the shock crushes the cable, and shorts it, the
inductance changes, which changes the oscillator frequency. Los Alamos, at a
later time, decided to use a slightly different way to measure the cable
length. What they would do was send an electrical signal down the cable, let it
reflect off the crush point, and come back. So, they would measure the transit
time. This is what the cortex method is. Essentially we measured the same
thing, but by slightly different methods.</p>

<p class="tab">There are some things
that a slifer does in sensing a change more rapidly in the speed of the crush
going up the cable, because you don't have to wait for the transit time of the
signal. There are some advantages to the slifer, and they're still being used
on the tunnel shots. I am not sure which method is better. I think cortex is a
little bit freer of noise, and in some instances, because the technology of
electronics have changed, it's better in that sense. It suffers from the same
problems we had in the early days of doing slifers. It's just that when they
brought more information to bear on the problem in these recent times, it's a
little easier to get better solutions from the data. But there are still problems
that are very hard to deal with .</p>

<p class="tab">I have looked at a
lot of data where I would see a time of arrival up above the device which
seemed shorter than it did off on the horizontal, where we were looking at the
horizontal arrival of the shockwave. Then after a while, the two curves from
those locations would come together. This was two separate cables, of course. I
saw that more often than not. If there was a baffle, or some sort of metal
plate, or something like that above the device, it looked like the shock was
coming from that source. Or if there was a large opening for a brief distance
above the device you could almost see that looking like a source.</p>

<p class="tab">So, there was this
problem of where the center of energy looked like it was, very close-in. People
like to measure close-in, near the center; the material properties don't matter
as much there because of the very high pressures. But what does matter is the minute
geometry of what's going on with the explosion, in terms of where the energy
flows. So, you've got a trade-off taking place at that point. It's almost
better to look at the data farther out, but at that point you're worried about
material properties more.</p>

<p class="tab">If you looked at the
entire curve on these things, sometimes you could determine what errors you
were looking at. If your cable was further down than you thought it was, you
could see that kind of error, because it was a constant difference from what
you should be reading. And if you were comparing it to an emplacement hole, sometimes
you could determine that. If the satellite hole were farther away than you
thought, you could compare it to the emplacement hole, and sometimes you would
get a feel for that kind of an error. These were all techniques, and some of
them I had developed in the early days, like looking at where the first crush point
was on the satellite hole to try and iron out some of those difficulties. A lot
of that is now taking place more professionally with current methods than I was
able to do.</p>

<br>

<p class="tab">The earth in which the energy of
the detonation is deposited is not an infinite, homogeneous material,
unfortunately for those who would calculate and predict what will occur. The
various layers of rocks of different properties, the faults, the presence or
absence of water all affect the ground response. One example is the surface ground
motion produced by an event called Tybo, which was detonated in an emplacement
hole in Pahute Mesa. The surface motion, and the measured ground shock was,
unexpectedly, the highest that had ever been seen at the Test Site. John Rambo
tried to model the geologic setting, and in his calculations determine why this
should have been so.</p>

<br>

<p class="tab"><b>Rambo</b>: I started to wonder about these
peculiar ground motions when there were two shots that were fired quite close together
physically, and also in time. One was nine kilotons, and it was located below
the water table at about six hundred and eighty-eight meters. The upper one was
at about four hundred and thirty some meters, and it was about thirty-five
kilotons. The interesting thing was that the free surface velocity for the
deeper one was about one point one meters per second, and the free surface
velocity for the upper one, which was higher in yield and much closer to the surface,
was about one meter per second. These were actually measured, and because there
was about thirty seconds between the detonations it was easy to see separate
signals.</p>

<p class="tab"><b>Carothers</b>: The thirty-five kilotons closer
to the surface gave less motion than the nine kilotons deeper down?</p>

<p class="tab"><b>Rambo</b>: That's right. And so, that was certainly a puzzle.</p>

<p class="tab"><b>Carothers</b>: No puzzle. The lower one was
below the water table. The coupling is higher there.</p>

<p class="tab"><b>Rambo</b>: But above the water you had all
this porous material, for quite a ways. The shock was running through much more
porous material from the more deeply emplaced lower yield shot than the shock
was from the upper yield shot. The perception at that time was that this was
something to wonder about.</p>

<p class="tab">It turns out, from what we saw in
the calculations, that being below the water table tended to give what I call a
focusing effect that changed the attenuation rate of the signal, even though
you're going through the same porous material. The shock is being absorbed right
above the water table; there is quite a lot of attenuation at that point. But
there is another effect. The shape of the wave shows where it comes from, or
where it looks like it comes from, and that is important. If it becomes more
planer, it's going to attenuate less than the spherical wave you get if
everything is a uniform medium.</p>

<p class="tab">I didn't know this until we did
the Tybo shot. That was an event that had very high ground motion. It was about
nine point eight meters per second.</p>

<p class="tab"><b>Carothers</b>: That is the highest ground
motion we have ever seen on a contained shot in Nevada, if I remember
correctly.</p>

<p class="tab"><b>Rambo</b>: That's right. Tybo was
certainly a mystery because of the high ground motion. There was at one time
some TV footage of what it looked like from the side, when it went off. It
showed this huge mound rising up, and you could see the curvature quite
clearly. The containment scientist related to me that it looked like it was going
to come out of the ground. It just looked like a cratering shot, and gave you
that impression, it was so rounded.</p>

<p class="tab">So, there was a lot of interest
in why this could have occurred . I went back and I ran fifty or more 1-0
calculations, and I couldn't get anything close to what happened, no matter
what I did. Even if I ran it saturated to the surface, I couldn't get anything
like that. And, it just was not in the realm of material properties, and I
tried a lot of them. Even increasing the yield to the maximum credible yield,
and going to extreme material properties I could not get a match to that kind
of a signal.</p>

<p class="tab"><b>Carothers</b>: That merely illustrates the deficiencies of your code .</p>

<p class="tab"><b>Rambo</b>: You're right, and the
deficiency I found out about was that a 1-D calculation didn't take into
account a flat water table effect in the soil.</p>

<p class="tab"><b>Carothers</b>: Of course not, because in a 1-D
calculation the device sits in a sphere of saturated material. So, the shock
goes out spherically, and it doesn't care what the interfaces are, except a little
energy may get reflected back, and it stays spherical.</p>

<p class="tab"><b>Rambo</b>: You did a better job than I
could do to describe it. To look at the surface signals on Tybo we had surface
arrays that went off in a couple of different directions. Without those arrays
I doubt if we would have been able to unravel it. Looking at that data, you
could see that the plastic part of the wave was traveling in different pathways
than the elastic part which was just going straight through the formation on
constant rays. From that I got the idea that a 2-D calculation would probably
show the effect, So I switched over to a 2-D calculation, and I definitely saw
the effect; there was at least a factor of two between a 1-D and 2-D calculation.</p>

<p class="tab">It's a Snell's law kind of an
effect. What happens is that there is a change in the shape of the outgoing
wave when it hits this porous surface. It becomes very broad and very shallow,
so it looks like the source is much deeper. That means it's going to attenuate
less because it's progressing now more like a plane wave rather than like a
highly spherically divergent one. It's still spherical, of course, but it's not
as divergent as it was, because the radius is now much bigger. The calculations
showed this enhancement, so you get a much higher free surface velocity then
you would with normal spherical kinds of geometries.</p>

<p class="tab">I think that was the first time
we had discovered that this huge variety of ground motions could indeed be due
to a focused effect from the layering. In the case of Tybo it happened to be
the water table, but there could be certainly other cases where you'd see things
of that nature. When you go from something that is saturated to something
that's highly porous, and maybe there's some strength in that rock as well, the
the signal is not attenuated very much in the porous material, and so you may
get a focusing effect.</p>

<p class="tab"><b>Carothers</b>: This effect occurs when you're
going from a medium with a relatively high sonic velocity into something where it's
slower? Or into a medium with a higher index of refraction, if you like.</p>

<p class="tab"><b>Rambo</b>: That's exactly the right
analogy. It tends to be most pronounced when the interface is between about twenty
to forty meters per kt to the one-third than at other distances. At very high stresses
the shock wave in the saturated and unsaturated materials give about the same
velocity, because they're so high up on the stress curve, or up on the
compressibility curve, that the velocities look very similar and you don't get
the big velocity differences, usually. If the interface is much farther out,
then the distance in which the shock wave has to change its attenuation is much
less, and so you don't see quite the effect. But around the twenty to forty meters
per kt to the one-third you can really see a pretty good effect from that, on
the ground motion. At least that's what the calculations tend to show .</p>


<a name="ch9"></a>
<br><br>
<h2>Chapter 9: Cavities and How They Grow</h2>
<br>

<p class="tab">When a nuclear device is
detonated it deposits a very large amount of energy into a rather small volume.
That deposition of energy produces a volume of extremely hot, extremely high
pressure gases from the surrounding materials. These generate a very strong
shock, which begins to move outward from the shot point. That shock is strong
enough that as it moves out it vaporizes some rock, melts more rock,
plastically deforms still more, and finally weakens to a place where only
elastic movements of the rock take place.</p>

<p class="tab">What is left behind after the passage
of the shock is a more or less spherical cavity that contains the radioactive
debris from the explosion, and vaporized and melted materials that contain some
fraction of the energy released. Fundamental to the understanding of how the
containment of nuclear explosions occurs is knowledge about the formation, the
growth, and the eventually decay of the temperature and pressure of the
post-shot cavity.</p>

<p class="tab">As with so many other things in
the field of containment, direct information and data about cavity formation
and the conditions in it are extremely difficult to come by. Much of what is
believed is derived from measurements at a distance where the instruments can survive
the shock passage, from observations on post-shot reentries made through
existing or newly mined passages, and from calculations which try to match the
data and observations there are and which then hopefully give insight into
other phenomena not directly observable.</p>

<br>
<i>Cavity Growth</i>
<br><br>

<p class="tab">The formation of the underground
cavity is an impressive phenomenon to consider. In a tenth of a second or so
the rock around the point of detonation of a one kiloton device is moved and
altered sufficiently to create a roughly spherical void that is of the order of
a hundred feet in diameter. For the Cannikin event, which had a yield ofa few
megatons, the formation of the cavity took somewhat longer, perhaps as much as
most of a second, but at the end of that time some 20,000,000 tons of rock had
been displaced to make a cavity in which the Empire State Building could stand.
The relative importance of the various mechanisms that cause the cavity growth and
formation is sti1\ debatable, although the general outline of what occurs is
gennera1\y agreed upon.</p>

<br>

<p class="tab"><b>Patch</b>: I think the shock and the gases
are not equally important in the growth of the cavity, but I think it's a
matter of the timing. In some sense, initially the cavity is driven by the gas
pressure inside. That's what launches the shock. But if you look at the
calculated pressures inside the cavity, because of the r-cubed effect, the
cavity doesn't have to expand very much before the volume goes up tremendously,
and the pressure is forced to drop. And so a great deal of the motion of the
cavity is really a coasting, momentum driven motion. The fact that the cavity
pressures end up at overburden, give or take factors of two, is somewhat
fortuitous, because we've done calculations for other, partially decoupled situations,
where you don't get anything like overburden pressure in the cavity, depending
on how it's decoupled. It just turns out, for the strengths in the rocks we
have, and the way things work out, that's kind of where you end up.</p>

<p class="tab">An example of where a
cavity does not end up at the overburden pressure is an explosion in water,
where you can get a tremendous overexpansion, and effectively a very low
pressure inside the cavity. It isn't smart enough to realize that the
overburden pressure around it is such that it ought to stop, and it keeps on going
until it gets to some very low pressure inside, depending on the depth and the
yield, and so on. Of course, it then gets smaller, since the outside pressure
is higher than that inside. Actually, such a bubble, or cavity oscillates in
size, predictably. So, I think it can work out either way.</p>

<p class="tab"><b>Carothers</b>: In the very early times after
the detonation the pressure of the shock generated must overwhelm any kind of material
properties or strengths of the rock.</p>

<p class="tab"><b>Rambo</b>: I think that's usually the case
in the megabar type of regime. I've heard some people now casting doubt on
that, so I did some equational things that relate to the slope of the shock
velocity and particle velocity curves. Material properties make a difference
overall, but most rocks tend to look pretty much the same in that high pressure
regime. You don't see any big differences; the slopes of the curves in a
granite look very much like the slopes of the ones for a weak alluvium. So,
there's a tendency to say, "Well, they're all going to be the same./I But
there are elements, or there are different things out there, that do look
different.</p>

<p class="tab"><b>Carothers</b>: What's your view of what drives
the cavity to its final size?</p>

<p class="tab"><b>Rambo</b>: My view is, and I take most of
it again from calculations, is that this enormous shockwave that's generated,
with· a very high gas pressure that sits behind it, gives momentum to the material
as the shock is traveling outward. From what I've seen in the best physics that
we know, in terms of calculations, is that the cavity pressure then starts to
decrease rather rapidly.</p>

<p class="tab"><b>Carothers</b>: Well, the rock vapor condenses
fairly early.</p>

<p class="tab"><b>Rambo</b>: It condenses, but that happens
at a later time. Even , at very early times, when that rock vapor hasn't even
had a chance to condense yet, the cavity pressures are down below where they can
have a strong effect on pushing the material outward. What's happening to the
ground around the device is that you've imparted a large momentum to it, and so
it wants to go out. Then it begins to decouple itself from the cavity pressure behind
it, and about all it seems to know is that it has this big momentum, and so it
is moving out. As it continues to move out, it's encountering resistive forces,
and the peak of the shockwave that's imparting this momentum is beginning to
decay rather rapidly. Pretty soon this momentum is fighting the restoring
forces of the overburden, and the shear strength of the material, as the cavity
wall material tries to get itself into a wider, thinner volume as it expands.
Eventually, the material reaches the point where, at maximum cavity radius, the
restoring forces which are wanting to push it back are as strong as the final momentum
forces that were pushing it out.</p>

<p class="tab"><b>Carothers</b>: Nort, the detonation releases
an enormous amount of energy into a quite small volume, the shock starts going
out, putting a lot of energy into the rock, which then coasts out to some place
determined by how strong the rock is. Is that what you think happens?</p>

<p class="tab"><b>Rimer</b>: That's containment lore.
Basically, the rock doesn't actually coast. I've heard, ever since I came to
S-Cubed, the story that you start the walls of the cavity moving, and it
doesn't matter how you modeled the cavity pressure. “The cavity just goes and coasts,
and keeps going until the rock strength stops it." That's not so. Cavity
pressure is an important driver. What's in the cavity, whether it's steam, or
the rock is dry, or whatever, is an important driver, and it does control, to
some extent, how long the cavity grows. If I were to rate three things of
importance to cavity growth, one is the strength of the rock, two is the cavity
equation of state, or what's in the cavity. Three is gas porosity, but gas
porosity is an order of magnitude less important than strength, for the final
cavity size. That's gas porosity, as distinct from water saturated porosity.</p>

<p class="tab">Outside the cavity
region the details of the rock volumetric equation of state, other than gas
porosity crush-up, are relatively unimportant to containment. They're important
if you're doing something like trying to determine the hydrodynamic yield.
They're important there, but if you're interested in containment based on displacements
of the rock, and how much plastic work you do in the rock to form these
residual stresses, they're not that important. </p>

<br>
<i>Cavity Size, or Radius</i>
<br><br>

<p class="tab">A number which is often referred
to in discussing containment is the cavity radius. When the term
"radius" is used, the implication is that a sphere is being referred
to. That is arguably not the right term or implication, since cavities are only
approximately spherical, but it is imbedded in the literature and the available
data. The quoted radius is generally determined by post-shot drillbacks which are
made to retrieve samples of the once molten rock for analysis by the
radiochemists. The place where the drill first encounters the radioactive
material, if known in space, can be used to determine a distance from where the
device was before detonation. If the assumption is made that the cavity grows spherically,
with the device as the center, a radius can be defined. Both the assumption that
the cavity is spherical, and that the position of the device is the center are
suspect, and probably wrong.</p>

<p class="tab">The predicted cavity radius is
used as one of the means of selecting a appropriate depth of burial. Also, it
is generally thought that for a given yield a larger cavity is better for
containment since that indicates a weaker rock that allows more cavity
expansion, and therefore a lower residual gas pressure in the cavity.</p>

<br>

<p class="tab"><b>Kunkle</b>: One of the things I have been
interested in is cavity sizes. That is, what data do we have that might be able
to determine the volume, and define the shape of the cavity. Is it really
spherical, or is it perhaps non-spherical? What is its volume, and its actual location.
Does it float upward or downward with respect to the shot center, and how is
the volume of the crater, if one appears on the surface, connected to the
volume of that initial cavity? One of the reasons I've been interested in these
things is that they are some of the measurable phenomena of the detonation. You
can go out and see a crater in the desert. You can drill back, and find the
lower hemisphere of a cavity. These are some of the few things we can actually
measure about what happens when a shot goes off.</p>

<p class="tab">Many of the other
things we would like to know, we just know very poorly. For example, the shape
of the rubble column, the chimney, under the ground is largely unknown. We have
in the past drilled into a few rubble columns in four and five different places
to try to learn something about their shape, but that only tells us about that
one, and they may be very individual for all we know. Such things we know
little about, but we do know some things fairly well, such as the lower radius
of the cavity, which we tag from our radchem drill backs.</p>

<p class="tab"><b>Carothers</b>: There are three cavities that
we know a fair amount about. One is Rainier, where they did an extensive
post-shot reentry and drilling program during the moratorium. One is Gnome,
which had a standing, partially collapsed cavity, where they reentered and
could walk around in it. And one is Salmon, which had a standing cavity, where
they could lower a television camera into the cavity and look at it. The Salmon
cavity was spherical. It had what could properly be called a radius, and a
center. Gnome and Rainier were both flattened on the bottom, with a bigger dimension
at the waist than that inferred in the upward direction. Of course, there was
surely an instant in time when they were rather spherical.</p>

<p class="tab"><b>Kunkle</b>: There must be some era when
that was true. It is a rather fortuitous circumstances that we have in the past
often shot in quite uniform material. These shots have been located mostly in Area
3, in the Sandpile area, which has a very uniform material. It's hard to conceive
of shooting in a more uniform geologic setting.</p>

<p class="tab"><b>Carothers</b>: And yet that's an area where
there are discrepancies in what you would normally expect the cavity radius to
be. Some of those cavities are reported as unusually large.</p>

<p class="tab"><b>Kunkle</b>: Yes, there's an area in
southern Area 3, in the alluvium, which seems prone to relatively large
cavities. But there seems to be a gradation in the mechanical properties of the
alluvium in Area 3 as you move from the north to the south, which is up along the
drainage toward Yucca Lake. The larger cavity radii may reflect some change in
the material. There seems to be a general relationship between the scaled size of
the cavity and the material it was shot in. For example, events shot in the
alluvium in southern Area 3 have a K-factor, which is a relative measure of
cavity size, around the low eighties. Shots in Pahute Mesa, in the very hard lavas,
tend to have K-values of 64 or so. And so, we see a range of cavity sizes reflecting
the geologic circumstances of the shots.</p>

<p class="tab"><b>Carothers</b>: Do you think it is the strength
of the material in which the device is fired that is responsible for the
variation in scaled cavity sizes?</p>

<p class="tab"><b>Kunkle</b>: The strength of the material
certainly has an effect. If you look at average numbers, as you move from the
soft, fluffy, low density alluviums in southern Area 3, with, say, a density of
1.65, to the medium density alluviums in the center of the valley, which have
densities of 1.8 or so, to the higher density alluviums in the north part of
the valley which have densities near 1.9 to 2.0, and down into the tuff units,
which are perceptibly stronger rock, to the very dense, strong lava units on
Pahute Mesa, you see a progression of cavity sizes from larger to smaller as
the units increase in their presumed strength.</p>

<p class="tab">I say presumed
because we don't really measure strength, but one could imagine that those
materials are getting stronger. The alluviums are too weak to core. They
crumble apart. The stuff that we took out of some of the lavas up on Pahute
near the Houston shot are good tombstone material. I describe them as very
competent, very strong, uniform rock. As you move through this progression of
rocks the cavities tend to get smaller.</p>

<p class="tab"><b>Carothers</b>: The data are scattered, but
there is a definite trend?</p>

<p class="tab"><b>Kunkle</b>: Yes. Much of the scatter is due
to measurement errors. Where actually is the cavity, for example. In the
radiochemical drill-backs you have to know where in space, or where in the
ground, you actually intercepted the radiation that marks the edge of the
cavity in order to back out the so-called cavity radius. The first problem you
run into is that this usually isn't a smooth transition from the native rock
into the radioactive melt glass. The transition is usually a meter or two wide,
with fractures and little pockets of activity mixed in. Turbulent mixing comes
to mind, though of course we've never seen that transition layer in that detail.</p>

<p class="tab">It's not a smooth,
sharp boundary, so one of the uncertainties is where to pick the edge of the
cavity to be. That's something which often has a meter, or two meters, of
uncertainty. Then there is an uncertainty as you lower a gyro tool into the
ground to try to survey in where that spot really is. Those errors build up,
and you're left with a sizable error, which increases linearly with the depth
of the shot, as to where you actually find that interface, just from the surveying.
Much of the spread we see in cavity radii, the K-values, the scaled cavity
radii, can be traced directly to our cavity radius measurement errors.</p>

<p class="tab">If we look at the
shots in Area 3 tuffs, which are fairly deeply buried, the average K-value for
those is around 74, 76, plus or minus 8. About two-thirds to a half of that
error, somewhere in that neighborhood, comes from cavity radius measurement
errors. And so, when you get a discrepancy for a shot, you don't know if you really
had a cavity that may have been large in that direction, or if you just
happened to get unlucky with the surveying.</p>

<br>

<p class="tab">For devices detonated in tunnels
it is possible to reenter, and if there is sufficient interest, mine back to
the boundary of the former cavity and even beyond, into the region where
overlying material has fallen in and filled the former void. Then there can be
accurate surveys, visual observations, and photographic documentation. Even so,
in the few cases where this has been done, determining a cavity boundary, or
volume, has been uncertain.</p>

<br>

<p class="tab"><b>Patch</b>: A problem we've always had, at
least for DNA, has been really tagging the cavity in such a way that you have
confidence that you know exactly what the cavity boundary is. In the tunnels we
tend to have fairly big perturbations because of stemming columns, and things
of that ilk. So, unfortunately, the cavity size is not known very well. It's
probably better to talk about the volume, and then small differences are being
cubed. In my mind that's a better way to look at it.</p>

<p class="tab">An issue which I
think is important is the different ways that cavities collapse. Some of them
collapse in a rotational mode. That's a shear collapse, if you will, where
apparently there's a shear plane that forms behind the molten edge. It's a
slope failure, a rotational slope failure. I don't know how far back this shear
plane is, but our experience is that the cavity radii tend to be about ten percent
greater in the horizontal plane than what you determine by measuring down
vertically. Of course, stuff comes down from the top also, and so the exact
size of the cavity is a little bit iffy.</p>

<p class="tab">Another thing is
that, at least to first order, all of the DNA sites we've fired in are wet
tuff, and they all are close to the same strength. So, we haven't really been
able to say, in terms of cavity growth, or cavity size, how rock strength
affects these things. I think that's an important parameter for us when we look
at the closures for the DNA experiments.</p>

<p class="tab">Maybe I can take a
slightly different tangent, that speaks in that general direction from a
somewhat different experience base. We've done a lot of work with Carl Smith
and the Sandia folks regarding the HE shots in G tunnel. Those shots have
ranged from eight pounds up to a ton. The second area which we worked in fairly
intensively was with Alex Morris at SRI, with fairly small shots. I think the
data, when you look at it, for that range of yields is pretty unequivocal that
strength has a very important effect on the cavity size.</p>

<p class="tab">And it's strength in
a funny way. That is, we have found, with reasonably high confidence, that the
response of these earth materials, be they grouts, or be they tuffs, are rate
dependent. In particular, they have an effectively higher strength if there are
very high strain rates. That shows up in this data base which spans quite a large range
in strain rates, from 3/8ths of a gram charge of HE up to really nuclear size.
Over that range we have seen dramatic differences in the scaled sizes of
cavities.</p>

<p class="tab">I think those are
reasonably well controlled observations, because we know, reasonably
accurately, what the equation of state for high explosive is, from its
initiation all the way out. And we have, for the SRI case, control of the grout
material. There is not as much control for the material in Carl Smith's work,
except to the extent that it's a homogeneous body of tuff that's relevant to
the DNA nuclear sites because the properties are close to those of the rocks
they shoot in.</p>

<p class="tab">I tend to think of
the microphotographs of samples that show this incredible structure, and I tend
to think of the movement of the rock as being a very complicated process of
grains trying to break cementation, and trying to slide over each other, and
doing all kinds of strange things. So, I think of the strength of the rock from
a more mechanical point of view. Being a mechanical engineer, I guess I think
more that way.</p>

<p class="tab">The role, or
influence, of the water in the rocks on the growth and size of the cavities is
another factor that is not that well understood. Certainly it has an effect.
There is general agreement that it weakens the strength of the rock, in some
indeterminate way, but how much it affects the growth of the cavity is an open
question.</p>

<p class="tab"><b>Carothers</b>: John, in calculating cavity
sizes, do you think that the principal influence is the strength of the rock
itself? How important is the amount of water in the rock?</p>

<p class="tab"><b>Rambo</b>: Perhaps we're limited in our calculations
in terms of driving pressures from the steam, but I see only a minor difference
in the amount of cavity pressure that's generated with say, ten percent water
as opposed to twenty-four percent water. The strength of the material makes a
big difference. I am much happier with a large cavity, because then I make the
assumption that it was fired in fairly weak rock, and the shockwave is
attenuated. And from all these biases that come from my calculational
background, I see a large cavity as more benign than I do something with a
small cavity.</p>

<p class="tab"><b>Kunkle</b>: I've looked at models of cavity
growth, and if the amount of water in the rock had an appreciable effect on the
cavity size you should be able to evaluate the volume percent saturation, and
as the amount of water and the volume of water in a given volume of rock
increases you should see larger cavities. I have not seen that there is any
significant dependence of the K-values, the scaled cavity sizes, on that
parameter.</p>

<p class="tab"><b>Carothers</b>: When the cavity reaches its
full growth, the belief is that the cavity pressure is determined by the
strength of the rock and the overburden pressure.</p>

<p class="tab"><b>Rambo</b>: Yes. I think you do have to add
the residual stress to the overburden pressure. But the cavity pressure is at
least overburden pressure. As far as the water goes, after full growth I don't
see a big difference in the cavity pressure, even though I've put more water in
the calculation. I do see some differences in the calculations, but not large
ones. There is a slight dependence, in some kinds of soils, where if there is a
lot of water, the water tends to lubricate it and make the material weaker.
Water can make a difference there. That's one effect that can certainly take
place. There is a tendency, in a soil-like material, to see that, but it's not strongly
connected to the cavity pressure itself.</p>

<p class="tab">But I will put in a
caveat - not every rock does that. There was some work done by Bob Terhune, in
which he went back into the calculations, and he said, "Look, we see the
strength phenomenon difference in the cavity radius, and we see it as to when
the residual stress sets up." He decided that it sort of made sense. So, he
looked at different areas. He looked at Area 20, and by and large it looked
like things set up differently there, in the sense that the cavity radii tend
to be smaller than in the valley. In a very hard rhyolite, like the rock the
Molbo event was fired in, where the drilling rates were low, there was a small
cavity radius. Then you get into something like Baneberry, where they measured
a very weak rock, and there was a fairly good size cavity radius. The
calculations show the same thing. So, I see tendencies in that direction.</p>

<p class="tab">There are still some
outliers that I can't explain, and that I don't understand. From time to time
you get something that's enormously large, or enormously small, in the relative
size of things. I've seen that kind of thing. Given that, I think there is a
trend through all of this that does follow the strength idea. But the data are
noisy, very noisy.</p>

<p class="tab"><b>Carothers</b>: Nort, more containment lore.
The cavity sizes at the Test Site are all about the same, scaled of course,
since all the rocks at the Test Site have 15% to 20% water, plus or minus a
bit. Would you agree with that?</p>

<p class="tab"><b>Rimer</b>: I don't believe that for a
minute. I know a lot of people believe that, but I don't believe that for a
minute. Most of the cavity measurements are from drillbacks into the lower half
of the cavity. They always take the radius measurement from some drill back
point to the old shot point. They don't account for cavity buoyancy, and even
elastic calculations will show the cavity moving up. An inelastic calculation
will show that the cavity may move up two, three, four feet; maybe even several
meters for a big shot, depending on how weak the rock is, just because of the
presence of the free surface. And for the bigger shots there's stronger
material below, so the upper hemisphere of the cavity is going to be quite a
bit larger than the smallest dimensions. Calculations have shown that. Of course,
nobody knows, because the cavities all collapse.</p>

<p class="tab"><b>Carothers</b>: There was one that didn't. That
was Salmon. The cavity was reentered, in the sense that they sent down TV
cameras, and there was a nice spherical cavity.</p>

<p class="tab"><b>Rimer</b>: You're right, but that was not
at the Test Site. It was at seven hundred eighty meters, in salt, but not salt
all the way to the free surface. And, they reentered nine months later. I spent
a lot of time calculating Salmon, and Gnome. It's clear to me that in the nine
months until they reentered Salmon that cavity wall creped in about five meters
in radius. I matched all the particle velocity records from that event, and the
calculations that matched them require about a 21 meter radius cavity. They
measured 16 or 17 meters. I do believe that Salmon creped in quite a bit. Now, it
was buried very deep; if it's less deep, there will be less creep. Evidence
from salt mines is that the open drifts want to creep back at you.</p>

<p class="tab"><b>Carothers</b>: Another cavity that was
reentered was Gnome, also in salt. It was not as uniform a medium, and not as
uniform a cavity either.</p>

<p class="tab"><b>Rimer</b>: The models that work for Salmon
work for Gnome. That was a layered salt, and that may explain the shape.</p>

<p class="tab"><b>Higgins</b>: After Rainier, and after we had
done other underground shots we found that we always got cavities with a radius
of fifty or so W to the 1I3rd feet. We thought, "Ah ha, all rocks are behaving
in the same way. It doesn't make any difference what's in them."</p>

<p class="tab">And then came some
information, first by very circuitous routes, and then directly, that the
French shots in granite in North Africa didn't make cavities with a radius of
fifty W to the 1 13rd feet. They only made three or four meter cavities, which
means a ten or twelve foot radius cavity for a kiloton. Well, that couldn't be,
so that information must be wrong. That was the first reaction.</p>

<p class="tab">Then we had a
symposium at Davis in 1964; I think it was called the Second Plowshare
Symposium. The French sent a very large delegation of physicists who were quite
willing to talk about some of the physical effects, as long as they thought it
was a one-on-one quid pro quo. They would tell us the cavity radius from some
shot, and then they would expect us to reciprocate. Well, the circumstances
were such we couldn't do that, so they stopped. But we did get some information
before that, and one of the things that was confirmed was that their cavities
were grossly different from what we had seen on the Hard Hat shot, which we had
fired in granite.</p>

<p class="tab"><b>Carothers</b>: How can that be? You had
determined that the rock doesn't really make any difference.</p>

<p class="tab"><b>Higgins</b>: That's what we thought. That
was the first clue, and we were not bright enough to tumble to it soon enough.
It should have told us that the conclusion we had come to about the rock didn't
make any difference was true because all of the rocks we were looking at were
mostly water. Even Gnome, which was shot in salt in '61, was four percent water
by weight, so when you put the sodium chloride and the other things into it, that
gives a material which is like twenty mole percent water. So, even the driest
thing we ever done a shot in was about one quarter water.</p>

<p class="tab">What was going on was
that the French were firing in the Hoggar massif, which is a block of granite
that's like tombstone granite. It doesn't have many cracks, it doesn't have any
pores, so there's almost no water there. It was less than a half of a percent, and
it probably was less than a tenth of a percent. So, in their case they really
did have a shot in material with no water - a dry granite.</p>

<p class="tab">The United States,
and this is an important point, because it affects the arms control talks, the
disarmament talks, the treaty negotiations, has never fired an event in any
material that isn't dominated by water. The seismic signal, all this business
about the geologic differences between the Nevada Test Site and the Soviet Siberian
platform, or Novya Zemlya, are trivial compared to the fact that they all have
water. Whether it's granite or tuff isn't important; what is different is the
transmission path. The French really did several shots in something that wasn't
wet, and only they have ever done that.</p>

<p class="tab"><b>Carothers</b>: John, have you done work on the
Hoggar shots? They are one body of experience of shooting in a very dry, very strong
rock, and the cavities there were small compared to the ones we normally see.</p>

<p class="tab"><b>Rambo</b>: I've done a little work on
that. My understanding is that the Hoggar granite is a rock that is like one
unit that has not been fractured. Or ifit is, the fractures are much farther
apart than they are in the granites we have. When we looked at our granites, the
fractures were on the order of a foot or so apart.</p>

<p class="tab">In our local NTS
geology, if you take a piece of granite and measure it in the laboratory, if
it's not fractured, you get a pretty hard rock. And yet, this material, in
bulk, is a weak rock, because of the fractures. And, it's certainly not going
to be helped any by the shockwave that goes through it. The two sites - the NTS
granite, and the Hoggar granite - give completely different answers in terms of
the cavity radii. If you shoot in something that's less fractured, then you
really are starting with a stronger rock, and you get a small cavity radius.
Compared to the laboratory data you have to degrade the strength of the rock by
almost a factor of ten, because of the rock fracture frequency. There has been
some work done in trying to get the strength from the fracture frequency. I did
calculations on one of the French shots, and I came up reasonably close to the
measured cavity radius.</p>

<p class="tab"><b>Carothers</b>: Nort, there's a set of granite
data, aside from Pile Driver, which you are probably familiar with, and that's
the French tests.</p>

<p class="tab"><b>Rimer</b>: Hoggar. Yes.</p>

<p class="tab"><b>Carothers</b>: The
difference from Pile Driver, as I understand it, is that the Hoggar granite is
very dry, and has a very low number of fractures in it.</p>

<p class="tab"><b>Rimer</b>: One every three to five feet,
compared to one every foot or so in Pile Driver.</p>

<p class="tab"><b>Carothers</b>: The other
thing about those shots is, presumably, that the cavity sizes were quite small
for the yields of the devices.</p>

<p class="tab"><b>Rimer</b>: I know. I spent a lot of time
on that. Actually, those cavities weren't that much smaller. If you assume that
rock is completely dry, you get a cavity radius which is roughly two-thirds the
cavity radius of Pile Driver.</p>

<p class="tab"><b>Carothers</b>: But that means their volumes
were less than one third of the cavities generally seen at the Test Site.</p>

<p class="tab"><b>Rimer</b>: That's true, and there were a
couple that were smaller. There are a lot of stories about the in-situ stresses
in that mountain, but I can't confirm them. They're not confirmable.</p>

<p class="tab">There is some sort of
phase reversal that came out of Hoggar, in seismic motion. It can be explained
by putting in in-situ shear stresses - in other words, the vertical stress
different from the horizontal stresses, in that rock. Steve Day, who was
S-Cubed for many years, and I did a lot of work, and a number of calculations, on
that, trying to explain that. We got some good answers, but I'm not totally
convinced, because if you accept the answers on the cavity size as being
because the material is dry, then the pulse widths would be very much smaller.
Therefore the displacements would be much smaller. The displacements that the
French have published are fairly consistent with the SRI data. They're further out,
and they're a little smaller than Perret's two measurements here, but they're
not as small as you would get from assuming a very dry, very strong material.
Also, the seismic ground motions aren't that much smaller, if we believe the
yields they have given us. So, I'm not convinced of the answer.</p>

<p class="tab"><b>Carothers</b>: Let me greatly oversimplify
this. There are the people who say, "That rock was very strong, and it is
the strength of the rock that really determines how large the cavity can
grow." Then there are the people who say, "That rock was very dry,
and therefore there was no steam, no gas pressure to push the cavity out."</p>

<p class="tab"><b>Rimer</b>: I don't like the cavity
pressure argument, because even if you accept that Pile Driver was fairly wet -
at most there was a couple of percent of water in there - the water would be
all in the pores. I'll buy the dry part as increasing the effective strength; I
won't buy it on the cavity pressure. There was just not enough water in Pile
Driver. Hoggar core samples were sent to Livermore at some time, and the actual
intact strength of that granite is very comparable to Pile Driver granite.</p>

<br>
<i>Cavity Shape</i>
<br><br>

<p class="tab">Presumably the shock wave that is
generated by the detonation starts out as a spherical wave, imparting the same
amount of energy per kilogram to all of the rock around the device. If the
world were homogeneous the rock should move out uniformly and radially, leaving
a spherical cavity. How good is that simple picture? Not very, it turns out.</p>

<br>

<p class="tab"><b>Carothers</b>: DNA has done some tunnel
reentries of one kind and another. What can you say about the cavities
themselves?</p>

<p class="tab"><b>Ristvet</b>: Well, we definitely know
they're not spherical. We find that they seem to be fairly symmetrical in the
equatorial radius when they're in virgin tuff, but they do snout down the grout
filled drifts. The cavities do grow preferentially in the directions of the LOS
drift and the bypass drift, which usually are where we have been tagging the
radius. Whether that's a function of the mismatch between the strength in the
grout and the strength on the tuff, or the high water content of the grouts so
they sort of popcorn back in, we don't know. Those are the two leading
candidates for an explanation .</p>

<p class="tab">We have two events
where we probed the bottom of the cavity in the conventional manner. I think
the one we did on Hunters Trophy confirms very definitely that the downward
growth is less than the equatorial growth. Out the back in the equatorial plane
the radius is closer to what the radius is below.</p>

<p class="tab">You would think,
based on block motion phenomenology, that the in-situ stress field would have
some sort of effect on cavity growth and create asymmetries. We don't see it in
the data, or it's in the noise. I think our measurements have shown that
gravity certainly has an influence on the cavity growth, and the calculations say
it should. Where the surface of the ground is does, definitely. We like to use
the equatorial cavity radius because that's the one of concern to us, and we
can actually walk up and physically put our hands on it. Well, we used to be
able to do that until the ES&amp;H of today. The "Low As Reasonably
Achievable" requirement makes it very difficult to do a reentry these
days.</p>

<p class="tab">I'm glad we did the
reentries we did when we did them. I think, without a doubt, that the reentries
on Misty Rain, and then the subsequent reentries on the shots that worked well
- Middle Note, Mission Cyber, Disko Elm, and Misty Echo -
told us more about how well we were doing at predicting the phenomenology that
we were trying to predict for containment than anything else. The Red Hot
reentry was invaluable; without it I'm not sure we would have ever done Misty
Echo.</p>

<p class="tab"><b>Patch</b>: The field folks have done a lot
of work to try to look at the shape of the cavity in the vicinity of the
stemming column, because that's where we potentially get unusual cavity shapes,
because it's not a homogeneous medium. We're trying to put something in the
tunnel there that fools the cavity into thinking it's still rock. How
successful we've been at that is something we're very interested in.</p>

<p class="tab"><b>Carothers</b>: Mr. Patch, DNA has never fired
in a homogeneous medium, and you know that.</p>

<p class="tab"><b>Patch</b>: Well, yes, that's true. But
when we take the tuff out of the mountain and put something else in, it's even
less homogeneous than it was. I would say that a lot of our interest in cavity shapes
has been with respect to how they've interacted with the stemming. I think
that, by and large, we've found that we tend to get preferential cavity growth
in the direction of the stemming column. We do perturb things, and we'd like to
understand why that is, and we'd like to know how to perturb them less than we evidently
do.</p>

<p class="tab"><b>Carothers</b>: John, presumably the cavity
grows in a more or less spherical fashion. Or, at least it does in the
calculations. Do you think the cavities are spherical?</p>

<p class="tab"><b>Rambo</b>: There was a shot called Clymer,
which had a large opening above the device. We had three satellite holes with
slifers in them, and I could track across those satellite holes and see how far
that perturbation went off to the side. It was the first time we had ever
actually looked at the shape of the shockwave changing with distance. That
became a basis for understanding, or questioning, this idea about a spherical
shockwave. It was an actual measurement to base that question on. It was the
only time that had ever been done; actually showing the shape of the shockwave.</p>

<p class="tab"><b>Carothers</b>: Did those measurements show
that the cavity, as it was growing, was not spherical?</p>

<p class="tab"><b>Rambo</b>: Yes, but that means that the
energy, if it had gone up a line-of-sight pipe for a certain distance, was
actually forming its own cavity at that point. Now, I've been biased by
calculations I've done in past years where we've shown that things starting in
that kind of configuration tend to get relatively spherical with time. But in
the early stages, those cavities are not spherical.</p>

<p class="tab"><b>Carothers</b>: In the case you're describing I
would think of it as looking more like a teardrop.</p>

<p class="tab"><b>Rambo</b>: A teardrop, or a bottle shape.
Usually these shapes are fairly weak in terms of what stress waves start out
from some opening away from the device, and the main body of the stress down below
tends to overwhelm them at later times.</p>

<p class="tab"><b>Carothers</b>: Bob Brownlee used to be in the
business of what LASL called hydro-yield. On Bilby, which was a shot of about
250 kilotons in Yucca Flat, he had three instrument holes. The working point
was fairly close to the Paleozoics. He has said that he could see from the
signals in those three holes that the cavity was not spherical; it had to have
been teardrop shaped to match his data. The shot point was close to the
Paleozoics, so it didn't grow down much, and it tended to grow up more. That
kind of a model gave a reasonable fit to his data, but a spherical cavity
didn't.</p>

<p class="tab"><b>Rambo</b>: I would probably interpret it
differently. You do occasionally run into weaker rock, in the tuffs, that tends
to move a little bit faster, but not for terribly long. I would say it had to
do with the material properties, particularly strength, which can make a big
difference to the growth of the cavity. If there is strong rock below, and
weaker rocks above, it can grow more in the upward direction.</p>

<p class="tab">I believe the
material properties could make a big difference, but I don't hold to the idea
that the cavity is going to, by its pressure, cause this change in how the
growth is going to occur. Some people think the cavity is being driven by
cavity pressure at late times, and I don't subscribe to that. I think it's
really the strength and material properties of the rocks that can cause a funny
shaped cavity. Those same properties can also affect the arrival times of the
shock. Some properties may cause early arrivals in the shockwaves, but yet may
retard cavity growth. But I certainly can believe a teardrop sort of cavity for
a shot near the Paleozoics.</p>

<br>
<i>Cavity Pressure</i>
<br><br>

<p class="tab">Something which affects leakage
through the stemming and the cables, and the possibility of hydro fracturing
through the native material is the the cavity pressure, and its variation with
time. One body of work, where pressures were measured on high explosive experiments
in the tuffs of G tunnel was done by Carl Smith. For nuclear events, Billy
Hudson developed a method of measuring the pressure in the fully formed cavity.</p>

<br>

<p class="tab"><b>Smith</b>: An important thing we could do
on the high explosive experiments, which is much more difficult and expensive
to do on a nuclear experiment, was to mine back to find out what went wrong with
some measurement. We dug back in, recovered all the gauges, saw how good our
grout jobs were, and we learned from all those things. For instance, there was
a shot where we were trying to measure the cavity pressure. The pressure came
down, and settled at about seven thousand psi. We thought that was a wonderful measurement,
but when we mined back in we found that the pipe was plugged. So, we knew the
cavity came down to seven thousand psi, and leaked down from there, but the
ground shock had jammed the pipe closed, and so we didn't see that.</p>

<p class="tab">That was confirmed on
subsequent shots of that size where we measured significantly lower cavity
pressures. A tamped eight pound shot will generate about eight thousand psi of
pressure. As you go to larger and larger sizes of HE the pressures drop
significantly. A sixty-four pound shot will develop about forty-six hundred
psi. Thousand pound shots only developed about twenty-five hundred psi. We
believe that's a rate effect in how the material responds, and how rapidly it
responds.</p>

<p class="tab"><b>Carothers</b>: And when you go to kilotons?</p>

<p class="tab"><b>Smith</b>: You generate just over in-situ pressure.</p>

<p class="tab"><b>Carothers</b>: Billy, you have measured
pressures in some of the nuclear cavities, have you not?</p>

<p class="tab"><b>Hudson</b>: I would claim that our
experiments were the first to measure cavity pressure on nuclear shots through
any significant fraction of the entire history. In the fairly distant past
people tried to measure cavity pressure in conjunction with some other
measurement, or some other experiment. As a result it was sort of a catch-as-catch-can
measurement. In particular, they tried to measure gas in tubes that were designed
to withdraw samples from the cavity. Usually those measurements involved flow
from the cavity into the tube they were trying to make the measurement in.
Usually that tube plugged. In fact, almost all you had to do was call the
system a gas sampling system to be sure nothing came out.</p>

<p class="tab">There's more than one
problem with that approach. You have a real problem if the tube plugs. Even if
it doesn't, if you try to measure the gas pressure at the end of a long tube
you have a problem because you're never in thermodynamic equilibrium. If you
have a hot gas, maybe with water vapor in it, flowing in one end of a long
tube, it condenses and cools, and by the time it gets to the other end the
pressure is quite different from what it was at the opening.</p>

<p class="tab">We reasoned that the
best way to make a pressure measurement would be to always have a very small
amount of flow toward the cavity. If you measure the pressure at the source of
flow, near your instrumentation package, and the flow is quite small, you could
argue that the flow at the instrumentation package is essentially the same as
the flow at the end by the cavity, and the pressures are essentially the same.
The tube shouldn't plug if the flow is always toward the cavity, and maybe you
could get a pressure measurement that way.</p>

<p class="tab">And so, that's what
we did. We filled the tube with fluid so we wouldn't have the thermodynamic
equilibrium problem you have with a gas. In the first experiments we actually
blew the fluid out of the tube, with high pressure, so we knew we had
established a flow and we would hopefully stop the cavity growth process from plugging
the tube. That worked very well, in that we got some data that at least looked
as we expected it to look. We might not have been in direct communication with
the cavity, but we were probably fairly close.</p>

<p class="tab">We tried the same
experiment several times after that. I think we've done it successfully five or
six times now. We've varied things a fair amount. For example, we've stopped
blowing the fluid out with high pressure gas. That doesn't seem to be
necessary, and it slows the response time. Not doing that also makes the
experiment a lot less expensive. It costs a lot of money to have high pressure gas
systems around, because they can explode and hurt people. If it's a high
pressure liquid system, there's not much energy involved, and it's not nearly
as much of a safety problem.</p>

<p class="tab">The first time we
tried was on a DNA shot, and for a reason we don't understand, it didn't work.
Probably it was fault motion severing the lines, or something. The first
successful one was on a Livermore shot, and after that the DNA people were very
anxious to have us try it on another of their shots. Fortunately, that one worked
very well. Since then we have had another DNA experiment which looked
successful, and three or four Livermore events where the data looked very good.</p>

<p class="tab">We've made enough
measurements, and we have enough data now that we really think that system
works to get cavity pressure. But if that's true, we still don't know why the
history from one event to the next seems to vary so widely. So there are still
a lot of questions to be answered with regard to cavity pressure.</p>

<p class="tab"><b>Carothers</b>: You describe the data as
varying widely from shot to shot. What does the pressure history look like? There
is the containment lore from the fifties and sixties that the cavity expands until
the cavity pressure is about equal to overburden pressure, and then it
gradually decays through various cooling processes. Do you see anything like
that?</p>

<p class="tab"><b>Hudson</b>: What we think is happening is
that there is a sort of a plateau pressure, a constant pressure that is
established after cavity growth, which then stays fairly constant for a while,
probably due to ablation, mass addition, and so on. The energy per unit volume
probably stays constant as long as nothing is leaking out.</p>

<p class="tab"><b>Carothers</b>: When you say it stays constant
for a while, how long is that? Seconds, minutes, hours?</p>

<p class="tab"><b>Hudson</b>: That's one of the things that
varies. On some events it's been minutes. On Cornucopia, on the other hand, it
was more like hours. The period during which the pressure is more or less constant
varies considerably. And, the plateau pressure itself varies considerably.
We've seen it both well below and well above what we thought the overburden
pressure was. We don't have a model yet.</p>

<p class="tab"><b>Carothers</b>: Perhaps the reason you don't
have a model is because there is no good model of cavity growth, in the
following sense. Cavities that have been reentered are not spherical. They are
not the shape that you see on viewgraphs where the predicted cavity has been
drawn with a compass. Cavities are lumpy, and some of them are sort of flat,
and so on. On Rainier they did a lot of postshot reentry work, and there was a
very lumpy looking cavity. And so was the Gnome cavity. Maybe you don't know
what the cavity volume and shape is on the various shots.</p>

<p class="tab"><b>Hudson</b>: That may be the answer. The
surface to volume ratio may be important. And as you suggest, the contour of
the surface may be such that on some events you may have a much greater surface
to volume ratio than on others, and consequently you have different cooling
phenomena. I don't know.</p>

<p class="tab">I think the reason
it's so interesting, and puzzling at the same time, is that cavity growth and
cavity pressure are the source function for the gas we're trying to contain.
Yet for decades we basically have ignored this part of the problem, in terms of
modeling. We've made very little progress. We have very little new information,
because we've made only feeble attempts to get new information concerning
cavity growth and cavity pressure.</p>

<p class="tab"><b>Carothers</b>: Well, cavities are different,
and perhaps that's why your results are different from shot to shot. How
different? Shape, almost certainly. As you said, surface to volume ratio. And
then there are people who say that as the cavity is growing the material is
moving out radially, and stretching tangentially, the pressure is high, and
during that time many hydrofractures are driven out from the cavity. They don't
extend a long way, a couple of cavity radii or so at most. But that exposes a
large surface of cold rock, and that cools down the cavity, dropping the
pressure. A person coming from that point of view might say that the rocks in
different places have different fracture susceptibilities, and so, different
energy loss histories. And therefore, different pressure histories.</p>

<p class="tab"><b>Hudson</b>: That might very well be.</p>

<br>
<i>Cavity Temperature</i>
<br><br>

<p class="tab">The temperature of the cavity
starts at a very high value, a million degrees or so, but it drops very rapidly
as the cavity expands. The only real information on the temperature and its
time history is derived from examining the detonation products that are separated
at different times from the main body of the material in the cavity.</p>

<br>

<p class="tab"><b>Higgins</b>: At the very high temperatures
very near the explosion the transport of energy is very rapid. In other words,
after the shock has gone by the particle velocities are high enough that there
is rapid communication of temperature and pressure between the center of the
expanding gas and its more outward regions. That goes on for some fair part of
the first part of the cavity growth. So, the temperature in the cavity gas goes
down to some temperature that is considerably less than the electron volt, or
the ten thousand degrees, that many of the calculators are fond of putting on
their pressure versus time charts.</p>

<p class="tab">I feel that's a
misleading kind of calculation. All of the evidence from the cavity
radiochemistry - from the fractionation of the various radiochemical species in
recovered products - points to the fact that the temperature in the cavity, by
the time the rebound occurs, which is, let's say, in the time between
milliseconds and seconds, has decreased to the point where it's not much above the
melting point of the rock. It's certainly below the point where there's any
rock vapor left.</p>

<p class="tab">That's important,
because it fixes the maximum threat. The dynamic phase is going on as the shock
wave passes out and leaves this hot stuff behind. The rebound comes back, and
that happens within a few hundred milliseconds. Because of the rapid exchange of
energy in the cavity up to that time, things have cooled until it's pretty much
in equilibrium; the energy is distributed throughout everything that's within
that cavity radius. My argument has been that the initial temperature, for
calculations, can't be much different than the vaporization temperature of the
rock. If it were higher more rock would vaporize until it did reach the
temperature of vaporization.</p>

<p class="tab"><b>Carothers</b>: That seems to be a reasonable argument.</p>

<p class="tab"><b>Higgins</b>: But it's hard for people who do
one-dimensional calculations to accept, because the inside zone in their
calculations is always at ten electron volts, which is a hundred thousand
degrees, after the cavity expands. The reason it doesn't stay that way is that anything
that is at ten electron volts is very reactive. It's going to go out and heat
up the next thing that's nine electron volts, or one electron volt, and that
time is short compared to a few hundred milliseconds.</p>

<p class="tab">The difficulty with
this whole discussion, from a physics standpoint, is that energy transport in
this region of, say, two-tenths of an electron volt, or three-tenths of an
electron volt, is something no one wants to deal with. The times, the
opacities, the reactions that are going on as things recombine, and you get
ionized states, and sometimes molecules that are two or three electrons
deficient are all things that are not easily calculable. In fact, they are
pretty much, as a general rule, unknown. So, nobody wants to calculate it
because nobody likes to work on a problem that doesn't have a nice solution.
Scientists don't like non-solutions.</p>

<p class="tab">I believe that all of
the evidence points to the fact that by two hundred milliseconds, or even one
hundred more likely, the cavity has cooled to about two thousand degrees
Kelvin. As the cavity is cooling down, the pressure is dropping, and so
everything is cool enough that the cavity gases don't have enough pressure to
drive fractures .</p>

<p class="tab">There is one more
phase. The wall of the cavity has a huge temperature gradient in it, and I
believe that what happens is that the water in the rockock volatilizes and pops
pieces of the rockback into the cavity, causing further cooling down. The
pop-back is where the water that is caught in the pores turns to steam and expands.
Water going from water at one cubic centimeter per gram goes to twenty cubic
centimeters per gram if it goes from three hundred degrees Kelvin to four
hundred degrees Kelvin. And that's considerably below the two thousand degrees
that might be only a few centimeters away. So, I believe that there is a period
of exfoliation that's quite rapid, occurring after the first hundred or so milliseconds,
but before a second.</p>

<p class="tab">The pressure doesn't
change much, because you're adding more mass and more molecules. The
temperature goes down because you're taking energy out of the molecules in the
cavity and warming the incoming material until it's in equilibrium. The glass has
fallen to the bottom of the cavity, together with a lot of rubble, and it's now
at about the melting point of the rock, between about eight hundred and a
thousand degrees centigrade. And that is the cavity we explore when we go back
in and drill or mine.</p>

<p class="tab">Sometime a lot later,
and it is an unstable thing, the roof of the cavity just falls in. It might
even start to fall in when that first pop-off of the water vapor in the water
pores occurs. I f the rebound has been strong enough so there is an arch
formed, then it will stay there for a while, whether an hour or a day, I don't
know. If that arch is not very strong, especially in alluvium, I think the
blow-off of the popcorn might very well start the chimney. If it's real close
to the surface, that's what happens. And that's why we see, in certain other
kinds of special circumstances, where you have reflecting surfaces nearby, very
early collapse, in a few minutes. Those are the cases where the cavity collapse
is initiated by the blow-off of the water in the cavity walls, and those are
really dangerous, because the pressure is still fairly high.</p>

<br>
<i>Where Does All That Material Go?</i>
<br><br>

<p class="tab"><b>Carothers</b>: John, when a detonation occurs,
a big cavity forms. What happened to all the material that used to be in the
cavity?</p>

<p class="tab"><b>Rambo</b>: In our calculations it's
displaced outward. We see positive outward displacement. So, you've taken this
volume and you've distributed it. If the material has porosity in it, which it usually
does, some of the volume is taken up in crushing that out. Although, when I run
a completely saturated calculation I still get a cavity of about the same size.
The calculations tend to show some positive displacement everywhere. The
material has to be either compressed, or move out. I think the outward motion
is mostly where it goes, instead of in crushing the material. And, the surface can
move up just a little. There are some cases, though, where it looks as though
you're moving out material to make the cavity, and then the surface is lower
too. So, yes, where does all that material go?</p>

<p class="tab">There was a shot we
fired, called Carpetbag. From the gauges, the surface was displaced down,
compared to where it was before the shot. That's always been a mystery. I tried
to deal with that, and I was unable to get the gauges to match the big negative
displacement fairly close to the cavity. I didn't see that in the calculations.
Another thing that happened on Carpetbag is that the surface kept sinking for
many months after the shot. It was quite an interesting phenomenon. I don't
think we've seen anything quite like that in other areas.</p>

<p class="tab">Carpetbag was below
the water table, and so the material was wet. I think the material must have
been a matrix which was quite wet and quite weak, and that just the slightest
hit from anything would have let that matrix rearrange, and relieve that whole area.</p>

<p class="tab"><b>Carothers</b>: Dan, where do you think all the
material that was in the cavity goes? Cavities are pretty large. Even for a
kiloton or so you could put this building in the cavity.</p>

<p class="tab"><b>Patch</b>: Let me say where it doesn't
seem to go. One can easily imagine what you do when you grow the cavity is
basically to crush the rock out to some radius. That seems to be a reasonable
picture for something that's got a lot of air voids in it; dry alluvium, or something
of that sort. But, our experience in wet tuff is that if you go in and take
samples post-shot it's very hard to see that you have what I will call a
completely compacted region, even quite close to the shot .</p>

<p class="tab">Now, we have seen,
certainly on some events, where it looks like you're getting this air void
back. Preshot you have a one percent air void. Post-shot you get these samples
out and you measure them, and they still have one percent air voids. You ask
yourself, "How can this be?" It's a very strange thing to have
happen. But if you look at the details of the crush curve, you'll see that this
one percent air void only takes a little load to crush it out.</p>

<p class="tab">Terra Tek has done
some beautiful work where they've looked with this technique of injecting metal
into the open pore space, and then etching the sample and looking at it with a
laser. It's very interesting work, and you can see that what has happened to
the rock is that the stresses have generated lots and lots of very fine fractures,
so when you take the sample out of the ground there's a tendency for these little
fractures to open up a little. It doesn't have to be much to get the one
percent back, although that's a different kind of air void. So I think the rock
actually does take up some of the cavity volume, but it's darn hard to prove
from the data.</p>

<p class="tab">I don't think anybody
can conclusively say, "Yes, see, this rock used to be one percent air
voids, and now it's smashed." But we do have suggestions that there is
some cavity growth that is accommodated by the crushing of the material. I
think what you basically do is you deform the material around the cavity, and
because of the r-cubed effect it turns out once you get a little ways away from
the cavity you're talking about a very small amount of deformation over an
enormous amount of material. The cavity has a lot of volume, but how much more
volume do you have when you go out three or four cavity radii.</p>

<p class="tab">Following the Rainier
event there were extensive reentry observations made. From observations made in
early 1961 Ross Wadman and Bill Richards (UCRL 6586, July 1961, Postshot Geologic
Studies of Excavations Below Rainier Ground Zero) made this comment:
"Block movement rather than rock compression accounts for the rock
displaced from the cavity. The rock moved radially away from ground zero along
shock produced shears that, in many cases, were strongly influenced by preshot
zones of weakness. The lithologic rock units, below the' cavity have been thinned
and depressed but not appreciably distorted or mixed.</p>

<br>
<i>Rock Melt and Non-Condensable Gases</i>
<br><br>

<p class="tab"><b>Carothers</b>: A kiloton of rock melted per
kiloton of yield is a number often mentioned, but there are other numbers used
sometimes. How much rock does get melted, and how do we know that?</p>

<p class="tab"><b>Higgins</b>: Well, the question of how much
rock gets melted is an awfully good one, and the how do we know is an also good
question. The methodology was, and is, to take a piece of rock that was melted
by the detonation, do chemistry on it, and determine what fraction of some
chemical species that is unique to the explosion is found in that piece of
rock. Then you presume that fraction represents the fraction of the total
melted rock, of which you have a little piece.</p>

<p class="tab"><b>Carothers</b>: So, if I have a piece of the
solidified melt that weighs ten pounds, and I find a millionth of some
device-produced isotope in there I say, "There must have been a million
times ten pounds of melted rock."</p>

<p class="tab"><b>Higgins</b>: Right.</p>

<p class="tab"><b>Carothers</b>: Isn't that rather presumptuous
of you chemists, to make such a large extrapolation?</p>

<p class="tab"><b>Higgins</b>: Well, yes, it is rather
presumptuous, but after doing literally hundreds of samples we have found that
the answer each one of those hundreds of samples gives is essentially the same.
But not always, which is why I said that it is a very good question. It is still
an open question. However, there was a time when everyone thought they knew
that answer precisely.</p>

<p class="tab"><b>Carothers</b>: To know something precisely is
to calculate it. An experimentalist never knows anything precisely.</p>

<p class="tab"><b>Higgins</b>: It's almost that bad. From the
earliest samples there were definitions people tried to follow. There were
several kinds of melted rock recovered, and one of them was called "puddle
glass." Puddle glass was defined as being a non-vesicular, black, shiny, glassy
material.</p>

<p class="tab">From the first few
hundred samples it was found that the numbers one obtained for puddle glass per
kiloton were remarkably consistent, and constant at about eight hundred tons of
puddle glass per kiloton of fission. Or, if you wanted to be more approximate, a
kiloton for a kiloton of yield.</p>

<p class="tab">The other kinds of
glass that were found, which were called variously chimney glass or frothy
samples, gave numbers which were more scattered. In the range that I've seen
they were from about two hundred tons per kiloton as the very smallest number,
up to as much as three thousand tons per kiloton. And I would guess that even
larger numbers could be measured if you took a chunk of rock that you could not
visually identify as glassy melt, and analyzed it by that same technique.</p>

<p class="tab"><b>Carothers</b>: When you talk about determining
the amount of melt by taking a very small sample, determining what you believe
to be a fraction of some isotope that was produced, and then multiplying that
small sample mass by the supposed total amount of that isotope, you're doing
the same kind of thing you do with cloud sampling on atmospheric shots. You're
making the assumption that things have been homogeneously mixed, and that
you've got a representative sample.</p>

<p class="tab"><b>Higgins</b>: That's right. And the only
proof of whether that is true or not true is from internal tests. One such
internal test is to look for a fraction of the fissile material, for example,
as compared to the fraction of an external tracer, and look at the variability
of one to the other in the same set of samples. If they're widely different,
then we could guess that none of the isotopes are representative of the total.</p>

<p class="tab"><b>Carothers</b>: The process is similar to what
you do in atmospheric cloud sampling, but it must be a harder problem. When you
sample a cloud after an atmospheric detonation, you're only trying to determine
the bomb fraction; you're not trying to determine the size of the cloud. Here
you're trying to determine the size of the cloud, as it were.</p>

<p class="tab"><b>Higgins</b>: Yes. But while the numbers
weren't published often, we also determined the size of the cloud in atmospheric
testing. And, a rather surprising number is that a kiloton of lofted material per
kiloton of yield is valid for an atmospheric burst, as long as the fireball
touches the ground. That was an astounding discovery.</p>

<p class="tab"><b>Carothers</b>: You're beginning to sound as
though a kiloton per kiloton is a magical number.</p>

<p class="tab"><b>Higgins</b>: Yes, it almost sounds that way.</p>

<p class="tab">In the beginning of
underground testing we used symmetrically placed tracers in the ground zero
room. We put them at the corners of a cube, or perhaps an even more ordered
symmetry than that. We put them at points representing the faces and corners of
a cubic array, for example. We found there were exceptions to perfect mixing
for very small yields. But at about one or two kilotons and above, it really
didn't make any difference if we put in six tracers, or one, or four. We got
essentially uniform mixing.</p>

<p class="tab">The implication of
all that is, there is a mixing of vaporized material in the early cavity, while
it's growing. The particle velocities are very high, and the particles in the
growing cavity make many, many transits across the gaseous region before it
stabilizes and starts to condense. If that weren't true, putting a tracer on
two sides of the device would give different results in the two directions in
the final cavity, and that was never seen on larger yields. On very small
yields we did find pronounced asymmetries.</p>

<p class="tab">During the 1960's we
did experiments where we had open holes below the device, to try to separate
the radioactive debris from the center of energy. We even built rather
unsophisticated reflectors, and those were successful to a degree. But if you
think about it a little bit, if you deflect all these very hot fission
products, they are hot enough to interact with their surroundings and cause new
gas to be formed, which then mixes back in the direction the fission products
came from.</p>

<p class="tab">In one experiment we
put several hundred grams of U233 in the bottom of a hole which was open to
about two hundred feet below the device. In the glassy material that was recovered
we looked for just the presence of U233. What we found was as large a fraction
of the U233, which was two hundred feet from the device, as of the device
material itself. So, the 233 bounced out of the bottom of the hole, back up the
hole, and mixed with all the gaseous material pretty uniformly. While we got a
big fraction of the total radioactivity directed down the hole, what was in the
bottom of the hole mixed very well with those things that were where the device
went off.</p>

<p class="tab">What was implicit in
the results of those experiments was that the glass was a consequence of a
multistage set of vaporizations. That is, the initial device energy vaporized
material, and the shock wave generated from that vaporized material continued
to form more vapor outside of that region. So, simply directing the first vapor
down the hole didn't do anything at all about the material that was being
generated by the expanding shock wave. Very crudely, what those experiments
showed was that the vapor first formed was about seventy or eighty tons per
kiloton, and that the additional melting and vaporization made up the other
eight hundred or nine hundred that we observed from the total sample later on.
The surprise, I think, was that such a small fraction of what was finally melted
and vaporized was produced by the device itself. It was about one tenth, or a
little less.</p>

<p class="tab"><b>Carothers</b>: The cavity is growing, and
there's some vapor in there; pretty dense, but vaporized material. You are
saying that to the particles it is a thin vapor; the mean free paths are long.
It's diffuse enough that the particles can move freely through it.</p>

<p class="tab"><b>Higgins</b>: The conclusion is correct, but
to think of it as being very thin is probably not correct. A better way to
think of it is as an extremely hot region where the particle velocities
initially are very high - like eighty centimeters per microsecond.</p>

<p class="tab"><b>Carothers</b>: And everything is highly
ionized. Since the atomic scattering cross sections are large compared to
nuclear scattering, if you strip the atoms of most of their electrons the mean
free paths becomes quite long.</p>

<p class="tab"><b>Higgins</b>: That's precisely correct. You
have particle velocities approaching many tens of centimeters per microsecond.
The vapor density, including atoms and electrons, is grams per cubic
centimeter, or some significant fraction of that, but with such high velocities
the transit time for any sensible number of meters is not long. The expansion
time of the cavity, whether it's from a kiloton or a hundred kilotons, is in
the order of a fraction of a second up to, for the very largest yields, a
second. So, when the particles are going many centimeters per microsecond you
have time for a lot of transits across the cavity, and bouncing around, and
scattering, and normalizations of the various regions with each other.</p>

<p class="tab"><b>Carothers</b>: If you keep getting consistent
numbers from the puddle glass, that also would imply that it doesn't matter
much what the original material was; tuff, or alluvium, or basalt, or whatever.</p>

<p class="tab"><b>Higgins</b>: Yes. That was the early
conclusion, and the early experiments verified that, in a way. Our first
experiments in granite, which were Hard Hat and Pile Driver, produced slightly
less melt, but not so much so that one would say it was a different mechanism.
I believe, in retrospect, and now that we've looked at material from a lot more
sites in the tuff and alluvium, that those were spuriously obtained results. It
really isn't true in general that the same amount of rock is melted per kiloton
at different sites. That was an accident of the composition of the materials.
Ted Butkovitch and several other people have more carefully measured some of
these same numbers. They add the so-called puddle glass to all of the other
glass and ask “How much was heated above some temperature?" The usual
temperature they use is a thousand degrees centigrade. And they find that
number varies with porosity and water content.</p>

<p class="tab"><b>Carothers</b>: The more water, with its high
specific heat, the less melt?</p>

<p class="tab"><b>Higgins</b>: No, it goes the other way. The
more water, the more molten material there is. The reason that's true is that
water and almost any silicate rock or compound form eutectics that have melting
points that are sharply less than the melting points of the pure rock.</p>

<p class="tab">In our initial work
we'd always go to the laboratory and carefully dry the samples. Then we would
measure all of the things like melting points, and vaporization temperatures,
and so on. That turns out to be a gross mistake. We discovered the hard way
that when you're dealing with the earth's materials, water is an intrinsic part
of the system. To remove it distorts all of the results from that point
forward.</p>

<p class="tab">There were things
that people had worked on for a long time that were changed and amplified by
the work at the Test Site. I don't mean that we've been that remarkable in our
science in underground testing, but it really wasn't until we began to look at the
molten rock formed by nuclear explosions that volcanologists examined their
numbers to determine what temperatures existed in the earth to form lava. Prior
to the underground tests the volcanologists did the same thing we did. They
dried out their lava samples, and said, "This lava came out of the ground
at fifteen hundred centigrade." Then, when they went and looked at the volcano,
what was coming out of the ground was coming out at nine hundred degrees
centigrade. And they found some lavas, in western Colorado, that indicated six
hundred degrees centigrade. How in the world did those volcanos produce that
molten rock at six hundred degrees when everybody knows volcanos start out at fifteen
hundred?</p>

<p class="tab">So, there were
elaborate theories about secondary melting producing two or three times more
lava than the primary vent produced, and that meant you really had to reduce
the measured volcanic flows two, or three, or four-fold, because what you saw really
wasn't the amount that came out of the volcano itself. The theory was that what
was produced was really a lot less than what you saw, but it was so hot that it
melted a lot of other rock. There were a lot of things like that floating
around in the literature.</p>

<p class="tab">Now, the tuff at the
Test Site came out of a volcano. And when it came out, it came out as a solid,
even though a pretty hot solid. Some of it came out as a liquid, but not very much.
But water condensed into this hot solid almost immediately, and then it melts at
around eight hundred or nine hundred degrees centigrade. If you take the water
out of it, it melts at fifteen hundred or so. We were extremely puzzled by that
until we began to do some experiments at modest pressures, keeping some of the
water in it. And lo and behold, the more water that was in it, the lower the
melting point. And, of course, the lower the melting point the less energy it
takes to heat it to melting.</p>

<p class="tab">The point is that the
amount of melt is very much dependent on the amount of water that is present -
the more water there is, the more melt, and the less water, the less melt. So,
when we said there was the same amount of melt from granite and tuff, we were looking
at only that portion of the tuff melt that made puddle glass, and comparing it
with the total melt from granite, where all of the melt was essentially puddle
glass. They turned out to be very close to the same amount, but that was a
fortuitous accident. The total melt from a a detonation in tuff, we now know,
varies with water content, and it goes from a low of about a thousand tons per
kiloton up to about three thousand. Somewhere in that factor of three, all of
the experiments that we've looked at fall.</p>

<p class="tab"><b>Carothers</b>: How could it get to be as big
as three thousand tons per kiloton?</p>

<p class="tab"><b>Higgins</b>: By the inclusion of all of the
secondary melted rock. And there's another thing to remember; the rock vapor
that's initially produced is much hotter than the vaporization point of the rock.
Much hotter. So, a little of that rock vapor can go onto a cold rock and
vaporize it too, and still the total is maybe right at the vaporization point.
The heat capacity per unit mass of rock vapor is not very different than the heat
capacity of the solid rock itself. Slightly less, but very slightly less. So,
if you have a gram of rock vapor that's three thousand degrees above the
vaporization point, it can very happily vaporize two more grams of rock, and
you'll end up with three grams at the vaporization point. That mechanism probably
accounts for a lot of the molten material we see post-shot; the secondary
vaporization and melting.</p>

<p class="tab"><b>Carothers</b>: The material you find in fractures?</p>

<p class="tab"><b>Higgins</b>: Yes, or even in the puddle
glass. The way we get the occasional sample of the initial rock that's
vaporized by the shot is from the material that's frozen out in fractures. When
it goes into a fracture it is essentially frozen instantly. Something that
gives us information about this comes from the tunnel line-of-sight shots. When
the pipe closure fails drastically, a little tiny fraction, a solid angle's
worth if you like, of that initial vapor gets directed out a very long
distance. We've occasionally, unfortunately, seen that happen. It cools off,
and it has so little total energy that it can't cause any more melt. When you
work back, it always turns out to be between seventy, eighty, or ninety tons
per kiloton. That does kind of prove these speculations that are done from
calculations, and thermodynamics, and some other arguments are correct.</p>

<p class="tab"><b>Carothers</b>: When you say seventy, or
eighty, or ninety tons per kiloton, you mean that's the initial amount of vapor
that's produced directly from the device itself?</p>

<p class="tab"><b>Higgins</b>: Right. That's the initial rock
vapor. Of course, the device doesn't really make much contribution to that
mass. In the early days we used to say that we could approximate the device by putting
a ton of iron where the device was, and that was a good approximation. If you
mix in all of the construction materials and the canister in with the device,
that's about a ton. And if you mix the molecular weights, starting with
ninety-two for uranium and one for hydrogen, iron is about right. It's sort of
the geometric mean of everything that's around.</p>

<p class="tab"><b>Carothers</b>: We have talked about the amount
of rock that is melted per kiloton. When that is melted, how much carbon
dioxide is produced?</p>

<p class="tab"><b>Higgins</b>: Well, that is part, but just
part, of the problem of non-condensable gases produced by the explosion. Carbon
dioxide is sort of the generic name for the non-condensable gases produced. It's
clear there are quite a few of them, and the reason they are important is that
when we say that we can contain the explosion, we really mean that we can
contain the gases that carryall the various radioactive materials.</p>

<p class="tab">First, there are the
vaporized rock gases. They condenses really rapidly because they go from vapor
to liquid at three thousand centigrade or so, and there's a lot of cold rock
around, so those vapors don't go very far. The next least condensable thing is
water, and steam can go a little bit further than the rock vapors. When, on the
rare occasion the steam gets out it's pretty catastrophic, and it's very
spectacular. Those events are very distressing to the containment people. There
are tons and tons and tons of steam present in the cavity prior to its
condensation to water. If it finds a path out it can carry large numbers of
curies, usually on the order of a hundred thousand curies of radioactive
material per kiloton, out with it.</p>

<p class="tab">That is sort of the
last violent level of non-condensable gases. Below that, on a scale of colder
and colder condensation, there are carbon dioxide, and methane, and hydrogen,
and other permanent gases at room temperature, that are produced by the thermal
decomposition of things that surround the explosion. On some of the early tests
we observed that the test would be contained, including the rock vapor and the
steam, but that on surface collapse, or on a time scale of a few tens of
minutes, or hours, following detonation there would be clouds of radioactive
gas rolling around the region of the shot. They were invisible, but they
carried what turned out to be a large numbers of curies of radioactive gases.</p>

<p class="tab">Now, fortunately, in
all the cases that were documented, those gases were noble gases, and they are
biologically inert. There was great concern at the time that they might contain
radioactive iodine, but in spite of intensive efforts no great amount of iodine
was ever found in those gases.</p>

<p class="tab"><b>Carothers</b>: You'd think there could be.
There's the iodine-xenon link .</p>

<p class="tab"><b>Higgins</b>: Yes, and there's lots of xenon,
but almost no iodine. It's a fortunate fact of the decay sequences that it
happens that way.</p>

<p class="tab">When we examine those
unfortunate experiments, and look for reasons for that radioactive gas, there
was first the association of certain areas of the Test Site with that
phenomenon. The next step was, what is different about those areas of the Test
Site? It was found, number one, that the bad experiments always occurred in the
alluvium, and not in the tuff. Number two, they always, almost, occurred in
regions where the alluvial material contained large amounts of Paleozoic
carbonate gravel. And the worst ones were from Area 5, which means the Frenchman
Flatside of the pass when you go out to the CP. There were others, from the far
north end of Yucca Valley; Area 2, Area 10, and to a lesser degree, Area 8. In
examining those, the presence of carbonate rocks was observed.</p>

<p class="tab">The carbonate
decomposes at high temperatures, and produces carbon dioxide, which then
displaces the gas that's in the pores in the rock, as in a sponge, and pushes
that out of the way. As soon as it pushes all of the gas out of the way all the
way to the surface, seepage will occur. [f there's enough air-filled porosity between
the detonation point and the surface, it will push out until it's expanded to
atmospheric pressure, and then it'll just stop.</p>

<p class="tab"><b>Carothers</b>: Presumably there is some
association between how much carbonate rock is present, how much of that rock
is melted, and how much carbon dioxide will be formed. Does anybody know that,
or do they just estimate it?</p>

<p class="tab"><b>Higgins</b>: I'd say that at the present
time it's an educated estimate. What has been measured is the temperature at
which the carbon dioxide is given off, and that is somewhat less than the melting
point of the rock. It's like six hundred and fifty, or seven hundred degrees
centigrade.</p>

<p class="tab"><b>Carothers</b>: Then I would be right in
saying, “Well, if there are eight hundred and seventy tons of melt per kiloton,
all the carbonate in those eight hundred and seventy tons is going to be
decomposed."</p>

<p class="tab"><b>Higgins</b>: Yes. A nitpicker would say it
should be a little larger than that, but not very much. The question is, where
is the carbonate rock? If you move the working point into a layer that doesn't
have any carbonate, you would say there wouldn't be any carbon dioxide
generated. That isn't quite consistent with the observations. The reason is
that when collapse occurs, if there's carbonate right above the cavity that can
fall into the hot cavity, some of that can get decomposed. But, it would be
much smaller than if the working point were in that carbonate region. So, those
little qualifications notwithstanding, it's the general assumption that the
amount melted is the amount interacting to form carbonate.</p>

<p class="tab">The other kind of
non-condensable gas is that formed chemically by the reaction of metals with
water to release hydrogen. It could be the iron or aluminum in the canister, or
a lot of other things. One of the more exotic is boron carbide, which can
interact with water; one boron carbide can make seven hydrogen molecules. But
the chemistry is the same. It has to be in the melt region to be hot enough,
and be mixed with water, which is steam under those circumstances. Of course,
there's plenty of water around. If you want to approximate the world you take
silicon dioxide, plus water on an equal molar basis, and that's pretty good.
You're only making second and third order corrections to put in the calcium,
and the aluminum, and the carbon, and all the other stuff.</p>

<p class="tab"><b>Carothers</b>: Funny, Gary, that with all that
silicon around we ended up carbon-based.</p>

<p class="tab"><b>Higgins</b>: Isn't it? There is one little
fact of nature, however, that says silicon was important. That is that the
sense and orientation of the DNA molecule is identical to that of the silica in
a glass structure - I learned this fact from Bill Libby. And I maintain that DNA
got its pattern by being on a clay particle, and that the first live
reproducible virii came from clay. That is, they were organic molecules that
got the pattern, and replicated off a piece of clay.</p>


<a name="ch10"></a>
<br><br>
<h2>Chapter 10: Cavity Collapse, Chimneys and Craters</h2>
<br>

<p class="tab">
There are many observable things
that occur after a detonation takes place, and the cavity has reached its full
growth. At some time the roof of the cavity gives way, and the overlying rock
falls into the cavity volume. This fall of material sometimes causes the
surface to slump and form what is called a crater, although purists call the subsidence
that occurs a "sink." A crater is something that is formed when
material is ejected from an area, and there are a few true craters on the Test
Site, the Sedan crater being the most impressive example. Here sinks and
craters will all be called craters, bowing to the overwhelming majority who use
that nomenclature.</p>

<p class="tab">How and why and when cavities
collapse, what the conditions are in the column of displaced material that
often, but not always reaches the surface, and the reasons for the shape and
sizes of the surface craters is largely unknown. There are some correlations
that can be inferred.</p>

<br>

<p class="tab"><b>Keller</b>: It was in using the data bank I
had put together that I discovered the correlation between crater dimensions
and yield, and some other things like that. One thing I noticed was that the line-of-sight
pipe events always collapsed much faster than the others. And I also discovered
that there was a good correlation, if you presume bulking, between the
dimensions of the cavities, as best we knew them, and the dimensions of the
craters, and the yield.</p>

<p class="tab">You would intuitively
think there had to be some correlation, except it was popular then, and even
now in some people’s minds, to think that compaction was equally as probable as
bulking during the chimneying process. Since then the subject has been picked
up at Los Alamos by Erik Jones at one time, and Tom Weaver, and Tom Kunkle, so
there have been three more resurrections of that subject. Each time there was a
larger data bank and better statistical techniques for analyzing it, but
nothing new was discovered; it was only refined. One surprising thing was that
there was an amazing lack of scatter in the fits to the data.</p>

<p class="tab">The thing I always
liked about the crater dimensions was that they were the best known features.
They used to do very detailed contour mappings of the craters, and so you could
really tell exactly what the volume was. And there was a pre-shot and post-shot
difference map. Today you don't know that as well because they don't do that
before and after comparison.</p>

<p class="tab">It turned out that
the depth of the crater, not the volume, was the most sensitive characteristic
of the crater with regard to the yield. The crater radius was the first order
correction to that, and still the volume wasn't. I'm not sure why that's true.
Many people tried to relate the crater volume to the yield. They got very poor results,
so they were just turned off by the whole concept, and were rather outspoken
about how you couldn't tell anything about the event from the crater
dimensions.</p>

<p class="tab"><b>Carothers</b>: Craters come in a lot of
different shapes. There are ones people call post holes, others they call
dishes, and there are various other shapes. How can it be that the depth of the
crater, which seems to be so variable from area to area for equal yields, tell you
anything about the yield?</p>

<p class="tab"></b>Keller</b>: Well, let me tell you what the
simple relationship was. The first thing I took was a column straight down the
middle of the chimney. I took the height of that column before collapse to be from
the top of the cavity to the surface, and after collapse to be from the bottom
of the cavity to the bottom of the crater. Any difference in that dimension
before and after collapse was bulking or compaction of the rocks in the
chimney. I expected that there would be convergence of that because of the
slumping you see in craters, and also because of the collapse of the cavity
into the bottom. And so I expected bulking, and I just plotted that bulking factor,
the ratio of those two columns versus the depth of burial. There was a lot of
scatter, but it was not nearly as much as I had expected. This bulking factor
was very high for low depths of burial and yields, and it asymptotically
approached a value of about eighteen percent, as I recall, for high yields and
very large depths of burial. That was the first clue that there was reasonable
order.</p>

<p class="tab">The thing that
defeats the argument about there being compaction is that there is a very clean
cutoff between events that breach the surface and those that don't. It's a scaled-depth-of-burial
cutoff, and it's relatively sharp. If you had compaction sometimes, it wouldn't
be that well defined. Basically you're forced to believe that bulking does
occur every time, and that the bulking actually limits how far the chimney will
propagate.</p>

<p class="tab">Then I tried the
crater volumes and that didn't help. I looked at the crater radii to see if
there was any correlation there. Now, the depth of the crater will give you a
yield but it may be too high or too low. But there seems to be compensations to
the extent that if the depth is too great for a particular yield the radius of
the crater is too small. And so, there are skinny craters and there are extra wide
craters, but I could correct the yield I determined from the depth with the
yield from the radius, which is not so well behaved.</p>

<br>

<p class="tab">The craters that form at some
long time after the shot, after there has been a collapse that didn't reach the
surface, and the area is presumably stable, have been a threat to personnel
that wasn't fully appreciated for some time.</p>

<br>

<p class="tab"><b>Miller</b>: One time we had something that
was almost like what happened up on T-tunnel a few years later, where people
got hurt when it collapsed. We had an event in Area 2, and it used to be they didn't
fence the GZ, and this hole had no fence. We were doing angle drilling, and we
were rigging up the post-shot rig. Part of our equipment were these big blowers
to suck air to the cellars in case we had a release from the drilling. This
teamster drove up to the location, and he's driving a big rig. He drove all the
way to the GZ almost, turned around to get spotted, and as he's returning the ground
collapsed. The float with those blowers went into the crater. Fortunately it
was not a cookie cutter; it was a saucer shape. Part of the tractor wheels went
into the dirt where it cracked, and the tractor couldn't move. This guy jumped
out with his hard hat and his lunch pail, and just ran like hell. We took
another tractor, or dozer in there, and grabbed hold and pulled the whole thing
out. Fortunately nobody was hurt. It was close though, very close. That was the
event that caused us to start fencing the ground zero area.</p>

<p class="tab"><b>Keller</b>: On the accident on Rainier Mesa
with Midas Myth, when they dropped the trailers and some people in the crater
as it formed, the same order that I had found earlier for crater formation was
relevant to that event. Midas Myth turned out to have one of the smallest
scaled depth of burial for events in Rainier Mesa. Although they'd existed on
other events on the Mesa, craters had not been seen, or recognized. They were
just so shallow that they were not noticed.</p>

<p class="tab"><b>Carothers</b>: Roy, did you ever do any
drilling work on Rainier Mesa?</p>

<p class="tab"><b>Miller</b>: Oh yeah. There was a shot in a
vertical hole there called Wineskin, in U12r, in '69. That had a surface
collapse. The fact is, after the collapse they had where they dropped the
trailers in the crater, they said there had never been one on Rainier Mesa to
collapse to the surface. Ken Oswald took them all up there and showed them that
surface collapse.</p>

<p class="tab"><b>Keller</b>: When you plotted those events
that had been shot in Rainier Mesa, and whose chimney heights were known, Midas
Myth fit right on a nice curve. The chimney height was just right on the line,
and the chimney height would be above the surface, which gives you a crater. At
the time, the folks who thought the shots on Rainier Mesa never cratered were
not aware of the surveys that had been done, and that showed the shots did
crater a little bit. And so it was a matter of not knowing what they didn't
know. And one did not normally put trailers at ground zero. It was an
unfortunate incident. There is a lot more order to this data than some people are
willing to believe, and so within some uncertainty it's a very useful way to
look at some things, such as yield, or crater formation.</p>

<p class="tab">One thing that's
evolved most recently out of that is that Tom Kunkle and I looked at large
yields, and we found that some of the crater volumes were larger than that of
the cavity inferred from the measured cavity radii. Of course, if bulking is
existent in every shot, you can't have a crater volume that's larger than the
cavity volume. We looked at that more carefully, and since I believe they all
bulk and there's no reason to believe that the large yields ought to compact,
the cavity inferred from the crater dimensions is a simple constant times W
1/3rd, in radius.</p>

<p class="tab">The conclusion you
have to come to is that the radius measured in the downward direction is not
characteristic of the cavity volume, and that the cavity volume is larger than
that measurement would suggest. And there are good calculational reasons to
believe that. There are calculations that have been done that show stress
gradients, and the refractions from the surface, tend to allow growth in the
upward direction. And so it's in light of that conviction, unless you're real
near the surface and you get a strong relief wave, and you crater, that
cavities really are pretty much a constant times W to the 1/3rd. Now, they are
occasionally bigger. They're obviously bigger, as measured, in the southern
area of Yucca. Not only is the measured cavity radius larger in that area, the
craters are also larger, which supports that correlation.</p>

<p class="tab"><b>Carothers</b>: You can look at the crater, and
you can do surveys, and you can get the dimensions as accurately as you care to
pay for. On the other hand, the cavity radius, if there is such a thing, is in fact
poorly known. They drill down, poke into an uncertain spot where the cavity
used to be, and somebody picks a radius based on some level of radiation there.
The impression I get is that no one believes those reported radii are very
accurate. How did you deal with that when you tried to compare the crater
depths before and after the shot?</p>

<p class="tab"><b>Keller</b>: I presumed that there was
uncertainty in the radii, and that the crater volumes were known better than
the cavity radii. So, I went back and calculated yields from the crater
dimensions, and there were a few yields that were way off. One of them was Bandicoot.
Since then they have gone back and re-drilled it, and found that the measured
cavity radius is larger than originally reported. There's also reason to
believe that the actual yield was substantially higher than the published
yield. And so, those kinds of things show up.</p>

<p class="tab">There are a couple of
events where it's probably worth noticing those differences, and one is Merlin.
Merlin is the shot from which the samples were obtained for which all material
properties for alluvium are based these days. "Merlin alluvium" - you
hear it all the time. Well, those properties are deduced from a presumed yield for
Merlin. I've never really pushed it, but I suspect that the Merlin yield as
given isn't correct either.</p>

<p class="tab">It was like '67 when
I first developed this correlation, and Bob Brownlee was excited about it, or
seemed to be anyway. He took it to Charles Brown and said, "Hey, here's a
way to measure yield." And there were a couple of folks who said,
"That's just because we always bury shots at the same scaled depth, and
you use depth in there, and that's why you get that." Well, that’s not
true. If you just knew the depth you wouldn't get nearly as good a correlation.
Another thing Brown said was, "We already have Hydyne, we have rad chem,
and we have seismic; what do we need another yield determination for?" That
was his response. Well, it's actually turned out to be more useful than that,
but it was interesting to hear the logic that would prevail in those
circumstances.</p>

<p class="tab"><b>Kunkle</b>: The radius we measure from the
radiochemical drill back is developed by taking the point where the bomb went
off, and finding the geometric distance to where the drill hole first found radiation.
There are a fair number of assumptions there. One is that the effective center
of the cavity is the center of of the explosion. Now, there's no reason to
believe that should be true. Another assumption is that you have a spherical
cavity. Based on these assumptions, you can derive a volume.</p>

<p class="tab">Many of our shots,
especially those for a successful event, have a scaled depth of burial of
perhaps a hundred twenty, a hundred twenty-five meters. Those in the valley
collapse to the surface, and make very large, nice surface craters. J've always
felt there ought to be a relationship between the size of that surface crater,
the volume of the surface crater, and the volume of the cavity. And in fact
there is. This leads me to believe that yes, in fact, by and large, that radius
we're getting tells us something about an actual radius - that the cavity is
more or less spherical, and it's more or less centered on the explosion point.</p>

<p class="tab"><b>Carothers</b>: You could make the argument
that cavities are perhaps not spherical for a variety of reasons, but except
for a certain number of special cases, they're spherical enough. These one or
two meter wiggles and protrusions in the cavity wall don't amount to much. We
can average those out. And so, while cavities aren't spherical as we draw with
our compass . . .</p>

<p class="tab"><b>Kunkle</b>: They may be as you draw circles
freehand, like many of us draw circles. That has been my impression of how cavity
sections may be. Conversely, I think we've seen cases, and we expect to see
cases, where the cavities are squashed by the geology. One of the things we
seem to see, when shooting over very hard material, in a softer material, or
under a very hard layer in a softer layer is that the cavity is either pushed
down when it's in the softer material under the hard layer, or squashed on the
bottom as it tries to grow down through the hard material. By and large, the
little data we have from our drill backs tends to support these models. In the
final stages of cavity growth,
the material strength must be determining where that cavity stops. And so, in
weaker materials the cavity should be bigger.</p>

<p class="tab"><b>Carothers</b>: What comments would you make
about craters with respect to cavities?</p>

<p class="tab"><b>Kunkle</b>: Well, for events that take
place at relatively small scaled depths of burial - a hundred twenty or hundred
forty scaled meters - the crater and the depth of burial together are a very
good indicator of how big the cavity was underground.</p>

<p class="tab">I don't think this is
surprising. At least, it wasn't to me. One would envision that the size of the
crater ought to be related to the initial size of the cavity and its depth of
burial, given the material it's in, of course. And, indeed, this is in fact the
case. There is an excellent relationship between the yield of the device, it's
depth of burial, and the depth and size of the crater on the surface.</p>

<p class="tab">You'd have to improve
the rad chem yields for me to do any better in tuff, which is a very uniform material.
That was, to me, a rather surprising result. I didn't expect to find such a
good regression relationship. Now, in alluvium, it doesn't work as well. There
are evidently different types of alluvium we shoot in. More or less, the tuffs
in the valley seem, to the bomb, to be tuffs. And of course, geologically there
are not large differences between them either. That gives a good ability to
deduce actual event yields from observable, unclassified aspects, as we have
found.</p>

<p class="tab"><b>Carothers</b>: Unclassified aspects perhaps,
but I have to know a lot of things. I have to know the relationship exists, and
then I have to know that this shot, whose yield I want to know, was fired in
the same material and not something else. I do need to know a number of things
in order to derive that yield.</p>

<p class="tab"><b>Kunkle</b>: Yes. The events I've been most
interested in are those involving treaty compliance for a hundred and fifty
kiloton limit. And so, the question is, can I verify a hundred and fifty
kilotons from unclassified information? After all, I know the depth of burial. I
can tell that from the cable lengths, although that could be disguised. But I
could find out the depth of the hole, to find a maximum depth of burial. I can
tell if there's a surface crater - that's quite easy to know from a satellite
or other overhead photography.</p>

<p class="tab">Does this tell me
something about yield, if I happen to know it was in a tuff unit in the valley?
At a hundred fifty kilotons, if I shoot in the valley, I'm going to be in a
tuff unit, because I need that depth of burial to successfully contain the
device. Those are all the things I need to know; it is in a tuff unit, the
depth of burial, did it make a surface crater. Mostly I need the depth of the
crater, which is fairly easy to arrive at from overhead photography. After all,
we do it that way now using aerial photographs.</p>

<p class="tab">From that information
I maintain I can get yields to plus or minus twenty percent, which is about the
same as the rad chem people do. And, I don't need to do more than that. It's a
very reliable way, at least to me who believes in the process, to verify the yield.</p>

<p class="tab"><b>Carothers</b>: And the reason that it works,
presumably, is that the tuff in the valley is a fairly uniform material, and
the cavities therefore follow a fairly smooth law.</p>

<p class="tab"><b>Kunkle</b>: That's right.</p>

<p class="tab"><b>Carothers</b>: And as they collapse to the
surface, any bulking from shot to shot is very similar. So, since you mostly
want to know the depth of the crater, you must feel that's related to the size of
the cavity. In a sense you're using the crater to infer a radius for the
cavity. That's what gives you the yield in this uniform material, in which
you've fired enough shots that you have calibrated it, in a sense. Is that sort
of it?</p>

<p class="tab"><b>Kunkle</b>: That's it.</p>

<p class="tab"><b>Carothers</b>: Well, if I went to some
different place, like Pahute Mesa, where this rock layer is hard and that layer
is soft, and this pillow of lava is here but was not there, it might be much
more difficult.</p>

<p class="tab"><b>Kunkle</b>: It's more difficult, but
actually the relationship works fairly well on Pahute Mesa, adjusted for the,
Mesa because there are harder rocks and smaller cavities, and less frequency of
cratering up there. But when I adjust for those things, that is, do a Pahute regression,
it works quite well there. Where it doesn't work well is in the alluvium. I have
to know more about the type of alluvium the shot is in. We certainly see a larger
range of densities, and water contents, and gas porosities in the alluviums
than we do through the other geologic testing units. Of course, if one knows
that such a relationship exists, we have published enough declassified event
yields to calibrate the relationship.</p>

<p class="tab">Let me bring up a
side issue. In studying the underground phenomenology from nuclear detonations,
I kept coming across this group of shots that were just odd. Nothing looked
quite like it should. It was interesting group. Then I found out what they
were. If you find a particular kind of device, you throw it out of your analysis,
because people don't know very well what the yield was. It just became clear to
me that those yields have big uncertainties.</p>

<p class="tab">And so, one of the
things that occasionally comes up in looking at a proposed shot site is that
the neighboring experience may include some things that look pretty wild.
There's a crater there where there shouldn't have been one, or there isn't one
where there should have been, or this K value looks very strange. But when you actually
look at them, there are these particular devices, and I usually just tend to
ignore them. And there are some that are so odd that I just, when they come up,
gently dismiss them as much as I can. Very odd things happened on Alva and
Marvel. But of course, you'd certainly expect them to behave differently than
other shots.</p>

<p class="tab"><b>Carothers</b>: There's another class of shots
which ought to effect the cavity, and thereby the crater. Those are the
vertical pipe shots . Generally they collapsed rather quickly compared to the
other shots. Do they follow your curves?</p>

<p class="tab"><b>Kunkle</b>: We really didn't do enough of
those. There are a half a dozen or so, and they're scattered about. They're not
a very uniform group.</p>

<p class="tab">As far as collapse
times go, I've never been able to predict them, so I can't say what effect the
pipes had on them. One of the last of these we did was Huron King. It was done
the summer I showed up here. Everyone was very happy that it took fifty-nine minutes
to collapse, because that demonstrated that the pipe must have had really no
effect on it. I suppose that's a good demonstration, but we had a lot of
downhole diagnostics that demonstrated it better. So, I became acquainted with
that argument rather early on.</p>

<p class="tab">Collapse times are
interesting, and they're interesting because we can't predict them. For some
shots in alluvium in the valley there are some sort of general rules that allow
you to tell if it is going to collapse in one hour or ten hours, but really no
more exactly than that.</p>

<p class="tab">For shots in the
valley tuffs, where we can predict if it will collapse to the surface, and the
general size of the surface crater, and a lot of things about the shot, we cannot
even get a handle on collapse times. When the cavity collapses seems nearly a
random process. Certainly if it happened in a minute or two, that would be very
unusual, and in fact, we haven't seen that. Anywhere from one to ten hours,
well, okay. It's been interesting that we just can't do much better than that.</p>

<p class="tab"><b>Carothers</b>: Do you think the water that is
present plays a strong role in the collapse?</p>

<p class="tab"><b>Kunkle</b>: By itself, the water, either by
weight percent or by volume percent in the cavity region, that we actually
measure, seems to play no particular role in determining collapse time. It must
be the interaction of the water with the rock. We have shot in relatively dry
sites of four or five or six percent, up to relatively wet sites in the high
twenties. So there's some variation there, but not as much as you'd like to
have for an experiment to see any effects. But we often see, comparing
different shots, factors of ten difference in collapse times. We see markedly
different collapse times from similar sites with presumably very comparable
amounts of water. I believe that the water, or steam if you like, must play a
role in the collapse, but there's probably enough of it always present to do
whatever it's going to do.</p>

<p class="tab"><b>Carothers</b>: Perhaps that's the point. At the
Test Site you rarely shoot in an area with very diferent kinds of rocks.</p>

<p class="tab"><b>Kunkle</b>: The collapse times, I found, go
hand in hand with another conundrum I have, which is predicting ground motions.
Ground motions display a range of characteristics which are understandable, but
not predictable.</p>

<p class="tab">For example, a class
of shots that has been studied a lot is the shots in the valley in the tuff
units. Usually they have fairly high design yields. The ground motions fall on
log log plots in a very nice and uniform way when you plot them for maximum
velocity and distance. But they're not the same from shot to shot. On some shots
the velocity falls off very rapidly, and they have correspondingly very high
motions toward ground zero. On other shots the velocity falls off very slowly,
or relatively more slowly, with distance, but they don't have much velocity at
surface ground zero. It's almost as if there's an energy conservation that the
amount of energy under the curve is staying the same, but it's distribution around
surface ground zero can be very different.</p>

<p class="tab">The puzzling thing is
that we can't predict for any particular shot which of these behaviors is going
to show. The motion will fall on a well-defined curve, but we can't tell in
advance what curve that is, and we can't relate the curve to any of the
geological aspects. In particular, in our tuff pile location, which is a very
uniform section of tuff geology, we have shot very similar shots in very
similar settings; same device, same depth of burial, same location in the structure.
If you had to try to repeat an event, you can't do any better than that. And
they have had completely different ground motions. And, completely different
collapse times.</p>

<p class="tab">And the collapse
times aren't related to the ground motions either, by the way. I thought, ah
ha, now I'll have some way to predict collapse times, but no, that didn't pan
out. I think that both collapse times and ground motions are sensitive to the
detailed properties of the close-in geology, the geology near the event work point.</p>

<p class="tab"><b>Carothers</b>: I was about to raise that
issue. The shots, you say, were just about as similar as two shots could be, in
terms of yield and geologic setting. Perhaps so. Yield, sure. On the other
hand, they were probably a thousand of so feet apart. Maybe more. So, they weren't
really in the same geologic setting, except in a general way. The details near
the working point, the inhomogeneities on the scale of the cavity size, you
don't know.</p>

<p class="tab"><b>Kunkle</b>: Well, that's true. For some
things, like the scaled cavity size, the inhomogeneities don't seem to matter
too much in the tuff units. For other things, such as the collapse times or
ground motions, it seems to matter very much, and in unpredictable ways. We
don't measure enough to be able to link the downhole measurements with what we
see happening post-shot.</p>

<p class="tab"><b>Carothers</b>: There are people in the
containment community who might say, "I could believe that some of the
results you see are caused by details of the structure which you guys have
never seen. And you've never seen those details because you don't care about them,
because they don't affect the containment of your shots. However, you see the
effects when you sit down and try to calculate certain things. Some of that
detail could be things such as the motion of blocks that distribute the energy
in different ways on different shots. Even though the shot points, by your logs
and samples, look the same, they're not the same. The blocks aren't the same."</p>

<p class="tab"><b>Kunkle</b>: I certainly believe that block
motion has an effect. By the way, there is a weak correlation between the joint
frequency we see in holes and the collapse times. And the joint frequency tends
to increase as you move toward the margins of the valley, from the center, and
collapse times decrease as you move out towards the margins of the valley from
the center. Maybe if you have more joints the blocks at the keystone are
smaller, and then they're not as competent when it comes time to hold the
cavity up. Whatever, there does seem to be some correlation.</p>

<p class="tab">I think the exact
positioning of layers, and the impedance between the various layers in the
bedded tuffs plays a part. Calculation ally you see this. Calculated ground
motions and residual stresses are very sensitive to even small variations in
the layer properties you use - their thicknesses, their positioning. We found
this out on an analysis of the Cottage event, for example. The standard model
was very sensitive to small variations, and we've seen this in other shots
we've tried to calculate. So, the actual details of the geology often seem to
matter. Fortunately, not for a lot of the containment aspects.</p>

<p class="tab"><b>Carothers</b>: Not for the containment aspects
of the kind of events that you do. If your Laboratory said it was necessary to
fire an event which had a line-of-sight to the surface, then some of these things
could possibly become important. But for the kinds of events that Livermore and
Los Alamos do these days, simple emplacement hole shots at a conservative depth
of burial, they obviously aren't important to the containment aspects of the
shot.</p>

<p class="tab"><b>Kunkle</b>: No. Now, we may see some of
these effects reflected in some of our containment statistics. What I mean by
some of them is the effects of block motions. This is an argument that Carl
Keller has made, and I find it quite persuasive. You can imagine our emplacement
hole as actually the narrowest of soda straws. It's a pencil line when drawn to
actual size on cross sections. And one phenomenon that probably happens on
higher yield shots is block motion which is large enough to simply shear off
the pencil line. There is then no longer a line running down to the cavity.</p>

<p class="tab">You could say that
somewhere around fifteen or twenty kilotons we technically get block motions
large enough to shear and very effectively block off those stemming columns.
That may be a key to containing larger yield events. That's one of the reasons
they may be easier to contain; the ground motions, the chaotic block motions
close in may tend to slide the earth around and seal off the stemming columns.</p>

<p class="tab">So, the cavity sizes
and crater dimensions fit nicely in a family. From that you can assume, or
infer, what may be happening in the ground. The crater size must be reduced
somewhat from the cavity volume, because of bulking of the earth materials. You
can work out a bulking factor by calculating the cavity size and the crater
volume, and looking at the difference in volumes. Now, we can work out a bulking
factor in the tuff that is seven or eight percent, but we can't a-priori know
that. I can't work that out from the mechanical models, or the physical
measurements on the tuff itself. It's something we simply observe.</p>

<p class="tab">And then there's the
ground motion. We observe the ground motions and they're understandable. That
is, when a new shot is done, you look at the ground motion data. It's
understandable in the context of the other shots, but it's not predictable in
advance.</p>

<p class="tab"><b>Carothers</b>: When you talk about bulking
factors, there's the question of how the collapse occurs. Is it a rain of
little pebbles, or a massive chunk of material that moves down as a unit. What
do you think it is? Or what evidence is there for it being one or the other?</p>

<p class="tab"><b>Kunkle</b>: The only evidence I'm aware of
is from drill backs and reentries on Rainier Mesa. There are downhole movies,
and holes drilled in chimneys, which show perceptible large gaps between the various
blocks, most of the way down.</p>

<p class="tab">But this is, of
course, a limited set of experience. We occasionally will drill through the
edge of a chimney, or collapsed area, during the post-shot operation. You
commonly lose circulation when you reach that region. That indicates you've
reached some kind of fractured area, but we know little of the mechanical properties
of the chimney material, such as the rubble sizes, and the spacing between the
pieces.</p>

<p class="tab"><b>Weart</b>: We did some measurements during
the Marshmallow reentry to see how large the cavity was, how far out it had
grown. To do that we mined in until we intercepted the edge. We followed certain
bedding planes that existed in the tuff, and all of a sudden we came to an area
where, although it was still perfectly solid rock, it was disrupted. As we
continued to mine in it was clear that what we were now in was a jumble of
tuff, and it was not characteristic of the the material we had been following.</p>

<p class="tab"><b>Carothers</b>: You couldn't tell from the
mining itself that you had entered the cavity region? You were still mining in
solid, competent rock?</p>

<p class="tab"><b>Weart</b>: Yes. It required no additional
support over and above what we had used out in the rest of the drift. It was
tightly compacted material. I think a lot of people have the picture that when
the cavity collapses there is a rain of rocks of various sizes, and there is a
pile of unconsolidated material that makes up the chimney.</p>

<p class="tab">That was not our
experience at the working point depth. Right at the cavity boundary it was
tightly compacted material. We could find evidence as we mined in of fractures
that had developed outside this cavity radius. They had had molten material
injected in them. It was usually radioactive, but not necessarily so. There
wasn't any indication at all of radioactivity at the boundary of the native
rock and the cavity.</p>

<p class="tab">We did contact the
cavity on more than one radius. I don't recall if we mined straight through. We
might have. We did try to determine the radius on the horizontal plane, and it
wasn't perfectly spherical. And subsequent shots, like Gum Drop, were not
perfectly spherical either.</p>

<p class="tab"><b>Flangas</b>: When we reentered the Pile
Driver cavity, up until we hit the cavity wall there was nothing to indicate
there was anything beyond. There was a clean interface, and within a matter of
inches we were into the cavity. Now, we've had others where we see the ground
get more and more fractured, and more and more ravelly, fifteen, twenty feet
away from the cavity wall. That's in the tuffs more. But we've seen them both
ways. Ground is not homogeneous, it's not consistent.</p>

<p class="tab"><b>Carothers</b>: It sure took us a long time to
learn that. Why didn't you explain that to us sooner?</p>

<p class="tab"><b>Flangas</b>: Nobody asked me. My job was digging
them, not figuring them out.</p>

<p class="tab">As far as chimneys
go, on Rainier we drove a raise up to get about a hundred feet above the shot
horizon, and that's where we ran into the material that was just powdered. It
was just totally disaggregated. It was like working through flour. Then we used
a technique they call spiling, in order to get that drift across. We wanted to
drift across the cavity and get directly over the ground zero.</p>

<p class="tab"><b>Carothers</b>: What's spiling?</p>

<p class="tab"><b>Flangas</b>: Spiling. Spiling is a roof
support system that is used in very loose or blocky ground. Pointed (chisel
shaped) wood (4" x 6") or sometimes metal beams are angled and driven
upward and outward over the leading set with the back end braced over the preceding
set. This cantilever bracing supports an incompetent roof ahead of the last set
and keeps the miners safely under cover while advancing the heading. 50, as we
spiled across there we noticed that material was totally disaggregated. And
from my experience in block caving, that was a block caver's dream. We could
have pulled rock out of there from now on. There's a lot of material in that chimney.</p>

<p class="tab"><b>Carothers</b>: Tom, there has been the picture
some people have presented of a continual process of decrepitation going on
before cavity collapse. There's the heat in the cavity, it heats up a layer of rock,
turns the water it contains to steam, which then blows off that layer of rock,
and so on. So, the cavity walls are continually flaking off.</p>

<p class="tab"><b>Kunkle</b>: I would expect such pieces of
rock to be quite small compared to the major blocks that would fall in during
cavity collapse. And, by and large, the cooling that occurs is from the energy
that is transported into the rock to make it hot. The conditions near the wall
of an underground cavity, following a nuclear explosion, must be quite suitable
for steam vapor explosions to occur. The rock and the water in the cavity are
under a large pressure. The water in the rock can now be superheated, probably,
to appreciable temperatures before it will flash to steam. At those high
temperatures, the flash of the superheated water to vapor can have an energy
release comparable to a good high explosive. But the energy has already gone
into it, by thermal conductivity, and so it is already hot steam and water and
rock, being added back to the cavity. The work's already been done, other than
the mechanical work, which is soaked up.</p>

<p class="tab">But I think those
pieces must be small. You're looking at an average size of a pocket, even the
big ones maybe, of a few millimeters across. So, you can imagine a little
droplet of high explosive detonating just inside the wall, and scaling off some
small amount of rock. I think this is unlikely to contribute to the major collapse.</p>

<p class="tab">Now, there has been a
school of thought that believes that the cavity pressure is related to the
collapse time. The model seems to be that of an impermeable membrane, which
allows you to push against the rock. I've thought that a mechanism that may be
more important in determining when cavities collapse than the steam pressure inside
the cavity is the stress in the rock around the cavity. If our calculational
models are to be believed, we often reach stress states in the rock immediately
surrounding the cavity of compressive stress; the residual stress we like to
.talk about. That's also expected to dissipate, as water moves out of pores and
relieves that, and collapse times may be more related to the migration of the water
out of the combined pore spaces than to the actual pressure decay in the
cavity. The two may go hand-in-hand, but we know very little about any of these
mechanisms.</p>

<p class="tab"><b>Carothers</b>: When the cavity does collapse,
whatever gases there are in the cavity have to go somewhere. The steam can be condensed
by the cold material that falls in. There is presumably only a small volume of
other gases, so there ought to be a low pressure in any volume that remains.
You might think there would be flow from the surface down into the chimney
until that volume is filled up.</p>

<p class="tab"><b>Kunkle</b>: That's indeed seen in apical
voids. It's not unusual, in a subsurface collapse that extends a fair distance
up the hole, to have a containment diagnostic package survive in the stemming above.
That package comes into communication, through the stemming materials, with the
apical void. For example, on the Barnwell event, some of the upper pressure
transducers showed a declining pressure soon after the major collapse, as they
came into communication with the reduced pressure in the apical void.</p>

<p class="tab">On Rivoli there was a
measurement just under the topmost plug which showed the pressure decreasing,
presumably as it came into equilibration with pressure in the apical void at
the top of the rubble column. So this, indeed, does seem to occur.</p>

<p class="tab">I have heard rumors
through the years, but I've never seen written documentation, that when you
drill back into standing cavities, they have sub-atmospheric pressure in them.
I'm pretty sure we've had, at Los Alamos, events in Yucca Flat where we've drilled
back into standing cavities where there were pressures below atmospheric. They
subsequently collapsed. To my knowledge there are no standing cavities at the
Nevada Test Site.</p>

<p class="tab"><b>Brownlee</b>: Los Alamos had at least three,
and I don't mean that there might not have been four, shots in which we did a
very low yield in saturated tuff. For us that's unusual, because low yields would
normally be done in alluvium. These happened to be in saturated tuff.</p>

<p class="tab">One time the guys
came to me terribly excited because they'd had this low yield in saturated
tuff, and they said, "When we drilled back, we hit the cavity, and the
fans that do the ventilating were running backwards. All the air was going into
the shaft; all of a sudden the cavity was just sucking air. How could that
possibly be?" So I said, "The next time that happens, make sure you
estimate how much air goes in." We had three shots for which we measured
the flow of air into those cavities, and what we found, of course, was that the
amount of air that went in was the volume of the cavity.</p>

<p class="tab">So, we had a standing
cavity with a vacuum. What you immediately deduce is that the cavity was small,
and in tuff, so it stood. It didn't fall in. But it was sealed off, and this
told us a lot about gas flow through tuff, and how things could seal.</p>

<p class="tab"><b>Carothers</b>: Subsurface collapses, by
definition, go part of the way to the surface, and when they stop, there seems
always to be an apical void above the chimney material. If that void is at low pressure,
the flow will be downward from the surface to fill up this big vacuum chamber.
That is a mechanism which would tend to militate against any release of gases
that might have gotten up that high. Do you believe that's possible, John?</p>

<p class="tab"><b>Rambo</b>: I like that idea. We saw that
happen on Barnwell, certainly. The pressure dropped, and you could see that on
the downhole gauges. The subsurface collapse tended to draw a vacuum, and we
didn't see any radiation get above where it was measured at the stemming
platform, which was very high in the hole, about four hundred meters up. And
so, I think that downward flow certainly does happen.</p>

<p class="tab">There were a set of
experiments carried out by Ed Peterson, of S-Cubed, sponsored by DNA, which had
to do with whether there was any containment threat if a shot site was situated
close to the chimney of a previous event. Data was sought as to whether or not there
might be flow of gas through the old chimney to the surface.</p>

<p class="tab"><b>Peterson</b>: At the time we did the chimney pressurization
measurements there were a couple of things that were coming up. One was that
they were going to shoot Hybla Gold near a nuclear chimney, and they were
worried about, if they got gases from the shot into the chimney, would they
then leak up to the surface very rapidly. If you place events reasonably close
together, and if you get rapid gas flow into an old chimney, could those gases
end up going up to the surface rapidly? That was the motivation. It was a
pretty much a containment-type question.</p>

<p class="tab"><b>Carothers</b>: Wouldn't it be reasonable for
me to ask, "Why would you be concerned about gases going up an old
collapse chimney? After all, there was a shot there, the chimney formed, and
gases didn't go up it from the original shot. Why would it do that from another
shot?</p>

<p class="tab"><b>Peterson</b>: That is an extremely legitimate
question. And it is probably correct that if there were another shot, and it
didn't collapse, then there would be all the steam in the cavity, and there would
be a horrendous drive because of the steam pushing all the noncondensables Then
you could make the argument, just as you did, that the steam is going to
condense in the old chimney, because the first one didn't leak either. What you
say is true.</p>

<p class="tab">I don't know all the
motivations for those measurements, but I think we are now in a world in which
not everybody who looks at the problem understands all the details of what goes
on. So, if you do a test and measure something, and say, "Okay, we did the
test and measured it. And so, now that we've measured it, we sort of know what
happens," it makes it much more believable to a large portion of the
community.</p>

<p class="tab"><b>Carothers</b>: I believe that. What kinds of
things did you do?</p>

<p class="tab"><b>Peterson</b>: The thing we did on those tests
was, we injected air slightly above the working point level through a drill
hole. They drilled a slant hole going up at fifteen degrees, from one of the underground
drifts, and came into the chimney some fifty to a hundred feet above the
working point. Through this hole we injected air, plus a tracer such as sulfur
hexafluoride. Then we measured the pressure through a drill hole that was
drilled from the surface down to the top of the chimney. We also measured the pressure
in another drill hole that came in horizontally. That one went in near where
the working point originally was. In all three of those holes we could measure
pressure, and tracer gas concentration. We also, on the surface, put out three
circular arrays so we could take air samples every thirty degrees around the
surface ground zero. Those we could analyze for the tracers.</p>

<p class="tab">Basically we
maintained a constant flow rate, and looked at the pressure response as a
function of time. On most of our chimney tests I believe we were flowing gas in
at about three thousand cubic feet per minute. It was between one and three
thousand, somewhere around that. Eventually, after twenty hours or so, we could
build up the pressure in the chimney to maybe three, four, five psi.</p>

<p class="tab">We put in numbers of
millions of cubic feet of gas. You can model it, and we found we could model it
very well. From the model we could calculate what would happen if we let the
pressure decay, and built it up again, and so forth. So, we got to the point
where we thought we could understand reasonably well the conditions in the
chimney. We did three chimneys, and I think we did seven tests on those three
chimneys, which were from Dining Car, Ming Blade, and Mighty Epic.</p>

<p class="tab">I believe some of the
motivation for using the Mighty Epic chimney was because Diablo Hawk was going
to be done in that general vicinity. I think we verified, if nothing else, that
gas doesn't come up to the surface from those chimneys.</p>

<p class="tab"><b>Carothers</b>: Is that because, although the
chimney may have a lot of cracks, and the gas goes up to the top of the
chimney, there is then some amount of material from the top of the chimney to
the surface of the Mesa, and that's what's really keeping the gas in?</p>

<p class="tab"><b>Peterson</b>: Yes, one can make that
argument. I believe it was on Dining Car where, when we did our first test, we
actually detected gases up on the Mesa at positions that were probably on the
order of two or three hundred feet from the surface ground zero. Subsequently,
after the USGS came out and looked at it, they found a region there that was
fractured. The fractures went down at about a thirty degree angle, and would
intersect the uncased bore hole that went down into the top of the chimney.
Subsequently that bore hole was cased, and we did another test. Nothing came up
to the surface.</p>

<p class="tab">So, in that case we
really made the right guess - the material above the chimney was what kept the
gas in. I can't remember the exact numbers, but we probably put in two to four
million cubic feet of gas, and our guess is that at the most, even when we
detected it, maybe less than a hundred cubic feet had come out on the Mesa. The
tracers are very sensitive, to one part to ten to the twelfth.</p>

<p class="tab">If we had been
testing over a chimney that was in alluvium, where you wouldn't necessarily get
the flow through the fractures, we would then have put some type of a tarp on
the surface, and collected the gas under it. That way. if it does ooze up over
a large region, you can still pick it up. I think that what we showed was that there
was no gross flow. These slight oozings - I don't think one can tell. But I
think the amounts would be so small that it would be almost impossible to
detect, no matter what it was that was oozing up at that rate.</p>

<p class="tab"><b>Carothers</b>: The conclusion that I would
arrive at is that indeed I can safely detonate a device quite close to an old
chimney, because it is no more of a flow path than the new chimney that's going
to form.</p>

<p class="tab"><b>Peterson</b>: I think that's true. If you're
looking purely at the fluid flow aspects of it, what you say it true.</p>

<p class="tab"><b>Carothers</b>: How else should I look at it?</p>

<p class="tab"><b>Peterson</b>: Well, because DNA has a
line-of-sight, and ground shock closures, and things like that on the tunnel
events, if you do put another shot too close to an old chimney, you may affect
the ground motion in a manner that might adversely affect some other part of
the system.</p>

<p class="tab"><b>Carothers</b>: You're implying that the
properties of the chimney, of this material which has fallen in, are different
from the surrounding materials, and so you can't treat it as similar to, or the
same as the rest of medium?</p>

<p class="tab"><b>Peterson</b>: That's true. It may be a
perturbation to the ground motion. But I think from the fluid flow and leakage
point of view what you say it very true.</p>

<p class="tab"><b>Carothers</b>: Do you think that would be true
in alluvium as well?</p>

<p class="tab"><b>Peterson</b>: I think so. I see no reason why
it wouldn't be. On Pahute, Livermore has done shots where they get some
collapse, or partial collapse, and there are little fractures that ooze small amounts
of activity from atmospheric pumping. But they are very small amounts. The
thing is, you can count anything, Jim. It's like our sulfur hexafluoride -
there are just molecules that came out. With the measurement capabilities that
people have today you can measure far below anything the EPA says is
significant for anything, or that anyone else says is significant. You can
measure molecules of anything, like our tracer. And there are a lot of
molecules. It's true that Caesar's last breath is still floating around, and
every breath you draw in should have a molecule or two of Caesar's last breath.
One can mathematically show it.</p>

<p class="tab"><b>Carothers</b>: Carl, the Test Site, including
the tunnels, is used as a two dimensional grid, as far as siting events goes,
and there are some arbitrary rules about how far from an old chimney a new
event should be located. Eventually, perhaps, for various reasons, people could
be forced locate events closer than those rules would allow. My impression is
that nobody really knows very much about what the properties of the chimneys
are, and so they stay away from them because they don't know.</p>

<p class="tab"><b>Keller</b>: That's right.</p>

<p class="tab"><b>Carothers</b>: Do you think that could become
an issue in the future?</p>

<p class="tab"><b>Keller</b>: I think that if there were a
few measurements of chimney permeabilities, and measurements outside those same
chimneys, to develop real data on what the relative permeability is, inside
versus outside, then you could be much more quantitative about how close you
could get. The gas flow codes we have now would easily handle that problem.
There are some kinds of sitings that are already all right. You can shoot,
certainly, well underneath. I don't see anything wrong with dropping one
chimney into another.</p>

<p class="tab"><b>Carothers</b>: No, I don't either. No one has
done it though.</p>

<p class="tab"><b>Keller</b>: No. Well, they've gotten close.
But I think in that case you don't have to be very quantitative to convince
yourself it's all right.</p>

<p class="tab">The thing that I
think is most compelling for the measurement of permeabilities in the chimneys
is the CO<sub>2</sub> question. As they site in different areas, and they
encounter higher CO<sub>2</sub> contents, they will have to be more explicit
about what is an acceptable level. The standard five percent that has been the
threshold of concern is based on an analysis of seeps, which occurred all over
the site and includes events like Diagonal Line and a bunch of Livermore shots.
There's a whole area which Livermore uses that has a high CO<sub>2</sub>
content. It's also fairly well cemented. It's very important that the threshold
of concern for CO<sub>2</sub> is very medium dependent. If you're shooting in a
material where the chimney is not significantly different from the native
material in permeability, you can go to very high levels of CO<sub>2</sub>. And
in fact, some events were shot in carbonate rock; Nash, and Bourbon, and
Handcar.</p>

<p class="tab"><b>Carothers</b>: Nash also leaked.</p>

<p class="tab"><b>Keller</b>: Yes, but Bourbon didn't, and so
you wonder why. Well, Bourbon was deep enough. Seeps depend on the path, and if
it's long enough, it can even be fairly permeable. Jack House paid for some
work on the relationship of CO<sub>2</sub> and medium properties to leaks, and that will
be very useful for him if permeability measurements are made. Now, as I have
said, you can infer permeabilities from the leak arrival times, but that
assumes you know what the CO<sub>2</sub> generation is, and that's kind of a
flaky number. There are the arguments about whether cuttings or sidewall
samples give you a good number, and how you should average, and so on. So one
doesn't know the inventory very well.</p>

<p class="tab"><b>Carothers</b>: Russ, you have said that there
are indications that things other than the simple movement of gases from the
detonation through the chimney toward the surface go on in the chimney after the
shot.</p>

<p class="tab"><b>Duff</b>: When the early Plowshare
activity in S-Cubed came along, I had an opportunity on Gasbuggy to look at the
chemistry of a nuclear chimney. We had extensive measurements of gas composition
over time, after the shot. Chuck Smith, at Livermore, did measurements not only
on the composition of the gas - carbon dioxide and air and methane and ethane,
and so forth - he also looked at HD, HT, H<sub>2</sub>, HTO. So, we had not only
chemistry, we had isotopic chemistry. I tried to develop for El Paso Natural
Gas, who were the commercial partner, a model which would explain all of those
measurements in a consistent fashion. I think we did, and it is a very
different model from what the Laboratory developed.</p>

<p class="tab">One thing that came
out of it was the postulate that during collapse some of the hot rock was
elevated, or at least not flooded by the condensate. So, over a period of six
months there was a continuing series of reactions at these hot rock surfaces
between the various chemical species. There must have been hot spots in the chimney,
and by hot I mean six, seven, eight hundred degrees Kelvin, that lasted for six
months.</p>

<p class="tab"><b>Carothers</b>: That's not the conventional wisdom.</p>

<p class="tab"><b>Duff</b>: Of course it is not. But you
look at all the chemical evidence, and ask, "How can you explain
that?" Well, I could explain it by a series of assumptions, and continuing
reactions were required. So far as I know nobody else has tried to explain why
the chemistry changed over six months. But it did. That was my first effort to
apply concepts of equilibrium chemistry to the nuclear explosion environment.</p>

<p class="tab">In the DNA program
there have been a number of places where chemical concerns might be important.
We have long seen explosive gases in the tunnel after the shot. Where do they
come from?</p>

<p class="tab"><b>Carothers</b>: Joe LaComb recently said they
were finding hydrogen during their reentry, but it's clean, so it doesn't come from
the cavity.</p>

<p class="tab"><b>Duff</b>: Well, I haven't thought it came
from the cavity for a long time. I've been promoting for four or five years the
idea that DNA was seeing the effects of reactions between grout and metal,
making hydrogen. Since the grout, in particular super-lean grout, is made with
desert fines, there is carbonate in it. There have been a lot of chemical
calculations which have been done, and reported, which can explain the presence
of a lot of carbon monoxide, and little carbon dioxide. In the cavities we're
dealing with there should be a lot of carbon dioxide. The stuff that shows up
in the tunnels is carbon monoxide, and right there is evidence that it is not
cavity gas.</p>

<p class="tab">There is some
radioactivity in these gases, and I think that represents fission products that
get into the very early prompt flow. They get mixed into the stemming, and then
are purged out of the stemming by late-time reactions which make hydrogen and
carbon monoxide, which then seep into the tunnel complex. That was behind my
suggestions a couple of years ago of putting some manganese dioxide into the
system to try to control the late-time reactions.</p>

<p class="tab"><b>Carothers</b>: I recall that Livermore put
manganese dioxide around the device canister on a few shots in the sixties.</p>

<p class="tab"><b>Duff</b>: Jade is one. It was done in a
radiochemical context. They were trying to modify the oxidation states of
certain fission product oxides so the radiochemical collection process would be
better. Before that work came to any particular fruition, as I understand it
other chemical techniques were developed and it was dropped .</p>

<p class="tab">I've been talking to
Joe LaComb and various other people about chemical related activities. Bob Bass
was receptive, and he got Sandia to make some gas sampling systems. They have been
fielded on a couple of events now. I am professionally gratified to hear Joe
LaComb make comments as he did at a recent CEP meeting, saying that maybe, in
fact, chemistry is important. I've been saying for a long time now,
"Chemistry is a perfectly good branch of physics. There's information
there, let's extract it." So, I think there is an avenue of potential
advance which I look forward to DNA exploring.</p>

<p class="tab"><b>Carothers</b>: The only chemistry I ever hear
about at the CEP concerns how many tons of carbonate rock will be affected per kiloton,
or some brief mention of the iron in the canister, and how much hydrogen will
be produced from that.</p>

<p class="tab"><b>Duff</b>: I know. I know. Some four years
ago I got hold of a suite of gas sampling data from Livermore, and tried to see
what it told us about iron reactions, and how much rock was able to give up carbon
dioxide, and so forth. It was surprising data, because there were shots that
were right, in the sense that they had big amounts of iron around, they were in
tuff, and you'd expect under those circumstances to be a lot of hydrogen, and
indeed there was. There were other cases where there was a minimal amount of
iron, the shot was in alluvium, with relatively high amounts of carbonates,
where you'd expect carbon dioxide to dominate and it did. But there were also
cases where the reverse was true, There were cases where you'd expect lots of
carbon dioxide and instead you got lots of hydrogen. Or you expected lots of
hydrogen and you got lots of carbon dioxide.</p>

<p class="tab">Another problem,
which is long standing, was shown in Gasbuggy, but it is also true in all of
the Livermore gas sampling. Why is there so much ethane and propane found in
the gas after a shot?</p>

<p class="tab"><b>Carothers</b>: Now Russell, there aren't any
hydrocarbons at the Nevada Test Site. There is tuff, and clay, and lavas, and
such like, but there isn't any ethane or propane. You might expect to find that
in a gas field, but certainly not in Nevada.</p>

<p class="tab"><b>Duff</b>: There's hydrogen and there's
carbon dioxide at NTS. And at high temperatures these react, and you get
methane, a detectable and measurable amount, like one percent. And, if you look
at Chuck Smith's gas sampling data there is ethane and propane found and
reported. In equilibrium you expect that hydrocarbon series to be down about
five orders of magnitude as you go through each step. The mystery to me is that
the observation is one order of magnitude between methane, ethane, and propane.
One order of magnitude for each step, and we calculate five or six.</p>

<p class="tab"><b>Carothers</b>: At five orders of magnitude per
step I would think it would be very difficult to see propane, and perhaps you
might not even see the ethane.</p>

<p class="tab"><b>Duff</b>: That's right, but we do see
them. Now, I don't have the foggiest idea what the implication or importance of
that is, but it is a mystery which has been around since Gasbuggy. I firmly
believe that when we see something that is a surprise, we have a chance to learn
something we didn't know. When we see what we expected to see, we haven't
learned anything new. And so, it's in this context that I want to understand
that mystery. Not because I think it's going to be better than sliced bread, or
somehow take care of the national debt; it's not that kind of important. But I
think there may be something about the phenomenology which is hidden, at the present
time, in that particular observation. So, as a guy who is interested more in
the scientific aspects of things than in meeting the schedule, I am intrigued.
And, I think there may be something of value there.</p>

<p class="tab">We have a situation
in the gas sampling area, which I think is fortuitous. We are getting data, and
we've been able to pretty much make sense of it. For instance, on Mission Cyber
we were able to say, from gas samples, that in the chimney the cavity gas was seventy-three
percent hydrogen and twenty-seven percent carbon dioxide, with a little bit of
other stuff. We've got three measurements at different times, and we get
essentially the same answer each time. That's not really a profound thing, but
it allows us to investigate the whys. What temperatures, what pressures would give
rise to that answer? I wish this had happened a decade ago so I'd have some
professional time to try to do something with it. It will be the next
generation who gets to exploit it, and I hope there is somebody who wants to
champion that kind of work, because I think there is an opportunity for major
success there.
</p>


<a name="ch11"></a>
<br><br>
<h2>Chapter 11: The Residual Stress Cage</h2>
<br>

<p class="tab">What is important in the
containment of an underground nuclear explosion? Certainly the depth at which
the explosion takes place is crucial. Obviously a detonation on the surface of
ground will release the products of the explosion to the atmosphere. A
detonation taking place miles underground would certainly be expected to be
completely contained, barring some man-made feature which would provide a path
to the surface. "Deeper is better." The lithostatic stress, which is
always there, works to prevent the formation of any openings through which
high pressure gases might escape, and as the weight of the overburden becomes
greater the energy released can no longer lift the overlying material as far,
and so on.</p>

<p class="tab">However, great depths of burial
create difficult and very expensive problems to solve. What is a depth of
burial at which the containment of the detonation products confidently can be
expected, but which is no greater than required for that confidence? For the
moment we will put aside consideration of the man-made features such as
line-of-site pipes, cables, stemming columns, and other such things.</p>

<p class="tab">There are three principal
phenomena, aside from the lithostatic stress and the overburden weight that are
thought to play important roles in the containment of the detonation products
of a nuclear explosion. The importance of any of these mechanisms, or whether anyone
of them is important at all, or possibly even exists at all in the context of
containment has been the subject of extended debate. Certainly they exist, but
when they occur and to what degree they influence a particular event is a
matter more of opinion than of demonstrable fact. Nonetheless, detonations are
contained, regardless of the minimal understanding of these mechanisms.</p>

<p class="tab">One is what in the earliest days of underground
testing was called the "mystical magical membrane," and is variously
referred to today as the "residual stress," the "stress
cage," or the "containment cage." It comes about, in theory,
when the rock materials that have been pushed out by the passage of the shock
wave, and compressed, move back toward the cavity and set up a region around
the cavity where the hoop stresses in the rock are greater than the cavity pressure.
Hence, gases in the cavity cannot be forced through that region.</p>

<p class="tab">Another postulated mechanism is
hydrofracturing, or cracking, of the rock near the cavity by the gases which
are at high pressures in the cavity. Such a crack exposes additional cold surfaces,
and speeds the cooling of the cavity material, reducing the high pressures that
might force materials toward the surface. Hence, they could reduce the flow
from the cavity, and be beneficial to containment. On the other hand, such
fractures would seem to provide paths for flow of gases toward the surface, or
perhaps to some plane of weakness such as fault. As such they could be a threat
to the containment of the event.</p>

<p class="tab">The third, thought to be
sometimes important in tunnel events where a line-of-sight pipe is used, is
block motion. This refers to fact that upon tunnel reentries very large blocks
of rock have been observed to have moved many feet. Such motion could
conceivably be good for containment by moving a very thick block of material across
the tunnel, effectively sealing it. Or, it could be bad by destroying or
interfering with the action of the mechanical closure hardware typically used
on line-of-sight shots.</p>

<p class="tab">There is, of course, the
possibility that all three of these things might occur in various degrees on
every detonation, either reinforcing or interfering with each other in the
containment of the gases. In a similar way, it is difficult to confine the
discussion of peoples' opinions about why shots contain to just one of these
mechanisms. This chapter will consider principally residual stress, the next hydrofractures,
and the one following that, block motion.</p>

<br>

<p class="tab"><b>Carothers</b>: In the earliest days of the
underground program there were people who said, "I don't understand why
every shot doesn't hydrofract to the surface and vent. Why do they stay there? Everything
is diverging, everything is being pulled apart, there is this high pressure
gas, and it should hydrofract to the surface very quickly. But it doesn't do
that." There were other people who said, "Well, there is some sort of
mystical magical membrane that keeps it from doing that. There has to be,
because otherwise, you're right, you couldn't contain an underground
shot."</p>

<p class="tab"><b>Higgins</b>: Just right. And that argument
is correct, and all of the descriptions of what that mystical magical membrane
was were there. We just didn't really stop to look. There were clues about the
residual stress that we found on Rainier. When we went back and examined the
sandbags that had been in the stemming around Rainier, we found that the sand,
which was just loose tuff that had been shoveled out of the tunnel and put into
cloth bags, was now so hard that we had to use pick axes to remove them. The
sand was as tight and as solid as the original tuff. Surprising, we thought,
but we ignored the clue.</p>

<p class="tab">That compaction, we
said, was due to the passage of the shock wave. But when we tried to compact
materials with plane shocks in the laboratory, we didn't get that. So we said,
"I wonder why that is," and ignored the clue that the rebound
recompaction was an important part of the containment process. People used to
refer to something they called the "mystical magical membrane." Well,
it has a real basis in physics, but by using that term we tended to dismiss it
as a part of the overall process. That's where the physics should have included
the business of rebound, and what we now refer to as the containment cage.</p>

<p class="tab">Roland Herbst gave a
long talk about this along about 1960 or 1961. He remarked about the fact, and
we reduced the argument to the plane wave case, that following the passage of a
shock there was reverse motion, or rebound, in the direction from which the shock
had come. So, you had not described everything when you talked, in a shock tube,
about the passage of the shock wave itself. I said, "You mean the shock
rebounds from the other end." And he said, "No, no, no. Make the tube
infinitely long. After the shock passes, a little while later the material will
go back the other way. There will be a rebound. That's because the material now
knows there was a shock wave." We argued about this, and he convinced me
that yes, if there was an initial pressure, or an initial number of atoms per
cubic centimeter, there would be rebound without any reflection. Knowing that
there is a rebound, what we then should have said was that after a period of
time the material comes back and recompresses. It's the physical nature of the
approximately spherical cavity that makes it persist. It's simply the recompaction
of the rock, which is considerable.</p>

<p class="tab">Bob Brownlee has a
series of photographs he's put together from the atmospheric test series. In
many of the early atmospheric tests we had smoke rockets that were fired
prior to the shot to leave a curtain of tracers in the atmosphere, so we could
watch the air shock from the atmospheric burst, and calculate its dispersion
and strength and so forth. We were looking at some of those photographs one day
and Bob said, "Watch the smoke trail go by." We were looking at a
long view of some bunkers, and the smoke rocket trail went by from left to
right, and he said, "Now, watch it come back." And I said,
"Recompaction." We had all of the physics in front of our eyes way
back in the 1952, 1953 period from the atmospheric tests, because the air does
the same thing. When the shock wave goes by, that's not the end; it comes back
again. And that's the recompaction in the air.</p>

<p class="tab">I think we saw these
things, and we didn't think about the importance of them, or that they really
were clues to something far broader than we had constructed a concept for.</p>

<p class="tab">The point I'm trying
to make is that the rebound is a necessary part of the shock expansion, and one
that we ignore because of our calculational mindset. We run calculational
problems in an artificial one-dimensional framework, which is okay; we can put
even a boundary out there, and it sort of works for most things. Except, it
doesn't properly tell us the rest of the story. What happens after the shock
wave is gone? For a long time we were happy if we could run a one-dimensional
computer simulation of a nuclear explosion out to ten microseconds. That made
the cavity start to grow, and all these things start to happen, and the shock
wave was gone out of the problem. But we didn't ask what happened after that.</p>

<p class="tab"><b>Rimer</b>: I was amazed when I came to
S-Cubed that people were talking about this "mystical magical
membrane," when, to a civil engineer, there was nothing mystical or
magical about it at all. The residual stress concept for metals, structures,
and concrete is a very well-known and well established concept in civil
engineering.</p>

<p class="tab"><b>Carothers</b>: What kinds of things bring that
about? Certainly not a shock wave.</p>

<p class="tab"><b>Rimer</b>: Plastic failure, under a
non-uniform stress distribution. Say you take a column and press on it. That's
a uniform stress distribution; it doesn't introduce residual stresses. But if
you take a beam and put a load on it, you introduce compression on the top, tension
on the bottom, and so you get a non-uniform stress distribution through the
beam. Or, the torsion of a cylinder. If you load it into the plastic regime,
the outside fibers get loaded higher, and they go plastic first. When you take
the load off, stresses get locked in. That's a well-known concept in civil
engineering.</p>

<p class="tab"><b>Carothers</b>: Well, we didn't have any civil engineers 
considering this problem. All we had were physicists and calculator types.</p>

<p class="tab"><b>Rimer</b>: That's right.</p>

<p class="tab"><b>Broyles</b>: I don't remember who really
came up with the actual idea of the stress cage. It was based on some calculations,
but it was fairly nebulous. When you look back at it, it's so simple that a
high school physics student can understand it. When you deform something
classically, and stretch it out elastically, it rebounds, and is going to have
a residual stress.</p>

<p class="tab"><b>Carothers</b>: That wasn't appreciated by
people for a long time.</p>

<p class="tab"><b>Broyles</b>: No, and we at Sandia didn't
either. And it's not at all clear yet under what conditions, particularly in
alluvium, are you going to get how much of a stress cage, or how consistently,
or regularly. I think it's quite clear-cut that in tuffaceous materials you regularly
get a stress cage, and that there's creep, and that it decays. And that you can
cause perturbations in it, and get yourself in trouble with things like
line-of-sight pipes sticking through it.</p>

<p class="tab">We got started, and
Wendell Weart got started, worrying about hydrofracing as a way of breaking out
of the cavity. He started trying to understand how you could have calculations
which said you had several times overburden pressure in the cavity, and not have
the stuff get out of the cavity. We then developed, and did the first in-situ
measurements, using high explosives, that really demonstrated the containment
stress cage, I don't claim that Sandia invented the idea of the stress cage,
but I think we really pursued it, and proved it in a real environment, even
though we were devoting most of our efforts to the line-of-sight shots.</p>

<p class="tab"><b>Bass</b>: I believe I have seen firm
evidence of the existence of a residual stress situation, in some situations in
the field - but in a homogeneous rock. Years and years ago we did two
experiments at Sandia. A fellow named Lynn Tyler did a residual stress
experiment called Puff and Tuff. I did all the calculations on that thing, and
I'm very proud of Puff and Tuff. It was a beautiful experiment. We fired a 256
pound charge, which had two pipes looking at it. One came down the tunnel we
used to put the charge in. We put a funnel on the front of it, where it went to
the HE. That was calculated to keep the pipe open, so the gas would come down,
and then be there available to crack the formation. It is very important that
you put the funnel on; otherwise the hydrodynamics will close off the pipe right
away, and you get no gases in it. The tunnel was stemmed, of course.</p>

<p class="tab">When we were first
designing the experiment, that was the only pipe we planned. AI Church, of the
firing group, was sitting in on the meeting on firing the HE, and he said,
"Why don't you just drill a hole on beyond the charge, and have one that
is in the tuff, not in the stemming?" So, after we excavated the place for
the charge, we drilled a hole on into the tuff. It was six inches in diameter,
and we put a transit pipe in it and forgot about it. And again we put this
funnel on. Thank God Allen suggested that pipe, because that one worked, and
the one in the stemming didn't work at all.</p>

<p class="tab">So we fired the shot.
The HE gases went down the pipe in the tuff, right away, and delivered enough
pressure at the end to crack the rock. We know it got down there very quickly
because we had a pressure gauge at the end of the pipe in the stemming to find
out when the gas got down there, and it got down there like a bat out of hell.
We had calculated where the residual stress should be, and when we went back in
there was no cracking at all for one cavity radius beyond the original cavity.
Then all of a sudden we have a vertical crack that goes up and down as far as
you can see, with black detonation products all through it. But there's
absolutely no crack where we calculated the existence of a residual stress
field. Now, I think that is very good evidence.</p>

<p class="tab">There was one thing
that was bad about the experiment. That was, we did change the stresses in the
tunnel by the excavation. In the same place where this residual stress field
would be, we had a modified stress state due to the excavation. This always has
to be considered. There's some creep that will take place, and there will be
some differences. But indeed, you could go back in there and for a full cavity
radius there was no crack at all. We used the Alpine Miner when we went back
in, and we stopped it every six or eight inches, and did a complete map of the
area.</p>

<p class="tab">Now, something very
interesting happened with the pipe in the stemming. We closed that pipe in the
stemming. That stemming was supposedly GSRM - rock matching stemming grout.
Now, you know as well as I do, it doesn't match at all. Indeed, we closed the pipe
in the stemming; we did not close the pipe in the tuff. I think that this
happens should be known in the containment community.</p>

<p class="tab">On Carl Smith's high
explosive experiments we do see some stress records that look good, and there
may be an indication of residual stress on those. I believe I've seen residual
stress twice. Once was on Puff and Tuff; the other was a precursor to Puff and Tuff.
That was a five pound cylindrical HE charge. It was the first thing that Lynn
Tyler did.</p>

<p class="tab">After the shot Lynn
got a very bright guy to go in and dig it out. This guy had nothing better to
do, and he went in there with a dental pick, a tiny chisel, and a paint brush,
and dug it out like an archeologist. He found a cavity, a nice little cavity,
elongated because of the cylindrical charge. Of course it was small, and the material
was a nice smooth, very homogeneous, weak tuff, with no cracks in it at all.
Then he found a region that didn't look like the same stuff at all. It had
absolutely no structure to it. He did find some little cracks too; right on the
edge of the cavity he found some circumferential cracks. Then he got into this
region of absolute mush. He went into this region, which was about the same
size as the cavity. Then he went to the edge of that material, and he found circumferential
cracks all the way around, and radial cracks running all over hell. Now, I claim
that is a stress cage. And, unfortunately, I have just given you the best write
up known to man. It has never been documented, and I cannot get the man who did
it to do that.</p>

<p class="tab"><b>Carothers</b>: Carl, your gauges can survive
for a little while in a ten kilobar regime. It would seem it would be fairly
straightforward for you to make measurements at, say, one kilobar.</p>

<p class="tab"><b>Smith</b>: One kilobar is pretty close to
the crossover point, where things last forever.</p>

<p class="tab"><b>Carothers</b>: Then you should be able to make
measurements which would address the question of whether there is actually such
a thing as a residual stress cage, or whether it is a figment of the calculator's
imagination. Have you done any work on that?</p>

<p class="tab"><b>Smith</b>: That has been a prime question
for ten years.</p>

<p class="tab"><b>Carothers</b>: If it's still a question, you
must not have gotten the answer.</p>

<p class="tab"><b>Smith</b>: On the HE shots, at a kilobar
and below, we have long-term measurements that do show the existence of the
residual stress cage, very clearly and unequivocally. These are from both the
stress gauges that show a long-term offset, and also from the motion gauges,
which are integrated accelerometers, that show the rebound. They show you the
material coming back in, and when you look at the calculations you will see
that motion is what sets up the residual stress cage. That's really quite clear
from the HE tests, which go from eight pounds up to two thousand pounds. In addition,
we have been quite successful in measuring cavity pressures on most of those HE
shots.</p>

<p class="tab"><b>Carothers</b>: If your measurements clearly
show the existence of a region of long-term higher stress around your shots,
why are there still arguments about whether or not there is what is called a
residual stress cage, which presumably is the principal mechanism which causes
nuclear events to be contained?</p>

<p class="tab"><b>Smith</b>: I suspect that nowadays
everyone sort of believes there is residual stress, because it's been talked
about and thought about for so long. But, good valid measurements on the
nuclear scale are very hard to come by, and I think this is related to the
inhomogenieties of the field. On the HE scale we were doing experiments in very
selected areas, and we very carefully explored the geology ahead of time to
make sure we had a good uniform material. We took a lot of samples to have it
characterized, and so we had a lot of data for the calculators to play with. It
was an almost homogeneous bed to work in, without fractures and faults, or
major discontinuities. But when you go to the nuclear scale, you are
encompassing all those geologic problems. The argument may be more now, “What
are the departures from a homogeneous region, and how do these departures affect
the residual stress?" Maybe these departures are sufficient to negate it
to some extent, or in some regions.</p>

<p class="tab">While I was doing
hydrofrac work I was also involved with the measurements on the DNA nuclear
shots. Occasionally Don Eilers would talk Bob Bass into making measurements on
some of his vertical shots, and so there were about a half dozen vertical
shots, including some LLL shots, where we did some measurements.</p>

<p class="tab"><b>Carothers</b>: When you're working in the
tunnels you're always working in the tuffs. Were the vertical shots deep enough
that they were in the tuffs too?</p>

<p class="tab"><b>Smith</b>: Most of them were, but there
was one I remember that was in the alluvium. That was U10be, one of the
Livermore shots. It was a low yield thing, and we got some fairly nice
measurements on that. It was the early days of the gypsum concrete plugs, and there
were two stress measurements in one of those plugs; one at the top, and one
near the bottom. They saw a little over half a kilobar, and after the dynamic
phase they came down and showed about a hundred bar offset. We were recording
the signals on a tape deck, which would run out of tape at about eight minutes.
But, at about seven minutes these signals, which had been decaying, got down to
zero stress level. So, those are a couple of measurements in alluvium that
suggest there was a residual stress field loading that stemming plug. And so
there are these bits and pieces of measurements on nuclear shots which say,
"Yes, there's a residual stress."</p>

<p class="tab"><b>Carothers</b>: If you have a shock that's
moving out in an infinite medium, after the shock has passed the material moves
back a bit, doesn't it?</p>

<p class="tab"><b>Rambo</b>: Yes. I see that in the calculations.
I think that's part of the fundamental process. There's material outside of the
plastic region which responds in an elastic way. The wave runs through and pushes
things out, and that whole elastic area outside of the plastic region tends to
want to come back in an elastic type rebound. Even the plastic area does some
of that.</p>

<p class="tab">So, for a brief
period, we see in calculations, and it certainly is up for endless discussion,
that there is a rebound. The data that we look at, in terms of velocity data,
tends to show that also; the overdriven system wants to come back a little bit,
to flow back, or to compress around the cavity. In the calculations we tend to
see that kind of motion. We think that's the source of our residual stress field,
and that's the source of what helps us in containment. That's without respect
to any reflections from layers, or the surface. Those tend to come, usually,
after the rebound for a lot of events, but of course there are some that come
earlier due to where layers are.</p>

<p class="tab">We see this motion in
the velocity gauges that are put around many of the shots. You see the peak
wave, and then the velocity starts to come back. If you integrate those, in
many cases you get the motion of the material coming back, either to where it
was or maybe not quite as far, depending on where you are. There are many cases
where it comes back all the way, but there are a few cases where it doesn't.</p>

<p class="tab">The surface of the
ground is a free surface, so the stress at the surface is, in the calculations,
always zero. So, there is a reflection back, and it runs back down toward the
shot. Spall is the occurrence of the doubling of the particle velocities at the
surface. They're traveling twice as fast as the particles do from down below,
and so the ground tends to break apart. You see a rise at the surface that, if
you have a sharp wave front, will go twice as fast as the particles do down
below. And so this sends a signal that is releasing the stress.</p>

<p class="tab"><b>Carothers</b>: The shock goes out as a
compressional wave, and is reflected back as a tension wave? It tends to pull
the residual stress cage apart, in a sense?</p>

<p class="tab"><b>Rambo</b>: That's exactly right. Bob
Terhune was worried about this tension, or rarefaction wave coming back from
the surface on some particular shots. He thought he was able to see, in the calculations,
some shots that had difficulties because high velocities brought this
rarefaction wave back before the residual stress had time to set up. In the
calculations, and I'm not sure I can answer exactly why in all cases, but if the
rarefaction gets back before or during the time of the setup of the residual
stress, it doesn't behave as well, at least in the calculations, and it may not
set up right. And that may be a detriment to containment.</p>

<p class="tab"><b>Hudson</b>: I would say that the idea of a
residual stress field as the key to containment is little more than a myth.</p>

<p class="tab"><b>Carothers</b>: You have attempted to make
measurements of the residual stress field on some nuclear shots, haven't you?</p>

<p class="tab"><b>Hudson</b>: I have. Not very successfully.
I have one set of data on a low yield event, where the stress in the ground, in
the vicinity of the deepest plug, which turned out to be about where the
residual stress field was expected, peaked at about a kilobar, or a little
less, which was about where it was supposed to. It then fell rapidly to an
almost steady state level at perhaps a fourth of a kilobar, which was kind of
what was expected, or predicted for residual stress. I even published this, not
too widely, but within the community. The data were criticized because there
was no way we could demonstrate that the gauge had not been significantly
affected by the strain in the medium.</p>

<p class="tab">This whole subject is
called the inclusion problem. If you're in a stress regime where the ground
behaves as a fluid, you don't have a problem, and you can probably make very
good stress measurements. That boundary is probably at three or four kilobars.
Above three or four kilobars almost everything acts, in the ground anyway, like
a fluid. So, if you can measure the pressure, you probably know what the stress
is. When you get below, say, one kilobar, then you're trying to make a
measurement in a material which doesn't necessarily expand again after it is
compressed. The result is that you can have a residual strain - residual
compression, residual expansion, what have you - that continues to make the
gauge feel like it's in a higher or lower stress field, when it really may not
be. So, I sort of gave up on making residual stress measurements. They're
almost imponderable.</p>

<p class="tab"><b>Carothers</b>: There was somebody who said
that he could not think of any kind of stress gauge that you can make that
isn't sensitive to strain.</p>

<p class="tab"><b>Hudson</b>: These stress gauges I'm talking
about were designed so they could be corrected for strain. Some materials are
much more sensitive to strain than others, and some are much more sensitive to
stress than they are to strain. So, by using the right combination of materials
you can subtract out the strain. But it's still hard to convince everyone that
you've properly accounted for the problem.</p>

<p class="tab"><b>App</b>: I don't believe we know as much
about the residual stress as we once thought we did. The people who have looked
at the stress cage more closely than anybody have been the DNA. They have
better control, because they're able to mine back, and they can use more
gauging at working point level than we can. I've looked at the data that Carl
Smith and Bob Bass have been collecting. We've been using that data, and it's
interesting that they cannot consistently see a residual stress in their stress
measurements. Now, it may be an instrumentation problem, or it may be that the
residual stress really is absent, or at least different than the way we model it.
I don't know which. Calculations certainly show the formation of a residual
stress field. There's no doubt about that. But that doesn't mean it actually
exists in nature.</p>

<p class="tab"><b>Carothers</b>: There are people who might say
something like the following: "The physics is right. The codes are right.
And if you lived in a uniform, homogeneous world, and you calculated what was
going to happen, you would see a residual stress cage, and it would be there.
But you don't live in such a world."</p>

<p class="tab"><b>App</b>: Well, the codes are pretty good
at looking at the potential effects of layering, and non-homogenieties. One
suspicion is that material that has been shocked, has been worked, has been
strained, and has had tremendous pore pressures built up due to trapped water,
is a completely different material than it started out as. It loses its
strength, and cannot support a residual stress field.</p>

<p class="tab">Some of the
theoretical models predict no stress cage. The physics in the effective stress
models would suggest that, out at least to some range, you have zero strength
in the material. Now, the material has to have some residual shear strength in
order to have a residual stress field. It has to be able to support deviatoric
stress, or stress differences, in order to have a stress field of the type
we're referring to, where the stress tangential to the cavity is higher than any
other stress component. If the shear strength goes to zero, you can't have a
residual stress field. There has to be some residual strength in that rock.
Now, the question is, does that material have essentially no residual shear
strength?</p>

<br>
<p class="tab">Russ Duff, of S-Cubed, has
questioned the role of the residual stress as the principal agent of
containment. As he expresses it, it is not the physics used in developing the
calculational codes, but the presumptions upon which they are based that should
be called into question.</p>
<br>

<p class="tab"><b>Duff</b>: The important observation, to
me, in the Rainier reentry, was that the explosion developed a large
quasi-spherical cavity with a reasonably well defined lower boundary. This
lower boundary was surrounded by roughly a meter of plastically deformed rock,
which was fractured at more or less regular intervals. But, outside of this
meter or so, the statements are that the rock displacement seems to be
dominated by generalized block motions, by motions that occurred along faults,
bedding planes, joints; weaknesses in the rock of one sort or another. Now,
that observation was made, and was well documented - there are photographs,
there are sketches, there are the clear words.</p>

<p class="tab">We can set that next
to the comments that have been often made by Joe LaComb and others, that inside
of something like two cavity radii you really can't make sense out of the
displacements. Things move around in an unpredictable way. For instance, on Tom-Midnight
Zephyr, which was a relatively low yield shot fired in Area 12, there was a
reentry hole drilled from the tunnel back towards Tom through a region of
displaced tuff. If you look at the configuration, and you expand the cavity,
displace the rock as the naive picture would displace that rock, the reentry
hole, RE #1, would pass from the tunnel to the working point through displaced tuff.</p>

<p class="tab">What was observed?
Rubber, steel, electric cable, grout, tuff; little bits and pieces of all kinds
of things. There was not spherical displacement, or quasi-spherical
displacement. This is an example in the relatively recent history of the same
thing that was pointed out concerning the displacements that were seen at
Rainier. Now Rainier was very much simpler, being a shot with no line of sight,
and no stemming in the way tunnels are currently stemmed.</p>

<p class="tab">The community has
known this now for thirty years, and I feel that we haven't drawn the obvious
conclusion from it. The conclusion is that our first-order model of what
happens after an explosion, which is based on the assumption that a
one-dimensional spherical picture is an acceptable, a correct first
approximation to what goes on, is simply not correct. As we do more complex
things, as we worry about layering, or as we do line-of-sight experiments in tunnels,
or things of that sort, then we go to axi-symmetric calculations. We try to
treat the wave reflections from interfaces, we look at the collapse of tunnels,
and the interactions with line-of-sight pipes, and things of that kind. This is
all based on an extension of our belief that the first-order approximation of
one-dimensional spherical motion is at least a place to start.</p>

<p class="tab">Out of this basic
assumption comes our concept of the residual stress field. We say the explosion
occurs, the cavity forms, the rock is forced out, there is plastic distortion.
There is then elastic rebound, which compresses the rock, builds up a residual
stress field, and "Voila!" We have the intellectual explanation for the "mystical magical
membrane" that people used to talk about before the 1973 or 1974 time
frame, when the residual stress concept was widely taken to be the basis for
containment.</p>

<p class="tab"><b>Carothers</b>: Would it be fair to say that
this assumption of a spherically symmetric cavity growth is based on the idea
that the amount of deposited energy is so large, is deposited so fast, and the shocks
that develop are so strong that within that region you're talking about it
doesn't really matter what's there? That it overwhelms the material properties,
and it doesn't matter whether it's tuff or alluvium or granite or whatever? Is
that the basis of this approximation, do you think?</p>

<p class="tab"><b>Duff</b>: Well, that may be the basis of
it, and that is what was observed at Rainier, but that approximation seems to
apply only for one meter past the cavity boundary- not for the region over
which we think the residual stress field sets up and is effective.</p>

<p class="tab"><b>Carothers</b>: Which you take to be between
one and two cavity radii?</p>

<p class="tab"><b>Duff</b>: Yes. So, I think what we have
done, and I'm saying DNA now because DNA is the only testing organization which
has made a practice of trying to measure rock properties and strengths in detail,
is we've taken cores of the rock, and we have protected that core as well as we
can. We have then sent it to the laboratory, primarily to Terra Tek, and they
have developed good and presumably reliable techniques to measure the
mechanical properties of that rock. And we have used those measured properties
as input to material models, which then go into the code, and the continuum mechanics
calculational procedures then give us predictions of stresses, velocities,
displacements, and ultimately, residual stresses; all the observables and
calculated parameters of interest.</p>

<p class="tab">I believe, however,
that if nature tells us that the displacement for a major part of the overall
phenomenon that we're looking at is not quasi-one dimensional, but is governed
by the motion of more or less arbitrary blocks of rock, the predictions we get
from a one-dimensional model may not be correct.</p>

<p class="tab">Now, I want to
qualify that in the following sense. The explosion of a nuclear device does
give rise to a very large energy release, and it gives rise to very high
pressures. These pressures are going to send shock waves out, the shock waves
are going to make material motions to generate particle displacements, particle
velocities, and they will compress rock just as the one-dimensional argument
says. But, if a material is free, or if a material chooses to deform in a
non-radial way by slipping along joints or faults or bedding planes, then the
overall response will be, or may be, intrinsically different than what we have
accepted as intellectually satisfying. In other words, I'm arguing that the
residual stress concept, which comes out of the one-dimensional simple picture,
may be one of those constructs which seems consistent with the understanding,
which is intellectually very satisfying, which meets the needs of the
community, and which is flat wrong.</p>

<p class="tab"><b>Carothers</b>: I thought DNA people had made
post-shot measurements in the tunnels, and that they had found evidence of residual
stresses.</p>

<p class="tab"><b>Duff</b>: They have not found residual
stress. The DNA efforts to measure residual stresses have come in two areas,
basically. One of them has been reentry hydrofracs. They will decide that
they're going to run a reentry tunnel between the work drift and the main drift
on a particular shot. Usually before DNA runs a tunnel they do an exploratory
boring to make sure that there's nothing ahead of them that would cause some
particular concern. So, they'll have a drill hole that goes from some place
near the end of stemming to the cavity boundary, or the cavity vicinity. After
they've finished the reconnaissance in that hole they sometimes will hydrofrac
it . They set a pair of packers in two places and pump in, let's say, blue dyed
water. Then as they mine back - when they reenter
this area they can see that the blue fractures go some direction, and some distance.
From this they can get the directions of the fractures, and from the
measurements of the hydrofracing pressures, they get an idea of the stress
states that existed at the time.</p>

<p class="tab">Some of the
experiments have shown directions of fracturing which are consistent with the
expectation, or prediction, of a residual stress field. Inside of a particular
radius the fractures are perpendicular to the hole, and outside they are
parallel with the hole, or vice versa. But the magnitudes have, I think,
routinely been comparable to or less than the magnitude of pressure required to
break the rock before there was a shot. So, there is only at most a very small
stress increase, but sometimes there is evidence that the directions are right.</p>

<p class="tab">Also there have been
some efforts to install hydrofracing instruments. Typically this is a hose, or
a pipe of some sort, at the end of which they put what has been described as a
rebar nest. That is a whole bunch of rebars welded together, jammed in the end
of a hole and grouted in. One can then hydrofrac this area with red dye,
measuring the pressures. After the shot, and hopefully very soon after the
shot, one will pump in blue dye and try to frac the rock again. Then when you
reenter you compare the directions of the red fractures with the directions of
the blue fractures. And you compare the pressure measurements as indications of
the stress states. I don't think these techniques have worked very well - the pressure
lines break when the shot is fired, or something happens to the equipment.</p>

<p class="tab">There is a third
system which is described as the zero moving parts system. This is equipment
developed by Terra Tek, in which there is a high pressure vessel connected to a
scratch gauge which indicates pressure. When the ground shock comes along, this
high pressure vessel is opened, and a colored fluid is injected into the rock.
The scratch gauge indicates the pressure history in the fluid. No electronics,
no moving parts except the fluid runs out, and that's it.</p>

<p class="tab">That has provided
data from at least one experiment. The evidence from the one case where it did
work, that I heard about, is surprising because the indicated stress, at
basically zero time and immediately after, was lower than pre-shot.</p>

<p class="tab"><b>Carothers</b>: Well, we know that can't be so.</p>

<p class="tab"><b>Duff</b>: No, I don't know we know that
can't be so. The measurement is not consistent with the expectation of a
residual stress, but you can argue that well, after all this was only the first
time the equipment apparently worked. Maybe it didn't work, maybe there was
some bug somewhere - so try it again. Maybe they have tried it again; I don't
know. I think that when it comes to measuring residual stresses in a nuclear
environment, we haven't done it. There are a lot of technical reasons why it's
hard to do.</p>

<p class="tab">In the nuclear case,
the early cases, when there were indications of low stresses, people said,
"We didn't get around to reentering and drilling this hole and doing the
hydrofrac until three, four, five, six months after the shot. Maybe the stress
has just leaked away. But it must have been there earlier." Some of the
other experiments, like the zero moving parts measurement by Terra Tek, suggest
maybe there isn't any in the first place.</p>

<p class="tab">They have found some
evidence that the directions of fractures are what one would expect based on
the predictions, but they haven't found strong stress fields. Now, one can
argue, "Oh, they have decayed away." That might be true.</p>

<p class="tab"><b>Carothers</b>: There were tests done at SRI -
small amounts of HE detonated in concrete blocks - and residual stress fields
were found.</p>

<p class="tab"><b>Duff</b>: Those were the grout-spheres
tests at SRI. I think in that case we may have been misled by experiments which
were modeling a real world, but the models were too good, in a sense. The
grouts as poured were sufficiently homogeneous that the assumptions of the
one-dimensional model were in fact reasonably valid for those experiments.</p>

<p class="tab">The measurement
technique which was used in those tests consisted of circumferential copper
wires cast into grout spheres. The sphere was then placed in a magnetic field,
such that as the cavity was formed, and as the grout moved radially outward,
the wires cut the magnetic field and generated a voltage; this voltage was
proportional to the velocity of the wire. The diagnostics worked, and that in
itself tells us the motion was reasonably uniform. It was not dominated by
block displacements, which would have sheared the wires. That is a major
diagnostic problem in the nuclear area; it's very difficult to get cable
survival, which is why it has been difficult to get cavity pressures or cavity
gas samples on a routine basis. The conclusion I've come to is that we have measured
residual stresses in the grout spheres experiments, where we're dealing with a
homogeneous, well-behaved material. And they seem to be strong. But they go
away quite quickly, through some diffusion or creep process.</p>

<p class="tab">I think any time that
nature responds as the one-dimensional calculations suggest that it should
respond, we will in fact get all of the results of the one-dimensional
calculations - the residual stress field and all the other things that go with
it. My point is we that have had, in the books, the results of the very careful
work that Livermore had the opportunity, and the skill, to do on Rainier. And
all of us have heard Joe LaComb and others talk about the difficulties of understanding
displacements within a couple of cavity radii of an explosion. I don't think we
have drawn the appropriate conclusion from the information we have. And that
conclusion, as far as I'm concerned, is that the assumptions we've made about
how the world is going to respond do not lead to the way the world does
respond. Therefore, the conclusions that we draw from our assumed response prediction
may not be correct.</p>

<p class="tab">I think there is some
residual stress field, because there is some plastic distortion. There is an
elastic rebound, but I doubt if the residual stress field is of the magnitude
that we predict, is in the locations that we predict, or that it sets up at the
time that we predict. It's some result of the distortions and the displacements
which actually occur, but not those that we assume based on the simple
one-dimensional models.</p>

<p class="tab"><b>Carothers</b>: Let's see if you would agree
with this. The calculations are fine, and they predict the right phenomenology,
but for a world we don't have. If we're going to believe, or base our actions
on this kind of a model we could be wrong. You might go on further and say that
there are a few cases where we have been wrong for reasons that we have not yet
explained, and the model does not give an explanation.</p>

<p class="tab"><b>Duff</b>: Precisely. I think that's well stated.</p>

<p class="tab">Let's look at some
other bits of evidence. Cavity radius. I'm not talking about whether the cavity
is oblate, or prolate, or spherized. We have a constant factor, called the
K-factor, that is used in every presentation as a measure of the expected cavity
size. And we find that 70 is a remarkably good empirical scaling
constant for cavity size at NTS.</p>

<p class="tab"><b>Carothers</b>: Well, plus or minus twenty percent.</p>

<p class="tab"><b>Duff</b>: There is some spread. From
eighty to sixty would get ninety percent of the cavities. Now, if you were to
go to the person doing the calculations and say, “I have this rock. It is a lava
from Area 19, and it is a pretty good basaltic material. We took it over to
Terra Tek, and they said it was hard, tough, strong. Okay, Mr. Calculator put
that into your code and tell me what the cavity dimension is going to be."</p>

<p class="tab">While he's doing
that, somebody from Los Alamos brings in a core taken from the Sandpile
alluvium. And with some effort Terra Tek will, in fact, come up with a strength
for that. You give that to Mr. Calculator and say, “Tell me how big the
cavity should be."</p>

<p class="tab"><b>Carothers</b>: About the same size?</p>

<p class="tab"><b>Duff</b>: No way.</p>

<p class="tab"><b>Carothers</b>: Well, that's what we see.</p>

<p class="tab"><b>Duff</b>: Sure. But that's not what we calculate.</p>

<p class="tab"><b>Carothers</b>: Well, that's Mr. Calculator's fault, isn't it?</p>

<p class="tab"><b>Duff</b>: Is it, Jim? Is it his fault, or
is it the fact that the containment community, of which I am one, and my hand
is up as guilty, has had its head in the proverbial sand, like an ostrich, and has
been ignoring the data?</p>

<p class="tab">My point is, we can't
calculate even something so simple. The concepts that we think apply, namely
that the material properties as measured in the laboratory, and fed into the
material models that we want to use, give the right answers, don't. They don't
give answers which are in good agreement with our observations. There are two
things we can do about that. One of them is we could say we didn't calculate it
right. Another one is, we could wonder if our model is wrong. Maybe we're not
thinking about the problem right. What I'm suggesting for consideration here is
that we're not thinking about it right.</p>

<p class="tab">And I have a piece of
evidence. Let's consider Pile Driver. That was an experiment done in granite.
The strength of that granite, measured in the usual Terra Tek or Livermore
manner, I think turned out to be eighty kilobars. It is an extremely strong, competent
rock. You put that into a code like TENSOR at Livermore, or TOODY, or STAR at
Pac Tech, or CRAM here, or SKIPPER here, and you get a very small cavity
radius. And you get a number of other observables related to stresses and
velocities. You get certain predictions. Then you ask, "What is the
data?" The data is quite different.</p>

<p class="tab">Norton Rimer is one
person who has had reasonable success trying to fit a material model to the
Pile Driver experience, from first principles. He started with an explosion in
a rock whose properties he defined, and made sure that he got the particle
velocities and the stresses that were measured. In order to do that he had to
use what he called an effective stress model. In other words, he said,
"The strength of the rock is not even to a first approximation what Terra Tek
measured." Its strength is related to the fluid pressures which you
generate in the little fractures. The point is, it was the inhomogeneities in
the rock, and not the rock itself, which were central to an effective
description. Effective means we had a model which at least agreed with the
observations. The straightforward calculation that we would make the way DNA,
or Los Alamos, or Livermore ordinarily treats the problem doesn't come close.
The code is probably okay; that's just F = ma, usually. And if one has done his
job right on certain test problems you can believe that F = ma, and the code is
computing that.</p>

<p class="tab">But I want to
emphasize this point again in connection with the cavity radius observations. I
think we are dealing with a situation where the response of the ground to the
explosion is dominated by interface slipping characteristics. And, the
interface characteristics are likely to be quite different from the apparent
characteristics of intact rock. It is not inconceivable to me that the
interfaces in hard rock can slip more or less as easily as interfaces can in
alluvium. This leads me to question the prediction, the expectation, of a
residual stress which comes from simple continuum mechanics codes. There the
intrinsic assumption is that material points which start out close together
will end up close together.</p>

<p class="tab">This assumption leads
to a whole bunch of conclusions, residual stress being one of them. If the
essential phenomena are governed by motions which don't satisfy the fundamental
continuum mechanics assumption, then I don't think that as technical people we
are justified in expecting the predictions of continuum mechanics to apply.</p>

<p class="tab">What this leads me to
is a real question of whether the very convenient, very comfortable, appealing,
residual stress concept, which we've all talked about for the last eighteen
years, is more than a crutch; more than a construct which is convenient, but
which may be quite irrelevant to our real problem. Now, I don't know that the conventional
wisdom is wrong. I am saying there's a body of evidence that leads me to
question it.</p>

<p class="tab">For the last several
years there has been a damage failure surface which goes into the DNA
calculations. A rock is assumed to be damaged by the shock process, and its
strength after shock passage is less than it was before.</p>

<p class="tab"><b>Carothers</b>: How damaged unspecified, but
damaged in some way?</p>

<p class="tab"><b>Duff</b>: Yes. If you take a rock to
Terra Tek and you squeeze it; release it, and then you squeeze it again, it
will show less strength than it showed the first time. It has been damaged in
some way. We have modeled that kind of effect. The models that are used by the DNA
community at the present time relate weakness to stress level. In other words,
if you stress a rock to four kilobars, its strength is reduced by, say, thirty
percent. If you go to six kilobars, it's forty percent. A stress related damage
criterion is used in the code, and that fits the experimental data that comes
out of the laboratory. It doesn't fit the experimental data which you would
derive from core recovered after a shot.</p>

<p class="tab">That core is weaker
than would be expected, on the basis of the existing damage models. Norton
Rimer and Bill Proffer have been doing some material modeling work, and Norton
has looked at a different way of describing damage. Instead of using a stress
related criteria, he's using a strain related criteria. If you distort rock
five percent, to make up some numbers, say the strength goes down ten percent.
If you distort it twenty percent, the strength comes down more. He has
developed a model, which is very preliminary, in which the model parameters
chosen for the calculations were fitted to give the same results along a
laboratory uniaxial strain load to four kilobars, and a biaxial strain unload
as in the earlier damage models.</p>

<p class="tab">In other words, he and
Bill treat the Terra Tek data in the same way. However, the two models give
grossly different results on laboratory paths to peak stresses to eight kiIobars.
The newer strain dependent model has the additional feature of approximating laboratory
test data on post-shot damaged samples, whereas the earlier models did not. All
of the parameters for the calculations consist of a single set of shear-strain
parameters, and a range of damaged strengths varying from mush, for close-in,
highly strained material - which is consistent with the measurements - to approximately
one-half the virgin strengths. The results of the calculations show a later
rebound, longer duration of rebound, and a residual stress state which Norton characterizes
as marginal for preventing cavity gases from moving significant distances from
the cavity. The calculated residual stress field has lower peaks at considerably
greater ranges, and in fact, there are multiple residual stress peaks that come
out of these calculations.</p>

<p class="tab">The residual stress
concept, as we've thought about it, is based on relatively simple models of
material response. Either the material is just strong - it's elastic-plastic
material, and does things as an elastic-plastic material does - or it is a
material which degrades in its performance it a particular way based on the
stress levels reached. And, we have gone from these calculations to an
intellectual construct, which gives us a framework in which to evaluate containment.
Norton is saying, "If I look at exactly the same laboratory data in a
different way, and certainly there is no a-priori basis for saying a stress
criterion is better than a strain criterion for describing the onset of damage,
I get qualitatively different answers."</p>

<p class="tab"><b>Carothers</b>: Tom, for years people have
lived with the residual stress cage concept as a measure of goodness, if you
like, when calculations are presented. I have had difficulty finding anyone who
would say there was good experimental evidence for this residual stress, this
"containment cage," in the field.</p>

<p class="tab"><b>Kunkle</b>: I have discussed this with Fred
App at some length, and he is one of the principal modelers of residual stress
fields around nuclear events. Indeed, he would very much like to have a stress
profile, or a pressure sensor record to work with. The trouble is that the
stress cage occurs in regions of intense groundshock; scaled ranges of maybe
twenty scaled meters, and we don't have equipment that normally survives there.
Livermore has fielded some experiments in an attempt to look for the residual
stress, and I don't believe they've ever had a gauge survive and return unambiguous
pressure measurements that could be interpreted in terms of residual stress.
So, it's a theoretical concept that we've never been able to validate, but we
don't have, to my knowledge, any experimental data that would say it's
incorrect. A major factor in containment research throughout the underground
test program is what is the nature of the so-called "magic membrane"
that keeps all the gas inside the cavity, or nearby the cavity.</p>

<p class="tab"><b>Carothers</b>: John, did your early SOC
calculations show a residual stress field around the cavity?</p>

<p class="tab"><b>Rambo</b>: Our calculations did show that
rebound phase, but because it was a spherical calculation it was constantly
bouncing. The wave would go up to the surface and come back down, and then go
back up again. But, by and large you could see some differences in residual
stress if you had different strengths in there. So, it was kind of good enough
to roughly characterize those things, and if you did have a big reflection
coming in from the surface, or the edge of a layer that was close in, which was
also spherical, sometimes that would make a difference in what you saw, even in
a spherical sense.</p>

<p class="tab">And we thought,
"Well, you know, it's kind of conservative because these reflections come
back rather strongly, and if you can survive it as a sphere, then maybe you can
survive it in a real situation where the layers are flat and not reflecting
quite so strongly." That was the logic behind how we started in that area,
and we did do a lot of calculations which we got up in front of the CEP and
presented, showing these things.</p>

<p class="tab"><b>Carothers</b>: There are people who say there
is no experimental evidence that we have, that shows a rebound and a stress
cage on an actual shot. Maybe you do get stress fields over here, but they might
be bigger than you calculate, and over there they might be smaller, or
non-existent, because of the various beds, and layers, and faults, and blocks,
and so on. Could you comment on that?</p>

<p class="tab"><b>Rambo</b>: You said we've never measured a
residual stress, and I say, "Well, is that because we haven't been able to
measure it effectively, or is it that the measurements that did take place didn't
show anything?"</p>

<p class="tab"><b>Carothers</b>: Well, rarely do you look. When
you do, the instruments don't survive. Or it's been a long time later, and that
stress field has decayed. It is, in fact, a very difficult experimental problem.</p>

<p class="tab"><b>Rambo</b>: There was some data from
Orkney, a Livermore shot up in area 10. This event did have gauges that would
supposedly measure the hoop stress and the radial stress, in two different locations,
and the instruments survived. In fact, you could probably run them today if you
wanted to. I ran a 1-D calculation to see if I got anything that looked like
what they measured. The calculation that I did, going through my normal
procedure of guessing things about the material properties, showed residual
stress. The gauges also showed what looked like a residual stress, but not to
the degree I calculated it. The timing was about right, but the magnitude of it
seemed to be less than I calculated. I think that what's happening out in the
real world is that there may not be as much residual stress as I calculate.</p>

<p class="tab">You can get into
arguments about, "Well, was that real data, or are there other things that
went on?" That argument goes for almost everything we've measured in the
field. My point is, maybe what I'm doing isn't completely erroneous. Over the
years I've come to put a lot of faith in the shear strength in my models, as
being part of what takes place in terms of this rebound, and how good it is and
how good it isn't. In looking at a lot of the logs, where I've tried to divine
the shear strength from looking at the velocity logs, I get a feel that the
shear strength varies all over the place. It's one of those things that comes
and goes, and comes and goes. You can look at density logs and they don't look
the same as what we might be experiencing terms of shear strength.</p>

<p class="tab">What I think is out
there is not homogeneous, and I agree with that completely. I think that there
are areas where the residual stress may look a lot better than in other areas.
It may have a lot to do with why you get cavities that are not spherical, and
why you may go in one direction, even horizontally, or off to one particular side,
and you don't see the things that you see in a calculation. And that's because
of the limited amount of information I have, to do what I have to do in terms
of averaging properties and organizing the materials. I'm looking for generic
effects when I do these things, and weaknesses. But I have to also say that
there are some cases where we've modeled a generic weakness, and we may have
seen the same thing in the field. I say, "may", because the
statistics are very poor.</p>

<p class="tab">There are things like
Baneberry, which we modeled, that didn't show residual stress. There was a lot
of evidence that it didn't have anything like that. For instance, it leaked out
of the ground. More recently there was the Barnwell event, which looked
calculationally like it had residual stress problems. And after the shot there
was radiation high in the stemming. There was Nash, which I did run some
calculations on and compared to the Bourbon event. Nash looked worse than
Bourbon, and Nash leaked but Bourbon contained. That is probably the only
evidence of things actually having happened that I calculated.</p>

<p class="tab">The statistics are
very poor. There have been cases where I've calculated things that showed
residual stress, and they leaked, or had some difficulties. And there have been
some cases where I did a calculation which showed that didn't have any residual
stress, and they contained just fine. But there's one thread that seems to wander
through these calculations of residual stress, although the statistics, as I
said earlier, are terrible. That is, there's usually something else wrong with
the event besides the residual stress. On Baneberry there was lots clay and
lots of water. On Barnwell there was also quite a bit of water. On Nash there
was a lot of CO<sub>2</sub>, a non-condensable gas. Those things may play a
factor. If you know you haven't got any residual stress, it may be a secondary
thing that is really important. To draw a conclusion out of three or four
events like that is a very poor style, but nevertheless in this business, I
keep looking for a thread.</p>

<p class="tab"><b>Carothers</b>: Russ Duff has said that the
calculations are not wrong, but the world in which you work is not the kind of
world that the calculations calculate. That's the business of the
inhomogeneities, the layers of different rocks, the three dimensionality,
possibly block motions. If you only had the right kind of world, the calculations
would be just fine, but you're applying them to a world that doesn't exist.</p>

<p class="tab"><b>Rambo</b>: I would like to temper that
comment a bit. There are some areas where the non-homogeneities are more
apparent than others. Take the tunnels, where you're in stronger rock, and
there are lots of fracture planes. They have indeed seen motion along these
planes, and the calculators that I talk with say, "We just can't model
that sort of thing yet. Or maybe we will never be able to model that kind of thing."
Those fracture planes may play a strong role in what eventually ends up as the
non-residual stress, or the residual stress being taken away. But as you get
down to the Flat, the differences in the strength are not quite as different.
In the Flat we're talking about more of a soil type of material, but still
there are those areas that have hard rocks and porous materials.</p>

<p class="tab">My experience is in
looking at drilling rates. In the Flat, drilling tends to go fairly quickly
through most of the tuffs - not all of them, but most of them. I get a
different impression from that than what I see up on the Mesa, in looking at
the strengths that are measured in the tunnels. It's just a bias that I've
picked up over the years, in looking at, and becoming more aware of what's
happening in the tunnels. A calculator tends to look at things a little bit
differently, because he's looking for, or trying to divine, properties that
have to do with containment, or those he thinks have to do with containment.</p>

<p class="tab">Another answer to
this question about residual stress is that many of the people who say there
isn't anything such as residual stress are talking about shots in the tunnels.
That's the discussion that seems to be going on now. One of the things that has
come through this whole business is that, in the lore, low yield events have more
trouble containing than high yield events. And, the people in the tunnels are
always shooting in a sub-kiloton to maybe less than two kilotons range, for the
most part. They have done ten kilotons shots, but the low yield events seem to
be showing most of the residual stress problems. Or, most of the events where
they've leaked radioactivity have been in the low yield range.</p>

<p class="tab">To a first degree I
try to put layers in the model at different strengths, but there may be things
that we don't know are there, or cracks, or the strength properties we may
think are all one strength may not be. My argument is that you see more of this
kind of thing in the tunnels than you do out in the Flat. My feeling is you
ought to see it where you have relatively high strength rock with cracks, and with
lots of weakness around the shot point. Those things are going to move, and
they do move; in the tunnels they can see that they have.</p>

<p class="tab">Although we can hit
those kinds of things occasionally in the Flat, I believe we're in more of a
soil-like material where the difference in strengths between the material and
the fracture zones is less. So, the block motion is not going to be quite so
strong.</p>

<p class="tab"><b>Carothers</b>: How long do you think the
residual stress stays there?</p>

<p class="tab"><b>Rambo</b>: In looking at Billy Hudson's
cavity pressure measurements, that pressure seems to decay rather quickly for a
half minute or a minute. Then it seems to decay very slowly. I'm saying you can
only have cavity pressure if there's something there to hold it, so I'm making
an association between the cavity pressure that's sitting there, and some sort
of residual stress that holds it in. Your question hasn't got an easy answer to
it.</p>

<p class="tab"><b>Carothers</b>: What mechanism would you
hypothesize that would allow or cause a relaxation of the residual stress?</p>

<p class="tab"><b>Rambo</b>: I think there could be constant
readjusting. First of all, the cavity pressure is likely to decay away because
there are cracks and porosity for the gases to go through. As this happens I think
the pressure against the cavity walls becomes less, and the materials start to
rearrange themselves in terms of stress fields. You hear this in the geophone
record as a constant rumbling that's goes on after the shot, before collapse
takes place. I think the cooling can even bring some of the cavity gases into
condensing to the point where the cavity is at less than atmospheric pressure,
and that has certainly been noticed on some shots.</p>

<p class="tab">I think this
relieving mechanism is just the normal part of the collapse process that's
taking place. I don't understand it very well; I can understand how you can get
pressure decaying, and causing some of that. What happens after that is just
mysterious in my mind, because I've never heard any explanation of it. It has
to do with things like what's the strength of various blocks, and this, that,
and the other thing. It's the mysterious part of this business, that we have no
knowledge of, that sometimes has a lot to do with the success or failure of a
shot. That was Agrini and Riola. There are mechanisms out there that have
nothing to do with residual stress or what's in the cavity, and that is the
risk factor which we can't do much about that goes along with a shot.</p>

<p class="tab"><b>Carothers</b>: Mr Rimer, from things you have
said, I take it that you believe in the residual stress field.</p>

<p class="tab"><b>Rimer</b>: I believe in it for relatively
homogeneous materials. The problem is, on nuclear events, we have never
successfully measured residual compressive hoop stresses. There are one or two measurements
where we put the gauge side-on, and we've gotten records that last a long time.
There are funny things that I've seen when you compare those records to a
radial stress record at the same location.</p>

<p class="tab">On small scale
experiments, like the SRI grout spheres, we've actually seen the effects of
residual stress. There was a tube in those spheres that was to connect to the
cavity after the explosion, so we could hydrofracture from the cavity. Well,
once there was a break in the tube, and instead of going all the way to the
cavity, it broke somewhere in between. When we pumped in that dyed fluid, it
went all around the cavity, right where the dip in the residual stress field was
supposed to be. It didn't go into the cavity. It found the easiest path, and
that's where it went.</p>

<p class="tab">On HE tests Carl
Smith has measured very long time stresses. Unfortunately, these are the radial
ones, the ones that don't matter too much. We need the hoop stresses. It is a
strong containment diagnostics goal of DNA to try to measure these residual
stresses.</p>

<p class="tab"><b>Bass</b>: You're not liable to see
residual stress show up on a radial stress gauge, and that's where all the
measurements are made to try to find it. You can see it on a hoop stress gauge
if the hoop stress gauge lasts long enough. Those measurements have not been
very successful, and they are too far out.</p>

<p class="tab"><b>Carothers</b>: A criticism I have heard of
those measurements is, "Convince me that you're measuring stress and not
strain."</p>

<p class="tab"><b>Bass</b>: I won't argue that point at
all. Especially when you get down to the range where you can make the
measurement. When you get below the shear strength of the tuff, which is
three-tenths of a kilobar, I don't know what's going on, and I don't know what we're
measuring. I think we're measuring the pressure component, rather than a stress
component when we get below three-tenths of a kilobar. And we've got a lot of
information saying that's the case, because the curve bends off the wrong way
when you make those measurements. This falloff steepens when you get below
three-tenths of a kilobar. In my compilations of data, which are used sort of
as the bible of what ground shock exists where, I say don't draw the line below
twice the strength of material, because we don't know what we're doing in that
region. We just flat don't know.</p>

<p class="tab"><b>Rimer</b>: On Misty Echo and Mission Ghost
we, preshot, hydrofractured the rock to get the in-situ stresses. Then
post-shot we hydrofractured it again. Observations in G tunnel by Carl Smith on
HE events showed that the directions of the minimum stresses are oriented
differently post-shot than they were pre-shot. That change remains for many
months; the magnitudes of the stresses don't remain, but the directions do. We
found a change in direction on Mission Ghost. The magnitudes though, where we
predict two hundred bars, they were sixty bars, but they were in the right
spot. The directions were changed, and the largest changes we measured with the
post-shot hydrofractures were near where the largest residual stresses were
supposed to be.</p>

<p class="tab"><b>Carothers</b>: People have talked about the
residual stress as unloading, or relaxing, either due to migration of water out
of the pores, or due to creep, but they don't talk about very long time scales.
Certainly not months.</p>

<p class="tab"><b>Rimer</b>: Minutes. We have tried to
calculate this. Pac Tech has used the standard creep model, with data from lab
tests at Terra Tek on tuffs. We've tried that way, and we've also tried with a
pore fluid migration model, with detailed effective stress concepts. It's difficult;
we can make those codes do almost anything, because we haven't tied down the
material properties, the models of the rock, especially after a ground shock
has passed through. We can't give, from those calculations, a precise time
frame for it, but I would say it's minutes. Because we don't know how to tie
the calculations down, on every event we're still trying to measure residual
stress . But I would say that stress field relaxes in minutes .</p>

<p class="tab"><b>Carothers</b>: It's hard to believe that in
minutes there would be enough fluid migration to do very much. The permeability
is rather low, the pressure gradients aren't all that high, and the fluid has
to move a fair distance. The residual stress field, if it does exist, isn't as
thin as a foot.</p>

<p class="tab"><b>Rimer</b>: No. It depends on the yield of
the device, but it's in the range of many meters. But that's another thing we
don't know - how far the fluid has to move to relieve these stresses.</p>

<p class="tab"><b>Carothers</b>: Dan, let me make a summary
statement that I think represents what a number of people have said about
residual stress calculations. People who calculate shocks going out, and so on,
are using the right physics, and their codes are okay, and the calculations are
fine. However, when they do that they're always assuming a homogeneous medium.
When you look at the grout sphere experiments, or the work that Carl Smith did
- Carl searched around in G tunnel for homogeneous blocks in which to do his
experiments - those are homogeneous media. Unfortunately, the world isn't like
that. There are layers, and cracks, and fractures, and so you don't actually
know what the material properties are, on the scale that you're going to be
calculating.</p>

<p class="tab"><b>Patch</b>: Sure. One of the problems is
basically what you're referring to, which is the geostructure - fractures, and
bedding planes, and all that stuff.</p>

<p class="tab">It would be
surprising if you didn't run into some perturbation of this so-called stress
field that's formed around the cavity. One of the problems that we certainly
have is that we don't have a direct measurement of it. We've been trying and
trying to get a direct ,measure of the residual stress field - what the stress
state is, after the shot is over, for a real shot in a real medium, in more
than one place. That is certainly a very high priority goal in the DNA containment
diagnostic program.</p>

<p class="tab"><b>Carothers</b>: And that's a measurement that
is very hard to do.</p>

<p class="tab"><b>Patch</b>: Yes, very hard to do. The
second thing that has given us a great deal of concern is the time dependence
of this stress state. We think we know when it sets up. We're pretty uncertain,
unfortunately, what its actual magnitude is, and surely don't know when it goes
away. There seems to be a body of evidence that suggests it can go away pretty
darn quickly.</p>

<p class="tab">Terra Tek did some
work back probably in the mid-eighties, trying to simulate creep for loaded
tuffs. It was an outgrowth of these questions and issues that came out of the
SRI program. When SRI fired these little shots, and then subsequently fractured
them, it made a difference when they fractured the cavity. If they did it very
quickly, they found very high fracture resistances. It took measured pressures
as high as five or six thousand psi in trying to break out of those little
explosively formed cavities. That seemed to be pretty strong evidence of a
residual stress field, since the spheres would only hold about fifteen hundred
if you just fractured a natural cavity. But if you waited, the fracture
pressure that the cavity could hold dropped with time, and it dropped very
quickly. A matter of half a minute made a difference - it might bring it from six
thousand down to two thousand or so.</p>

<p class="tab"><b>Carothers</b>: What do you think causes that to happen?</p>

<p class="tab"><b>Patch</b>: There are two schools of
thought. One is that it's basically the pore fluid migrating down the pressure
gradient. Conceptually, oversimplifying, it carries the stress with it. The
fluid flows, and it's under the highest pressure where the stress is the highest,
and it goes away, relieving the stress. And that kind of mechanism scales. The
bigger the shot the longer the time it takes; it all scales as the cube root of
the yield.</p>

<p class="tab">The other possibility
is that it's creep, or a stress relaxation mechanism of a semi-classical type;
a material that is loaded has a stress difference on it, and it tries to flow
in a quasi-plastic kind of way. That, in some sense, is a point property, and
it's independent on the size of the medium. And so, these two mechanisms, in
terms of their time dependence, are very different. The implication is that for
a nuclear shot, if the stress field were flowing out as a pore fluid effect, it
would take a very long period of time, because you're trying to migrate fluid
down what is a shallow gradient in terms of psi per foot, and you have to move
a lot of water. The other mechanism is independent of that. It just tries to
equilibrate stress differences. Each little microelement of the material, if
you will, is unhappy and readjusts it's grains, or whatever it wants to do to accommodate
that.</p>

<p class="tab">I have been more of
the creep mechanism school, myself. The reason, as much as any is that some
folks who are smarter than I took a look at what would happen if you took an
stressed material, and had the pore fluid flow out of it. Unfortunately, the
stress is not like colored dye, and the psi's don't flow with the fluid. What
happens is that the material tends to transfer the load; part of it comes out with
the fluid, and part of it is taken up by the matrix of the material. And then
the issue was, does it take up a lot of it, or a little of it. My recollection
is that it didn't really cancel out very well.</p>

<p class="tab"><b>Ristvet</b>: If we believe some of our
recent DNA data, yes, we have residual stress, but it's very small. I think
some of the measurements we made on the last three events kind of suggest that yes,
the residual stress is there, but the magnitude is less than the cavity
pressure. What's interesting is we are now calculating those small numbers
using a discrete element code that allows certain block motions to occur.</p>

<p class="tab">We're getting almost
to the point where we can make some measurements. We're finally getting smart
enough about how to make the measurements, after twenty some events where we
failed. And everybody knew what the problem was; it's called cable survivability.
So we went out and made the hardest cables we could, and I give credit to SRI,
and in part to Carl Keller who modified SRI's design, and then to Sandia who
even made it better. What they have developed is this wire rope wrapped cable.
In the tuff or alluvium I think it will work just great, because it can cut
through the medium, in a sense, because it is so rigid in comparison, and yet
it can protect the soft conductors inside.</p>

<p class="tab"><b>Carothers</b>: Norton Rimer has said that as
far as he was concerned the best location for testing a device was in a weak
rock. If you have a strong rock, like granite, you will get a small cavity, high
pressure, and a lot of tensile fractures. He said he liked a nice soft,
forgiving rock.</p>

<p class="tab"><b>App</b>: Same here. I believe that. Our
current models of the ashflow tuffs at the Nevada Test Site suggest that you
get a stronger residual stress field in them than in other rocks. For example,
you don't get a lot of tensile failure. The failure is predominately shear failure;
the material is not physically pulling apart. Also there is a lot of rebound
for the formation of a residual stress field. Calculationally, the residual
stress is stronger than you get for a weaker material like alluvium, or for a
denser material like welded tuff or lava. I think what Norton said is right.</p>

<p class="tab">Lava is strong in
shear, and it is always jointed. You're not going to find many rocks that are
not jointed. The shear strength might be quite high, but the effective tensile
strength is zero; during the outward cavity growth the cracks open up. During
rebound they close down again, but during that hysteresis period when the
cracks are opening and closing the mechanism isn't there to create a residual
stress field, because residual stress formation depends on shear failure.</p>

<p class="tab">When the material is
failing in shear, as soon as the rebound starts you immediately start forming
the compressive, elastic stresses that comprise the residual stress field. So,
there's a very basic phenomenological difference between a strong rock and what
I will call a medium strength rock such as ash flow tuff. On the other hand, when
you go to a very weak rock, like a Baneberry clay, there's not enough strength
to support any kind of shear, or residual stress.</p>

<p class="tab">If you make a plot of
calculated peak residual stress versus strength of the rock, it starts out very
low, increases with increasing strength, hits a peak, and then decreases with
increasing strength. The way the models are currently set up, it appears that
the ash flow tuffs are almost ideal for the formation of a strong residual
stress field. The fact that the alluvium is very weak doesn't matter that much
because the water table is below it, so it's dry, and there is a lot of volume
to take up the gases, even if it doesn't form much of a residual stress cage.</p>

<a name="ch12"></a>
<br><br>
<h2>Chapter 12: Hydrofractures</h2>
<br>

<p class="tab">As discussed in the preceding
chapter, what might be called the conventional view, and the conventional
calculations assume a homogeneous medium,. Energy is deposited in that medium,
and there is a spherical shockwave that goes out. The properties of the medium
lead to a rebound of the material, and to the formation around the cavity of a
stressed region which is called the residual stress cage, or containment cage.
The stress in the rocks in that region is high enough that the pressure in the
cavity cannot drive gas or fractures through it. In this view, the residual
stress is an important phenomenon in containing the gases produced by the explosion.</p>

<p class="tab">There is another view, which
might be expressed as follows: there are pieces of evidence which are hard to
reconcile with the conventional model. There might or might not be a stress
cage, but as a matter of fact, such a concept could be a wrong road. The principal
mechanism that accounts for containment could be the release of cavity pressure
through fractures driven from the cavity. Because of the nature of the material
the fractures don't propagate far enough to reach the surface, although they
might through preexisting weaknesses such as fractures or cracks. Perhaps the
leading proponent of this view was Russell Duff.</p>

<br>

<p class="tab"><b>Duff</b>: There is a very considerable
body of evidence about containment mechanisms that has been around for a long time,
and I don't think our community has responded to that evidence in a responsible
scientific fashion, in that the response has not been as true to the scientific
method as we might like to think. There is an alternative containment concept
to the residual stress cage concept, and that's the work of Griffith and Nilsen
on fracture-related containment mechanisms.</p>

<p class="tab"><b>Carothers</b>: At the CEP you have talked
about calculations which indicated fractures go out very quickly, but there's
so much cooling to the walls, and so much pressure needed to drive them, that
at most they only go a hundred meters or so. In this picture of containment, as
I understand it, the hypothetical stress cage has little to do with it. There
are fractures, and as a matter of fact, the more fractures there are the better
it is, because they lead to cooling, and to a decrease in the pressure in the
cavity.</p>

<p class="tab"><b>Duff</b>: I can provide a piece of pretty
good evidence to support the fracture argument. Let's talk about Red Hot. This
was an event which occurred in a hemispherical cavity. The yield was relatively
small. We have calculated the expected cavity expansion from this event, and
it's about three or four meters. What's observed is roughly one meter.</p>

<p class="tab">When you have a
twenty-three meter start and then you go one more, or you go three or four
more, that is a big relative volume difference. From 23 meters to 24 meters is
a little bit of expansion, like 12 or 13 percent in volume. From 23 meters to
27 or 28 meters is a lot of expansion, like 60 to 80 percent. What mechanism
can make the cavity not expand? Well, one obvious thing is that the pressure
went away. When would the pressure have to go away to make the cavity expansion
only be one meter instead of three or four? The answer is five or ten
milliseconds. Now, that is so fast that whatever happened did so inside of any
time frame in which residual stress fields would be set up; that would be more
like a hundred millisecond time frame.</p>

<p class="tab">So, how can nature
get rid of the pressure from an explosion in ten milliseconds? Nilsen looked at
this problem, and looked at the fracture system that you might expect from such
an explosion in such a cavity. He used his code called FAST, which is a
calculating system which is related in many ways to analytic treatments. He came
up with an answer that it would require fractures from the cavity at roughly
three meter intervals to dump the pressure.</p>

<p class="tab">We reentered Red Hot,
and it happened that the reentry drift intersected a fracture; you can see it
in the floor of the reentry drift. It goes out about fifteen or twenty feet
from the cavity boundary and stops, so it wasn't driven for a very long time,
but it was driven quite energetically. It is a very narrow crack for the last
few feet, but it is quite a large fracture at the cavity boundary. There is a grapefruit
sized hunk of rock in this glass-filled fracture, and that rock came from some
place far away. So, there was at least one fracture on Red Hot. It didn't go
very far, probably because the pressure didn't last very long. Let's say the
pressure didn't last very long because there was a system of fractures, lots of
fractures.</p>

<p class="tab">Nilsen said you could
kill the pressure if you had fractures every three meters. So, Joe LaComb
drilled a hole parallel to the flat face of the cavity, and I believe he
encountered fourteen fractures along the length of this hole. On average they
were three meters apart. So, I think that there is a net of at least
circumstantial evidence which says Red Hot was contained because a whole system
of fractures developed and they dumped the pressure on a very fast time scale.</p>

<p class="tab"><b>Ristvet</b>: There was an another
hypothesis, which was that the crater threw a lot of cold debris into the
cavity. When we looked at the crater through the drilling, with the TV cameras,
it was almost exactly as S-Cubed and myself had predicted. I did it
empirically, and S-Cubed did it calculationally. The throwout was very small, because
the high pressures in the cavity just didn't let anything get thrown out. You
have to have extremely high ejection velocities to move through that
overpressure.</p>

<p class="tab">That also says
something else about the timing, which helped validate the calculations too.
Those high pressures lasted for only a few tens of miliseconds, and then they
dropped very, very fast. That was probably during the time those short, stubby
fractures formed.</p>

<p class="tab">Now, we did see, on
Red Hot reentry, two steam type hydrofracs, the kind with no glass, or very
little glass associated with them. They went up above the Deep Well access
drift to the base of the vitric. They follow the in-situ stress field
perfectly. Those two are not well explained. They had to occur at a very early
time, while the pressure was still up, and probably the other fracs were still forming.
And maybe they continued to grow during the dynamic phases of the tunnel and
cavity growth.</p>

<p class="tab"><b>Carothers</b>: I have heard that on Red Hot
there is a big fracture that extends a long way, and is wide and open.</p>

<p class="tab"><b>Ristvet</b>: Yes, that's also in the Deep
Well access drift, where we saw these two steam-type fractures. Those were
observed during the actual reentry when Bill Vollendorf and probably Mel
Merrit, because he was the scientific director, or whatever the title was in those
days, on the shot, went back in there. And yes, they could see this big opening
in the top of the Deep Well access drift, filled with glass. However, the ones
we actually mined up to were very wide, a foot wide or so, but they didn't go
anywhere. They only went three, four, five meters from the cavity. I think the
viscosity of that glass just plugs those things up real quick.</p>

<p class="tab"><b>Smith</b>: Well, in addition to those
short fractures, there is that fracture that goes over the top of the drift
that went over to Deep Well. And this is a fracture with radioactivity in it.
My predecessor had them drill down, and my impression is that they traced it
down about thirty feet. When I got into the program I was still curious about
it, and we drilled a bunch more holes up. It goes up over a hundred feet from
where the tunnel intersects it; we drilled holes through it, and ran radiation
probes through it. So, in addition to all those short fractures there is this
additional one, and I think people tend to forget about that fracture. They
concentrate on what was found in the DNA work, when they were looking at all
the phenomenology of decoupled and coupled shots.</p>

<p class="tab"><b>Carothers</b>: Gary, there were samples of
glass found in the fractures that occurred on Ranier. Could you tell, from the radiochemistry,
when those fractures occurred?</p>

<p class="tab"><b>Higgins</b>: That fracturing was going on
within the first two hundred milliseconds, because the material found in them
was from the cavity itself, like copper, and uranium. Uranium is one of those elements
that, if it has the slightest opportunity, is going to recombine with any
oxygen present. It had done that, but it had done so locally, sufficient to
create F-centers, where it had stripped away electrons and made a little
electron-deficient well around it. We could see that by x-ray diffraction; we
could see islands around the uranium where it had become uranium oxide at the
expense of all of its good neighbors. It had arrived as a metal, or it wouldn't
have done that, and that record would not have been in the glass. That glass is
bright red, instead of being black, because all of the F-centers are
color-reactive. The bright red color is because the uranium has made some of
the silicon dioxide into silicon monoxide, which only exists as a gas, or in a
glass as a dissolved gas.</p>

<p class="tab"><b>Carothers</b>: You say this fracture occurred
during the first two hundred milliseconds. Does that mean it occurred before
the rebound, and perhaps the rebound shut it off?</p>

<p class="tab"><b>Higgins</b>: That's correct. I think there's
good evidence, from the chemistry, anfdalso now in the calculations to indicate
that. During cavity growth, if the cavity gases are at a high enough pressure,
and they are, fractures will occur. The mystical magical membrane idea occurred
because we knew the pressure was high enough to hydrofract, but it didn't.
Well, there's now evidence that it does hydrofract, and part of the normal
rebound process is pinching those cracks off. I think that in many materials,
like in alluvium, that is also a transient phenomenon, that there is another outgoing
relaxation wave. However, that's a sonic wave, and takes many, many
milliseconds. The stress cage builds up, shuts the fractures off, and then the
stresses relax. By then the pressure and temperature have gone down to where
they are essentially in equilibrium with their surroundings.</p>

<p class="tab"><b>Carothers</b>: Things have to happen in sequence
on a pretty fast time scale to keep you out of trouble in the scenario you
describe.</p>

<p class="tab"><b>Higgins</b>: Yes, that's exactly right. I
believe that pretty fast time scale means some of our mysterious failures are
cases where that sequence was just a little out of step.</p>

<p class="tab"><b>Carothers</b>: From the evidence from Rainier,
seeing the fractures and so on, wouldn't one be led to think that
hydrofractures could occur on all shots?"</p>

<p class="tab"><b>Higgins</b>: Yes.</p>

<p class="tab"><b>Carothers</b>: Now, there are shots which
don't release enough energy to form much of a stress cage, if any. Why don't
they hydrofract to the surface?</p>

<p class="tab"><b>Higgins</b>: I think they do hydrofract, and
what contains them is primarily cooling in the fractures. They don't have
enough energy to form a stress cage, and they also don't have enough energy to drive
a fracture; it takes a lot of energy to do that. You can blow material into the
front of the crack, but to get it very far down the crack is really very
difficult. People who have tried to calculate hydrofracture from a theoretical
point of view are always astounded at how difficult it is to drive a
hydrofracture. To initiate a fracture is very easy. To drive it any
considerable distance is a very hard thing to do.</p>

<p class="tab"><b>Carothers</b>: Particularly when there are
losses into the walls, and where you have cooling so you have liquid at the tip
of the crack, which you're trying to push on from the back.</p>

<p class="tab"><b>Higgins</b>: Yes. Absolutely. The first
thing condensation does, and I think is the most important thing, although I
haven't convinced anyone of it, is to cause the tip of the fracture to cease
being a discontinuity, and become a rounded hemispherical circle. And that
happens fairly fast if you try to drive a fracture with a condensable liquid.
I've often thought it might be fun to try to simulate such things with a liquid
metal driving a fracture into a cold, solid metal. It's not likely to go very
far, because you're going to get a wad pretty fast.</p>

<p class="tab"><b>Keller</b>: When I was at DNA I funded
S-Cubed to build a hydrogen-oxygen torch as a very well controlled high
pressure, high temperature steam source, to use in experiments to validate the condensable
flow codes; the hydrofrac codes. Some experiments were done in sand-filled
pipes to check the porous flow, and some were done in drill holes in G tunnel
and P tunnel. The first two in G tunnel worked very well. The last experiment
in P tunnel was like the Perils of Pauline. They had trouble, and finally it
was a lot of effort which didn't produce very good data. But the first couple
of experiments have been used numerous times as proof of the models.</p>

<p class="tab"><b>Peterson</b>: I and another fellow, and a few
other people here, put together a steam generator that burned hydrogen and
oxygen. With that we did some fracture tests in the very impermeable tuffs in G
tunnel. On the tests we had a bore hole that was drilled in from the tunnel.
What I call the test region, where the steam was being injected, was a
four-inch diameter hole eighteen inches long. We injected hydrogen and oxygen
and burned it in that little section of the hole. And we also injected water,
which turned to steam, to get the right steam conditions. We were trying to get
a steam source that had characteristics similar to what we thought was in the
cavity.</p>

<p class="tab">To do that we were
running about a thousand degree Centigrade steam, and I believe we were running
pressures of seven or eight hundred psi. We could adjust the steam generator to
give whatever we thought we needed for the source conditions. The energy was
tremendous that we were putting in there; we were dumping like one or two megawatts
into that little hole. To run for about two minutes required twenty-four big
cylinders of hydrogen and twelve cylinders of oxygen.</p>

<p class="tab">We looked at the
steam flow, and the fracture propagation. The main attempt was to try to
calibrate the KRAK code, and validate it. So, we looked at steam fracturing
from that source, and steam flow, and steam condensation. We had numbers of
drill holes that had been drilled in at various distances from the source hole,
and we looked at the fracture tip propagation across those bore holes, and
looked at the pressure rise, and so forth and so on. It was to get a better
idea of fracturing, to see whether the models really do calculate steam
fracturing correctly.</p>

<p class="tab"><b>Carothers</b>: When you hydrofracture
something you take some water, or steam, or whatever. You pressurize it.
There's a little discontinuity in the rock, and the rock cracks. The fluid
moves down the crack, transmits the pressure, and the crack extends. That's my
view of hydrofracture.</p>

<p class="tab"><b>Peterson</b>: I don't think it's any different
than mine. I think it's been interesting over the last five years to see what
we've learned in terms of fracturing. If we look at fracturing from a cavity,
and we take a standard tamped shot, the only time, in most cases, that it looks
like you can get any fracture from this cavity is during the time that the
cavity is actually growing.</p>

<p class="tab">That's the only time
that the stress fields are set up in a manner which allows the pressure in the
fracture to be greater than the confining pressure. If the confining pressure
around the fracture is greater than the pressure inside, the fracture just
closes back up. It won't grow. While the cavity growth is continuing, the
shockwave is moving out further, and the shock is way ahead of the cavity. Sometimes
you can see that you can get these fractures that will grow a little bit. They
don't go very far and they don't last very long in time. And then when the
stress fields change, they are again closed right up. So the most you see when
you go back into one of these events is one of these gas seams that people will
talk about once in a while. They saw a little, thin seam that had some radioactivity
in it. Even our calculations, at least the ones that I have seen, never
indicate that once the cavity is formed that you can fracture out of it any
more. If our calculations are right, you just can't because the pressure in the
cavity is too low by that time.</p>

<p class="tab"><b>Carothers</b>: When the cavity is expanding
the material at the boundary has to be moving apart and so that makes it easier
for something to keep pushing it apart, because it's stretching, in a way.</p>

<p class="tab"><b>Peterson</b>: Yes. And when it stops
stretching, and stops that outward velocity you can look at it crudely as the
momentum just squeezes it back together. And the reflection of the stress wave from
a long way away comes back too, and just squeezes it all back shut.</p>

<p class="tab"><b>Carothers</b>: There are pictures taken during
the Rainier reentry showing thick seams of dark material, which were glass from
the cavity, or material from the cavity, that flowed out in the rock a long way.</p>

<p class="tab"><b>Peterson</b>: I don't know what you term a
long way. If you're talking like one cavity radius outside the cavity, to me
that isn't very far at all. Something like that does not disagree with the
analyses that we have done, and is not surprising, and I don't think is
unusual. I think one could expect it.</p>

<p class="tab"><b>Carothers</b>: There was also the supposition
on Rainier that this could be attributed to a separation in bedding planes,
rather than a fracture of the native rock.</p>

<p class="tab"><b>Peterson</b>: I think that's true, but if I
go back and put on a calculator's hat, I don't think it's fair to distinguish
the fact that the fracture went along a bedding plane. I f the stresses are set
up so you can grow this fracture, it's obviously going to pick the easiest place
to go. If there's a fault line that's aimed in the right direction, it will go
that way. It likes to take the easiest path. So, that's where one would expect
to see them. I don't think it's going to start off through the middle of a big
bed of rock all by itself, if it could take the planes in one of the interfaces
and go along that direction.</p>

<p class="tab">I think the
interesting thing from the work that's been done on fracturing is that it has
allowed us to at least think, at the present, that we understand why Red Hot
contained, and didn't just blow everything out of that tunnel.</p>

<p class="tab">There was a plug
formed in the tunnel, and that plug was moving out fairly rapidly. If you go
back and do basic back of the envelope analysis, if you did have a classical
cavity pressure history back in Red Hot, that plug should never have stopped.
It should never have even wanted to slow down. The analyses, now that we can do
fracture calculations, show that if you detonate something in a cavity like Red
Hot, you grow multitudes of fractures. Just multitudes of them. There's no
reason that the world around it doesn't want to fracture.</p>

<p class="tab">Red Hot was in a
pre-formed cavity, and as a result there wasn't much plastic deformation. There
weren't big stresses built up in the material around the cavity. The cavity
pressure is extremely large compared to the stresses surrounding it. And so it
likes to fract, just as they do these massive hydrofracs in the oil field. It's
analogous . So you get multitudes of these fractures, and the harder you drive these
fractures the more of them you get. When you really drive the rock hard, as on
Red Hot, you get a tremendous number of them that are formed.</p>

<p class="tab">So, you get a lot of
surface area, and as you get a lot of surface area, then you get a lot of
cooling. And so you quench the pressure really fast. Of course, that quenches
the fractures, and then they all just sort of dribble out and quit. Yet the
cavity pressure has gone down tremendously to the point that it isn't really a
containment problem. I think that's what our fracturing modeling is telling us.
In the reentry on Red Hot, over the last few years, they've found many of these
types of fractures that have been driven from that cavity. So, the model may
even be correct. I think the fracturing work has been a very good thing to have
done, and has given us another handle on why things contain.</p>

<p class="tab"><b>Duff</b>: The leakage, the almost
disaster, which was associated with Red Hot was related not to a long, high
driving cavity pressure, but to a very poor stemming plan. It was stemmed by a
wall of sandbags, and that wall of sandbags acted as the wadding in a shotgun.
It was put in motion by the pressure, and proceeded to knock out the succeeding
closure systems, one after the other. It came to rest twelve hundred feet down
the drift, and we were just lucky.</p>

<p class="tab"><b>Carothers</b>: John, arguments have been made
that hydrofractures from the growing cavity are at least part of the reason
shots contain. Do you place any credence in that model?</p>

<p class="tab"><b>Rambo</b>: I certainly place some credence
in it. I think the hydrofractures don't go all that far because of the cracks
there are in the rocks. So, they tend to cool down, and not go too far. But that
puts, I think, a little more responsibility on us to think about what other
pathways are available for the gases to go someplace. I think hydro fractures
are part of it.</p>

<p class="tab"><b>Carothers</b>: The pressure acts everywhere.
There's a bedding plane, go that way. There's a fault, go that way. You can't
take account of that in your calculations, can you?</p>

<p class="tab"><b>Rambo</b>: No, the late time phenomenon is
not accounted for. When we do run into to a residual stress problem that we
want to look at further, we take our material properties down to S-Cubed. They
can run calculations that do the dynamics, and accounts for hydrofracture where
the gas is allowed to flow out in some worst case scenario, like a single
hydrofracture. How far is that going to go, for example. That's what we did on
Barnwell, and they did calculate a fracture that went something like a hundred,
or a hundred and fifty meters. That was a couple of cavity radii or so. Hydrofractures
don't seem to go further than that, at least in the calculations.</p>

<p class="tab"><b>Carothers</b>: Norton, you've done a lot of
calculational work on hydrofractures. Tell me something about hydrofracturing.</p>

<p class="tab"><b>Rimer</b>: I hope I'm telling you people
at the CEP that there are limitations on what we know. Therefore we make
assumptions, which we consider conservative, and that's a funny word to use, since
we try to overestimate, and to do things in a direction to overestimate the
length of a fracture. For example, we assume that the rock has no fracture
toughness, no strength in tension at all. If it has strength in tension, the
fracture will be slightly shorter. We assume we get one single fracture. If
there are multiples, the driving pressure will go down faster, and the
fractures will be shorter. We do the worst-case calculations, and if those are
acceptable, if they give short fractures that aren't going to threaten things,
we're very happy.</p>

<p class="tab">We don't know the
actual details of a lot of this. For instance, we don't know how to calculate
the initiation of a fracture; a fracture initiates at a point of weakness. How
could we possibly know where in a cavity that's going to happen, especially
after the cavity has expanded a factor of a hundred in volume, or forty in volume,
depending on which shot we're talking about? We can't possibly know that, so we
assume it initiates.</p>

<p class="tab">Another thing is that
it is difficult to make clear what we mean by a hydrofracture. The classic
hydrofracture is one where the gas breaks the rock, and pours out through that
fracture. That's not what we believe happens. We believe there are preexisting,
or shot formed, planes of weakness - bedding planes, faults, all of which may
be closed pre-shot - which are the likely places where something will open, and
the radiation may come out along those planes. It's not breaking new things, in
general. I don't think, in a tamped event in tuff, that we've ever really seen
a hydrofracture, in the classic definition of a hydrofracture. What we've seen
are radioactive seams which we've encountered on mining for a new event, two
cavity radii away. We've seen radiation. The Geiger counter registers
something, otherwise, you wouldn't have noticed it. You look more closely, and you
see gray, altered tuff, which looks like it encountered some steam. And, it's
invariably on some bedding plane.</p>

<p class="tab">It's the steam in the
cavity that's the fracturing gas, and that alters the tuff. There are other
phenomena with steam, and we do consider them. With all the models we presume
the fracture initiates, and presume only a single fracture. We can model
multiple fractures, and we have done that successfully for the Junior Jade HE experiments.
Then there are a lot of degrees of modeling that we employ in our fracture
calculations.</p>

<p class="tab">The first thing we do
is model a fracture where we assume cavity pressure is right at the tip of the
fracture as it expands. And we only limit the speed at which it can grow by
solid mechanics considerations; fractures cannot go faster than half the
Raleigh speed - half of the shear wave speed, roughly. We allow it to go into
any zone in the code. That gives us the most likely direction for the
hydrofracture. The next thing we do is take that direction, and we presume a single
fracture goes along that path. We insist that only those cells that are along
that path are allowed to fracture. Now what do we do as to how the material in
the fracture behaves? We can assume it's steam, and allow it to condense, allow
it to seep into the wall, allow heat conduction into the wall. Or, we can remove
those assumptions, and make the fracture longer. We try all sorts of different
assumptions, to see where it gets us.</p>

<p class="tab">We include all these
assumptions, or we don't include them to give degrees of conservatism. And one
of those assumptions is that steam is in the fracture, and either it can or it
cannot condense. We calculate the temperature of the gas. We have all that
capability. Most recently Bob Nilson has put in a different approach to the
fluid flow in the fracture. He's doing a finite difference approach now, which
allows us to put in inertial effects. So, we're doing all those detailed
models. We're not maybe having the nth degree of precision; for instance, we're
modeling the steam as condensable and not based on temperature. We're not
putting a good equation of state of steam in the code. We could, but why slow
down the calculation?</p>

<p class="tab"><b>Carothers</b>: When you say that you get the
direction that the fracture might go, what determines that? Do you put in an
estimate of the in-situ stress field?</p>

<p class="tab"><b>Rimer</b>: Within the two-dimensional
limitations of the code we put in in-situ stress fields. The vertical stress is
rho*g*h; the weight of the material above it. We put that in exactly in all of
our calculations, to the extent that the grid of the code is in equilibrium. If
we run it a million cycles, without the bomb, nothing is going to move. That we
had to do for the geophysics calculations, because they're very late time. For
the horizontal stresses, the two stress components have to be equal, due to the
two-dimensionality, otherwise you get horizontal motion. But they don't have to
be equal to the vertical stress. And we've done calculations with those stresses
equal to the minimum stress measured pre-shot in the ground.</p>

<p class="tab"><b>Carothers</b>: In the tunnels you have the
opportunity to get insitu stress measurements; directions, magnitudes, and so
forth?</p>

<p class="tab"><b>Rimer</b>: Yes. It's an interesting
phenomenon. It's really 3-D. One of the minimum stresses is the horizontal stress.
The other principal stress, horizontally, is usually as large as the vertical
stress, so we can't model that in the code, but it's conservative to model that
one as a minimum also, because the lower the stress, particularly for a
decoupled shot, the more likely a fracture path will exist. For a tamped shot
those stresses don't mean diddly, because you get a good residual stress field.</p>

<p class="tab"><b>Carothers</b>: When the tip of the fracture is
growing, what does the tip look like? Does it have a radius, or is it a mathematical
point, or what? How do you put that in the code?</p>

<p class="tab"><b>Rimer</b>: The mathematicians who do this
like to have it be a mathematical point. We allow it to propagate through a
cell at a given speed. It's a simplification. The more important thing is, what
is the pressure distribution of the gas along the fracture. If you're driving a
fracture through a strong residual stress, cavity pressure may have to go all
the way to the tip before you can open up the fracture further. In a decoupled
event, we calculate a distribution of pressure, fluid pressure, along the
fracture, and sometimes the tip is opened by tensile failure, the actual
tensile stresses in the rocks surrounding the fracture at the tip. And, you may
not have any gas at the tip, but you're still prying open the fracture. There
are a number of analytical solutions, theoretical solutions, that Bob Nilson
has tried FAST against, and we've run the full code against simplified cases to
see if we match the mathematical solutions, and we do.</p>

<p class="tab"><b>Carothers</b>: You mentioned tensile failure.
That would imply to me you were driving steam, or water into the fracture, and
that the fracture was opening ahead of where the slug of water was.</p>

<p class="tab"><b>Rimer</b>: That's right. It's being pried
open, particularly if the material around it has not failed. If it's elastic
you have this strong rock just being pried open.</p>

<p class="tab"><b>Smith</b>: The calculators talk about the
tip of the fracture being out in front of the water, and indeed we found that
in our hydrofrac work in G tunnel. We would hydrofrac with dyed water, and then
go back and chase the fractures, the dyed marks. We would sometimes find that
the dye would quit, but there would be a fracture in front of it, and so indeed
it looked as though pushing that water in was prying open the rock. There were
sections out in front of the dyed fluid, the water, that had fractured before
the water had gotten to it. Of course, the calculators were delighted when we found
that phenomenology, because they think they had predicted it.</p>

<p class="tab"><b>Rimer</b>: If the material around the tip
is plastic, then you don't have a lever action, so you can't pry anything open.
It's the actual conditions in the rock that really matter. For some situations,
the actual plastic failure is very important.</p>

<p class="tab"><b>Carothers</b>: If you're doing your calculations
with a two dimensional code, isn't that a form of built-in conservatism? The world
is really three dimensional, and so many effects vary as r-cubed, but you're
taking account of them as r-squared.</p>

<p class="tab"><b>Rimer</b>: That's a very good point. I'd
say yes and no. It's not that things go as r-cubed - we have the spherical
attenuation in the two dimensional code. The problem is the shape of the
fracture. If the fracture is horizontal, the axis of symmetry of the 2-D code makes
it a disc. That may or may not be bad. However, if the fracture is up at an
angle, like we showed as the most likely path for Misty Echo, it makes the
fracture be a cone, and that's not the same volume for the fracture.</p>

<p class="tab">The worst case may be
if you just had a strip that fractured, like toward the Baneberry fault. We
always felt that one of these days we were going to get back to Baneberry, and
model it assuming the fracture is not as a complete disc or cone, but just as a
little piece in a particular direction. That would deplete the cavity pressure less.
The time when that fracture came out, which was minutes, may be very sensitive
to the amount the fracture depletes the cavity pressure.</p>

<p class="tab"><b>Ristvet</b>: You've seen many a calculation
presented at the CEP where the peak of the stress field was about one and a
half cavity radii out beyond the cavity wall. Now we think it's out a little beyond
two cavity radii with the damage models that have come into being. It was
always comforting to see that two or three times cavity pressure, so you could
say, 1/ Ah, there's no way it can hydrofrac out of there." Well, there are
some cases where the residual stress would probably be very small, so I've had
a number of hydrofrac calculations done at S-Cubed. It turns out that it's very
hard to hydrofrac even if you don't have any residual stress.</p>

<p class="tab">We used to model
everything as one hydrofrac, and maybe the only time we ever have seen one
single major hydrofrac out of a cavity was perhaps Baneberry where there was a
very preferential pathway. There was a clay loaded fault, which I would not
want to have passing through my cavity, especially one oriented such that the
cavity grew up into it and didn't really displace it through radial shear. I
think that would be a very scary situation, even if we don't create residual
stress for all the other reasons that have been talked about.</p>

<p class="tab"><b>Kunkel</b>: We can begin to plot the
frequency of fractures at some distance from work points by other bore holes we
have drilled. In the valley testing areas we have lots of holes, and we very infrequently
come across radiation from a previous shot in another hole. When we do it is
always the object of much curiosity. Certainly we're not commonly getting
fracturing at large distances away from our shots, large distances being half a
depth of burial.</p>

<p class="tab"><b>Carothers</b>: Byron, on your reentries, aside
from Red Hot, do you see physical evidence of hydro fractures? Have you come
across something wh ere you said, "Yes sir, that's a hydrofrac?"</p>

<p class="tab"><b>Ristvet</b>: Yes, but it's very rare. The
ones we have found have been solitary ones, maybe two, typically along bedding
planes or pre-existing faults, and they've extended to a couple of cavity
radii. They may actually occur during the dynamic growth phase, when the
material is in tension basically, and you can have radial shear.</p>

<p class="tab">Usually those are
very interesting, because we don't see any glass. What we've always seen is
altered tuff. It sort of looks like gray portland cement. We've taken tuff, and
when you hit it with a steam torch, or even a regular torch, you get this gray
powdery material. The zeolites want to go to feldspar, so you're creating these
micro-crystaline feldspars, and so these seams are easy to spot. The USGS, back
in the old TEP days of the sixties, when we were first getting into this
underground thing, were looking at all this stuff. And I believe Gary Higgins
did similar experiments.</p>

<p class="tab">Some of these seams
don't have any radioactivity in them. Some of them have slight amounts, which
are probably the daughter products of some of the early-time gaseous precursors
that got out of there. We've never re-entered soon enough to know what the smoking
gun really was, because all the lanthanum-barium stuff has decayed away, so you
really don't know what gases were down there. You can only sort of guess.</p>

<p class="tab"><b>Carothers</b>: You make hydrofracing sound
much less of a containment threat than some people have feared.</p>

<p class="tab"><b>Ristvet</b>: I think as long as you have a
coupled event, where you don't start off with a big air-filled room,
hydrofracing is not a serious threat. And we've never seen any evidence
ofhydrofrac around any of our low yield events in big cavities, in which the
pressures are, after a few miliseconds, typically three to four times what the pressures
are in a tamped event. I think Mr. Hudson's measurements, and calculations, of
those pressures are pretty close. Again, the calculations say we should have
some short stubby fractures. We've mined right up to the cavities, mined right
into them, and we had experiments on Minnie Jade to try to detect if they ever occurred
and get a timing on them, and we never saw any.</p>

<p class="tab">We drilled back over
Minnie Jade really specifically looking, because Minnie Jade was the first of
those low yield cavity shots. The equilibrium pressure in those cavities is
between five and six thousand psi, which is more than enough to highly
overwhelm the tuff, and there's no residual stress whatsoever. Those cavities
are steam filled. and why they didn't hydrofrac is difficult to say, because
even the codes, as best as we can model things, say we should have some close
to meter long hydrofracs.</p>

<p class="tab">Maybe we do have
hydrofracs of a few centimeters. I suspect that is the mechanism, because our
cavities have almost always cooled faster than the calculations done by
S-Cubed, using simple decay models, predict. When we plug in the empirical kind
of data, we can usually predict them doggone close. I think we do drive those
higher pressure gases, at least partially, into the pores, and that's a pretty
effective cooling mechanism, because the pore water is only seventy degrees Farenheit.</p>

<p class="tab"><b>Smith</b>: I did some hydrofac work in G
tunnel, which evolved into airfrac. We were driving fractures with air, and
again it was to look at the steam hydrofrac problem. We did it with air rather
than steam, because then there is one less variable to play with.</p>

<p class="tab">But, G tunnel kind of
trickled down because they ran into money problems, and there was also this new
wave of the future with ES&amp;H, and all the increasing regulations. It turned
out that the air we had been breathing for years was not adequate. And the electrical
facilities were old. They would have had to upgrade all those things, and the
cost to do that would have been very, very high. To drill a new shaft for air
ventilation was prohibitively expensive. A lot of those old tunnels were in
pretty sad shape, so they were virtually abandoned.</p>

<p class="tab">It was costing about
1.2 million a year to keep that tunnel open, but there was other work in there
which paid part of that. There was work for the waste disposal folks, and there
was some interesting work on gas stimulation which was paid for by private money
from the Gas Research Institute of Chicago. That work was related to the things
they do to hydrofrac gas-bearing formations. What they had in G tunnel was 1,500
feet of overburden, where they could do the experiments, and then mine back
into the areas and look at the results. So, they were able to test a lot of
assumptions about stimulating wells with hydrofracs.</p>

<p class="tab">There was one
experiment they did that was hydrofracing from the surface, 1,500 feet above.
They did the standard industry practice of colored sands, and walnut shells,
and all the usual stuff. Then they started drilling holes, trying to find this
fracture that was supposed to propagate five or six hundred feet. They
eventually mined back and found out it had propagated no more than twenty or
thirty feet from where it started. It got into a region of massive fractures
and just stopped.</p>

<p class="tab"><b>Carothers</b>: As you know, people at S-Cubed
have been doing calculational work on hydrofractures; how they're formed, how they
propagate, and so on. Apparently they have come to the conclusion that such
fractures don't propagate very far - perhaps one or two cavity radii. Perhaps
that's because you simply can't, in a sense, pump them enough. You can't keep
delivering the necessary fluids and the necessary pressures to keep them going.</p>

<p class="tab"><b>Smith</b>: We discovered that
experimentally. No way could we get big enough air compressors to drive those
things. The harder you drive a fracture, the more the aperture opens up.</p>

<p class="tab">We did a whole series
of shots prior to Misty Echo, called Junior Jade. That was a series of eight
pound shots, where we varied the size of the air cavity around an eight pound
charge. We were looking at what point do you begin to create fractures. If the
shot is tightly coupled presumably it will set up the residual stress, and there
won't be fractures. At some point, if the cavity is large enough, you won't set
up any residual stress, and there will be fractures.</p>

<p class="tab">All told we did about
five of these shots, and on the one that was tightly coupled, the cavity indeed
grew, and we measured the cavity pressure. We also measured the volume of these
cavities with a volumetric technique before and after the shot, and then we
mined back into them. On the tightly coupled one, we ended up with a cavity
which had grown to two or three times the original volume.</p>

<p class="tab">On the next step,
with a larger initial cavity, fractures were driven out. The beauty of working
with HE in this soft rock is that all the fractures are stained with the HE detonation
products, which are basically carbon, and so the black fractures just stand out
like gang busters. There were many fractures radiating out from this cavity,
and then, out about ten feet one of the fractures turned. We knew from our old
in-situ hydrofrac measurements that it went in the direction of the in-situ
stress. The fracture always opens up against the minimum in-situ stress.</p>

<p class="tab">Also, the big,
massive hydrofrac out of Red Hot, that goes over to the Deep Well cavity, is
tilted over. On all the hydrofrac work we had done, the fractures were all
vertical, and so I asked myself, "Why is that fracture tilted over?
Surely, it's in-situ stress that controls that thing." Then we started
doing some more hydrofrac work a little bit closer to the portal, and there all
the fractures tilted over.</p>

<p class="tab">As you play with
that, you discover that there is a topographic effect. As you move out from
underneath the cap of the mesa, you're seeing the sloping surface of the front
of the mesa. And, when you go around a bend the fracture also turns, and it's
tilted. Both the azimuth and the inclination of the fracture is affected by the
the topographic surface. When you get down underneath the cap of the mesa, alI
the fractures become vertical. So that answered that question.</p>

<p class="tab">So, when the
fractures got far enough away from the cavities, they turned, because they're
controlled by the in-situ stress. On an HE scale we were able to show that
phenomenology of driving fractures, and actually look at them. With those five
shots, going from fully tamped to decoupled, we could say that in-situ stress
was controlling there. But, we still don't understand the answer to this: when
the HE goes off, how does the shot know whether there's going to be an in-situ
stress field and not be able to drive fractures, versus it's decoupled and can
drive fractures? One thinks of the residual stress phenomena as something
happening later on, and containing the fractures, but it looks like these
fractures grew as part of the dynamic process, because the fractures grew, and
the cavity didn't expand. All that pressure was lost out into the fractures.</p>

<p class="tab">Until that time we
always thought of fractures leaving the cavities because there was no residual
stress field in a partially decoupled shot. The fractures grew in response to
the cavity pressure being higher than the residual stress. But it turns out
that it's part of the dynamic process, right at the start. The calculations say
that the residual stress field sets up when the material rebounds, and that's
fairly late.</p>

<p class="tab">Almost invariably
when we mined back we would not run into any fractures on a fully tamped, fully
grouted shot. First you would start hitting softer material, and there was a
very distinct boundary between this material and the rock that hadn't been
altered, or damaged. You could tell it with a geology pick. Then you hit the cavity.
Now, occasionally we would find a black-filled fracture. And occasionally on
DNA shots they will run into a radioactive fracture, but it's not the common
experience.</p>

<p class="tab"><b>Carothers</b>: It is only fairly recently that
people have begun to say that while there is residual stress, it isn't
necessarily as large as calculated, or as uniform, or doesn't last very long,
and the basic mechanism is hydrofracturing which reduces the cavity pressure by
absorbing a lot of energy.</p>

<p class="tab"><b>Hudson</b>: I can't argue with that. I
think a much more believable scenario than the residual stress scenario is
having high pressure fluid flowing out of the cavity in fractures. It probably happens
all the time. If these fractures are generally distributed, .let's say in all
directions, then probably it's a good thing. The gas is just distributed evenly
in all directions through a large volume, the pressure falls, and it doesn't
get to the surface. That may be what happens every time you fire an event. On
the other hand, every event may be different. On some events the gas may be
bottled up, and they're the ones you should worry about. On other events it may
escape quickly, and you shouldn't worry at all. So maybe the really big
residual stress field is a bad thing to have, because it keeps things bottled
up. We don't know.</p>

<p class="tab"><b>Bass</b>: Carl Smith did a bunch of shots
in G tunnel called Junior Jade. He wanted to look at cracking out of the
cavity. Joe LaComb sponsored it, and it was a very interesting bunch of work.
It falls in with some of the Sandia work on how do you gas frac tuff, and
things like that. And the answer is, of course, that you gas frac, or you fracture
a well with a propellant, not with an explosive. You want a slow burning
propellant to do this work. Well, Junior Jade was very interesting in this
respect because as he changed the size of the cavity you have no cracking, and
then you have cracking.</p>

<p class="tab">It really threw a
real mess into the hands of all the DNA calculational people, because they were
not calculating cavity size right, or anything else. Calculating cavity size is
almost impossible. You've got to have the right material model, you've got to
have the right damage model, and nobody's got it.</p>

<p class="tab"><b>Carothers</b>: Dan, you can take cores and
squash them, and so on, but that core isn't necessarily representative of a
block the size of this room, or this building, which may have one or more
fractures running through it. Therefore, while rebound is certainly real, it may
be more faith than anything else when you say, "I ran some calculations,
and I got a good residual stress field, so this shot is okay." So, there
seems to be a body of opinion that an important mechanism for containment is
that there are lots of fractures that grow while the cavity is growing and the
material at the walls is stretching. They don't go very far, but there are a
lot of them, and that dumps a lot of energy, so the cavity pressure goes down,
and that's what really happens. What are your comments about that?</p>

<p class="tab"><b>Patch</b>: I don't think there's anywhere
near sufficient volume or time available to get rid of a significant amount of
the cavity gas, or the energy that's in the cavity that way. It's conceivable
that in a decoupled cavity shot, or a partially decoupled cavity shot like Red Hot,
fractures can have a significant influence on the cavity state, although I've
always been a little bit bothered by that. I don't see any way, on the average
tamped shot, that you can grow crack volumes that are significant fractions of
the total cavity volume, so it's hard to see how they can influence the
conditions in the cavity.</p>

<p class="tab"><b>Carothers</b>: Then my question is, "Why
don't all shots vent?" Something has to stop fractures which could grow to
the surface.</p>

<p class="tab"><b>Patch</b>: Yes, something has to do it.
The cavity pressures are known, and measured, to be higher than the kind of
pressures it takes to hydrofracture the media. We've done many hydrofracture tests
in the tuffs, and the minimum fracture pressures are 300 to 700 psi - they're
not that big. Now the opposing school could say, "Well, that's okay,
because there's a lot of molten rock around, and you're just plugging up those
cracks with molten rock." So, there are many facets to the argument, and
they confuse, or add ammunition to either camp. I think there is plenty of
evidence that the geostructure certainly perturbs the stress state locally,
because we have data from the many reentries that DNA has done. And it's not
unusual to come across a radioactive seam within roughly two cavity radii, or
thereabouts.</p>

<p class="tab"><b>Carothers</b>: That's not a very long fracture.</p>

<p class="tab"><b>Patch</b>: No, it's not long. And the
seams generally are not that hot, in the radioactive sense. You get some
detectable amount of activity, but you don't get high readings. My impression
is that they're not that frequent either; you don't run into a gigantic network,
or a whole nest of these things. There will be one or two, or maybe three, on a
reentry that are potentially bothersome when you get in close enough.</p>


<a name="ch13"></a>
<br><br>
<h2>Chapter 13: Block Motion</h2>
<br>

<p class="tab">In the post-shot reentries that
DNA has done in the tunnels it has been observed that large blocks of rock have
moved and been displaced as a result of the shot. On the emplacement hole
detonations there is no reentry other than post-shot drilling to recover samples
for radiochemical analysis, so the fact or effect of such block motions is not
known for those events. What effect such motions have on postulated containment
mechanisms such as the residual stress field, or on such phenomena such as
cavity growth or size, is a matter of conjecture. Before the device is
detonated it is not possible to say which, if any, block might move, or how
much it might move. The question, however, is an important one for persons
designing a line-of-sight pipe with various closure mechanisms which are to
protect the samples that are to be exposed. It is possible that motions of the
rocks could damage the sample protection hardware, and cause the loss of much
of the data and equipment that typically is used on the effects shots in the tunnels.</p>

<br>

<p class="tab"><b>Carothers</b>: One of the things people have
seen on post-shot tunnel reentries in Rainier Mesa is block motion. Now, when
people talk about block motion, are they talking about blocks the size of this building,
or the size of this desk?</p>

<p class="tab"><b>Orkild</b>: It depends. A block can be a
piece of rock between two cracks; two joints, or two faults. A crack is just a
break. "Joint" is a generic term referring to how the crack was
formed; a joint is generally formed by cooling, and normally by definition is a
crack that has no motion on it. A fault has had movement. So, depending on the
spacing of the joints and faults, blocks can have sizes from little cubes to
the size of buildings. And, if you move one block you have to move the other
blocks.</p>

<p class="tab">The Rainier unit
itself, called Rainier Mesa tuff, is a series of blocks. Erosion has been going
on long enough that the cooling joints have opened up, and those blocks are
just sitting there, basically held together by gravity. When something happens,
those blocks do move among themselves. As you go deeper into the Mesa, I think
the cracks are smaller, but you still have a series of blocks. And, as you go
deeper, gravity is holding them together better and better, until your eye
might not be able to detect them as blocks.</p>

<p class="tab">When you detonate a
nuclear device, some of those blocks move around a little. This one might move
a lot easier than that one, this other one might not move at all. We only know
what we see in the reentry drifts, but we do see that. When you go back into
the tunnel you can observe, and see that this block slid up over that block
x-number of inches. Blocks do move, and you wonder why that bed down there
stayed there, and this bed up here moved. Then you look and say, “Ah, here's a
nice clay zone that this bed can slide on. It can move along that much easier
than the one below can move along that gravel bed below it. That's much more difficult."
So, blocks do move with respect to each other. We have seen up to a number of
feet of motion.</p>

<p class="tab"><b>Carothers</b>: The picture I've gotten from
what you've said is that we could look at Rainier Mesa as a large piece of
material that has a lot of more or less vertical joints and faults, and a
number of more or less horizontal layers, which were laid down at different times.
And so, in a way it's a fairly loose pile of stuff, on a very big scale.</p>

<p class="tab"><b>Orkild</b>: That's correct, on a very large
scale. Now, the Marshmallow site, in Area 16, was essentially completely
shattered, broken, and cracked. When they mined into it, it was just sitting there
as a mass of rocks, held there by gravity, and it was slowly creeping down the
hill. Each time it got bumped, it jiggled a little bit and settled back again.
The cracks readjusted, and the gases would seep out here and there. Many, many
years from now Rainier Mesa will be like that - essentially a pile of rubble.
The blocks are getting smaller and smaller as time goes on.</p>

<p class="tab"><b>Ristvet</b>: Block motion is interesting to
me is because I got involved with it when I was first at DNA. That was in
relation to survivability of underground structures, from both a defensive and a
strategic aspect. The big question was, at what stress levels do these motions
occur? I said, “Well, it's really more of a displacement level than a stress
level."</p>

<p class="tab">There's two kinds of
block motions in a gross sense, and one has a subset. There's shock-induced
block motion, where you're driving it with the displacements of the cavity.
There's also shock-triggered block motions, and we've seen a little of that at
the Test Site. The high yield shots that were done up on Pahute Mesa triggered
a lot of aftershock activity, which results from built-in strains along the
pre-existing tectonic discontinuities and faults. All we have ever seen in
Rainier Mesa, in all the tunnel events, has been the shock-induced kind of
motion.</p>

<p class="tab">Now, there are two
types of shock-induced block motion. There are the motions that occur along
already existing discontinuities, usually bedding planes with some sort of
material along them that has very low shear strength. It's usually a very thin layer
of montmorillonite clay, typically forty or fifty percent or so. Those motions
are well documented. Typically they occur out to between two and three cavity
radii. It's rare to see them out beyond that, but they have occurred out to as
far as six cavity radii. But, those motions are very small.</p>

<p class="tab">We've also seen
motion on faults. It's interesting because the faults move, if they're
lubricated, but they also seem to be very affected by the in-situ stress field.
At the Test Site the faults that strike northwest don't move, but the faults
that strike northeast do move. Those happen to be oriented properly with
respect to the minimum and maximum in-situ stresses, which are almost
horizontal, and ninety degrees to each other at the Test Site. One is equal to
the overburden, and the other is significantly less - two, three, four hundred
psi less, and that's because of the crustal extension going on.</p>

<p class="tab">The other kind of
block motion is when you get in very close to the cavity, and I don't think
this kind extends more than about half a cavity radius from the edge of the
cavity. Again this is in the tuffs, in the tunnels, and only in the horizontal equatorial
plane. This kind of motion stops very close-in, and that's not where the
residual stress field is. You see lots of schlickensided faces - shears - and they
are almost always either perfectly radial to the cavity, or perfectly
tangential and they're quite frequent. This is from observations.</p>

<p class="tab"><b>Carothers</b>: How much motion do you see? A
few inches, a few feet?</p>

<p class="tab"><b>Ristvet</b>: Anything from a few millimeters
up to ... probably some of the largest motions we have seen, which were on
Diablo Hawk, were motions of thirteen or fourteen feet, on a bedding plane.
There was also a fault that was in part related to that bedding plane motion
which moved, and totally cut off the drift. There was about six and a half feet
of horizontal motion, and two feet of vertical, and that essentially cut the
drift off.</p>

<p class="tab"><b>Carothers</b>: It would seem that the likelyhood
of getting such motion would depend on the way the drift was oriented in the
stress field.</p>

<p class="tab"><b>Ristvet</b>: Very true.</p>

<p class="tab"><b>Carothers</b>: Do you pay any attention to that?</p>

<p class="tab"><b>Ristvet</b>: Well, yes and no. As far as
siting an event, it doesn't seem to make a lot of difference. In the case of
the group of experiments from Miner's Iron through Mighty Oak, it did make a difference
because it really reduced the potential for the kinds of block motion that
would help keep stemming in. It's interesting that on the events where we have
had good block motion, where it's been oriented such that the residual stress
field and the faults crossing the drifts would probably move, we've always had
very good containment. And certainly Misty Rain was not oriented properly, even
though we did see one very major block motion, which was along a pre-existing
fault.</p>

<p class="tab"><b>Carothers</b>: If you think it's good, then it
would seem you could turn the drift a little and have it the way you think
would enhance this block motion.</p>

<p class="tab"><b>Ristvet</b>: Yes, we could, but if we did
that we'd run out of real estate very quickly. It's a desirable secondary
feature, I think. Of course, on Misty Rain, it was almost an undesirable
feature. The only two faults in Misty Rain that were mapped, that crossed the drift,
were the two that moved. And one caught the TAPS, which then didn't close. We
modified the TAPS after that experience to give us more clearance, so if it
ever happened again the door would probably come down and seal. What happened
is, the shroud is very thin metal, whereas the rest is very thick. Now, the
movement was very small. It was less than an inch, but it was enough to buckle
the metal, which caught the door, just barely. When we went in there, even
though the door looked very secure, one did not want to go underneath it
without putting a little bracing there.</p>

<p class="tab"><b>Carothers</b>: You also talk about residual
stress, and it might be that if you do get such motion, it's going to inhibit
or decrease the formation of the residual stress.</p>

<p class="tab"><b>Ristvet</b>: What it does is, it spreads it
out over a bigger area, or a bigger volume. Consequently the peak is greatly
degraded, and allows the relaxation to take place a lot faster, because you're
having rock creep occurring along these planes as the residual stress is trying
to set up. What I'm talking about is not new, and the modelers who work with
the continuum models have been very aware that is probably what real life is
like. We've just always felt it comforting when we thought these motions didn't
degrade it as much as perhaps it does.</p>

<p class="tab"><b>Bass</b>: We have noticed these random
motions; indeed, these disordered motions occur. There's no question about
that, but I don't believe they're controlling.</p>

<p class="tab">Carl Smith had a very
interesting experience on one event. He and I put in a thing called a SCEMS - a
Self Contained Environmental Measurement System. Sandia has been doing them off
and on for years and years. You put in this very strong unit, and then go back
and recover it after the shot. And hope it has worked. Actually it has worked
on some occasions. Right now it's a dead issue; it should never be fielded
again. The last time it cost a quarter of a million dollars, and the data
return was absolutely zero.</p>

<p class="tab">Carl did get some
data on an event not too long ago. He had one of these units up at five kilobars,
and that was the closest we thought we could go. In order to make the
measurements Carl put some cables out from it, to gauges maybe twenty feet in
front of it. We also put gauges in the body of the machine, so when those
cables got broken we would still get something. I had designed these SCEMS in
the past, and in an attempt to make it move with the surrounding rocks we put
big fins around it to tie it to the mountain. That works, and they do tie it to
the mountain. The accelerometers on-board and off-board did show the same
thing. And when you integrate them they showed the same thing, within limits.</p>

<p class="tab">When Carl went back
in, the guys who did the reentry were very careful about it and took a lot of
good pictures, and you can see this chaotic motion of the type Russ Duff talks
about. Here sits the SCEMS, and there sits the outboard gauge. Between the
gauge and the SCEMS the cable does the damnedest didoes you've ever seen. It's
moved three feet this way, and two feet that way, and everything else. And the
motion had cut the cable in various places. That rock does not just move
radially out, in detail, but the general motion is outward.</p>

<p class="tab">Carl has looked at
permanent displacements for eight or ten events, and put them all together, and
has gotten a very nice curve out of it. Even up in the kilobar regime, and
these would be up to five and eight kilobars, which is about as close as you
can get back in and measure and have any accuracy, outward motion is absolutely
a straight function. Inside there's terrific chaos, but that doesn't necessarily
destroy the possibility of a stress cage.</p>

<p class="tab"><b>Smith</b>: There aren't any easy answers
about block motion. The questions are all research problems.</p>

<p class="tab">We did field, about
three shots ago, one of the so-called SCEMS units - Self Contained whatever.
You can't make the cables survive as close in as the gauges were, so you have
this self-contained recording unit. Then, you dig back, recover it, and read
out the recording. There was about twenty feet separation between with the
gauge and the recorder. And, there was a big fault that went through the space
where they were separated. On the reentry we found that the fault had moved,
but a foot this side of the hole with the cable in it there was another hole,
and that hole was intact. That fault moved six or eight inches, and it was a
massive fault that extended for numerous feet, but the movement didn't extend
in one direction at all, because it didn't cut the other hole.</p>

<p class="tab">That makes you think,
“Yes, these big fractures occur, and move at least six inches." But if you
look at them on a global extent, they just don't extend anywhere. You've got
all this massive block movement, but when you go and look at that fracture very
carefully, and look at the other evidence, you discover that there are just numerous
of these short fractures. Now, when you mine back and see what looks like
massive block movement, it may be a whole series of short fractures where each
of them may have moved six or eight inches. But, I don't think those fractures
extend for tens of feet. As I said, I think it's a research problem.</p>

<p class="tab"><b>Bass</b>: We also now have some data
about when those blocks move. We had never had a timing of when blocks moved
until Misty Echo. On Misty Echo I got a lucky break. I found a place to put instrumentation
on a fault that Dean Townsend absolutely promised me would move. And, it was
out at the tenth kilobar regime. So, being at a tenth kilobar I could get
cables to last. I had three-axis accelerometers on each side of that fault, and
we watched it move, and we know when it moved. And we know that it moved contemporaneously
with the peak particle velocity. It moved right away. So, I think block motions
are occurring during the peak of the particle velocity, which I think is a
helpful thing. That's before the stress cage is formed. That's important.</p>

<p class="tab">For a long time
people thought blocks or faults moved in seconds. But on Misty Echo they moved
right at the peak particle velocity, and a funny thing happened to these
blocks. They were sitting there, side by side. In radial motion outward, they
moved together. In horizontal motion they moved together. In vertical motion
they didn't. The one farthest from the device rose up over the other block,
which went out and down. That lasted about for six hundred milliseconds, and
then they moved off together. The bigger block behind became the controlling
block, and started moving down. This is well documented.</p>

<p class="tab">The motion lasted a
second, and we ended up saying it moved seven centimeters, that there should be
an even centimeter vertical displacement
at that point. That was at one second. We said, "Okay, that's interesting.
That should be interesting for seismic source mechanisms, and a few things like
that." We asked Joe LaComb to go back in and verify this by reentry. He came
back and said that there was no motion at all. What happened was that the shotcrete
didn't break. I said, "Damn it, there was motion. Go back and look
again." Joe listened to me, thank God, and he sent F&amp;S back in again
to knock the shotcrete off. I said it moved seven centimeters - it had moved
five. I think that's a fantastic bit of data, as to when it moved, and how much
it moved.</p>

<p class="tab">The question about if
there is all this motion, what does it do to the stress cage - I think the
answer is that the motion takes place before the stress cage is formed. The
stress cage forms on rebound.</p>

<p class="tab"><b>Carothers</b>: You said the motion you
measured took place during a period of like a second.</p>

<p class="tab"><b>Bass</b>: But that was way, way out. That
was long, slow stuff. The blocks were still moving way, way away from the
working point. But that's a good point. You've caught me in a problem there,
but what we measured was a long way from the working point. And those blocks
were moving together at that time.</p>

<p class="tab"><b>Carothers</b>: The stress cage sets up, if there
is such a thing, presumably in less than a second. So, if all these blocks are
going to do all this moving around before that stress field sets up, they have
to do it in less than a second.</p>

<p class="tab"><b>Bass</b>: All the close in ones that
affect containment. I think they are all pretty well calmed down by then.</p>

<p class="tab"><b>Duff</b>: On the reentry of Misty Rain
they drove a tunnel between the initial line-of-sight tunnel and the work
tunnel. It was roughly six meters to the side of the main tunnel. They observed
nine faults, which were not recognized pre-shot, over a range of some twenty
meters or so. They didn't get very close to the cavity boundary, but there were
new sources of displacement even that far out.</p>

<p class="tab"><b>Jenkins</b>: In order to get a feel for the
spacing of faults all you have to do is look at the outcrops surrounding Yucca
Flat. You can see that the density of faulting is much greater than we show in
the cross sections. I think that holds pretty well throughout the tuff units,
especially the stronger ones, like those buried under the alluvium, for
instance.</p>

<p class="tab">A number of very
small movements along the faults would give the impression that the blocks are
shifting. And they do, but on a scale that's difficult to illustrate. In other
words, instead of making very tiny lines on the cross section, you put in the
dip of the unit, and the boundary of what you think will be the major faults.</p>

<p class="tab"><b>Carothers</b>: So, if I want to talk about
very small fractures, faults if you will, I will find them every couple of
meters in the Test Site? That's typical of basin-range geology?</p>

<p class="tab"><b>Jenkins</b>: Yes, it is.</p>

<p class="tab"><b>Carothers</b>: It is hard for me to visualize
what happens when a block of material the size of this building moves a foot or
so. Where does the material go that used to be where the block moved to?</p>

<p class="tab"><b>Jenkins</b>: Well, along faults, especially
rotational faults, you have a lot of problems with conservation of material.
It's awfully hard to do. The material goes some place, and we never seem to know
where that is. But, we can see the fact that the block has moved. It was here,
and now it's down there. Or over there. It's terribly difficult to draw an
accurate cross section because of this very fact. Whenever you start pulling
the world apart, something goes wrong such that you lose part of the material
that was in there.</p>

<p class="tab"><b>Duff</b>: We did a fairly careful job of
trying to measure the displacement of an interface on Mighty Epic. This was an
event where the Paleozoic rock was coming up underneath the working point, in
one direction away from the line-of-sight tunnel, at right angles to it. The
interface got within seventy to ninety meters of a horizontal tunnel that was
perpendicular to the line-of-sight tunnel. A fairly elaborate experimental
program was undertaken to try to measure the displacement of the interface that
was predicted to occur.</p>

<p class="tab">The Paleozoic, being
hard, strong rock would not move, the tuffs would move over the top of it, and
one should see a sliding along this interface. Such sliding would represent a
potential threat to underground deeply buried assets of one sort or another,
such as a deeply buried command post, or missile silo, for example. So, they
wanted to know, could it be predicted? This elaborate measurement program was
undertaken, and indeed the expected displacement occurred. The only trouble
was, it didn't occur at the interface we were looking at. It occurred at a
weakness in the tuff, some distance above the interface. There was a weakness
there that we hadn't known about. That is an example of a weakness that was exercised
in a particularly dramatic way. Motions of a meter or two occurred. We were
able to find it after the shot, but we didn't find it before the shot. We went
back and looked at pre-shot records, and cores, and we were unable to identify
it.</p>

<p class="tab">I think that there
are probably a very large number of other displacements that occur that we
never recognize because we don't know what was there before the shot. We do
relatively little looking close-in to an explosion. The Laboratories never, or
almost never, do, and DNA is restricted in its efforts by money, and time, and difficulty,
and all the other things that really do apply in the real world.</p>

<p class="tab"><b>Carothers</b>: You were talking about the
world being inhomogeneous.</p>

<p class="tab"><b>Duff</b>: Intrinsically inhomogeneous.</p>

<p class="tab"><b>Carothers</b>: Let me offer a thought. The
world is inhomogeneous on any scale that you care to use to look at it. I f you
want to start with a scale of a few thousand miles or so, there's space, and
then there's atmosphere, and then there's dirt. If you want to go to an atomic
scale, there is silicon, and carbon, and oxygen. On a somewhat larger scale
there are molecules, then grains of minerals, and then you to get pebbles, and
cobbles, and on and on. How that affects your predictions, it seems to me, is a
question that can only be answered if you tell me the wavelength of the
phenomena you're concerned with. Would you comment on that?</p>

<p class="tab"><b>Duff</b>: I think that's a very crucial
point, and one that does indeed need discussion. I think the scale of the
disturbance that we're concerned with in a nuclear test is, or can be,
characterized by one of the characteristic dimensions of the test. Let's call
that one the cavity radius.</p>

<p class="tab"><b>Carothers</b>: That would seem to be a
reasonable dimension to choose.</p>

<p class="tab"><b>Duff</b>: Yes. Therefore, I think
inhomogeneities that occur on scales that are of that order of magnitude can
influence the phenomenology. And my point is that the modeling that we have done,
largely that DNA has done, is based on measurements of pieces of rock core
which are measured in centimeters. Whereas, we know from reentry observations
that there are non-uniform motions that are occurring on dimensions of meters
or tens of meters. I think this points up a disconnect, an intellectual
disconnect, between the phenomena we are concerned with and the data that we're
using to try to describe it.</p>

<p class="tab">If we find that
motions are dominated by what happens at faults, interfaces, bedding planes -
non-uniformities of one sort or another, as was pointed out by Livermore in the
Rainier work in 1960 or so - then we are remiss in basing our study of
phenomenology on the response of homogeneous material, measured on the scale of
centimeters.</p>

<p class="tab"><b>Carothers</b>: Dan, if you're going to think
about loads on hardware, and plugs, and so on, what about the observed fact
that large blocks of rock move? How do you take account of that?</p>

<p class="tab"><b>Patch</b>: I think dealing with block
motion before the fact is almost an exercise in futility. The reason I say that
is because you can predict, based on a number of rules of thumb, and empirical evidence,
and some modeling too, kind of the region in which you would expect block
motion and maybe make a guess as to what the amplitude is going to be. And you
might be relatively close, if you're lucky. But you can't actually say,
"This block is going to move. This one, not that one, and this is how far
it's going to move." Our experience is that sometimes a very minor feature
will move a lot, and a very major feature won't move at all. To figure out
exactly how this is going to play out, pre-shot, is not in the cards.</p>

<p class="tab"><b>Carothers</b>: I believe that. Apparently
there was block motion on Misty Rain, and it severed the pipe. Some people have
said, "That was pretty lucky, because if that hadn't happened it might have
behaved like Mighty Oak." Is that true?</p>

<p class="tab"><b>Patch</b>: I know there are a number of
very smart people who believe that very strongly. And I don't. Part of my
feeling on block motion is that it perforce comes relatively late. I wouldn't
disagree with folks who say it gets started right away, but it's a cumulative thing,
and it has to occur on time scales that are comparable to the cavity growth
scales. So, you really get these substantial offsets late in the dynamic
motion. I don't know any other way it can happen.</p>

<p class="tab"><b>Carothers</b>: Presumably large amounts of
material are moving. If you're concerned with the survival of hardware, that
postulated mechanism would be a concern, and something you would have to think
about. What you do about it, I don't know.</p>

<p class="tab"><b>Patch</b>: We perhaps have been lucky, but
the only instance I can think of where block motion apparently affected the
closure was on Midas Myth, where there seemed to be some kind of offset motion that
torqued the housing on the TAPS and kept the door from closing all the way. But
by and large, because block motion is, let me say, pervasive, we've been fairly
lucky in not having something go right through our pieces of hardware.</p>

<p class="tab">On the other hand, we
have an amazing propensity on these low yield shots, purely by the luck of the
draw, to put the F AC right behind a fault. On almost every one of those shots,
maybe not the last couple, but certainly there was a string of about three or
four at least, where there was a fairly major fault right in front of the FAC itself.
Indeed, on one of them, I think Diamond Beach, it actually cut right through
the nose of the FAC if you drew the plane. They have not threatened the
survival of those closures; that is, the closures have all survived post-shot.</p>

<p class="tab">Now, such motions did
cause a whole lot of unusual local motion in the stemming itself, in the
vicinity of the FAC, on Diamond Beech in particular, where grout was extruded
out and around it. There were some strange things that were difficult to figure
out. So I guess I would say block motion hasn't seemed to pose a real threat to
the closure hardware, but there are certainly cases where it has severed the
tunnel, where there has been almost a full offset. It's made grout go strange
places you wouldn't predict pre-shot very well.</p>

<p class="tab"><b>Carothers</b>: Here you are, scratching your
head, and you're calculating, and you're doing the best job you can. And
lurking somewhere over in that mountain is this big block, maybe. Or maybe not.
Maybe it's going to move. Maybe not. Maybe it's going to move an inch, maybe
it's going to move ten feet. What's it going to do to the hardware? Basically
you have no mechanism to deal with that, or I can't imagine how you could.</p>

<p class="tab"><b>Patch</b>: I think the way we deal with
that is probably pragmatically, and that is to say that we don't want a design
that depends on the survival of anyone feature. And so we're willing to take
our chances. Generally when these blocks move it's the whole mountain that
moves, and trying to resist it somehow by building an extra strong structure
is, I think, not very likely to be successful.</p>

<p class="tab"><b>Carothers</b>: Personally, I have a hard time conceptualizing
this block motion. Presumably this block, which is the size of this room, or
this building, moves. Something had to get out of the way.</p>

<p class="tab"><b>Patch</b>: You've put your finger on a
problem that I have all the time. That's right; it doesn't have a void to move
into. Simplistically, if you take a box of sugar cubes and start trying to move
them around, if you start trying to grow a cavity in the middle of a box of
sugar cubes, very strange things happen, unless they can deform in some way .</p>

<p class="tab"><b>Peterson</b>: Some people have stated that
the reason we've had problems with some of the events, Mighty Oak being the
worst, was the fact that we went to larger pipe tapers. They have postulated that
once we went to the larger pipe tapers, the only reason we've had containment
is because we've had very fortuitous block motion. That block motion has served
to sever the LOS drift, and prevent things from leaking. Now, there's quite a
bit of evidence on some shots that we have had block motion. For example, it
looks as though block motion cut the drift on Misty Rain. People speculate that
if it hadn't cut it quite as much as it did, Misty Rain would have looked like
Mighty Oak.</p>

<p class="tab">There are clearly
identifiable instances where a block of material has moved. Misty Rain is one
example, and I think it's true on most of the events. It is documented on
numbers of events. There was some on Mighty Oak as well, but you can then
always argue that it wasn't enough.</p>

<p class="tab"><b>Carothers</b>: You could also argue that was
what caused the problem.</p>

<p class="tab"><b>Peterson</b>: Well, that's the next point I
was getting to. I can go to the other extreme of looking at, say, what is
called the “tired mountain," which I think is maybe more properly said as
shock conditioning occurs out to a larger radius then we can measure by going
in and doing sonic measurements, or acoustic measurements, or seismic
measurements. Or, than we can determine from doing material properties tests. I
think Russ Duff speculates it is because of this that one can say there is
enhanced block motion. In other words, if you have more and more events in a
place, you sort of jiggle the joints, and it allows them to slip easier, and
that can enhance the block motion. If you enhance the block motion, then there's
no reason for a residual stress field, as we think we get when we do our
standard one or two dimensional calculations, to form.</p>

<p class="tab"><b>Carothers</b>: Wouldn't it depend on how big
the blocks are?</p>

<p class="tab"><b>Peterson</b>: That's true. But you don't know
that such a stress field forms anyway, and there's a possibility that it doesn't.
And of course, if you don't develop the stresses so you really squeeze the tunnel
shut, and form a stemming plug as we calculate, then of course you need the
block motion to cut the tunnel.</p>

<p class="tab"><b>Carothers</b>: Well, I think there's
unequivocal evidence, on a number of tunnel events, that the tunnel after the
shot was smaller than it was to begin with. And it's not that it's been
sheared, it's just smaller. That would seem to me to imply that there has been a
considerable stress in those materials.</p>

<p class="tab"><b>Peterson</b>: Absolutely. I agree with what
you say. What I was trying to say was that if we follow the block motion
argument to some extreme, if you get much of it I think it could lower the
stresses in certain regions. It might enhance them in certain other regions. If
you happen to have an event in which you get block motion that lowers the
stresses along the stemming column, then you may not set up a stemming plug. I
f you do not set up the stemming plug, and you still don't wish it to leak,
then you better hope the block motion was enough so it severed the tunnel.
Somehow you have to have something that stops the cavity gas from leaking out.</p>

<p class="tab">If you get block motion to the extent that
you do not get good formation of a stemming plug, then you probably need the
block motion in order to stop the leakage. It's a Catch 22, which is the point
I was trying to make. If I follow the argument to the extreme, it's almost to
the point that if you get significant block motion, then you probably need the
block motion in order to prevent leakage.</p>

<p class="tab">Or, you could look at
the other extreme - if you don't get the block motion, then you probably set up
a stress field similar to what we calculate, and then you don't need the block
motion. Which of these is right, or whether it's a combination of the two, and
those are the ones that really get you in trouble, the ones that fall in the middle,
I don't know.</p>

<p class="tab"><b>Carothers</b>: It's hard for the layman to
imagine how very large blocks of rock, perhaps as large as this building, move
around in the earth. If such a thing happens, then lots of other blocks must be
moving too.</p>

<p class="tab"><b>Peterson</b>: Yes. I am not an expert on
block motion, but DNA has a fairly large program that studies block motion for
some of their work. They have done a lot of studies, and so it's a very well documented
phenomenon. If you go back to the Rainier reports, one of the things discussed
in those reports is that it wasn't just a uniform expansion of the material.
There really were very large blocks of material that moved relative to one
another.</p>

<p class="tab">Some of the data
indicate that the motion comes somewhat late in terms of some of the time
scales we talk about. It takes time for a very large block of material to move.
We're not talking small things. They are very, very big pieces.</p>

<p class="tab"><b>Carothers</b>: Dimensions of hundreds of feet,
possibly.</p>

<p class="tab"><b>Peterson</b>: Easily. So they don't move
instantly. DNA has much information, and inside about two cavity radii it's
very difficult to understand what's going on. One of the reasons is because
things just don't move radially out. You can't count on everything to move
radially out from the source.</p>

<p class="tab"><b>Carothers</b>: Or to put it another way, you
cannot count on calculations based on the assumption that the earth is a
homogeneous material. Which is what you do in one dimensional calculations.</p>

<p class="tab"><b>Peterson</b>: That's true. We can put in
layers in some of our two dimensional calculations, but in general we don't
know enough of what is there. We might know about one fault, and maybe we could
put it in a calculation, but maybe there are others there that we don't know
about, that are maybe just as important. So you really don't know how to put
the structure in a calculation. It's difficult to do if you know it, and if you
don't know it, it just gets that much more difficult.</p>

<p class="tab">I don't mean to imply
by this that I believe it's either the block motion that's made the changes we
have seen, or that it's the increase in pipe taper that's made those changes. I
have found both arguments interesting, because the increased pipe taper one
says, “You had to have block motion in order to get containment on the recent
shots." The larger damage region argument says, “We're developing block
motions because we were continually shaking the ground in the region where we
do the shots." If you follow it to the next level, you can say, “lf you
have block motion, then you need block motion to get containment." But you
could follow it back the other way and say, “lf I don't have block motion, then
things might work the way they always have sometime in the past."</p>

<p class="tab"><b>Carothers</b>: There is another set of
detonations; those which occur in Yucca Flat. No line-of-sight, no tunnel.
There's just the emplacement hole and its stemming. I don't understand how the block
motion argument might apply to those shots. Does block motion occur only
because the tunnel is there? Suppose there were no tunnel.</p>

<p class="tab"><b>Peterson</b>: I don't believe that the tunnel
has anything at all to do with the block motion, or very, very little to do
with it. I think it's the motion that occurs as a result of the natural
discontinuities in the ground before the shot. I think the block motions
generally occur independent of whether that little tunnel is or is not there. I
don't think the tunnel causes block motion.</p>

<p class="tab">In Yucca Flat, when a
device is detonated in the tuffs, I think blocks probably do move there also,
but in a stemmed hole I don't believe it necessarily bothers you at all.</p>

<p class="tab"><b>Carothers</b>: Well, the evidence is that it
doesn't. Of course, in emplacement holes all there is in the first few hundred
feet is a bunch of gravel and a few plugs.</p>

<p class="tab"><b>Peterson</b>: Yes. And so they'll never see
it, or it doesn't really matter to them at all. I believe it's something that
we in containment need to think about, however. I personally don't know what
the answer is.</p>

<p class="tab"><b>Carothers</b>: Let me disagree with you. The
evidence in the Flat is that whether it occurs or doesn't occur is of no
concern. The concern, really, is on the part of the DNA people who could
lose their experiments and samples. It does not seem to be a containment concern,
at least for stemmed emplacement holes that do not have a line-of-sight pipe.</p>

<p class="tab"><b>Peterson</b>: You are absolutely correct.
Since I work for DNA, I think of close-in containment as being extremely
important. In terms of release to the atmosphere, I don't think it is a containment
issue at all.</p>


<a name="ch14"></a>
<br><br>
<h2>Chapter 14: Depths of Burial, Drilling</h2>
<br>

<p class="tab">Probably the most important
factor in the containment of an underground nuclear detonation is the depth at
which it is buried. It is fairly certain that a device of any yield detonated
at the center of the earth would not release any activity to the surface.
Conversely, a device of however small a yield, detonated on the surface, would obviously
release radioactivity into the atmosphere. So, somewhere between these reducto
ad absurdum limits there is a depth for a given yield which will surely prevent
a release of radioactivity to the atmosphere. Given sufficient depth, and
proper stemming of the necessary emplacement hole, all the considerations of
cavity formation, residual stress cages, material properties, calculational
models, geologic setting, and so forth become irrelevant.</p>

<p class="tab">Like most other statements of
obvious, simple solutions to complex problems, the one above is essentially
useless in the face of the real-life constraints that exist in dealing with the
problem. The first and most immediate constraint is usually money, and in the preparations
for an underground detonation how and where the device is placed determines a
large fraction of what the eventual cost will be. Drilling six, eight, ten foot
diameter holes is not an inexpensive activity, and the cost per foot of depth
increases as the hole gets deeper.</p>

<p class="tab">As noted in the section on
hydrology, the Test Site is one of the few place in the world where the water
table is as deep as 500 meters, but devices with a yield above about sixty to
seventy kilotons must be emplaced deeper than that. Below that depth the hole
will fill with water. To keep that water away from the device and the equipment
that is emplaced, the hole must be cased with a liner that will be water-tight;
a costly procedure.</p>

<p class="tab">Expensive electrical cables that
carry the firing signals to the device, the necessary power to the diagnostic
equipment, and ones used to return the data from the detectors must run from
the surface to the bottom of the hole. For these and other reasons there is a substantial
financial incentive to fire the device at the minimum depth, which will
obviously depend on the yield, required for successful containment.</p>

<br>

<p class="tab"><b>Higgins</b>: Starting in about the year after
Rainier, 1958, we started the Plowshare program. Plowshare, as it was then
envisioned, was going to include a lot of things, like stimulation of gas wells,
and excavation; the nonmilitary applications of nuclear explosives. The
questions raised by those applications extended beyond just the cavity puddle
and the radiochemical analysis of the samples from the explosion. They went
into things like, “Well, how far do the fractures extend? Or there are any
fractures?" We knew by then there were some. “Where is the heat, and how
much of it is available to recover?" And, “Suppose that, instead of
shooting the shot in tuff at the Test Site, we fired it in salt. Wouldn't all
the steam stay in then? Salt is impermeable, plastic, and solid. Won't all the
steam stay in the bubble and be ready to be recovered?"</p>

<p class="tab">So, starting in 1958,
the Plowshare program put a lot of effort into trying to answer questions like
that. They were important questions, and we didn't have answers for them. We
began to be concerned about effects other than just the rad chem sampling. Being
quite naive in some respects, one of the things we thought was that it would be
a good idea to try a series of Rainier-like explosions. These would be a few
kilotons at most, and they would be in a lot of different kinds of materials,
to see in what way the properties of the medium influenced the effects that we
observed.</p>

<p class="tab">These were to be pure
science shots. We designed a set which included a shot in granite, a shot in as
pure salt as we could find, a shot in some kind of carbonate rock, which at
that time we called limestone. I believe that early on we also talked about a
shot in basalt, as opposed to tuff, which really isn't much like any other rock
in the world. However, it turns out that there really is a lot of tuff, so it's
not as irrelevant as we thought at one time. Being mostly not earth scientists,
we thought that the world really had a lot more granite, and salt, and
sandstone than anything else. But it turns out that four-fifths or so of the
world is basalt. Volcanics really are the commonest kind of rock, and the so
the Test Site isn't an unusual geologic place in that sense.</p>

<p class="tab">The first one we
proposed was Gnome, in salt, and it was carried out, in salt, near Carlsbad,
New Mexico on December 10, 1961. Before Gnome was fired we had designed other
shots; the granite shot, and the one in sandstone, and various others. Hard Hat
was originally the medium-effects test in granite. The granite existed at NTS,
and so why not do the shot there? So it got designed at about the same time
that Gnome got designed.</p>

<p class="tab">Excavation was always
part of the grand plan of Plowshare. Explosive excavation is not at all new. It
was, in fact, the preferred method for excavation in swamps, and some other
types of terrain, as early as the mid-nineteenth century. The French,
particularly, did a lot of work developing high explosive excavation, and
scaling laws, and theories having to do with explosive engineering. There was,
and is, extensive literature on the subject, but it all dates from before 1900,
and so a lot of modern engineers aren't familiar with it.</p>

<p class="tab"><b>Carothers</b>: Why wasn't there some material
from after 1920, say?</p>

<p class="tab"><b>Higgins</b>: Well, technology developed, and
the efficiency of modern machines superseded explosive excavation from an
economic point of view. When the competitor was a team of mules and a scraper,
after Nobel's development of dynamite explosives excavation was much cheaper.
By 1900 that was about the end of it however, because engines and machines got
to be very good. Now it's almost to a point where you can move hard rock with
machines easier than you can blast it to break it.</p>

<p class="tab">Going back to 1955,
there was a surface detonation called Teapot Ess. It was not part of the
Plowshare program, but it was an underground explosion, deep enough so the
fireball would be contained, but not the debris. As I recall it was buried at
some tens of feet, and it was about a kiloton. The purpose of that was to understand
the effects as a potential antitank weapon, and to confirm the old French
scaling curves for producing craters. Would the scaling laws developed with
dynamite work with a nuclear yield, or asking the question the other way
around, was the nuclear energy as useful as the high explosive energy? There
was quite a school of thought that said, "A nuclear kiloton really isn't
as big as a thousand tons of TNT."</p>

<p class="tab">Well, the Teapot Ess
explosion proved that the nuclear energy was as efficient. To the degree one
can determine from measuring the size of the crater, it was just about as good
as high explosives. The people in the Plowshare program, starting in a few
years later, began to scale things and said, "All right, if a kiloton
works as well as a thousand tons of TNT, then how about a megaton?" And
they began to realize that things like a Panama Canal could be excavated with
explosions in the megaton and submegaton range, placed at depths of 600 feet or
so.</p>

<p class="tab"><b>Carothers</b>: I presume the original argument
would be, "The chemical explosive produces a lot of gas, so there's a
push, or pressure, from this gas which lifts and throws out material. The nuclear
explosive doesn't do that, so it won't be as effective or as efficient in
moving the dirt."</p>

<p class="tab"><b>Higgins</b>: That was the argument. That
first test, the pre-Plowshare program test, was not definitive in that
particular, but the crater was about the right size. The issue stiII was not
settled, but it looked as though the vaporized rock did the same amount of work
as if it had been a permanent gas. That was important from a containment point
of view, because that meant the vaporized material contained a lot of the
energy. There was a good mixing, at least until most of the energy was in the
gaseous material, and there wasn't a lot of radiant energy left behind.</p>

<p class="tab">So, the Plowshare
cratering program people proposed a series of shots, like Teapot ESS, at a
number of depths to confirm the scaling curves, and to examine this business of
the gas coupling at deeper depths. I think the scaled depth of Teapot ESS was
about 60 feet. The optimum scaled depth of burst for cratering is about 120,
and so Teapot ESS was at about half the optimum depth. The gas becomes more
important as the detonation point gets deeper, and the argument was that as you
approached a scaled depth of 100 or 120 for a nuclear source the gas
acceleration phase, or the gas coupling, wouldn't be very effective. So, one of
the objectives of the early Plowshare cratering program was to confirm the
scaling curves.</p>

<p class="tab">First we confirmed
that the old scaling curves that had been published by the French in 1870's
were valid. And it turns out they're very precise, and they were valid for both
TNT and nuclear explosives. When we used a thousand calorie per gram high explosive
like TNT, we got the same results that the French had. And we found that the
effect of wet rock or dry sand was not all that pronounced. There was a little
difference, but all these curves existed. By confirming one or two of them we
found that we could use all of the curves.</p>

<p class="tab">The real issue was
how far up in yield could you go, because it's obvious, if you think about it,
that in a gravity field there is an upper limit to the size of crater you can
make. If you tried to do half the world, it would obviously all fall back,
because it's going to fall back into the same world. It might be oriented
differently, but there's going to be no crater at all. What flies up one place
will fall back somewhere else.</p>

<p class="tab">The largest explosion
we did was the Sedan event on July 6, 1962. It was 100 kilotons or so, at a
depth of about 630 feet. That was the optimum depth from the old scaling
curves. Lo and behold! It scaled just as if it had been high explosives. It
produced a 300 foot deep crater that was essentially 350 feet in radius, and
was very close, or exactly on, the high explosive curves. That verified the scaling
curves from 1 gram to 100 kilotons, which is 10 to the 8th grams.</p>

<p class="tab">The point, for
containment, is that 100 kilotons at the optimum scaled depth of burst produced
the right scaled dimensions for the crater. We also looked at the craters from
the Pacific surface shots, and those large yields at the surface produced
craters also of the right scaled dimensions. The inference was that when the explosive
was contained, and it produced no crater, the same logic should apply. In other
words, an explosion should be completely contained at the same scaled depth of
burst, whether the explosion was a gram or 10 grams or 100 kilotons or even a
megaton.</p>

<p class="tab">In the absence of
gravity, in a perfectly elastic medium, the effects of energy at a point
decreases as the radius cubed. But when you put gravity in, and say the
explosion is going to be contained in this constant force field, things change.
If you include gravity, the containment depth doesn't scale as the yield to the
1/3. Empirically it was found that it wasn't 1/3, but more like 1/3.4. The
scaled containment depth, on that basis, was 220 feet. A couple of high
explosive tests were fired at that depth. One was in basalt, a hard dry rock
that was thought to be representative of a portion of the hard ridge that
separates the Atlantic and Pacific, and therefore was relevant to the Panama
Canal issue.</p>

<p class="tab">The Sulky experiment
was conducted at a depth which should have just barely produced a crater. And,
it barely produced a crater. It did what it was supposed to do, at a little
less than a half a kiloton. So, it appeared that the logic worked. What was
missing was that for containment of high explosives, or the nuclear explosive, that
doesn't include any of the gases. While there was no crater produced, for the
220 scaled depth essentially all of the gases went through cracks and came out
into the atmosphere. None of the solid material did, but from today's
containment of nuclear explosives point of view that would not be adequate. It
would not adequate from the U.S. point of view, I should say. There's a
difference between the Soviet view and the U.S. view on what containment is.</p>

<p class="tab">So, the 220 scaling
law is useful only as saying, "Well, that limit we know is too
shallow." It certainly establishes a lower limit to the depth of burst for
containment, and in that sense it probably is useful. If you apply it to four
megatons or so, as you would for Cannikin at Amchitka, that lower limit turns
out to be a little over a 1,000 feet, instead of 6,000 feet. Well, there's a
great deal of difference in cost between drilling a hole 1,000 feet deep and
one 6,000 feet deep. That last mile, so to speak, really costs you.</p>

<p class="tab"><b>Carothers</b>: We were willing to go the extra mile.</p>

<p class="tab"><b>Higgins</b>: Yes, in spite of the evidence.</p>

<p class="tab">But those experiments
established how shallow one might go and not release prompt debris. I don't
think anyone would have tried it. But it does point out that as you go to
larger and larger explosions, the price of complete containment, in the sense
that we are now doing it, is quite high. I'm convinced, and I think others who
have looked at it are, that we could, if we were ever do a megaton test again,
bury it half as deep as we have done in the past, with complete safety.</p>

<p class="tab"><b>Carothers</b>: You've been an exponent of that
for some time. I have a comment. As the yield goes up to a megaton, or even to
ten kilotons, you're burying the explosive at a depth where I doubt there has
ever been a large chemical explosion done. So, you're extrapolating these
curves, and the implicit presumption is that the earth in which you are doing
this explosion is a homogeneous earth, so what happens near the surface is the
same thing that will happen at depth when there are layers of different
materials which have dips, and faults, and cracks.</p>

<p class="tab"><b>Higgins</b>: That is a complex issue, and
there isn't a simple answer. The criticisms and the concerns early on in all of
the underground and containment programs were that these fissures and faults
and irregularities and uncertainties in the earth would really dominate the
observed effects. In fact, as data began to accumulate, what was found was that
the wavelength, or the size of the stress wave, and the size of these
irregularities were different. Things as small as faults offsets, and voids,
and changes of material properties apparently don't interact with the stress
wave from the explosion because it is spread out more in space and time than
they can involve. The stress wave just doesn't see them; it just wraps around
the irregularities.</p>

<p class="tab">While it was a very
real concern, the early data have been confirmed in a large variety of cases.
Faults and fissures and irregularities become important only in very special
circumstances. They can be important, but they have to be supplemented by other
irregularities that make the stress wave itself, and the pressure field, irregular
in such a way that they reinforce each other. I think Baneberry is probably the
best example of a lot of such effects occurring simultaneously, and I think
most people agree that kind of interaction was involved in the Baneberry
failure. I don't think everybody agrees as to which of those things was most
important.</p>

<p class="tab"><b>Carothers</b>: The importance of
irregularities should vary depending on the yield. In other words, if I am on
the scaling curves, burying something at the proper depth, it would seem that
if I detonate a gram or so I might be greatly influenced by some irregularities
in the medium. Now, the earth, like nuclear cross sections, doesn't scale - the
earth is just there. If I want to detonate a gram, or ten grams, things as
small as the particle size of the medium might be very important to me. If I
want to detonate a megaton, particle size is probably completely insignificant.
Put another way, they are very small compared to the wavelength of the stress
wave .</p>

<p class="tab"><b>Higgins</b>: Exactly right. And it's one of
the mistakes that can occur if you try to do scaled models of tests at the one
gram scale. You have to be very careful to scale all of the particle sizes, and
other features, along with the size of the explosive.</p>

<p class="tab">When we have a
nuclear explosion the wavelengths from the explosion are in the hundred meter
range, as far as the bulk of the growth is concerned. After all, the cavity
grows from the size of the explosion, which is a meter or so, up to a hundred
meters or so. Those things that are a lot smaller than a meter, or a hundred meters,
aren't going to make a lot of difference. If you had a hundred meter sized
hole, I think there's no doubt that the explosion would find it and go out. A
one meter size hole, it's questionable. A tenth of a meter size hole is so
small that it’s not going to make any difference. This is my opinion, and I
think it's been shown in a couple of cases. It's not going to make any difference
no matter what's in the hole, including nothing. We've done tests many times
with ten centimeter size pipes. We worry about them because we worry how big is
too big, but the evidence is that they don't make a lot of difference.</p>

<p class="tab"><b>Carothers</b>: Well, there are some people who
might take exception to your statement. You said, “If you had a hole which was a
tenth of a meter in diameter, it doesn't make any difference what's in that
hole, including nothing." There was a period of time when you chemists
drilled holes, not quite that small, but still much smaller than a meter, near
events, and filled them with various things at various times, including
drilling mud, nitromethane, and starch.</p>

<p class="tab">Some of those holes
stayed open. Take Eel, for example. There were two small holes near the
emplacement hole. One was filled with drilling mud. the other with
nitromethane. The mud, the cables, and anything else that was in them blew out,
and the cavity did its best push all the gas out them. How does that square
with your statement that it doesn't matter what's in the hole?</p>

<p class="tab"><b>Higgins</b>: It does matter what's in it. I
made an imprecise, and also unconsidered statement. You can contrive to keep a
tenth of a meter hole open, but it takes some special efforts. To keep such a
size hole open isn't easy.</p>

<br>
<i>Drilling</i>
<br><br>

<p class="tab">Regardless of the depth that is
chosen as the appropriate one for a planned experiment, a hole must be drilled
so the device and the associated experimental hardware can be emplaced. The
drilling of the hole is not a containment issue in itself, but on more than one
occasion what the drillers were able to do has modified the planned containment
or experiment design. Information from the drilling process, should it reach
the containment scientist, can sometimes provide valuable insights as to the
properties of the medium through which the hole has been drilled. The
characteristics of the hole, such as its diameter and straightness constrain
how the various data collection experiments can be designed.</p>

<p class="tab">In 1961, when the moratorium
ended, Livermore did their first few shots in tunnels, with little success as
far as containment was concerned. Los Alamos always used drill holes, and their
experience was somewhat better. One of the concerns about the use of drill holes
was that they weren't big enough to allow much in the way of diagnostic
measurements. During the first few years the holes were 36 inches, or 48 inches
in diameter. While large compared to holes that were drilled for things such as
oil exploration and production, they were a very small diameter laboratory
space in which to place the diagnostic equipment needed to collect data about
the performance of the nuclear device.</p>

<br>

<p class="tab"><b>Miller</b>: By the time I got to the Test
Site the common size holes were 36 or 48 inches, and they were doing them in
one pass. In the very beginning they would drill a small hole, similar to what
they used to do in the oil fields, then open them up with what we called a hole
opener, or hole enlarger.</p>

<p class="tab"><b>Carothers</b>: The people who were trying to
make the measurements always wanted a bigger hole - four, six, eight, ten feet
in diameter. Who developed what you might call "big hole drilling?" Did
we do that, or was that a commercial development?</p>

<p class="tab"><b>Miller</b>: The evolution came from people
at the Test Site. The Laboratory would give the requirements to the then AEC,
and they, of course, had drilling contractor. Holmes and Narver had the drilling
before I came out to the Site. When I came to work out there I worked as an
engineer for Fenix and Sisson, and they did the design work for whatever was
required, in conjunction with REECO. I think the answer, probably, depends on
who you talk to.</p>

<p class="tab">I think that
initially it was probably entirely the A&amp;E, Fenix and Sisson, and it kind
of evolved to more REECO doing it, mainly because of personalities. It would
depend on who was given the job. We had some really fantastic people out there.
One with F&amp;S was named Art Hodge. I'm one of the few people on earth who
could get along with him, because I wouldn't take off him. He was a mean one,
but he was smarter than anybody I'd ever known. He was that type of guy. REECO
had a guy by the name of Sim Crews, who was a petroleum engineer. Between the
two of them, reluctantly sometimes, because F&amp;S and REECO were always at each
other’s throats, similar to Los Alamos and Livermore, is how these things developed.
The prime mover, of course, was the Laboratories - give us a bigger hole, give
it to us quicker and cheaper.</p>

<p class="tab"><b>Carothers</b>: Where did they go to get eight
foot diameter drill bits? Nobody in the world used them, did they?</p>

<p class="tab"><b>Miller</b>: That's not really so. The
mining industry used them a lot, for what they called raise drilling. They mine
in straight, drill a hole down, in a drift, and then run a drill pipe in there.
It's pretty simple to drill out a twelve and a quarter inch hole in a drift.
Then they put a bit on the top, and drill up, and all the cuttings fall out into
the drift. That is called raise drilling. Then they haul the cuttings out like
they would in a regular mining operation. When you start at the surface you
have to remove the surface stuff that you drill through, and that's the really
difficult part. Raise drilling is just one thing they use big bits for.</p>

<p class="tab"><b>Carothers</b>: What people have said is,
"Well, it was really at the Test Site where we developed big hole drilling.
That had not been done before."</p>

<p class="tab"><b>Miller</b>: That's not so. There was a guy
with Robin Bits, which sells cutters. Fantastic guy, an engineer. I heard him
give a talk, and he quoted four different localities where they have drilled
big holes, and how they progressed differently. There was the way we did it, there
was a guy from Canada who drilled some big holes, and there was a guy in
Wyoming, and somebody in Tennessee who did something with coal mines.</p>

<p class="tab"><b>Carothers</b>: Was this so they wouldn't have
to mine a shaft?</p>

<p class="tab"><b>Miller</b>: That's what they were for. It
was cheaper to drill than it was to mine a shaft with people. Everybody thinks
that big holes were only for shooting nuclear bombs in, but in Chicago, for instance,
they have a sewer system under the city, and they drilled big holes down into
places to put machinery and pumps down. In fact, this guy with Robin, a lot of
his experience came from the Chicago area. And, of course, most of the other
experience has come from the mining industry.</p>

<p class="tab">So, it wasn't all that
hard to get the tools if somebody wanted to go to a six foot hole instead of a
four, or an eight instead of six. There were people in the business, and there
was always somebody who wanted to make some money, of course. We didn't go from
four foot to eight foot. It wasn't that drastic a jump. It went from normal
size drilling in the oil fields - for instance, the biggest hole I was ever on
before I came out to the Test Site was a 20 inch hole. Then here we went to 36
inch. Of course, you drill a 48 inch hole, and you put a 36 inch ID casing in.
Then it went from a 48 to a 64, to a 72, to an 86, to a 96. It just went a
little at a time.</p>

<p class="tab">The biggest bit at
the Test Site was for a 142 inch hole we drilled, but we didn't drill that one
on the Test Site. We bought the two bits for one of our programs, and the only
time they were used was on the oil shale deal up at Piceance Creek, which was
done by a private contractor. The waste disposal project down in Carlsbad used
a 140 inch bit body that they extended out to 142 inch, which is pretty simple
to do. You just make the outside cutters, the gate cutters, about an inch
bigger on a radius, so you have a 142 inch gauge hole. Those were two holes.
Livermore never did drill a 140 inch hole at the Site.</p>

<p class="tab">I believe LASL
drilled about a 144 inch hole to 300 feet for some experiment about the time I
came out here. But it was not a common size hole. Of course, we had the
underreamers for a while, too.</p>

<p class="tab"><b>Carothers</b>: My recollection is that we
never had a lot of luck with underreamers.</p>

<p class="tab"><b>Miller</b>: Oh, we did. It was difficult to
do, but we did several underreamed holes. I think probably about the last one
we did was an underream up in Area 2, and that reamer is still there. They never
did get it out of the hole.</p>

<p class="tab"><b>Carothers</b>: I remember that. Fred Beane was
the Test Director. He came and said that this thing was like an umbrella - you
put it down when it is folded up, then it would open up. Then you'd turn it,
and it would make a big hole down there. So, one day he came in to see me, and
said, "We can't get it closed. Must be a rock in it, or something. Can't
get it out of the hole" What really happened?</p>

<p class="tab"><b>Miller</b>: Well, it started off in a hole
in Area 2. The requirement was for 40 feet of 144 inch diameter hole at the
bottom. So, we drilled a nice 60 inch hole and set a complete string of 48 inch
casing. We put that in, and ran the underreamer in. It ended up that there was
a square hole at the bottom.</p>

<p class="tab">What happened was
that 40 feet a is pretty long section to underream, and the underreamer got to
oscillating. When it did, the arms, because it was pneumatic pressure that held
them open, started doing their deal as they rotated, and it just amplified it
as they went down. Each cut it made, it spiraled. I didn't know how I was going
to explain that hole to people.</p>

<p class="tab">Those underreamers
were very expensive. It took a big piston and a lot of air pressure to force
those arms open, and we were using the drill pipe as a conduit to pressure
those arms. We would drill the hole, and enough extra hole, which we called a
rat hole, so the cuttings would just fall in there. We'd let them fall. If
there got to be too many, we'd pull the underreamer out, go back in, and clean out
the rat hole.</p>

<p class="tab">The one we lost was
not because of a rock. I didn't know it until after we shot it off, but the guy
who built it, another one of those exceptional engineers, who worked for an
outfit in LA, and did a lot of things for us told me that the specs originally
called for T-1 steel on the arms. Somebody in DOE saw the cost of it, and
changed it to some other kind of steel that wasn't as strong. This was an underreamer
with sixteen foot arms, and when those arms opened, they bent. If it had been
stronger steel it would probably have been all right. The arms folded up into a
grove, but they bent a little bit. So, they wouldn't go back into the grooves,
and that is what happened.</p>

<p class="tab"><b>Carothers</b>: I remember Fred Beane coming in
and saying, "Can't get the underreamer out. Can't get it closed. Schedule,
and all this, and all that." And I remember saying, "Well, shoot it
off."</p>

<p class="tab"><b>Miller</b>: One of the hardest things I
ever had to do was shoot that off, but I shot it off. That was a half a million
dollar tool. That was terrible. I've made a lot of hairy decisions, but I'm the
one who called Fred Beane, and then he probably called you. I said, "We're
not going to get this thing out of here. You might as well make your head up to
that. He said, "Well, what are you going to do?" I said, "There's
only two things to do, and that's abandon the hole, or, shoot the damn thing
off." And it was cheaper to shoot it off than to lose the hole.</p>

<p class="tab"><b>Carothers</b>: Well, the cost of what's done
for containment is something people in containment get hassled about every now
and then - all those cable gas blocks, all those logs that you have to run in
the hole, all this, all that. Then people eventually come to their senses, and
say, "Well, compared to the cost of the hole, all those things don't cost
very much." If you say, "I've got to have the hole," then adding
the cost of the rest of this stuff is no big deal.</p>

<p class="tab"><b>Miller</b>: The fact is that all the things
we did in the holes for containment didn't amount to all that much cost.</p>

<p class="tab">Of course, the
straight and plumb hole requirement was really a challenge for us, but that had
nothing to do with containment; that had to do with diagnostics.</p>

<p class="tab"><b>Carothers</b>: Yes. Once upon a time we wanted
to do some measurements where the emplacement pipe was to be straight, and just
hang down in the hole like a plumbbob. So, we said we wanted a straight hole,
and you gave us a straight hole. You said, "That hole is so straight you
can look from the top down to the bottom, and you'll find that the bottom is
only off about two inches from the top." We said, "Yeah, but our pipe
won't hang in that hole, because it's slanted." And then somebody,
probably you, said, "Oh, you want a plumb hole. Why didn't you say so. You
just said straight."</p>

<p class="tab"><b>Miller</b>: Yeah. I remember that hole. It
was U2v. In fact, I was working for Fenix and Sisson when that requirement came
for that first straight hole. You said straight, and assumed plumb.</p>

<p class="tab"><b>Carothers</b>: Well, of course.</p>

<p class="tab"><b>Miller</b>: We drilled a twenty-two hundred
foot hole that had a seven foot displacement at the bottom, and it was a
line-of-sight. So, "What's your problem?" "Well, we meant
straight down." I said, "Well, that's a different story."
Anyway, we got so we could do that.</p>

<p class="tab">Another thing that
happened with drilling, and it happened on that event that leaked - Riola. We
drilled into that thing to take pictures of the old emplacement hole, and
missed it the first time. And that brought up something people ought to know,
and we know it at the Test Site now.</p>

<p class="tab"><b>Carothers</b>: It was only a couple of hundred feet down.</p>

<p class="tab"><b>Miller</b>: It was more than that, but
you're right, it wasn't very far down. Anyway, we missed this eight foot target
down there. We did everything we could think of to do it right. Here was
everybody out there, including the containment people who wanted to take a picture
of what was down there, and we missed it.</p>

<p class="tab">Then I did something
that I very seldom ever did. I'd been up damn near four days straight, and I
said, "To hell with it." The whipstocker, the directional drilling engineer
- Robert Thompson had the contract out there - said, "We hit it." I
said, "You couldn't have. It's an empty hole." He said, "Well,
you've got to believe your figures." I said, "Not if they're
wrong." Anyway, he got mad. He'd been up a long time too. We had a little
screaming match, and I told the driller to pick up.</p>

<p class="tab">Then I said, "I
want to set that Dyna Drill at 160 degrees left, and we're going to drill until
we hit that thing." So, the directional drilling engineer got mad and
said, "To hell with you. I'm leaving." I said, "Bye."
Anyway, I picked it up and started drilling. I could do the directional
drilling work myself.</p>

<p class="tab">The partner of the
guy who got mad at me came out and said, "What are you doing?" I told
him what I was doing. He said, "You tell me exactly what you want to do,
and I'll do it for you. You don't have to do it. You're paying me to do
it." I said, "Fine." So I picked up and he drilled it, and I was
sitting there looking at that weight indicator. The whipstocker was in telling
a guy in the doghouse, "We'll be here until Christmas, and we won't get
that thing." It wasn't thirty seconds later it fell in. Hit it dead
center. I thought I was basing this on knowledge, but it was just pure
unadulterated luck. Well, you've got to depend on something, sometimes.</p>

<p class="tab">What people should
remember is that the reason we missed it was because we were using the magnetic
declination of sixteen degrees. We'd been using that for a long time, and we
had known we had missed some targets before. But, we never had the type of surveying
we had on this one. Usually it wasn't all that accurate. Anyway, we got to
checking back, and I called H&amp;N that night and said, "What is the declination
we should be using?” "Sixteen degrees.” And I said, "Yeah.” Well, you
go back to when the NTS first started, and all the charts out there, all the
quads, say sixteen degrees east declination, but in real fine print it says,
"Varying easterly three minutes per year.”</p>

<p class="tab">If you stop and
figure it out, over those years it had changed a degree and a half, and
everybody was still using sixteen degrees. Three minutes a year is nothing. But
over twenty years, you ended up with a degree. Anyway, based on that we started
taking a magnetic declination at each location. And it actually varied a little
bit across the Test Site. That shows how you can get in a rut.</p>

<p class="tab"><b>Carothers</b>: When you first came to the Site
both Livermore and Los Alamos were using holes that were cased all the way
down. How do you do that?</p>

<p class="tab"><b>Miller</b>: Well, this is similar to the
oil fields. The only difference is that in the oil fields the pipes screw
together, just like the pipe you use to emplace the device. Same kind of pipe.
It screws together, and it goes pretty fast. When you get to the bigger
diameters, you have to weld each section together. Those sections are 30 to 40 feet
long. The string is supported by a strongback, and the next joint is picked up
by what we call elevators, and put in and welded. Then you pick the whole thing
up and lower it down so you can put on the next joint, and so on until you
finally get to the bottom. It took a lot of time, and my time, which I was paid
for, but I thought it was ridiculous.</p>

<p class="tab">Now, when you get to
holes that go below the water table you have to do that if you want a dry hole.
You do the same thing of welding a string of casing together. Of course, the
bottom piece has a plate welded across the bottom, and so as the string goes
down the water supports it to some extent. Actually, you put water in it to get
it down, but after it's cemented in you bail that out.</p>

<p class="tab"><b>Carothers</b>: After a few years somebody at
Livermore said, "We don't need to case them." How did you feel about
that? Did you think that made any sense?</p>

<p class="tab"><b>Miller</b>: I can remember when that
happened, and I thought that was great. I thought we wasted so much money out
there it was sickening to me. And I still believe that. Not casing the holes
saved the Test Program so much money.</p>

<p class="tab"><b>Carothers</b>: Many millions. But the argument
always was that you had to case them, because otherwise you might be lowering a
device downhole, and the sides of the hole might slough in, or something like
that. Did you believe that?</p>

<p class="tab"><b>Miller</b>: Oh yeah.</p>

<p class="tab"><b>Carothers</b>: Well, then why in the world did
you think we should not case them?</p>

<p class="tab"><b>Miller</b>: Well, as I remember it, there
was a lot of discussion that went on about it. I didn't really think cave-ins
were going to happen, because we could repair the hole when we were drilling
it, and we did. A bunch of them caved in ahead of time, and we repaired them.
The ones that were really bad we cased. But, holes do slough. Fortunately, one
never has yet with the device in there. But I'll tell you, being out there on a
downhole and hearing rocks falling in is a little discouraging. It happened all
the time.</p>

<p class="tab"><b>Carothers</b>: How did people get up the nerve
to try it?</p>

<p class="tab"><b>Miller</b>: I don't know who originally
did, but I think it was not people, but a person - Charley Williams. He'd just
become Test Director. I was still working for Fenix and Sisson, and Walt
Johnson called me up and said, "How about an uncased hole? Do you think
it'll stay open?" I said, “It depends on where you put it." I was all
for it. Casing was a time consuming experience.</p>

<p class="tab">I'm not sure whether
the first one was 10d or 10w. In fact, I think the first uncased hole, and the
hole with the first device put down on a pipe, was the same hole, on the Test
Site. I think that at Hattiesburg they might have emplaced the device with a
drilling rig, and Rex was another one they did.</p>

<p class="tab"><b>Carothers</b>: Well, uncased holes have been
used successfully many, many times.</p>

<p class="tab"><b>Miller</b>: Yes. But a lot of those holes
sloughed ahead of time, and we'd repair them by cementing up the sloughing zone
and drilling back. You would never have used them without doing that.</p>

<p class="tab"><b>Carothers</b>: It was a long time before Los
Alamos started to use uncased holes.</p>

<p class="tab"><b>Miller</b>: Oh yes. They were dead set
against it, and I never understood it, especially on Pahute Mesa where you have
essentially competent ground. There are very few caving zones on Pahute Mesa.
Some, but not like Yucca Flats.</p>

<p class="tab"><b>Scolman</b>: Our going to uncased holes was
largely based on Livermore's success in shooting in uncased holes. It saved a
lot of money, but our field engineering group was dragged into that particular
regime kicking and screaming. For a long time the argument was, "Well, Area
3 alluvium is not like Area 9 or Area 2 alluvium."</p>

<p class="tab"><b>Carothers</b>: “It's loose, it's unconsolidated,
and it's going to fall in."</p>

<p class="tab"><b>Scolman</b>: Yes, and there's something to
be said for that. It is indeed different. But it turns out that yes, you can
drill it, and the hole will stand. On the other hand, if you will look at many
of the so-called Los Alamos uncased holes, they're uncased for a pretty small
fraction of their total depth. We tend to run an intermediate casing, as we
call it, in many cases through the alluvial layer, all the way, and then we
case when we get below the water table. So there's a relatively short section
that is uncased.</p>

<p class="tab"><b>Carothers</b>: Certainly holes do slough. A
hole is drilled to some total depth, and when checked sometime later it's ten
or twenty meters shallower. I don't think anybody knows whether that material
fell in pebble by pebble or as a hunk of stuff. That would make a difference if
you were half way downhole when it decided to slough.</p>

<p class="tab"><b>Scolman</b>: Test Directors worry about such
things. You're probably aware of one that we had slough immediately after
drilling, which came all the way to the surface. Luckily, it did not go up the hole,
and so the surface depression was actually to one side of the drill rig. It did
slough all the way to the surface. It was in Area 4, and it was within the last
five years.</p>

<p class="tab"><b>Miller</b>: There were two of them that did
that. The first one was an uncased hole that was drilled to like a thousand
feet. They were getting ready to use it, and went over there, and there's a doggone
collapse crater. There's the emplacement hole, and right next to it is the
collapsed area. The thing caved in, all the way to the surface.</p>

<p class="tab">The one they don't
like to talk about is the one that occurred with the drilling rig on it.
Everybody tried to keep that quiet, because if certain safety people heard
about it, who knows what they would have done. What happened was it collapsed
underneath the rig, under part of the sub-base, while they were drilling. They hauled
trucks in there with gravel; several truckloads; I never did find out how many.
They filled it back up, and gently moved the rig off, and abandoned the hole.</p>

<p class="tab">The result of that
was a meeting just between the drillers; there wasn't anybody else involved in
it. I was in some of the meetings. What can we do about it? And I won't mention
any names, but one LASL guy said that they were thinking about putting an
expanded metal mat all over the location, so if it happened again the roughnecks
wouldn't fall in it.</p>

<p class="tab">Then Fred Huckabee,
who is an old driller - he used to be a tool-pusher on one of our post-shot
rigs - he looked at me, and sort of made a face, and he said, "I'll tell
you what. I used to roughneck, Miller used to roughneck, and I think he feels
the same way. If my driller brought me out to a rig and it had this expanded
metal all over everything I'd have to ask him what it was for. And he'd tell
me, ‘In case the ground opens up, that's to keep you from falling in it.'"
He says, "I wouldn't have worked another minute for that driller. I would
have left." And Huckabee really got mad. He was serious, and he said,
"We don't want to start any crap like that, because that tells you that
it's unsafe to do what you're doing. You're putting a safety net like for somebody
from the Circus Circus - in case he misses his grip he's going to fall in the
safety net. You don't want to do that with a drilling rig."</p>

<p class="tab">So there were two
events where that happened in the LASL area, and after those things happened,
if they had an emplacement hole, and had a shot nearby, they would fill the
thing all the way back up with stemming material. Shoot the shot, and go back
and de-stem the hole. Suck the stuff out. Like re-drilling it, essentially.</p>

<p class="tab"><b>Carothers</b>: Didn't they do it with
something like a big vacuum cleaner?</p>

<p class="tab"><b>Miller</b>: Yeah, but it takes a drilling
rig. It was a design by this guy Art Hodge, for the Snubber event LASL had,
where they were going to de-stem this sand stemming in the shaft and reenter
it. We used it in Area 7 during the accelerated program when the stemming
slumped and tore the cables loose. We went out there and worked all night, and
used the same string to de-stem it so they could get down to repair the cables.
So, that's the reason LASL did that. They didn't want to lose any more holes.
They figured the one that occurred without the drilling rig on it was caused by
a nearby shot.</p>

<p class="tab"><b>Carothers</b>: This doesn't have to do with
drilling, but I'll bet you were involved in it. There were a couple of
occasions where we had cable breaks downhole, and we built cages and put people
downhole to fix them. Do you recall those?</p>

<p class="tab"><b>Miller</b>: Oh yeah. I guess about the
worst one was Jorum. It was un cased, but they didn't have to put people down
on that one. On Jorum, all the device and diagnostics was in like a submarine, because
the shot was in an uncased hole below the water table. The stemming material
from the device up to the top of the water was these real beautiful, round
beach pebbles - rounded so they wouldn't abrade the cables. But, they tore the
cables loose, and broke the tape and the kellum grips anyway. They saw that
with the TV. That was the first time I learned what a tremmi pipe was. We ran a
string of pipe in, to the water table, and did the rest of the stemming into
the water through that pipe.</p>

<p class="tab">I went down one hole,
on Flax. Tubing fell in on that one, and it was an uncased hole. They had
pre-run it to put in some CTE plugs. The stemming loads pulled one of the
strings of tubing out of the bracket, and it made a God-awful mess down there.
The top of that fish was about eight feet below the conductor pipe, and it was parted
in two more places down below. We designed a fishing tool to go in and grab the
fish that was across the hole, and an arm that would go out and grab the other
one.</p>

<p class="tab">For the top one they
sent Joe Dehart and I down. All I had to do was to latch these elevators on to
the pipe, and it was sticking straight up, but it took three days to write the
safety notes to send us down there. On the safety note it said, "Under no
circumstances will people be lowered below the conductor pipe." I read
that and said, "Can't do it. The top of the fish is eight foot below the conductor
pipe." "Well, we know that, but we won't get this approved unless we
say that." When I said, "Well, I don't understand," they said,
"Well, that's just to satisfy all the safety people, and the powers that
be." Everybody involved in it knew we had to do it.</p>

<p class="tab">So, we went down
below the surface conductor, and I latched onto that fish. We had sound powered
phones to the surface, and Joe Dehart, who was a big ironworker superintendent,
said, "Hold on there. Take off those phones." So we took the phones
off. He said, "You see down there?" And I said, "Yeah, it's
about sixteen hundred feet to the stemming." He said, "It took three
days to write this damn safety order." I said, "So? What about
it?" He said, "I'll send one of my ironworkers up in a bosuns chair
on the jib of a 4,600 crane a hundred feet, and I don't have to have a safety
order. If he falls out of it and hits the ground, what's going to happen to
him?" I said, "He dies, probably." And he said, "What
happens to us if we fall out of here and fall sixteen hundred feet?" I
said, "We die." He said, "What's the difference?" I said,
"That's easy, Joe. They can produce your ironworker's body. It's going to
be difficult to get our bodies. That's the only difference. The only difference."
He said, "Put your phones on. Let's go up."</p>

<p class="tab"><b>Carothers</b>: As I remember, there was a man
who fell into one of the holes up on Pahute, all the way.</p>

<p class="tab"><b>Miller</b>: Only to the water table.</p>

<p class="tab"><b>Carothers</b>: Well, that's a pretty high dive.</p>

<p class="tab"><b>Miller</b>: That's the only person I've
ever known to fall into an emplacement hole. A laborer fell into a rat hole
where we had put part of the drilling gear in, and it got stuck. They just
lowered a rope and pulled him out. I think he was down about twenty feet.
Scared the dickens out of him.</p>

<br>

<p class="tab"><b>Carothers</b>: People have said, "Well,
we'd never do Baneberry again. We won't do that. The drilling history all by
itself would alert us." I remember that there was lot of work and
cementing and drilling and trying to get that hole down to depth. Could you
tell me what went on there?</p>

<p class="tab"><b>Miller</b>: That was U8d. Well, up there in
that area there is a clay zone, apparently. The geologists tell me that when
water, which is the fluid we use, wets it, it starts caving in. For a month or
so - maybe not that long, but it seemed like a long time - we would drill a
little bit, and it would fall in. And we'd go and put a cement plug in, the
worst way you could put a cement plug. You'd like the hole to cave in cleanly,
and then go and cement through the zone from the bottom up. You can get an
excellent job that way. But when you can't get it cleaned out, you have to get
a little bit going from the top down, and I don't know how many times we did it,
but several times. What they finally did was, I think, they raised the working
point on account of our difficulty in drilling.</p>

<p class="tab"><b>Carothers</b>: We raised it forty feet. I'm
the one who did that. My Test Director, Fred Beane, would come in and say, "Well,
they had another collapse. But, they cemented it up, and they're going to drill
it out." The next day it was, "Well, it fell in again." And it
went on and on. Finally I said, "Fred, how deep is that hole now?" He
said however deep it was, and I said, "You know, that's deep enough. That
meets the overburden criterion. It's not what we said we wanted, but it's good
enough. If you quit messing around with that hole, do you think we could use
it?" He said, "Well, I think so." So I sent out a TWX, and we
took out just one joint of pipe. That's where the forty feet came from. I've
always wondered if we'd had that extra forty feet if it would have held just a
little bit longer, and maybe it wouldn't have come out. I don't know.</p>

<p class="tab"><b>Miller</b>: Let me tell you something else
that happened there that I never will forget. During that process I used to go
to Livermore every Monday morning; they had regular Monday meetings during that
time. After the decision was made to raise the working point I was in Fred
Beane's office. After I'd leave that meeting I'd go to his office, because I
really worked for him, in a way. Ralph Chase and Fred Beane and I were sitting
there, just talking, and Billy Hudson and Cliff Olsen came in there, and they
were really upset about raising the working point. They said, "We're going
to recommend against it, and we're going to put it in writing." Fred came
about half out of his chair, and he said, "You go ahead, and I'll say IN 0'
in writing." They turned red and walked down the hall. When Baneberry went
up in the sky I kept thinking about that.</p>

<p class="tab">The fact is I
recommended we abandon that hole sometime before all that. Not on account of I
was afraid it was going to vent, but because of the drilling problems. It was
costing a hell of a lot of money. It was terrible.</p>

<p class="tab"><b>Carothers</b>: Raising the working point
wasn't one of the smartest thing I ever did, probably. But I was the AD for
Test then, and somebody had to say what to do.</p>

<p class="tab"><b>Miller</b>: Well, it's your fault then, whatever you do.</p>

<p class="tab"><b>Carothers</b>: Yeah, that's right.</p>

<p class="tab"><b>Miller</b>: Well, it was my fault too, because
I couldn't drill it deep enough. We could have got it deeper, but we wouldn't
have got it shot before Christmas. A lot of the times that seemed like the controlling
factor; it was getting to be too close to Christmas.</p>

<p class="tab"><b>Carothers</b>: We didn't want to have people
down there over that time. They want to come home too.</p>

<p class="tab"><b>Miller</b>: Well, there were a lot of shots
over the years that had happened the week before Christmas, and people forget
that the post-shot drillers always worked through Christmas. Nobody ever thought
about that.</p>

<p class="tab"><b>Carothers</b>: That's true. Was post-shot
drilling your bailiwick too?</p>

<p class="tab"><b>Miller</b>: Yes.</p>

<p class="tab"><b>Carothers</b>: Now, in the early days we'd
shoot the shot, and it would collapse, usually. If it did they'd bulldoze a
road down into the crater, move a rig down to the bottom of the crater, and
they'd drill straight down.</p>

<p class="tab"><b>Miller</b>: That was pre-Cambrian time.
That was before me. I wouldn't have liked that.</p>

<p class="tab"><b>Carothers</b>: What's wrong with that?</p>

<p class="tab"><b>Miller</b>: Well, the worst drilling
conditions a drilling engineer can dream up in his wildest nightmares exists
down in a chimney. When you go back in from outside of the chimney, most of
your drilling is essentially in undisturbed ground. You don't get to the chimney
until you get to the chimney edge. And normally, fortunately, most times you
have enough overburden pressure to help you pack the ground so it doesn't
slough in. Not always, but most of the time, you have very little trouble. But
if you start at the top of the chimney and drill through the chimney all the
way down, it's just horrible conditions. Back in those days I would not have done
it. I would have quit. They didn't even use blowout preventers.</p>

<p class="tab"><b>Carothers</b>: What do you need those for?</p>

<p class="tab"><b>Miller</b>: Well, if you like to breath
radioactive gas, I guess no reason. I've reviewed lots of histories of when
they did things like that, and there were all kinds of problems. To investigate
a chimney for a containment scientist would be no problem, because we'd probably
do it six months or a year after the event. But doing postshot drilling rapidly
to get fast-time samples for the radiochemist is a different thing. I'm not
talking about the drilling. The drilling problems are going to remain. I'm
talking about the radiological problems.</p>

<p class="tab"><b>Carothers</b>: One of the things that
interests people in the containment world is, what is the condition of the
rocks in the chimney. They don't think about it in terms of drilling; they
think about it in terms of shooting another shot pretty close by. You said that
if you start to drill down from the top, you've got probably a lot of loose,
broken rock. You lose circulation. I can understand that at the very top of the
chimney, but as you get down a ways isn't that rock pretty well consolidated?</p>

<p class="tab"><b>Miller</b>: No. I don't think so. I don't
have that much experience drilling in the chimney, so some of these things are
what I believe. If it collapsed in one big plug, all at once, instantaneously, naturally
you probably wouldn't have that much difference. But if it did the slow caving
thing, until it finally built up to the surface, it would be different.</p>

<p class="tab">When they drilled
back right after the shot, I don't know how you could have learned anything
about the chimney, the way they pumped tremendous volumes of mud in the hole to
try to get the cuttings away, and contain the radioactive gases. I don't see
how a person could get any knowledge from any of those holes.</p>

<p class="tab"><b>Carothers</b>: People have told me that they
have mined back in the tunnels, and that there was at least one time when they
mined right through where the working point was, and you couldn't tell when you
hit the chimney. It was just competent rock all the way through.</p>

<p class="tab"><b>Miller</b>: They have actually mined back
to GZ. But you can tell. The one I did you could see. I went up there with Walt
Nervik and Ken Oswald, because they wanted to get some radiochemical samples.
They actually went up to the wall with a pick, and got the radioactive glass.
You could tell where the cavity edge was, because this cavity had formed, and
the rubble had come in there. There was a definite difference from one of the
tunnel beds tuff into that rubble zone, at least on the one I saw. There was a
difference.</p>

<p class="tab"><b>Carothers</b>: When you do a drill back, how
do you know when you hit the chimney?</p>

<p class="tab"><b>Miller</b>: Well, there's several things. I
always felt very comfortable out there on a post-shot drilling rig until we got
close to the chimney, then I always was sure things were going to start happening.
There were some of them where we would drill into the chimney edge, drill fifty
feet, and get stuck. When we get to what we call the chimney rubble, it's rock
that's being pressed together by the overburden, and when we put drilling fluid
in there, things happen down there. Sometimes things pretty bad.</p>

<p class="tab">One morning in Area
20 we were drilling along, and we were into the chimney. About six o'clock in
the morning I thought a truck had run into the trailer I was in. I ran outside,
and everybody was running toward GZ, because they thought it had collapsed. Anyway,
I started to go over there, and I couldn't see any dust. The driller said,
"Don't go up there, come up here." We never did get the drill pipe
out of there. We'd had an underground collapse and the pipe was stuck at the
chimney edge, the theoretical chimney edge. We always figured the cavity radius
had gone straight up, because we had no other thing to go on. That's where the
pipe was stuck, and that's where we shot it off. That happened several times. Things
happen down there in that chimney that don't happen before you get to it, and
they're all bad for drillers.</p>

<p class="tab"><b>Carothers</b>: I have heard that one of the
reasons they went away from drilling straight down, to the angle drilling, was
that there was a shot which had not collapsed, and the geophones were quiet. So
they moved a rig in, they were drilling, and all of a sudden the drill stem dropped
about sixty feet. Have you heard that story?</p>

<p class="tab"><b>Miller</b>: Yes. I know what hole it was,
and I know the guy that was there. What happened was, there was no collapse,
but they moved in two rigs forty feet from the GZ, one on each side. They really
crammed the rigs in together in those days. They used two because usually one
of them never got to total depth. Even down in the crater a lot of times they
would use two rigs because it increased your chances for success.</p>

<p class="tab">Anyway, they set the
surface casing at about eighty feet on both rigs, but one rig broke down. They
drilled with the other one to, I'd say, thirty feet below the surface casing
and the tools just fell in the hole. Well, everybody says, "It's fixing to
collapse. It could collapse." So, everybody evacuated the rig. The rigs
were still sitting there. It was Tiny Carroll who said, "I want volunteers
to go in there and tear those rigs down." Now, who is going to tear a rig down
except the roughnecks? There's nobody else qualified. So the roughnecks went in
and tore the rigs down and hauled them out.</p>

<p class="tab">That's one of the
reasons they went to angle rigs, but the main reason was that you can drill
from the side and be in undisturbed rock most of the time. You stay out of the chimney,
so it was quicker, easier, and had more chance of success. You didn't have to
build the road down in the crater. And we could preset the surface casing and
have that all done ahead of time, which you couldn't do in the crater. Angle
drilling was just like a discovered America for post-shot drillers. It was that
kind of a step forward.</p>


<a name="ch15"></a>
<br><br>
<h2>Chapter 15: Emplacement Holes, Stemming, Plugs, and Cable Blocks</h2>
<br>

<p class="tab">Let us suppose a location has
been selected for an event. It is far enough from permanent installations such as
roads and power substations that the ground shock won't cause damage. In
consultation with the USGS, information about the geologic setting is examined
to ensure there are no anomalous features which might compromise containment. A
hole is drilled to a depth appropriate for the yield of the device, and logs
are run to confirm that the formation is as expected. The device and the
diagnostic instruments are lowered into the hole together with their attached
cables. Since this is a simple event, there is no line-of-sight pipe extending
from near the device part way or completely to the surface. In this idealized
scenario none of the many things that can occur to make life difficult for the
field people and the containment people have happened. Everything so far looks
good.</p>

<p class="tab">Except... a hole perhaps eight
feet in diameter and several hundred feet deep has been put into the geologic
medium that appears to be well suited to contain the projected detonation and
its radioactive by-products. And, some tons of metal and other materials have
been placed at the bottom of the hole. There are perhaps a hundred or so cables
that carry diagnostic data and firing signals running from the working point to
the surface. Now the problem is to make the emplacement hole and cables no
easier a path to the surface for gases than the undisturbed medium. The hole
has to be filled with something, and filled in such a way that the cables are not
damaged or broken. Loss of data due to a broken diagnostic cable is not a
trivial matter, but it can usually be tolerated, and perhaps the desired
information obtained on a subsequent event. Loss of the cables that carry the
firing signals to the device is quite another matter, and creates a very
serious problem. And that has happened due to poor stemming methods and badly
chosen materials.</p>

<p class="tab">The cables themselves,
individually and collectively, are a problem, even if undamaged. It has been
demonstrated many times that gas entering the broken and open end of a coaxial
or multiconductor cable can, under modest driving pressures, travel inside the
outer insulating jacket of the cable for hundreds of feet. Cables are round,
and bundling together a hundred or so round cylinders about an inch in diameter
leaves many open channels for gas flow. Many of the small seepages that were
reported on the events in the sixties occurred through the cables and cable
bundles.</p>

<p class="tab">Finally, when the stemming
material is emplaced, you want it to stay there after the shot has been fired.
Where could it go? Into the cavity, of course, and it has happened that
stemming material has fallen from the emplacement hole into a cavity that did
not collapse for some time. Or, it could fall into the apical void that typically
forms at the top of a collapse that does not reach the surface, leaving an open
path for gas transport.</p>

<p class="tab">Faced with such problems in emplacement hole stemming, Los Alamos
and Livermore have taken different approaches to solving them.</p>

<br>

<p class="tab"><b>Carothers</b>: Bob, how did the Los Alamos
stemming plan evolve? You started with just pea gravel and cal-seal.</p>

<p class="tab"><b>Brownlee</b>: Well, remember we started out
in 1957 only trying to cut the fallout down. We saw the efficacy of plugs,
because if we put in a plug somewhere, that did a pretty doggone good job. One of
the tests we did was to have just a plug half way down in the pipe - nothing
else. Then we did one with a plug that sat just a little ways above the bomb.
Same kind of plug, but it did a much better job. It really cut the stuff down.
We said, “Well, that makes sense. If you hold it in, it's going to blow a
bigger hole because it can't go up, and it will get rid of more energy right
there in place. And that's a good idea." That's how we got started.</p>

<p class="tab">Then we came to '61,
and we said, II All right, we want to put a plug down low." And we had discussions
about the stuff that was coming out. “How is it coming out? How are we
measuring it?" Well, we were not measuring it so we could distinguish
between whether it was coming out through the stemming or whether it was coming
out of the cables. We didn't really know. So we went with hand-held meters to a
cable, and it was hot. Well, it was coming out of the cables, and it was coming
out of the stemming too.</p>

<p class="tab">So we put some
cal-seal on top of the hole. What if we put some cal-seal lower down, and kept the
gas down lower? "Well, the gas is in the casing of the emplacement hole,
and it doesn't matter where you stop it. Besides, you have the ground shock,
which will just break the cal-seal loose from the side of the casing and the
gas will come on up anyway." It wouldn't do that if the casing had a good,
clean, dry wall, and wasn't all covered with rust. So we did some experiments,
not at the Test Site, of pouring grout in iron casings that had not been
cleaned out, and ones that were cleaned out. We did this all very slowly - when
I tell the story it sounds more logical than it really was, but these questions
kept being addressed.</p>

<p class="tab">We finally decided to
try some fines, some finer grained gravel. Okay, some fines. What if you just
gathered up some surface material and dumped it down there? Would that do a
better job of holding the gas down? I think I came across the philosophy very early
that the farther down the hole you can keep stuff, the better off you are. So,
instead of putting cal-seal at the surface, let's put it down in the hole.
Well, the moment we started talking about pouring cal-seal downhole, the J-6
engineers had massive hemorrhages. "That can't be done. Impossible. And
besides the cables will have leaks, they'll get water in them, and we won't get
any data."</p>

<p class="tab">Okay, let's get away
from the cal-seal. Let's just put in some fines material as a plug, and see if
that helps. Yes, it seems to. How many of these fines plugs do you have to put
in? It all depends on the shot. Now, this business of "it all depends on
the shot" means that you have to tell the engineers in the field to do
something different each time, and we all know that they rarely have the mental
capacity for that. Therefore, what we need to do is have a standard stemming
plan. If the yield is big this thing works, and if the yield is small that
thing works. And you can always pour a little cal-seal on top.</p>

<p class="tab">Then you can order
your stemming by the foot, and they understand that. You just say, "However
deep the hole, just start by putting in a fines layer, and every so many feet,
put in another one." Then they don't have to think. You don't have to give
them a magic formula for each shot, and they just have this one thing to do.</p>

<p class="tab">And then you go out
and discover they're cheating! They're not really putting in the layers at the
places that you said they should. So you read them the riot act, and they say,
"But why? It doesn't matter where they are." Well, that's sort of
right, but you say, "We've got to know where they are anyway." And
so, there evolved, finally, LASL Standard 5. We said, "Okay. You do it
that way, and we'll watch to see that you do it that way. No more of this discussion
of 'Why can't it be different? Why can't it be random?' You do it the way we
said." We evolved to that, and it worked fine.</p>

<p class="tab">So, the reason why
our Los Alamos Standard 5 stemming plan had such a perseverance was because we
never happened to challenge it in a way that required us to make any change.
And therefore it lasts to this day.</p>

<p class="tab">But, if you look very
closely, you'll find that we have the standard plan, but you'll also find it's
modified here and there. This thing has actually been moved a little bit up,
and the spacing is a little different, for instance. If you look into it you'll
discover that it's not quite as standard as everybody thinks.</p>

<p class="tab">I think I have to say
that the LASL Standard 5 stemming plan was notably successful for our shots,
which tended to be pretty much the same, in the sense that there was a time
when we did relatively simple things. Livermore was doing exotic things, and so
they never knew quite what was going to happen, but we always knew what was
going to happen. The yield was not going to be more than this much, and we
could be pretty sure of that. We did things that even if they failed, they
didn't fail wrong, they failed safe. Therefore, our stemming plan handled the
things we were doing adequately, and I think it's fair to say that is true.</p>

<p class="tab">As we got better the
fines became different kinds of fines. The coarse became different kinds of coarse.
But, as we got the ability to calculate these things, we discovered those fines
were awfully good. No matter how they were shaken up with ground shock they still
bonded as tightly to the casings as ever, or to whatever, because we did a lot
of shots with casings. We discovered that by the time the gas had gotten around
very many of those layers the pressure in the cavity had fallen, and it was all
over. We had lots and lots of those layers, not just three or four.</p>

<p class="tab">There's one more
thing that we did different from Livermore in the early times, which was all to
our advantage. We allowed the stemming to breathe for a long time; we'd pour
some stemming in and we'd let it sit while any trapped air came out, and pour
some more stemming in. It was very slow. We did this as much for convenience as
for understanding what was going to happen, I think.</p>

<p class="tab">The Livermore
attitude was, :We're going to shoot tomorrow, we're behind schedule, and so we
will just dump in all the sand.” Livermore frequently worked behind the power
curve. It's just that simple; they were behind, and you could always catch up
all the time in the stemming process. Whereas, we had a schedule where, literally,
we were usually ready a week or two early. So, you could take all the time you
wanted. You stem, then you go down to the Steak House and have dinner, and come
back tomorrow to stem some more. This allowed our stemming to solidify, and all
the breathing was gone. On the other hand, Livermore started having collapses
of stemming. The stemming would suddenly slump, and it would tear the cables
off, and it got expensive. The only reason they changed is because it got
expensive.</p>

<p class="tab">However, I felt that
it was important to containment, and we started arguing that you needed to get
the air out of the stemming; you've got to let those fines compact and you've
got to let them settle. So, finally, the rate of stemming became a containment issue.</p>

<p class="tab">Hindsight says we had
to stem slowly whether we knew it or not, because we didn't dare not let those
fines take time. As a result, we never had any slumps of stemming. Finally, the
argument was that the reason we stemmed slowly was so we wouldn't have slumps,
but that's the engineers' argument. From the containment point of view we were
arguing you are stemming slowly because it has something to do with
containment, not just slumps. But a slump, if it broke the cables, was very
expensive.</p>

<p class="tab">Then we did a shaft,
and now we had a great huge opening; twenty feet by twenty feet. Now you have
slumps no matter how slowly you stem; there's a bubble there, it works its way
up, and the stuff slumps. So, we got caught on one of the shafts where we had a
slump which tore some cables. It turned out that we were stemming so slowly we
could go down and repair it right there, so it wasn't very expensive. You just
put people down there with their soldering irons and their pliers. In a shaft
you can get to it, but it's troublesome, because if you're stemming you've got
the bomb down there.</p>

<p class="tab"><b>Carothers</b>: Was it as surprising to you as
it was to me, Tom, that you could not pour sand down a rat hole, as it were?
And a very big rat hole.</p>

<p class="tab"><b>Scolman</b>: Yes, and I think it surprised
the people who poured it down. We found out the hard way that it was, indeed,
possible to bridge certainly a four foot diameter hole, and probably a hole of
any diameter you want, and have the stemming fall in later. So the thing that
started first off was, "Okay, what is it that we can really fill a hole
with?" And so we came up with the requirements, for example, of dry
material and material of a certain size.</p>

<p class="tab">The notion of
alternating coarse and fine layers came before my time; it was in existence
when I got there. My belief is that was done so one could say with confidence
that the permeability of the stemming column was lower than the permeability of
the surrounding medium. Remember we were mostly in cased holes in those days. I
think the ability to emplace the material was as important a part of the
criteria as the permeability. Whether that was so or not I don't know, because
as I said, that was folklore that was there when I came.</p>

<p class="tab"><b>Keller</b>: When I came to Los Alamos in
1966 the only interesting events were the line-of-sight events. We barely
considered the rest of them. Charles Brown used to talk a lot about the quality
of the grout job behind the casing, but that was about the main concern for the
normal emplacement hole event. The line-of-sight pipes involved the only
challenging containment problems, as far as I saw them.</p>

<p class="tab"><b>Carothers</b>: The Nuclear Test Ban Treaty had
been signed in 1963. A fair fraction of the events that were fired during the
mid to late sixties, of whatever nature, released some amount of activity. Some
of the amounts were pretty small, but maybe a quarter, or maybe a third of the
events recorded some amount of leakage at the surface. Was that considered
acceptable? Why wasn't Charles Brown worried about those?</p>

<p class="tab"><b>Keller</b>: Well, you look back now and it
seems cavalier, but at the time, while any leak was disliked, the seepage of
noble gases wasn't considered a major failure. The concerns were mainly that there
would be so much flow up the line-of-sight pipe that you'd have a major fallout
problem from the venting. The next level of concern was that you'd have enough
radiation leakage from the event to fog the photographic film in the recording
trailers. Below that, it was just an operational nuisance to have a leak. Hot
cables were pretty common.</p>

<p class="tab">But there was, even
before Baneberry, a deliberate attempt to limit the leakage to nothing. Then,
as now, J-6 stemmed the holes. And the question was whether or not the stemming
would work well enough. The LASL Standard 5 was the stemming plan for all the shots,
and it had been developed early on. It was developed partly to avoid slumping;
that's the reason the coarse materials are in there. The coarse material is
terrible stemming, if you consider gas flow, but it doesn't slump and that was
why they used so much of it. Then they put in the fines, layers, in moderation,
to get some impedance to gas flow.</p>

<p class="tab">The last event I
worked on before Baneberry was Manzanas, and that was the first event where Los
Alamos used coal-tar epoxy plugs. That was the hated, messy stuff that
Livermore had dreamed up, and J-6, Rae Blossom and company, were not the least
bit interested in being caught using a Livermore material. The whole idea was
abhorrent. So, I ran into a lot of resistance in trying to design a stemming
plan when I requested coal-tar epoxy plugs on Manzanas. And yet, it was pretty
clear that the stemming plan for Manzanas would be better if it had some
impermeable plugs in it instead of just coarse and fines. So, they finally
relented, and it was used.</p>

<p class="tab"><b>Carothers</b>: Jack, Livermore and Los Alamos
have always had different stemming plans. Do you know why that is so?</p>

<p class="tab"><b>House</b>: I guess I would have to sum it
up by saying Livermore has been far more adventuresome in looking at different
types of stemming material and stemming plans, and to some degree I think that
is an artifact of Livermore having dedicated engineers, who are paid to go out
and look for new and different, and perhaps better, ways to do things. Los
Alamos has never had the engineering resources to address questions of that
nature, and be adventuresome. I hate to cry poor, but this is really, to some
degree, the case.</p>

<p class="tab">When I joined the
containment business, the stemming plan was pretty simple. It was the LASL 5,
with alternating layers of coarse and fines, with the coarse lifts always being
about four to five times longer than the fines material. They had begun using
an additional type containment feature that was known as coal-tar epoxy, or
CTE. It was awful stuff - ultimately deemed unsuitable for use by humans. The
plan was pretty much defined, and we used that basic plan with little, if any,
alteration.</p>

<p class="tab">Now, that stemming
plan works, and there is an element of, "If it ain’t broke don't fix
it." The other thing about the LASL 5 basic stemming plan, which features
the alternating layers of coarse and fines material, is that we are very fond
of the apparent attenuation properties of the three meter thick lifts of fines
that exist in our holes, as far as slowing the gas down as it tries to find its
way toward the surface. Recently Livermore has chosen to use long lifts of sanded
gypsum concrete, and that seems to work fine for them.</p>

<p class="tab"><b>Carothers</b>: As I recall, before Baneberry
one of the things that was done about leaking cables was to go back in, cut the
cables, stuff the ends into the surface casing, and pour cal-seal on them.</p>

<p class="tab"><b>Olsen</b>: That was SOP for a long time.
We started using gas blocks not long before Baneberry; there were two or three
events before Baneberry where we had gas blocks. Those were for multiconductor cables,
which were pretty leaky. At the time co-ax’s also leaked. We were looking at
how to gas block co-ax’s, which you could do, but you had to use bulkhead
connectors, which the experimenters didn't like. We ended up manufacturing gas
blocked cable, to avoid as much as possible putting something discrete in the
line.</p>

<p class="tab">We were also looking
at cable fanouts before Baneberry. The event which sort of tripped the whole
thing on cable fanouts was Pod. We had some downhole motion-diagnostics, and
part of the accelerometer and velocity gauge is a thermister to measure the temperature,
because the damping is temperature sensitive. We saw, way up the hole, inside
the cable bundle where this package was buried, that the temperature went up to
that of steam, give or take a little. After a little thought it became obvious
that we had nice conduits in the cable bundle, which let the gas go straight up
.</p>

<p class="tab"><b>Carothers</b>: What was the origin of the
plugs? Were they material to seal the cable bundle?</p>

<p class="tab"><b>Olsen</b>: The first plugs were on
line-of-sight shots. We had some plugs on line-of-sight shots where the plug
was more a matter of structure than containment. Usually those holes were
cased, and the plugs were there, most commonly, to tie the pipe to the casing, to
control the response to the ground motion. Los Alamos was doing a number of
line-of-sight shots too, and they started to look into using plugs of some
sort. I think they had a concrete plug on Finfoot.</p>

<p class="tab">Then, because of the
diagnostics we had, we slowly began to realize these things were also stopping
gas that was coming up the stemming. We were looking at various things in stemming
columns, putting in radiation and pressure transducers. For stemming we put fines
in, and coarse in, and sometimes NTS dirt. Sometimes in the sixties you would
fill the hole with anything you could get a bucket loader into.</p>

<p class="tab">We tried cement, and
on Plaid we had a polymer plug. That stuff, which was a sloppy, milky mixture,
set up into a plug that was kind of the consistency of a tough gum eraser. I
think it was probably one of the best plug materials we've ever had. We'd still
be using it, but it was so damnably expensive, even then. But it was great,
because it didn't fracture, and it was really tough. It wasn't structural per
se, but it did tie things together, and it stopped flow around closures, which
was the thing that we had in mind.</p>

<p class="tab"><b>Carothers</b>: There was a shot on Pahute Mesa
where somebody, who shall be nameless, had a concrete plug poured, and somebody
else forgot about exotherms, and so the cables got hot, softened and shorted
out.</p>

<p class="tab"><b>Olsen</b>: Ah yes. On Greeley and Duryea
both we had those problems.</p>

<p class="tab"><b>Carothers</b>: People learn slowly, don't
they? One might wonder why it took two times to get people's attention. It's
strange to look back on, and you wonder, “How could such a stupid mistake be
made once, and how could it possibly be made twice?"</p>

<p class="tab"><b>Olsen</b>: I agree with you, but I think
it was part of the lack of a detailed overview. There were people doing their
own little thing, and it never occurred to the mechanical, or civil engineers
that the cables could have a problem. And it never occurred to the electrical engineers
that these guys who had been dumping stemming into holes for years would come
up with something to screw up the cables. And we did not have an overview that
looked at these interactions. I'm not sure that we still have that to quite the
extent that we should.</p>

<p class="tab"><b>Carothers</b>: Was that concrete plug for containment?</p>

<p class="tab"><b>Olsen</b>: The early things that went on,
on Pahute, were kind of funny, because some of the stemming things that went on
were done by engineers, who almost tried to second-guess containment. We didn't
design it. Some event engineer would say, "Well, containment is probably
going to want a plug, so I'll throw in a plug." So we'd see the plan, and
there would be the plug. So, okay. Not knowing that it should be somewhere
else, or whatever, we thought that was great, that we were finally getting some
respect, and they were putting in a plug. On Pahute, where we had never had any
experience with problems, and because there were no long lines of sight, or
anything like that, we didn't really look at the stemming very carefully.</p>

<p class="tab"><b>Carothers</b>: Something that Livermore
started to use routinely was one or more solid plugs in the stemming column,
which would support the stemming above them, and also be an impediment to gas flow.
Why did you think plugs were necessary, and start to use the coal-tar epoxy
mix?</p>

<p class="tab"><b>Olsen</b>: In retrospect that particular
thing probably got its rudiments from Scroll. After we looked at the results
for a while, we realized that we had a plug there, but the cement was in the wrong
place, and the stemming all ran into the cavity. If we had put it in the right
place we could have put in a lot less, and it would have done a better job.</p>

<p class="tab"><b>Hudson</b>: I guess we really started
worrying about plugs as containment features in Area 2, where we had subsurface
subsidences, followed by, perhaps, the displacement of gas to near the surface,
through the chimney. We weren't quite sure how the gas got to the surface, if
it did. But, if it did, it seemed to occur in several stages. During some of
the earlier stages we appeared to have radioactive gas going up the stemming
column rather easily. And so, we argued that putting in plugs to better block
the flow of gas was a good idea. Those were more for a gas block, I guess, than
they were for a stemming platform.</p>

<p class="tab">I don't remember just
when it was we decided that we needed a stemming platform. It was primarily
driven by the idea of a subsurface subsidence, where a significant amount of
gas would be displaced perhaps halfway to the surface, after which we might have
some, or all of the stemming fall into the void at the top of the subsidence.
Any kind of stemming fall would eliminate the impedance between that pocket of
gas and the surface. We wanted to avoid that. Riola was a perfect example of
where we needed a stemming platform, and we had one that didn't work.</p>

<p class="tab"><b>Carothers</b>: I remember one occasion, and
there were probably others, before Baneberry, where there was a stemming fall.
The device went unexpectedly low yield. It was buried quite deep, and only went
about a kiloton. That left a standing cavity into which all the stemming fell,
leaving an open hole to the surface. So, I believe stemming falls do occur. But
again, the LA5L argument is, "Well, the fines bridge, and we never lose
stemming."</p>

<p class="tab"><b>Hudson</b>: After starting to use
instrumentation in the past few years to monitor the performance of their
stemming, they have seen gas halfway up the stemming column, on some events, in
a fairly short period of time. They've also actually observed their stemming column
falling into the void above a chimney. Now, they will argue that they expect
the stemming to bridge; they expect the stemming not to fall. But you may
remember a CEP meeting where I asked Wendee Brunish if they thought they could
depend on that. She said, "No, but we don't really need it anyway."
So, they've lost confidence in their stemming as being a dependable bridging mechanism.</p>

<p class="tab"><b>Carothers</b>: The Livermore stemming has been
criticized in the last year or two on the grounds that most of the stemming is
just gravel, with a few plugs of gypsum concretein it. How did you arrive at
that kind of design? Was it based on measurements you'd made?</p>

<p class="tab"><b>Hudson</b>: I think the current design is
driven more by the philosophy of “good enough is good enough" than by
measurements. The only place you really block the emplacement hole is where
you're blocking the cable bundle and the cables themselves. So, long stretches
of low permeability stemming, where you don't do anything about the cable
bundle, is not effective anyway. Los Alamos, on the other hand, has reasoned
that stretches of coarse material will give the gases a chance to get out into
the overburden. So, maybe a mix of low permeability and high permeability
stemming is a good idea - that was their argument.</p>

<p class="tab">The current Livermore
plan is sort of a blend of Livermore and Los Alamos philosophy. The only
benefit that the coarse can possibly have, from a containment point of view, is
to allow the gas to expand and come into contact with the porous medium around it.
And that may be good. If you have a continuous cable bundle, surrounded by low
permeability material, it will certainly be a much better conduit than a cable
bundle surrounded by a very porous and permeable material. In either case we've
always felt that the only real block to the flow of gas is a location where you
block everything across the hole, including the cable bundle.</p>

<p class="tab"><b>Carothers</b>: You put the gas blocks there,
the fanouts there, the impermeable plug there, and that's presumably where the
gas will stop. Now, it has seemed strange to some people, me included, who visualize
the process as the device going off, the cavity forming, and maybe a lot of
noncondensable gases in the cavity which move out through the medium, which has
some kind of permeability. This gas should move out more or less spherically,
somewhat like a bubble, and when it comes to the plug, which is perhaps forty
or fifty square feet in area, the surface area of that bubble is thousands of
square feet. So, the gas just flows on around the plug, so what's the use of
the plug?</p>

<p class="tab"><b>Hudson</b>: I think the plugs in the
stemming column can only be effective at quite early times. Certainly what's in
the stemming column can't stop what's going on outside the stemming column, and
so you're right there. Sooner or later the gas is going to travel as a bubble,
and this is probably what happens on Pahute Mesa, where you have late-time
breathing. Even though we block it in the emplacement hole, there are enough
fractures to allow the gas to expand until it finally intersects other
fractures that reach the surface, after many hours, or days.</p>

<p class="tab"><b>Carothers</b>: Late-time seepage out of the
cracks on Pahute Mesa could be due to the fact that most of the material
covering the Mesa is the Rainier Mesa member, which was laid down while it was
hot. As it cooled, it cracked. It's several hundred feet thick, and the cracks
are not necessarily through going, but gases can move from one to the other. In
that context, that rock is almost not there to prevent the very slow seepage of
gas. It provides overburden, but not gas blocking. Does that seem to be a
reasonable scenario to you?</p>

<p class="tab"><b>Hudson</b>: Statistically it certainly
seems sound. A study that was done did strongly suggests that there is a
correlation. When this Rainier unit is exposed to the surface, certainly well
over half the time you end up with some late-time seepage, or breathing as it
is called. Whereas, when you don't have that member exposed, you don't have
that seepage. There are other circumstances from time to time also, like rad
chem drilling, which are hard to sort out. On the Barnwell event there mayor
may not have been a very late-time seep without the post-shot hole, but there
is evidence that the postshot hole was involved in a flow of gas toward the
surface. So, it's maybe not as simple as the statistics imply. The fact that we
don't see these late-time seeps on Pahute when we don't have this material exposed
at the surface is an indicator that there's probably something to the theory.</p>

<p class="tab"><b>Peterson</b>: Something that we did for
Livermore was a program on atmospheric pumping and why gases come out of
underground shots at long times after the shot. I think it has given them a
little different picture of why gases come out of chimneys.</p>

<p class="tab">The history of it
goes back a long way. When we did the DNA chimney pressurization experiments,
and we looked at the tracer coming up to, say, the top of the chimney and
detected it, one can imagine that when you put gas into a chimney, the gas
you're putting in is expanding as in a balloon. If that were the case, if you sampled
at the top of the chimney you'd see no tracer for a while, but eventually, when
the balloon got up to where you were sampling, you'd see the concentration that
you were putting in.</p>

<p class="tab">Well, obviously this
doesn't happen, because Mother Earth isn't uniform. If we look at the results
we got from the DNA chimneys, we started detecting the tracer maybe a factor of
ten earlier in time than you would expect if were expanding like a balloon. I f
we should have seen it in forty hours, we'd see it in four hours at the top of
the chimney when we had hardly any pressure up there. In thinking about that
for a while, it became somewhat obvious that the theory that one gets gases out
of chimneys just by simple atmospheric pumping - in other words, atmospheric
highs and lows - is not the right picture. That's a driver, but that's not why
it comes out. In order to get the gas to come out you need nonuniformities in
the material, and it sort of bootstraps its way out.</p>

<p class="tab">I talked to Livermore
about it because I knew they were interested in it many years ago. They thought
we were crazy, or whatever, but more recently they became somewhat more
interested. So we set up an experiment with a sand column, in a plexiglass
tube, about four inches in diameter, maybe six feet high. We had a void region
at the top that represented the atmosphere, and a void region at the bottom
that would represent a cavity, for example. The sand represented the alluvium,
and you can go through the equations and scale things so you get the relative volumes
almost correct.</p>

<p class="tab">The hypothesis was
that if it's just atmospheric pumping in a uniform medium, as you think of
alluvium, you would get gas out. I really didn't think you would. So we did a
number of experiments. In one of them we set it up with a uniform sand column,
and we put gas with a tracer in the bottom chamber that represented the cavity.
In another one we put gas with a tracer in the bottom, but we put a pump on the
top that would vary the pressure, as atmospheric cycles do. Because this is all
scaled one can do a lot of cycles in a fairly short time, and we ran it for
four or five thousand cycles. It was equivalent to a thousand years of
atmospheric pumping. Well, sure enough, when we monitored the tracer up in the
top volume, the tracer concentration in the one that wasn't pumped turned out to
be exactly the same as the one that was pumped. The pumping made absolutely no
difference whatsoever.</p>

<p class="tab">The pumping is a
driver, but you need some nonuniformities. So, we made a second sand column in
which we put one permeability of sand in an outer annulus, and a different
permeability of sand in the center. We used a very thin aluminum pipe in the
column so we could fill the center with one sand, and the outside annulus with another
sand. We did two columns that way. We left the pipe in one of those columns,
but pulled the pipe out of the other one so the two sands could talk to one
another. Well, in the one where the two sands could talk to one another the
tracer came up very fast. The column where the pipe was still in acted just
like the one that was absolutely uniform.</p>

<p class="tab">So, the whole thing
on this pumping business is that you need the atmospheric pumping, but it is
the degree of nonuniformity that exists that makes it work. It is the small
fractures, or nonuniformities in permeability, that determine how fast the
atmosphere can pump these gases out. When it is nonuniform, some gas flows up
in the fast flow paths, and as it does that it diffuses out to the side. When the
atmospheric pressure changes it can't push all the stuff that's diffused out to
the side back down. And so, on the next atmospheric low, a little more moves up
and diffuses out, and tends to stay there during the next high. If you have a
lot of these nonuniformities, then the gas can move up quite a bit faster than
if you have a fairly uniform medium. That's a containment thing that we have
looked at and studied, and I think we found some interesting answers.</p>

<p class="tab">We're still doing
some work on it. There are a bunch of models, and part of the work we're doing
is to look at some of those experimental results. There is some data, and we're
trying to look at it to see whether we can characterize what the formation
looks like, and why it has done what you see that it has done. You can say, IIGee,
it would be nice to learn all these things, and then somebody could go out and
drill one drill hole, and they would know whether that's the perfect place to
do a test or not." I think we're a long way from that. But I think you
have to learn these things, and get an understanding of what's happening, even
to be able to make the judgment as to whether you're ever going to be able to
do something like that or not.</p>

<p class="tab"><b>Carothers</b>: The things that have been done
in the field since Baneberry have essentially eliminated the seeps and leaks
through the stemming and the cables that had happened on both Laboratories' shots
fairly often before then. What did Los Alamos do about the cables, for
instance?</p>

<p class="tab"><b>Scolman</b>: We had been gas blocking
multi-conductors before Baneberry. After that we started gas blocking coaxial
cables. And, we pushed for the development of continuously gas blocked cables. As
I've often told people, anytime you break a cable you're asking for trouble.
For example, when you look for trouble with wiring in your house, or car, you
don't go to the middle of an existing run of wire; you look at the connectors.</p>

<p class="tab"><b>Carothers</b>: Did you ever do cable fanouts
before Baneberry?</p>

<p class="tab"><b>Scolman</b>: I don't think so. They were
initially a pain until we, and I think in this case until Livermore, figured
some simpler ways to do it. We did, for a while, have big three-dimensional
cages where the cables were physically separated from each other. They were a
pain to put down. And most of the time when we found we had a cable problem
going downhole, it was either where we had put a gas block in, which involved
breaking a cable and putting in a physical connector, or going through a
fanout. We made a point that whenever we were going downhole, when we had gone
by cable gas blocks, which in general meant a fanout in the same area, before we
went any further we required a complete cable check. We didn't want to put the
device downhole and then find out we had to bring it back later. And we did
have trouble doing those things. We also did an awful lot of experimentation to
try to do things that were probably not possible to do. One of the early
requirements was that our cable gas blocks and our plugs in the casing should
be able to handle five hundred psi. We found pretty soon that probably was not
possible.</p>

<p class="tab">The plugs were the
problem. The cable gas blocks you can make that good, but you can't make the
plugs that good. The other problem, of course, is that if you're going to tell
somebody that a downhole plug is good for five hundred pounds, you better be
able to test it in place. That's pretty tough to do, unless you put a pipe down,
and force a whole hell of a lot of air down there to start with. So, that
requirement on the plugs went away, but we did a lot of work trying to do
things like that.</p>

<p class="tab"><b>Carothers</b>: My impression is that Los
Alamos came to the use of plugs somewhat reluctantly. Why was that, aside from
the fact that they're expensive, messy, and a pain to emplace?</p>

<p class="tab"><b>Scolman</b>: I'd agree that it was
reluctantly. We didn't really think they were necessary. We had a body of
experience that said fines plugs were very effective. When you say 'plugs',
generally what you really mean are 'stemming platforms.'</p>

<p class="tab"><b>Carothers</b>: They're called a couple of
different things depending on who's talking about them. And I suspect the
people in the field who were emplacing them called them a lot of things we
needn't mention.</p>

<p class="tab"><b>Scolman</b>: To my knowledge, at least in my
time, I don't believe Los Alamos ever claimed one of their plugs was a stemming
platform.</p>

<p class="tab"><b>Carothers</b>: Well, Tom, I have been on the
CEP for many years, and I have seen the Los Alamos presenters perform various
interesting verbal contortions to avoid calling them stemming platforms.</p>

<p class="tab"><b>Scolman</b>: They were directed not to do
so. We did not believe that the material being used for these plugs was the
kind of physical material that one could count on to stop a stemming fall. In
other words, coal-tar epoxy is not a strong material. It's a little bit like asphalt.</p>

<p class="tab">There was some
pressure for us to follow the Livermore lead and call the plugs stemming
platforms, as guards against a loss of stemming. Our field engineering group
got their backs up and said, "Look, we're not going to tell you that it's
a stemming platform unless we do something to engineer it to be a stemming
platform. For example, put in a reinforced cage and some high strength
concrete.” We did, by the way, for quite a while, put a concrete layer under
the lowest plug to protect the coal-tar expoxy from heat. That was a bit of a
push toward saying, "Okay, it is indeed a stemming platform./I At least
there was protection from hot gases being there right at that surface. But we
were - reluctant is too mild a word - not going to buy in to the coal-tar epoxy
plugs as stemming platforms.</p>

<p class="tab"><b>Carothers</b>: Well, you were ultimately
proven to be right. There was Riola, the coal-tar epoxy stemming platform was challenged,
failed, and all the stemming fell out. That led to different kinds of plugs.
LANL now is using two-part epoxy, aren't they?</p>

<p class="tab"><b>Scolman</b>: Yes. I think that was driven as
much as anything by the toxicity of the coal-tar epoxy. Plus the fact that I
think it's a little cheaper. I've forgotten the numbers, but some appreciable
fraction of the cost of the stemming material was made up by the coal-tar epoxy
plugs. And frankly, I've always considered them chicken fat - just something
that makes you feel better. Particularly the lower ones.</p>

<p class="tab">Something that has
always bothered me is that I think if Los Alamos, in particular, can be faulted
in any way for the containment regime we've gotten ourselves into, it would be
because the things we do were designed for cased holes. We now use them almost exclusively
in uncased holes, and many of the things that are done don't make very damn
much sense in an uncased hole. Including using impervious plugs in a pervious
medium.</p>

<p class="tab"><b>Carothers</b>: Billy, the Livermore plugs are
supposed to support the stemming in the event that the stemming is lost beneath
the plug. Will they do that? How do you know?</p>

<p class="tab"><b>Hudson</b>: We advertise that the top two
plugs, the plugs that are forty or so feet thick, are stemming platforms. We
believe, based both on calculations and experiments, that any of our gypsum plugs
would act as a stemming platform, even if they were only twenty feet thick. We
have never seen, based on our measurements, a gypsum plug fail as a stemming
platform, even though it's been as thin as twenty feet. But then, we've only
had them challenged a small number of times. The twenty foot plugs, I think,
have only been challenged twice.</p>

<p class="tab"><b>Carothers</b>: You mean by challenged that
there has been a loss of stemming below the plug, the plug stayed there and the
stemming above the plug stayed there, so they worked?</p>

<p class="tab"><b>Hudson</b>: Yes.</p>

<p class="tab"><b>Carothers</b>: The coal-tar plugs were
emplaced by pouring the gravel and the coal-tar in at the top of the hole at
the same time, but seperately. One of the criticisms of that process was that
you really didn't know what kind of plug was formed when those materials
reached the bottom and presumably mixed.</p>

<p class="tab"><b>Hudson</b>: That's why we now mix the material
before we put it downhole. Instead of just letting it dribble down the side of
the hole we now put it in through a pipe until it's within about fifty feet of
its final resting place. I like to describe the process we were using in the
past as like throwing gravel and cement over the top of your house, hoping to
get a patio in your backyard.</p>

<p class="tab"><b>Kunkle</b>: Brian Travis tried to model the
heating and cooling of coal-tar epoxy plugs. In Los Alamos holes this was the
material we emplaced as rigid plugs, at the time. CTE, as we knew it by its initials.</p>

<p class="tab"><b>Carothers</b>: Over a couple of Los Alamos
engineers' dead bodies, probably.</p>

<p class="tab"><b>Kunkle</b>: Well, that material could
certainly make you dead if you came into contact with too much of it. I was
astounded when I first got here to learn they would actually use this stuff in
any field setting.</p>

<p class="tab">A thing I recall from
graduate school is watching a colleague, Dave Lolley in the Physiology
Department, who studied rats and rat problems. One of the rat problems he would
cause is skin cancer, which he would cause by simply painting coal-tar onto the
skin of the rat. After a few weeks, the rat had skin cancer. So, I was sort of
shocked to find we were using coal-tar in rather large amounts at the Nevada
Test Site.</p>

<p class="tab">At any rate, one of
the calculations that I was watching Brian Travis do was the expected heating
of the plugs - the rise in temperature due to the exotherm as the epoxy set,
and the subsequent decline in temperature - as indicated by the thermistors in
the plugs. They didn't make any sense. This must have been in July, August,
September, 1980.</p>

<p class="tab">We could make no
heads or tails of those downhole temperature measurements. A tentative
conclusion we reached was that the coal-tar and the gravel that was put into it
- it was a coal-tar concrete - must not have been well mixed together. There
must have been some plugs where one side was mostly coal-tar, and over on the
other side it was mostly gravel.</p>

<p class="tab">Each plug was
different, and none of them behaved as they should. That was a puzzlement to
us. And then, it must have been September, October, the Livermore Riola event
seeped a tiny amount of gas to the surface. That caused quite a stir, because
one of the coal-tar epoxy plugs had failed to hold the stemming material that
was above it. The plug simply wasn't there. Reentry observations showed that,
indeed, it was probably never there. That is, the stuff had been put in the
ground but it had never formed into a monolithic uniform plug.</p>

<p class="tab">Brownlee detailed me
at that time to go study coal-tar epoxy plugs, and the problems that were
plaguing them. I dutifully took on this assignment, and together with Billy
Hudson we formed a little outfit we called the Stemming Plans and Stemming
Modification group, otherwise known as SPASM. We investigated coal-tar epoxy
plugs, how the Laboratories were emplacing them and using them, and how well
they might be performing. This involved pouring plugs, full-scale plugs, in a
hundred foot deep hole we had, and pulling them back up. Then we broke them
apart to see what was in them. And we found that, as the calculations had
suggested, those downhole plugs were miserable.</p>

<p class="tab">They were not what
they were planned to be, but they had properties similar to those you might
have inferred from simple downhole diagnostics; the temperature records. They
were not uniformly mixed. They were segregated; sometimes into layers of nearly
pure coal tar epoxy, sometimes layers of gravel, and that type of behavior
could have been inferred, and partially was inferred from the temperature records.
There were diagnostics that coal-tar epoxy had been put down the hole, and that
it was reacting, because it had generated heat.</p>

<p class="tab"><b>Carothers</b>: It had generated heat, the
temperature had risen, and then had started down. Therefore it was setting up,
and becoming a rigid plug. I suspect that the people who were making those
measurements used the temperature records only to say, "Well, see the
temperature has come down and the plug is now cured. Therefore, we can
shoot."</p>

<p class="tab"><b>Kunkle</b>: That's right.</p>

<p class="tab">We began talking
about the the replacement of coal-tar epoxy with an alternate material. We, Los
Alamos and Livermore, finally settled on a water-based epoxy, Celanese by brand
name. We both put TPE, two-part epoxy, plugs in for a while.</p>

<p class="tab">This episode of
switching from coal-tar epoxy to two-part epoxy involved a lot of, "Well,
let's look back through the records and see what's actually happened on our
past events." This was a time to, quite literally, review all of our
post-Baneberry underground nuclear tests for how they were stemmed, what
downhole diagnostics were put in and what those diagnostics might have seen. The
thermistors were the in-situ diagnostics in the plugs and there were sometimes
something about plug performance. There were also radiation and pressure monitors,
RAMS units, instruments to measure surface accelerations, occasionally some
downhole accelerations - that kind of stuff. We went through, shot by shot, reviewing
our history of Los Alamos stemming. That got me pretty familiar with what we
had done in the past, and why, and what problems had been encountered.</p>

<p class="tab"><b>Carothers</b>: Those coal-tar plugs had been
used for many years, more than ten, at least.</p>

<p class="tab"><b>Kunkle</b>: We first put them in just
before Baneberry, on Manzanas. And before the Baneberry event we had a design
for a shot which would have some in it, but that shot was fielded after the Baneberry
stand down.</p>

<p class="tab"><b>Carothers</b>: The lesson to be learned from
coal-tar plugs is that probably during that ten or so year period all of those
plugs had been very poorly mixed. And that was okay because nobody knew it. People
would say to the Panel, “We have a stemming plan like this, and we have these
coal-tar plugs. They have been used successfully on x-teen events." Then
one day one got challenged. And it failed. Until a feature has actually been
challenged and survives the challenge, a statement like, “Well, we're going to
put in gypsum concrete. We have used that successfully ten times," doesn't
mean very much.</p>

<p class="tab"><b>Kunkle</b>: In the pre-Baneberry era, the
shots were without plugs. We saw many small releases, but they were acceptable
under the guidelines at the time. They didn't seem to much bother anybody, and
it was fairly well understood, by at least a few people, where they were coming
from. That was flow in cable bundles and such.</p>

<p class="tab">The coal-tar epoxy
was introduced to stop the flow in the cable bundles. That was it's real
purpose for us at Los Alamos; at least that's why we started using it. And it
seems to have worked pretty well at that, even if it didn't ever set up into a real
plug. When we did introduce the coal-tar epoxy plugs, and used them routinely after
the Baneberry stand-down, along with the cable gas blocks, the small releases
we'd seen near surface ground zero stopped. And so the coal-tar epoxy plugs
were quite satisfactory from some standpoints, but they were not structurally
competent to serve as stemming platforms .</p>

<p class="tab"><b>House</b>: TPE is not the ES&amp;H problem
that CTE was in terms of handling, and it is a much more suitable plug because
it does, in fact, become a rigid plug. There was a confirmed suspicion that
coal tar might never get hard and set up, and could, in the event of a stemming
fall below a plug, perhaps drain away. And in one confirmed instance, it did.
We have seen physical evidence in terms of pictures provided to the Panel of
just that happening. And that event in and of itself really spurred conversion
to some other type of plug material.</p>

<p class="tab">TPE is,
unfortunately, a far more expensive, in terms of pour per linear foot, than
Livermore's sanded gypsum concrete. But for some reason, that I won't attempt
to address, our field operations people have been not particularly receptive to
making a move to sanded gypsum concrete. I think, cost notwithstanding, and if
I remember the Chairman's sermon, delivered more than once, cost is not to be
considered a factor in containment design, we at Los Alamos favor the TPE
because of its properties. Albeit, we are in a process now of reducing the
number of TPE plugs, and replacing one of them with a grout mix designated as
HPNS-5, which means Husky Pup Neat Slurry, which seems to have a lot of
reasonable properties, and is far easier to emplace at great depth.</p>

<p class="tab"><b>Carothers</b>: How do you emplace the two-part
epoxy plugs?</p>

<p class="tab"><b>House</b>: Two-part epoxy is emplaced in a
very simple fashion. It is pre-mixed at the surface, in a specially configured,
or specially insulated, transit mix truck. The two-part epoxy is called, by the
Celanese Corporation, Part A and Part B. Three-eighths inch pea gravel
aggregate is added to it. It goes through a mixing process and comes out of the
truck, down a chute, and free falls down the hole. At one time we attempted, I
believe on the Trebbiano event, to emplace a plug at 990 feet using a tremmi
pipe. I think the field engineering folks had a six inch tremmi pipe to pour
the stuff down, and it didn't go down very well at all. And so it was concluded
that trying to emplace it through a pipe was unsuitable, and we have continued
with the free fall method.</p>

<p class="tab"><b>Carothers</b>: Do you have any concern that
there might be some separation of the gravel and the epoxy?</p>

<p class="tab"><b>House</b>: As you watch it come out of the
chute, out of the transit mix truck, it's easy to see that it is well mixed,
and the epoxy has enough adhesive properties to pretty well entrain the gravel
in it as it goes down hole. We're talking about 3/8 inch aggregate, which is
pretty small. Also, although admittedly this isn't a free fall sample, we do
take five gallon buckets right out of the end of the chute, and go test it. But
of course, that doesn't tell you what it is like when it gets to the bottom of
the hole.</p>

<p class="tab">We have done
experiments in abandoned or unusable emplacement holes, where we have poured
plugs at, say, 120 feet, and then gone down and cored them, and done some
sampling. At least at that kind of a depth, which is essentially equivalent to
the standard location of the top TPE plug, we find them to be pretty well
mixed, far more so than the old coal-tar plugs.</p>

<p class="tab"><b>Carothers</b>: Livermore has gone through a
series of stemming plan changes. Why didn't Livermore observe that LASL has
never had a seep since Baneberry, think their stemming plan must be pretty
good, and use the same design?</p>

<p class="tab"><b>Hudson</b>: I think if we could be sure we
had the same sort of working point medium, which we probably do if we put our
shots in tuff, it probably would be perfectly okay. The alluvium in the Los Alamos
areas has been described as "more forgiving" in that their alluvium
is less cemented than most of the Livermore alluvium. In fact, they have
difficulty in drilling a large diameter hole in their alluvium, which means
that it isn't cemented as much; it doesn't hang together.</p>

<p class="tab">Consequently, It's
always been a question, a puzzle, why they have historically had better luck
than Livermore. Their overburden material won't support open fractures like the
Livermore overburden will, and I suspect that's the main reason. In practice I
don't think it has always really been that much better. Prior to Baneberry their
release rate wasn't much different from ours. Since Baneberry we've had two
seeps, and they've had zero. What sort of statistics are those?</p>

<p class="tab">There's another
reason for the changes we have made. We've always paid a lot more attention to
the performance of our stemming plans than Los Alamos has to theirs, by using
downhole monitors to see what goes on. When we saw that radiation was getting
higher in the hole than we liked, we tried to make changes to stop it. Almost
all of the time those threats - when we had radiation higher in the hole than
we wanted - would not have led to a release. We were only concerned that they
were an indication of something, maybe, worse to come.</p>

<p class="tab">Los Alamos, on the
other hand, has for the most part ignored the performance of their stemming
plans. It's only recently that they've started fielding very many downhole
radiation detectors, for example. So, I suspect that they were fat, dumb, and
happy, while we were trying to fix things that weren't all that important.</p>

<p class="tab"><b>Carothers</b>: Well, if I were to speak on the
side of Los Alamos I could say, "We monitor the performance of our stemming
plans with the ground zero radiation monitors, and the stemming works just
fine."</p>

<p class="tab"><b>Hudson</b>: And I can't argue with that. If
you're only concerned with yes or no, as opposed to how and how well
containment was achieved, the statistics are such that you can't argue with
them.</p>

<p class="tab"><b>Rambo</b>: We're the only ones who do a
full stemming column calculation for the vertical shots. We include the
stemming column in the calculation. For many years all we did was the outside
world, but now we put in the plugs. We have material properties for the coarse
material, and when it was sand we had that, and for a while we were putting in
the two-part epoxy plugs.</p>

<p class="tab"><b>Carothers</b>: Might that be because Los
Alamos could say, "Why do calculations? We never have any trouble with our
stemming plan."</p>

<p class="tab"><b>Rambo</b>: That was true until recently.
But you can say that about just about anything in containment. Recently they
had a shot where gases got quite a ways up the hole because some of the stemming
fell out. Before that they didn't have that kind of problem. They thought that
the fines layers were going to compress strongly, because they showed in one of
the tunnel shots that the fines material does turn into something pretty hard.
That's a sellable argument. We ran with fines layers for a while too, in the residual
stress area, but we had some leaks past them. So we went to sanded gypsum
plugs, thinking they might be even better material, and we've still had some
leaks past those plugs. It didn't seem to make any difference whether we had
one or the other.</p>

<p class="tab"><b>Carothers</b>: It has always seemed a little
surprising that a plug would matter. In an uncased hole, when gases come to a
plug why don't they simply go around it? They can go into the native material as
well.</p>

<p class="tab"><b>Rambo</b>: Sure. And I imagine they do in
many cases. The difficulty is that once they get into the stemming, then you're
relying on man-made items to stop them before they get up to the surface.</p>

<p class="tab"><b>Carothers</b>: Livermore uses a few long
gypsum plugs in a column of gravel. That gravel has probably a permeability of
a hundred Darcies or more. Los Alamos uses many alternating layers of gravel
and fines, rather than a lot of gravel and a few plugs.</p>

<p class="tab"><b>Rambo</b>: And what do you hear when you
talk about that in our containment group? You hear things like, "Gee, it
costs a lot of money to put in those fines layers."</p>

<p class="tab"><b>Carothers</b>: Of course it does. Almost
anything you do is more expensive than just dumping in gravel. Putting in
sanded gypsum plugs isn't free, however.</p>

<p class="tab">When I see a drawing
of the stemming plan at the CEP, the vertical and horizontal scales are
different, so it appears that the hole is rather short, and pretty big in
diameter. The plugs appear to be thinner than their diameter. Now, if you
showed me the stemming plan with equal vertical and horizontal scales, there
would be a long, very thin emplacement hole with a few long, thin plugs in it.
Looking at that kind of representation, the plug appears to be just a small
irregularity in the ground.</p>

<p class="tab"><b>Rambo</b>: Yes, just another rock. It is
amazing, but there have been many times when they've measured pressure below
it, or radiation below it, and not measured anything above it.</p>

<p class="tab">I think it also helps
to put a plug in the so-called residual stress field, because you've compressed
all this material, and flow may indeed stop there. The cavity pressures that
they've measured seem to be decay and reach a plateau where they sit for quite
a while. That suggests to me that there is leakage, but not at a horrendous rate,
but of course shots are different in this regard. The pressure in the
Cornucopia cavity, which was fired in a fairly weak material, sat there for a
number of hours before it finally decayed all the way. It was down around
twenty bars, which is fairly low, but it was still there for a fairly long
time.</p>

<p class="tab">It's enough to say
there's something there that isn't letting all the cavity gases go out
immediately. There hasn't been enough data to put the whole story together yet,
but there may be something there. If we could see more data, perhaps we could
see that in a weaker material there is something which happens, or doesn't happen,
so the gases are held in for a while.</p>

<p class="tab">There were shots,
like Roquefort and Coso, where calculations showed them close to the margin,
and they had radiation high in the stemming column. I think one of the failures
in this business is that when we have radiation up the stemming column, very
seldom is anything ever done post-shot to look at why that happened. And without
ever looking at that you're doomed to keep repeating it. You never learn anything
unless you stop and take stock, and say, "Why don't we learn something
about this?" The constant statement is, "Well, it contained."
But by how much? And what did you learn from that? That part of the process is
dead.</p>

<p class="tab"><b>Carothers</b>: I can't remember any
significant post-shot exploration in the past few years.</p>

<p class="tab"><b>Rambo</b>: That's right. Anyway, there is
this realm of calculations that shows things on the margin sometimes. I'm not
sure it was totally residual stress, but I looked at Roquefort after I had presented
it to the CEP, and I said, "Look, there are some weaknesses around the top
of the cavity." I told the containment scientist, "It looks to me
like you could get something into the stemming column. Even though there's
residual stress in the outside world there isn't enough residual stress to
close across this coarse material that we're using for stemming. That's hard
rock with lots of permeability. How much residual stress does it take to close
that off? I don't know."</p>

<p class="tab">That's one of the key
issues that we don't really think about very carefully, and it's part of the
difficulty in interpreting the calculations. I told them, "I see you've
put your two plugs in some very weak areas in the hole. If you do get gases up
there, it's liable to go past the first two plugs." Well, that's exactly
what happened. And at that point I quit doing that because I was ahead of the
game, and it'll probably never happen again.</p>

<p class="tab">What I'm learning in
this process is that maybe I shouldn't be quite so positive about having a
residual stress and that means we're not going to get anything up the stemming
column. Of course, we've had a lot of successes, and that's why there's such
limited experience. The failures are really where you do most of your learning.</p>

<p class="tab"><b>Carothers</b>: Billy, in summary, why should
there be two different stemming plans? I could say, "One is better than
the other, so you should use the better one." Or, "They're both
equally good, in which case you should use the cheaper one."</p>

<p class="tab"><b>Hudson</b>: It really is not terribly
rational to have two entirely different stemming plans. I think we are getting
closer together. Maybe the people in the containment programs at Livermore and Los
Alamos are a little more rational today than they were in the past. But one
wonders, "Why have we persisted so long in doing things differently,
almost for the sake of doing things differently?" I think we probably
should adopt similar stemming plans, and similar ways of blocking cable
bundles. Parts of each are probably better than parts of the other. Parts of
each are less expensive than parts of the other. Why not develop a compromise
which is as good as either one, and costs less than either?</p>


<a name="ch16"></a>
<br><br>
<h2>Chapter 16: Tunnels and Line-of-Sight Pipes</h2>
<br>

<p class="tab">The Livermore people did the
first several tunnel events, starting with Rainier in 1957. One of the problems
that concerned the diagnostic physicists as the movement to underground
detonations began was that they would not be able to, on an underground detonation,
get the data that they were accustomed to getting on atmospheric shots. Fast
camera records for the determination of the device yield from the growth of the
fireball, for example, seemed to be out of the question. Or, how could there be
multiple lines of sight, looking at the reactions in different parts of the
device? And so on.</p>

<br>

<p class="tab"><b>Brownlee</b>: The guys who measured things,
whether they were the radiochemists, or the physicists measuring reaction
rates, or looking at neutrons or x-rays or gammas or whatever, felt that they obviously
needed to test in the atmosphere. So, when we got ready to go underground -
were forced to go underground from their point of view - there was the
hand-wringing, the weeping in the streets, the swearing, because, "We can't
make our measurements any more. We can't learn what we need to learn about the
bomb." Therefore, if they had to go underground they wanted, always, a pipe
that looked at the bomb and gave them a solid angle that was as big as the one
where they used to stand for an atmospheric shot. And this pipe had to be open
all the way. That's what they wanted.</p>

<br>

<p class="tab">To some, a tunnel seemed to offer
the best way, underground, to provide such access to the device. In principle a
tunnel could be as big in cross section as someone was willing to pay for.
Further, the device itself, and the associated firing equipment, could be brought
in and the device made ready for firing in a way very similar to the way it was
done on the atmospheric shots. Since there was personnel access to detector
stations until very near shot time, alignments could be made and checked, a
failed detector could be replaced, vacuum leaks could be repaired, and so on.
All of these things were difficult or impossible when the device and all the experimental
equipment had to be lowered down a relatively small diameter emplacement hole.</p>

<p class="tab">On the other hand, if there was
to be no release of radioactive materials to the atmosphere, somehow the
opening leading to the device had to be closed after the desired information
was obtained. The experience was mixed. Rainier had released no radioactive material.
Nor had Logan, which had a line-of-sight pipe used to allow samples to be
exposed to the device output. Neptune and Blanca had vented. Both of those
could be attributed to an insufficient amount of material over the detonation.
So, it seemed that an underground detonation with a pipe of some size to allow
the radiation from the explosion to reach diagnostic detectors, or to irradiate
samples could certainly be done and the detonation contained. However, as later
tunnel events showed, containment of the radioactive products was not as simple
as it had first seemed, nor was it easy to assure the protection of the
samples.</p>

<p class="tab">But first, to do an experiment in
a tunnel the tunnel had to be mined. Bill Flangas was the mining superintendent
at the Test Site for many years.</p>

<br>

<p class="tab"><b>Carothers</b>: I have asked people why they
picked Rainier Mesa for the first underground tunnel shot, and about the only
answers I have gotten is that it was there, and it was good minable rock. What
do they mean by “good minable rock?"</p>

<p class="tab"><b>Flangas</b>: Well, it's a rock that's in the
neighborhood of a couple of thousand psi in compressive strength, and so it's
easy to mine. In the tuffs in Rainier it's easy to drill out a face, and once
you've drilled it you didn't even have to use full strength dynamite. We were
using 25 to 30 percent compared to the usual 50 and 60 we use in hard rock.
It's the kind of material that has to be supported, but it's easily supported.
In those days we were using wooden sets, and then we went to steel sets, and
used some rock bolts. Then we went to wire mesh and shotcrete, which is a
mixture of cement and water. It's a modern version of gunnite. The products
come out of the nozzle, where they are plastered up against the wall. It's
gotten refined to the point where getting six and seven thousand psi strength
with shotcrete is pretty routine.</p>

<p class="tab">And in tuff you can
use the Alpine Miner, which is a machine that's like a tractor. It's got a
boom, and on the end of the boom is a rotating cylinder, which has carbide bits
on it. This boom articulates up and down, and back and forth. As the cylinder
rotates it just grinds the rock away. It works very well in soft rock, like
tuff. It wouldn't touch granite.</p>

<br>
<p class="tab">During the Hardtack II operation,
from September 12 to October 31, 1958, seven devices were detonated in tunnels
in Rainier Mesa. Neptune, Logan, and Blanca were mentioned in Chapter 1. Mercury
(slight yield), Mars (13 tons), Tamalpais (72 tons), and Evans (55 tons), were
all events with very low yields, but even so all but Mercury released some
radioactivity. Following Tamalpais, fired on October 8, 1958, there was a
noteworthy incident related to the gaseous by-products of a detonation, which
were not, in a sense, contained.</p>
<br>

<p class="tab"><b>Flangas</b>: Tamalpias was where we had the
infamous hydrogen explosion. When we shot Tamalpias, because of the short lived
products, some of the early readings in the tunnel were up there in the 10,000
R range. And so the consensus was, "Okay, this tunnel is gone." And
we still had not fired Evans.</p>

<p class="tab">We had been working
seven days a week, twenty-four hours a day, and I never left that tunnel day or
night. Most of the time I was sleeping on my desk. By the time we shot
Tamalpais some of us were flat wore out. So, once they start reading those kind
of numbers it looked like the ball game was over as far as that tunnel went,
and I went home. I got home about nine or ten o'clock that night, and I was
still asleep at two o'clock the next afternoon when a call came through that
said to hurry on back. The readings were down to 300 or 400 mR, and they were
anxious to get started again. By the time I got back up there it was like four
o'clock. The Livermore honchos were there, and some of my troops had been assembled
and they were there.</p>

<p class="tab">I asked the question,
“What have we got." They said,"It looks like the highest exposure
right now is like 400 mR." We could stand that for reentry. And then, of
course, my next question was about explosive mixtures. I was assured that there
was no explosive mixture. What had really happened is that due to the inexperience
of both the Lab people and others, the meters they had in those days got
saturated, and so they were reading zero, when in fact the place was loaded
with hydrogen.</p>

<p class="tab">I went into the
tunnel and I went back several hundred feet. The hair was standing up on my
head, because I knew there was something wrong, but I couldn't put a finger on
it. So, I came back out, and I repeated the question. "How are we in terms
of an explosive mixture, or are there are any other gases, or any exotic gases
I don't know anything about?" And again I was assured. "Quit worrying
about it. You do not have an explosive mixture."</p>

<p class="tab">I went back in the
tunnel. We were doing some preliminary work to get started, because it was
important to get ventilation established so we could clear the tunnel out so we
could proceed. I came back out again, was reassured again. As I ruled out every
possibility, it occurred to me to wonder if my antennae weren't geared to an
oxygen deficiency. One of the things copper miners fear the worst is oxygen
deficiency, and in those days, in a copper mine, under Nevada state law, you
had to provide every miner with a candle. The way you checked for oxygen
deficiency was with a candle, because a candle goes out at 16% oxygen, or
thereabouts.</p>

<p class="tab"><b>Carothers</b>: You can also check for hydrogen that way.</p>

<p class="tab"><b>Flangas</b>: Oh boy, can you. So, anyway, I
lit the candle, and I went all the way back in the tunnel. I was holding it
just about chest level, and it was burning, so that ruled out oxygen
deficiency. The rad-safe superintendent had climbed up on a sandbag plug, which
was at about the 700 station - 700 feet from the portal. And he says,
"Hey Flangas, hand me that candle." So, I handed him the candle.
Well, being a light gas, and without that environment having been disturbed,
the hydrogen had accumulated along the top of the tunnel. He was up in that
atmosphere, and Lordy, Lordy. I was standing in the middle of the drift, at the
700 station, and he was up at the top of that sandbag plug. He said, when we
talked to him a couple of days later, that he saw a flame that just went down
to the 1,200 station, where the other door was, and he was fascinated by the
sight. I was standing right on the track there, and the next thing I knew I was
head over heels, and when I picked myself up, I was at the 350 foot station.</p>

<p class="tab">I have no idea... it
was ... just everything was in motion. We had laid plywood along that entire
tunnel to protect the cables. That plywood was shredded to sawdust, to small fragments.
There was a six inch steel door at the 350 foot station, and fortunately one of
my shifters laid the track across there. We had to pull the track out to close
the door, so when we opened the door, we put the track back in. That six inch
door folded over that track into a U.</p>

<p class="tab"><b>Carothers</b>: Bill, with all that going on,
how come you're sitting here today?</p>

<p class="tab"><b>Flangas</b>: I have never been able to
figure that out. I came out of that thing without a scratch. I think if you
tried it a miIlion times you'd have a million dead miners and never succeed in
duplicating that.</p>

<p class="tab"><b>Carothers</b>: What about the guy who was up
on the sandbag plug?</p>

<p class="tab"><b>Flangas</b>: Fortunately, what happened to
him is that when it went off the concussion knocked him down to the base of the
plug, and when the explosion took place, it blew over him. Now, in that melee I
turned around to look for him. My miner's lamp was shattered, and the place was
just a bedlam. So, I looked for him for about a millisecond, and then I
decided, "What the hell, it's every man for himself, and I'm getting out
of here.”</p>

<p class="tab">There were another
four or five people in a side drift, and they escaped the blast. It went right
past them. After all of this settled down we kind of found one another in the
dark there. We finally retrieved this fellow by the name of Wilcox, and he was
out colder than a wedge, at the base of the plug. When the blast door folded over
it left a hole just barely big enough for a person to squeeze through. We
accounted for everybody and got them out. The people on the outside were pretty
excited. They thought everybody in that tunnel was dead, and that was a pretty
good presumption at that time. So they called the ambulances and doctors, and
there was a lot of commotion. It was a very unique experience.</p>

<p class="tab"><b>Carothers</b>: There was another case where
somebody turned on the power at the portal, and caused an explosion.</p>

<p class="tab"><b>Flangas</b>: That was the same incident.
Once we got everybody out, and things settled down, we put a gate with a
four-inch wire mesh across the portal. We just took some two by fours and made a
gate to keep anybody from inadvertently walking into the tunnel. Then somebody
said, "Well, let's turn on the lights and see what it looks like."
So, they turned on the lights, and that was the second explosion. I was gone by
then, but they tell me that wooden gate we put at the portal, with a four-inch
mesh, sailed some three or four hundred feet away. So, those two incidents took
place in the same tunnel within a couple of hours of each other.</p>

<p class="tab">We learned a hard
lesson there. As a result of those incidents, in a very short time reentry
became a very formal, tightly controlled process. That was a long time before
the rest of the Test Site became procedurized. In fact, I think I'm the person
responsible for developing and calling for the first formal mine rescue
training. I had a vested interest, because I was leading a lot of those reentry
teams. From there on it became a very sophisticated process, and it remains so
to this day. No shortcuts, and no hurry up and do something unless you've ruled
out all the possibilities. Subsequent to that there has never been another
incident of that type.</p>

<p class="tab"><b>Carothers</b>: There had been, in 1957, the
Rainier shot. After the moratorium started there was extensive reentry work.
Did you have anything have anything to do with that reentry?</p>

<p class="tab"><b>Flangas</b>: I had a lot to do with Rainier.
Once I came here and worked for a few days at E tunnel, I was sent up to take
over B tunnel. B tunnel was the one that had the Rainier shot, and at that time
they were making some efforts to dig a little incline down towards the original
ground zero. But Livermore had a couple events that they needed to fire prior
to the moratorium, and there was just one hellacious effort to get them off.</p>

<p class="tab">After the moratorium
started, and things settled down, we started mining back to recover the initial
ground zero, and we did. The only radioactivity that couldn't be handled was
just as you entered the cavity, where the melt was up against the wall. What we
did was, we just put some lead plates up where we crossed that threshold. Past
that you got into a relatively radioactively cool area.</p>

<p class="tab">The real problem on
that was the ground temperatures were still in the neighborhood of 160 to 170
degrees. We were drilling and blasting, and the manufacturer of the dynamite
wouldn't guarantee the product beyond 180 degrees. And we were dealing with at
least 160 degrees. So, we would drill the holes for the dynamite, then we would
cool them with water, and then put three or four people in there loading. We
could load it out in about one minute flat, under the circumstances, and wire
it. So, we felt fairly secure, even though the manufacturer would only
guarantee the dynamite up to 180 degrees. We knew that the manufacturers give themselves
a little wiggle room.</p>

<p class="tab">Every time we exposed
a fresh face, because there was a lot of humidity there, there was just a
tremendous amount of steam, and visibility was bad. And then there was this
business of really pushing on the loading and shooting. The miners took all that
in good stride, and we knew that it was significant work. There was always a
great degree of excitement with this business, and I guess that's what kept us
here. It was a unique operation.</p>

<p class="tab">We did that during
those moratorium years. Later on it was decided, I guess when things began to
get shaky with the Soviets, to prepare a couple of three test beds in the event
they were needed, so we dug a couple more sites up there at B tunnel, and we
were putting one down at E tunnel also. Then there were three tunnels, called
I, J, and K, which, if I remember right, came right after the Russians broke
the moratorium. We built up tremendously during that period.</p>

<p class="tab"><b>Carothers</b>: Only two of those were used.
That area was abandoned after Platte and Des Moines vented. Gene Pelsor said, "The
reason they're behaving like that is because the rocks are different." Us
somewhat naive physics types said, "Rocks? Different? What's different
about a rock?" Anyway, after Des Moines and Platt Livermore got a little
wary of the tunnel business, and began to move more and more to drill holes. I
think the last tunnel shot they did was Yuba, in 1963.</p>

<p class="tab"><b>Flangas</b>: That's about right. That was, again, up in B tunnel.</p>

<p class="tab"><b>Carothers</b>: Did you do any work on things
like Hard Hat, or Pile Driver? They were in granite.</p>

<p class="tab"><b>Flangas</b>: Yes, they were in granite. I
quarterbacked both of those. Granite is a much different medium than tuff. The
granite there is about ten, twelve, fourteen thousand psi. It takes different things
and ways to mine it. In the tuff we were drilling with a rotary drill with a
wing tip on it, and we could drill out the holes for the dynamite in a round in
fifteen or twenty minutes. In the granite it took an hour and a half two hours to drill
out a round. Generally we would drill ten foot holes and try to pull nine feet a round.</p>

<p class="tab">There were a number
of fracture patterns there, and there were a couple of major faults there too.
But generally speaking, the fracture patterns were very tight, and the material
stood up very well. But there were a series of hairline fractures, in a regular
sequence.</p>

<p class="tab">Pile Driver was an
extraordinarily big, complicated, expensive event. It took some three, three
and a half years to prepare and execute that. There was a shaft, and a drift at
the bottom. I think it was Walsh that sunk the original shaft down to about 800
feet. That first event, Hard Hat, took place there. Then I wound up making the
reentry on Hard Hat. That was my piece of that action.</p>

<br>
<p class="tab">Carter Broyles was the longtime
head of the Sandia effort in underground test and containment:</p>
<br>

<p class="tab"><b>Carothers</b>: Came the moratorium in 1958
with the balloon with the bomb hanging on it as time ran out. What did you do
during those three years of the moratorium?</p>

<p class="tab"><b>Broyles</b>: Designed Marshmallow.</p>

<p class="tab"><b>Carothers</b>: For three years?</p>

<p class="tab"><b>Broyles</b>: Almost. We designed and built
it once, in E tunnel. Then when we went back to testing we started all over
again. I did a few other things during that time. I finished writing reports
from the above ground tests, but I did spend a lot of time on Marshmallow. In
fact, for the next I don't know how many years, along with Wendell Weart, who
was the Containment Director for DNA or its predecessors, I was the Scientific
Director for DNA's effects tests. I was the Scientific Director for
Marshmallow, in '62, and then for Midi Mist, in '67. That job doesn't exist at
DNA now, but in that job I took the overall responsibility for not only the
engineering design of the tests, but for the experimental designs of the tests
as well.</p>

<p class="tab">Olen Nance, a
consultant, was my containment expert, along with Jack Welch, for Marshmallow.
It was Olen who designed the hook, the side drift, on Marshmallow, which was
supposed to close the tunnel off for sure.</p>

<p class="tab"><b>Carothers</b>: That was an experiment which
was designed to get effects information, in an underground environment. Logan
was the first event of that type, but Marshmallow was somewhat different. You
must have spent a lot of time thinking about sample protection.</p>

<p class="tab"><b>Broyles</b>: We did. That was really the
first horizontal line-of-sight (HLOS) containment design problem that we faced.
Marshmallow, in a way, was the most severe test we've ever had, because it had
two line-of-sight pipes. One looked directly at the bomb, and the other looked
into a holhraum. So, we were stemming and trying to close two pipes, one above
the other, both of which were pretty good size.</p>

<p class="tab">The original tunnel
stemming concept started out with stemming, then voids, then more stemming; the
general concept was to be non-symmetric to be sure we didn't generate jets, or
a continuous flow down the pipe. That design disappeared, and was replaced by
others, some of which may or may not have been better. The whole community was
developing a calculational capability, so people's understanding of what you
could and couldn't, and ought and ought not to do for containment developed
partly as people developed the tools for calculating what might be expected.
Bill Grasberger had some input into those calculations, even though he was
mainly the bomb designer for the initial source.</p>

<p class="tab">Olen's original idea
was really a follow-on from the buttonhook design of Rainier, which was
designed to push from the side and slam the tunnel shut. His design was a
cheaper, maybe more economical way to go. Instead of the buttonhook, it was
simply a side drift at an angle. It was designed to store energy, so it was
lined in order to slow down the diffusion of the energy, and so produce a stronger
ground shock. It wasn't very many shots later when people decided that the hook
wasn't all that useful. You could get just as much by the ground shock
squeezing the tunnel down.</p>

<p class="tab">There were two sets
of doors on Marshmallow. They were simply big, steel doors mounted like the
prow of a ship, They were covered with sheets of HE, and slammed shut as a
V-shaped thing. They were really debris stoppers and were not designed to
contain gases. That's what we had on Marshmallow. So, it was really the ground
shock that did any containment that occurred.</p>

<p class="tab">Marshmallow, while it
didn't contain perfectly, didn't really damage the outside world very much, as
did some other underground tests. If you go back and look at Marshmallow, it
had essentially every measurement of every type we've ever done on an test with
a source like that, including piping out a line-of-sight, and moving the camera
bunker underground. We reentered, and the cameras were recovered. The cameras
were in a protected bunker, which had a positive overpressure from tanks of
nitrogen. It was just like things we've been doing ever since. The film was
exposed to a few R, but it was given special development, and they actually recovered
images.</p>

<p class="tab"><b>Weart</b>: One of the first things I got
involved in when I came to Sandia was to reenter an event called Marshmallow,
which was a tunnel shot that was conducted in Area 16, in 1962. It was a shot with
a long line-of-sight pipe, in a tunnel. It was conducted for experimental
purposes, rather than for developing a device, and was considered to be a
relatively successful event. At that time there had been only a small amount of
experience with tunnel shots, and particularly with pipe shots in a tunnel.</p>

<p class="tab">Being a geologist,
and with my background, I provided the technical direction for that reentry.
People had a desire to continue this type of testing, but they realized that
they understood very little about what phenomena, what mechanisms actually
determined whether or not you could prevent the radioactivity from coming down
the tunnel or down the pipe, and out to an area where it would cause you great
difficulty with the recovery of your experiments. So, they thought maybe we
could learn something by mining back in to the first several hundred feet from
the detonation point. We wanted to see if we could reconstruct from what we
observed there what may have gone on. We did develop some ideas and concepts which
were used on subsequent pipe shots, but we really didn't have a good
understanding. It was all very empirical in those days.</p>

<p class="tab">Mostly the kind of
thing we did on Marshmallow was to collect samples of the material we had used
to fill portions of the tunnel. On that particular event the stemming was just
sandbags, and in fact, the tunnel wasn't completely filled. There were
individual stemmed sections with long air gaps in between. We took samples from
those plugs to see to what density they had been compacted by the ground shock.
Even in the void areas, where there was no stemming, the tunnel was now full of
the surrou'1ding tuff, which had been injected into these void regions. And it
was tightly compacted, as was the stemming material. To me the most impressive
thing was to go back in to where the pipe had been, and see the complete and
utter disruption of any continuity of the pipe. There were just massive pieces
of steel, almost unrecognizable if you hadn't known what they were ahead of
time.</p>

<p class="tab">As I recall, the area
of fairly intense radioactivity was separated from the place where the tunnel
was not collapsed, and was open, by a relatively short distance. It wasn't a
long interval; there wasn't a massive plug of a hundred feet or more. It was a
relatively short distance, and it led one to think that we may have come close
to a situation where we wouldn't have contained this event very well at all. It
pointed out that we really ought to understand what was going on.</p>

<p class="tab"><b>Broyles</b>: When Sandia got into the underground
business a few years later, the doors were recognized as one of the big
shortcomings for experiment protection, because we saw lots of projectiles in those
days. They would come down the pipes and penetrate the doors. We had a
distribution on those doors; everything from gaping holes down to craters with
embedded particles. We carried out an extensive survey, and we talked to all
the astrophysicists we could find who were experts on moon craters and asteroid
impacts, trying to figure out velocities and energies, and so on. We ended up
deciding we had things from fractions of grams to hunks, flying from very low
velocities up to ten or twenty kilometers per second.</p>

<p class="tab">From the things we
saw, we were satisfied that a lot of them, probably not all of them, were
pieces of the front end of the pipe, or something up quite close. It also
appeared that some of it, probably not the high velocity stuff, was grout being
thrown down the pipe. Even in those early days that was recognized as very
likely the stuff coming later in time. The early pieces were mostly from the
pipe walls, or closures, or the baffles. Most of the early shots had baffles,
which were somewhat like a collimator, or a heavy baffle that you put in a
muffler. They were a four-inch thick ring that stuck three or four inches into
the pipe. After one or two tries it was decided they kept the pipe open more
than they shut it down. They blew the pipe up, so it didn't get closed very
well.</p>

<p class="tab">All of those things
influenced people's thinking about what and how to design the close-in stemming
to prevent not only late time leaks and containment failures, but to try to
minimize the early time stuff that might damage the experiments.</p>

<p class="tab">There was always an
argument from the very beginning; did you do more good by stopping the stuff,
or by letting it go. And there were a lot of arguments that went on about
whether you could choose an optimum place to put a muffler. If you placed it in
close enough to where the ground shock closed it, maybe you wouldn't interfere
with the ground shock closing the pipe. But, if you got it in that close, the
cavity would expand and collapse it, and maybe it wouldn't matter. Those kind
of arguments went on, and people did some crude calculations. But very quickly
the community decided that ground shock wasn't really the way to guarantee, for
these horizontal line-of-sights, that the world was protected. And they decided
they needed more protection for the experiments than just the ground shock.</p>

<p class="tab">So, by the late
sixties, on Cypress, we put in the first double sliding doors. That was a
Sandia innovation for Cypress. They slid closed sideways as a backup to the
ground shock pipe closure, but they also were put in as an early time
protection against the high velocity debris, to protect the experiments from
that. All of those were originally designed simply as debris stoppers. Later,
people thought they could save money by combining that with some kind of gas
seal.</p>

<p class="tab">As people developed
calculational capabilities and equations of state to try to make intelligent
calculations, the spaces in the tunnel where there was air between the stemming
regions were replaced with some compressible solid material. If you look at the
earlier shots, they would have a hundred feet of this, then fifty feet of air,
then a hundred feet of that. Then the air got replaced with weak grout, with
asymmetrical voids on one side of the pipe so the ground shock would shear
things off and close it up.</p>

<p class="tab">As time went on, most
of the detailed worrying was really about sample protection, because they found
protection for the outside world had been taken over by the overburden plugs.
After a time everybody recognized that you could design a plug that just by
brute force could contain a complete leak. I think it was after Camphor that DNA
really went, in the early seventies, to more or less the current designs.</p>

<p class="tab"><b>Carothers</b>: There was a period of a few
years when Sandia sponsored their own events undergroundj there was Cypress,
and then Camphor?</p>

<p class="tab"><b>Broyles</b>: Cypress and Camphor were the
only two, in '69 and '71. Baneberry was near Christmas 1970, so Camphor got
delayed until June 1971. It was originally scheduled for right after Baneberry.
Those were the only two horizontal line-of-sight experiments, in tunnels, that
we did. Before that we sponsored a couple of the vertical line-of-sight shots.
Derringer was the first one, and that was, in a way, a different kind of thing.
There was a drift at the bottom of the hole, where the experiments were, and
there was no line-of-sight to the surface.</p>

<p class="tab">I really had nothing
to do with that; I was doing high altitude work at the time. Wendell was
involved with the containment design, and Bob Statler, I think, was the Test
Director for Derringer. The experiments were the exposure of components, and
subsystems, and the systems down the line-of-sight. It didn't really contain,
in the sense of protecting the experiments; they ended up not being protected
enough. Really, essentially not at all. But, the emphasis was more on getting
the real-time measurements out. If we could have recovered the samples it would
have been a bonus, but that clearly wasn't as important as the other
measurements.</p>

<p class="tab">Parallel to that
there has been the continued evolution of the calculational capability, and as
I see it, more and more willingness to believe the calculations of the ground
motion and the groundshock induced motion.</p>

<p class="tab"><b>Carothers</b>: Sandia was involved with tunnel
events for some years. What was your participation in that work?</p>

<p class="tab"><b>Weart</b>: I was involved as a sort of
containment design consultant for DNA on many of their shots. I'm not sure I remember
the exact sequence anymore, but Gum Drop was an early shot after Marshmallow,
and then there were a number of DNA tunnel shots with line-of-sight pipes.
Sandia initiated some experiments of their own which required line-of-sight
pipes in tunnels; Cypress, and Camphor. In addition to the tunnels, I worked on
the containment design for some of the vertical LOS pipes like Diluted Waters.</p>

<p class="tab"><b>Carothers</b>: What were the things that you
were trying to address on those early effects shots, as part of the
containment?</p>

<p class="tab"><b>Weart</b>: Everyone was concerned about
the energy flow down the pipes, and how to make sure that did not interact in
such a way that it kept the pipe open, rather than letting the ground shock squeeze
the pipe closed. We did have some codes that were used to do those kinds of
calculations, but they were, I'm afraid, a fairly simplistic look at things. It
was as much as anything a matter of timing the closures, rather than any
sophisticated effort to minimize or mitigate the flow. It was a matter of how
quickly could you get something in the way.</p>

<p class="tab">We viewed it as a
three part sequence. Very close, within fifty feet of the detonation point, we
tried to rely on the energy of the bomb to do the work for us. Then a little
further out, but where the line-of-sight would allow it, there were fast
acting, high explosive driven systems. And still further out, slower, larger
aperture mechanical systems, pneumatically driven. We tried to calculate the
times when significant energy pulses might arrive down the pipe so we could try
to intercept them. The hope was that we could, if not completely stop them, at
least slow them down until what we always regarded as the main mechanism, the
ground shock itself, would have a chance to outrace the energy in the pipe and
squeeze it off.</p>

<p class="tab"><b>Carothers</b>: You said that on Marshmallow
there was sandbag stemming. What did you use on Gum Drop?</p>

<p class="tab"><b>Weart</b>: I think it was still sand. The
early shots all used alternating sand plugs. At first we used sandbags; later
we went to sand blown in. But this was not continuous - there were voids designed
to be in the stemming. That came out of some early ideas that Olen Nance had.
His concept was to create an interval where the ground shock would not be moving
in smoothly and uniformly through a sand-stemmed area. Rather, when it reached
the void in the stemmed interval it would implode the wall, create a lot of turbulence,
and disrupt the pipe in a more discontinuous way than the more continuous
collapse in the stemmed areas. There were observations in some of the early reentries,
like Marshmallow and Gum Drop, which seemed to support this; in the areas where
there was no stemming there was much more complete disruption of the line-of-sight
pipes than in areas where the stemming was continuous. In the continuously
stemmed areas the pipe was squeezed more uniformly, which would leave a tightly
squeezed mass of steel, but with little paths through which gases could
migrate, and perhaps eventually erode the material to make much larger paths.</p>

<p class="tab">And those early
designs seemed to work. Whether it was what we did, or just because we were
lucky, the early shots were successful; if they had been utter disasters we
probably wouldn't have kept on doing it that way. Logan worked well.
Marshmallow did have a little seepage out, but not a massive failure; the experiments
weren't severely compromised, or anything like that, and Gum Drop, in 1965,
worked very well. So, people thought they knew all they needed to know.</p>

<p class="tab">But it wasn't too
long before we found out that even though you did things exactly the same way,
the results weren't always exactly the same. We continued to apply the same
techniques we had used for closing the line-of-sight pipe and for stemming the
drift itself, but as we began to have more and more of these events, many of
them were severe failures. High temperatures and intense radioactivity would
get out beyond the stemmed area, beyond the mechanical seals, out to the
experiments themselves. And occasionally, even though we would put in things we
called gas-seal doors, they were circumvented and some radioactivity was
released into the atmosphere. When these kind of events started to occur,
people started to wonder, “If the old techniques happened to work all right, what
could be different? What can we do to maximize our chance of success, since we
obviously aren't optimum.”</p>

<p class="tab"><b>Carothers</b>: One of the things you could
have pointed out to them, Wendell, as a geophysicist, is that the earth is not
a nice, homogeneous medium. One place is not like another place, even a rather
close by other place.</p>

<p class="tab"><b>Weart</b>: That's right. And as we went
along, I think that fact took on a great deal of significance to us. We had
relied upon the ground shock to provide closure, but we really hadn't tried to optimize
that ground shock by finding regions where the seismic velocity would be high,
and where we could maintain high pressures from the ground shock out to greater
distances. We knew at that time, from a variety of sources, that you do have
higher velocities in some parts of the rocks than in others. For instance, the
addition of moisture will change the velocity, and will change the coupling of
the energy.</p>

<p class="tab">We knew that we would
like the ground shock to eventually outdistance the energy within the LOS, and
sometimes people envisioned the gaps in the stemming as ways of dissipating the
energy in the LOS, and of slowing it down. Later, people built things into the
LOS, like mufflers, or enlarged zones, to do the same thing. But the effort was
on trying to slow down that energy in the LOS rather than to utilize favorable
geology to speed up the ground shock.</p>

<p class="tab"><b>Carothers</b>: We're talking about the
sixties, or early seventies. What tools, or techniques did you have then to
investigate geologic, or geophysical properties? Were there tools available if
people had wanted to look at the details of the geologic medium?</p>

<p class="tab"><b>Weart</b>: Yes. If there had been
sufficient impetus to do it, I think we could have, for instance, determined
the seismic velocity in the tuff in the tunnels. The tools were not as easily
applied as the ones we have today, but there were techniques for doing it.
Those things weren't really applied to containment design in the early days because
we really didn't understand in detail what was causing the closure. Because we
had some early successes, we just said, lilt's working, so we won't worry about
it."</p>

<p class="tab">As time went on, the
experimenters began to impose greater demands. They wanted bigger apertures,
which meant bigger pipes that took longer to close, and were harder to close.
And they wanted to move experiments in closer and closer. Sometimes these things
were in conflict with being able to do the things you'd really like to do to
assure the best prospects for containment. I think, in fact, in talking about
the Sandia events, Cypress and Camphor, that was one of the biggest changes
between those two designs. There was a much larger line-of-sight pipe on
Camphor, and an experiment station very close-in which we tried to protect with
a massive concrete structure, to hold it open for an interval. And that
interval turned out to be an important interval from the standpoint of ground
shock closure.</p>

<br>
<p class="tab">It is interesting to compare
Wendell Weart's remarks about the early tunnel shots - "So, people thought
they knew all they needed to know. But it wasn't too long before we found out
that even though you did things exactly the same way, the results weren't
always exactly the same. We continued to apply the same techniques we had used
for closing the line-of-sight pipe and for stemming the drift itself, but as we
began to have more and more of these events, many of them were severe failures.
High temperatures and intense radioactivity would get out beyond the stemmed
area, beyond the mechanical seals, out to the experiments themselves." -
with those of Ed Peterson about events that occurred some two decades later.</p>
<br>

<p class="tab"><b>Peterson</b>: It seems to me that things
behave differently now than they did in, say, the Dining Car era in the
mid-seventies. There are very small changes in design, but we have seen very
large changes in performance. Mighty Oak was the largest, and Misty Rain was
pretty large. Huron Landing was somewhat smaller, Miner's Iron was a little bit
smaller, and so forth. Yet the design changes were small. If somebody just came
up and told me, “This is how we're changing it," I'd say, “It's no big
deal. We only guessed at the first one, so how can ten percent kill you?"</p>

<p class="tab">But, it appears to,
and so, given the science that we all learned in school, one has to ask the
question, “Why?" and that is very, very difficult to answer. To me it is
as if you plot something versus time, and you were going along flat, and then
you see the curve continue to rise as far as things you don't like to see. It hasn't
been necessarily a step change, as you would see at a discontinuity; I think it
has been a gradual change. But I don't know why the gradual change occurred. We
were going flat for so long. And it isn't apparent to me what changes occur
with what small design modifications. To go to the extreme, you can talk about
the “tired mountain," which would explain things by saying that the
structure is just degenerating with time because you've done more and more
shots. I am not convinced at all that is what it is.</p>

<br>
<p class="tab">The DOD sponsored a variety of
effects shots after the moratorium, beginning with Hard Hat in 1962. There were
cratering events, vertical line-of-sight shots, and SmalI Boy, the last
atmospheric detonation to be conducted at the Test Site. By 1965 the focus was
more and more on tunnel events.</p>
<br>

<p class="tab"><b>Flangas</b>: DNA came into the picture in
the middle sixties. They came into the picture with Hard Hat. That was theirs.
A few years later they came up to Rainier and made a reconnaissance. I had dug
the original N tunnel, and I had dug the original P tunnel, both for Livermore.
And, both of them were abandoned. I think I dug N tunnel in about 1963, and
then after I finished N tunnel, I went to P tunnel, and took it back about a
thousand feet. Then, 10 and behold, one day they said, “We're not going to use
them." So, we boarded them up, and they were left that way for at least
two or three years.</p>

<p class="tab">I think it was about
1966 that a colonel came out looking for either to dig himself a tunnel, or
find a tunnel, and he wound up in contact with me. I said to him, “I don't know
who owns this tunnel, but there is a tunnel that has never been used. It is in
a delightful location, and it's a good tunnel" So, I took him into N
tunnel. That suited their needs, and whatever arrangements they made between the
AEC and the Lab, and the DOD resulted in them taking that over.</p>

<br>
<p class="tab">The first tunnel events in
Rainier Mesa were containment failures. Lacking the base of scientists and
engineers that existed at Los Alamos and Livermore, the DOD people doing the
events turned to Sandia and the few contractors who could help with the
problems of containment and protection of the experiments placed in the tunnels.</p>
<br>

<p class="tab"><b>LaComb</b>: At first it was General Atomics
people, and ultimately those people became S-Cubed, who were saying that there should
be this particular kind of grout here, and that one there. On Door Mist
(8/31/67), and after Door Mist, they were asking for very high strength grout,
which wasn't a good thing to do. Door Mist was not real successful.</p>

<p class="tab"><b>Carothers</b>: What led you to focus on the
high strength grout as the problem?</p>

<p class="tab"><b>LaComb</b>: The reentry observations
indicated that, to a degree, we did have a solid tunnel plug, but the leak path
went out fourteen feet into the tuff, around the plug, and back into the
tunnel. We're not sure what drove that, but we felt we'd have been better off
if we could have kept it in the tunnel rather than forcing it out of the tunnel.</p>

<p class="tab">Midi Mist, in June of '67, was
done with rock-matching grout. That is a misnomer, because that grout is
intentionally designed not to match the rock. It's called rock-matching grout,
but we've set criteria where it should have a compressional velocity lower than
the tuff, it should have a strength lower than the surrounding tuff, and it should
have a density which matched the rock as closely as possible, but hopefully not
higher. What we wanted to do, in theory, was to make the ground shock going out
from the zero room go slower in the tunnel than it was in the rocks, so the
shock was driving in on the tunnel, and slamming the pipe in the tunnel closed.
It's probably not a bad theory.</p>

<p class="tab"><b>Carothers</b>: Dan, to what extent do you get
involved in specifying the kinds of grouts, or over what length there should be
rock matching grout, or superlean grout, or whatever?</p>

<p class="tab"><b>Patch</b>: We like to think we play a
fairly important role in that. We certainly have looked at the effects of
changing the lengths of the grouts, and we've made recommendations based on
what we've seen in the calculations as to whether a grout should be stronger or
weaker. We have tried to work with the folks at the Waterways Experiment
Station as closely as we can to understand how they formulate grouts. We don't
do the formulation in the sense that we don't say how much of what to put into something,
because we would be way over our heads there. In a way we don't really work directly
with WES in terms of formulations. We'll talk to Byron Ristvet, or Joe LaComb,
and say, "For this kind of geometry we think we need a stronger grout in
this particular section, because it will help relieve loads," or whatever
the criteria and reasons are.</p>

<p class="tab">Then, it's been Joe primarily who
has had the most direct role in the grout formulation area. He'll go talk to
the WES folks and say, “These crazy calculators want something that will do
these strange things. What can you guys do?" They'll think about it, and
they're very, very good at knowing how all these ingredients interact with each
other. One of the problems we do have is that we're looking at how these materials
respond at many kiIobars, and the formulators are civil engineers and concrete
engineers who tend to think about how bridges would react, and what one would
do to make a pedestal stronger, or whatever. They bring a much more engineering
structural point of view, and we really have to try hard to overcome that
different point of view.</p>

<p class="tab"><b>Carothers</b>: Each time there's a
presentation of a DNA shot at the CEP it seems that the boundaries of the
different grouts, and the placement of the hardware are different. This run of
grout is a little longer, but not much, and that one is a little shorter, but
not much. There seems to be a lot of fine tuning.</p>

<p class="tab"><b>Patch</b>: There is a lot of fine-tuning,
and I think there's two reasons for that. One of the things that's going on
there is in some sense operational. For instance, people may want to put
bulkheads at certain places, but because the tunnel has some change in it, it's
undesirable to do that from a construction point of view. Things tend to move
around for that reason. Again, folks may want to move something a significant
distance, so they will call up and say, “We were planning to put the superlean
out to X range, but it would be really nice if we could make it five or six
feet longer. Do you think this is a problem?" And we'll either say, “That couldn't
possibly make any difference," or we'll say, “Well, we don't know. We'd better
look at that, because we think it's a little long right now." We run into
things like that, where people have wanted to make things a little longer, and
we thought were kind of on the long side already, or vice versa.</p>

<p class="tab"><b>Carothers</b>: Joe, what kind of consideration
was given to the front end of the pipe, where the energy began to get into the
pipe?</p>

<p class="tab"><b>LaComb</b>: Actually, I'm not sure the
front end for Double Play (6/15/66) was ever calculated, although Noyer kept
wanting to go back and do it. I think the General Atomic folks tried to
calculate Door Mist, and Chuck Dismukes came into the picture then. I think it
was about the Midi Mist, Door Mist time frame that the front end calculations
started coming in.</p>

<p class="tab"><b>Carothers</b>: Were you putting overburden
plugs on all of these shots?</p>

<p class="tab"><b>LaComb</b>: Yes. In those days it was
called a blast plug. I guess there's a difference.</p>

<p class="tab"><b>Carothers</b>: Perhaps it represents your
expectations, you might say.</p>

<p class="tab"><b>LaComb</b>: We were quite successful for a
little while. We never did really come up with a good explanation why we had
Mint Leaf (5/5/70). It was another gross failure, and it had another leak over the
top of the far-out TAPS. It's interesting that the cross sectional area of that
path was the same as the one on Door Mist. That's why Ed Peterson uses eleven
square feet when he calculates a leak from the cavity.</p>

<p class="tab">Hudson Moon (5/26/70) was not as
bad in the tunnel as Double Play or Door Mist was. Door Mist was a step beyond
Hudson Moon. Hudson Moon had all the lagging charred, and it didn't have its
strength, but it was still in place rather than being completely gone. The DBS,
the debris barrier system, which we had added to the pipe string to be a
barrier, did a good job of protecting the samples that were in the test
chamber. They got more of a soak temperature than anything straight down the
pipe. We were pretty lucky there, because the leak path went outside the pipe.
The pipe was closed off by the debris barrier system, so it was kind of a
cocoon for the samples.</p>

<p class="tab">The Hudson Moon rock samples had
been very soft, and they had a very high gas-filled porosity. At the time we
tested them, we said they'd sat at the portal during an extremely cold spell
and they'd frozen. So, we wrote the physical property tests off because the
rocks had frozen. After the test, when we went back into the tunnel and started
to investigate it, we came to the conclusion that maybe the measurements were
right. They might be real. So, then we went back and started digging further
into the Door Mist physical property data. We found that there also was a lot
of gas-filled voids there. And the longitudinal velocity in both tunnels was
low. Then we started doing some calculations, and we found there is a significant
difference in the ground shock attenuation between one percent and five percent
gas-filled porosity. So, we then attributed the Hudson Moon failure to the
gas-filled porosity.</p>

<p class="tab"><b>Duff</b>: Bob Bjork did a series of 1-D
calculations of ground shock propagation, and he rather dramatically showed the
influence of air-filled porosity on shock wave attenuation. These calculations
were based on naively simple material models, but they showed us that if you
compare the attenuation for one or two percent air voids with zero air voids,
there is quite a difference. If you go to five percent air voids, you get a
little more attenuation. If you go to fifteen percent air voids, a little more
attenuation. It's the first few percent that makes the big difference. So in
the context of the Hudson Moon failure, we hypothesized that what we had there
was a relatively dry medium, such that the ground shock, which had been expected
to squeeze the tunnel and develop a stemming plug, simply died. It got too weak
too soon.</p>

<p class="tab">Then we did a pair of thousand
pound HE shots in two media. One was in a fairly saturated medium, and the
other was in a fairly dry, Hudson Moon-type medium. And, indeed, they confirmed
the validity of the prediction. That has influenced DNA's thinking about
appropriate material properties ever since.</p>

<p class="tab"><b>Peterson</b>: After the Hudson Moon leak, one
of the things that was recognized to be different about Hudson Moon was that it
had a high gas-void content. With a material with a high gas-void content, the
ground shock damps out fairly quickly, and so one doesn't get the closure that
one would expect for an event in a low gas-void material. So, this was
pinpointed as one of the reasons for Hudson Moon.</p>

<p class="tab">And, this has been the philosophy
for a long time - you do not want a high air-void material. Let me give you two
contrasting things, which show why our lack of understanding bothers people like
me. There are people who say, and they may be right, that one of the reasons,
or at least one of the contributors to the Mighty Oak situation is that it was
shot in a material with a very low air-void content. As a result, the ground
shock was too strong, and it drove the stemming too hard. So, it drove it right
through the closures. You can keep going on with happened from there.</p>

<p class="tab">If you look at Mission Cyber, the
response you saw was that the peak stress versus range was low. There's a lot
of evidence that it didn't come from having too Iowan air void, but the response
on Mission Cyber was similar to what you'd calculate if you just put a lot of
air void in the material. It wasn't there, but the response looks similar. And
on Mission Cyber that worked great. It didn't crunch anything, and everything
was just perfect. So people say, “Well, you know, maybe some of this air void
is really okay."</p>

<p class="tab">So, you can go from the extreme
of people thinking there was too much air void to the point where they think
there was too little, and now maybe a little bit more is better. The history
has gone back and forth, and I'm not sure what the answer is.</p>

<p class="tab"><b>LaComb</b>: Misty North (5/2/72) was where
we first said we would test the over-burden plug, and we said we would pressure
test the gas seal door. That's where the gas seal plug came into being, We
called it the hasty plug for years, because we couldn't get the gas seal door
to seal. The concrete had enough permeability that there was always a leak.
Finally I said we'd put in another plug. I walked down the tunnel, looking
through the lagging, and said, "Put it right here." Three days and
twenty hours later I was watching the concrete go into the forms. We could have
shot at any time, because the area was so full of people it couldn't have
leaked. That's where the first gas seal plug came into being. We leak checked
it, and we pressurized between the plug and the door.</p>

<p class="tab">It was also the first time we
used cable gas blocks We had a block of concrete that was the world's most
expensive. There were over a thousand cable gas blocks in it, and the cost was
well over a million dollars, and those were big dollars.</p>

<p class="tab"><b>Carothers</b>: This was the first time you had
done cable gas blocks?</p>

<p class="tab"><b>LaComb</b>: Well, we'd been fooling around
with cable gas blocking for about two years. We weren't very sophisticated, but
we knew how to do it if we had to. We didn't have to go out and start inventing
the wheel. And we still use the same technique today. We don't have quite as
crude an installation, but it's basically the same. Now we use the bulkhead
connectors, but we don't use a board anymore because we put them in Vistinex.
And we angle them so if there is a leak it will just go out and come up some different
conduit.</p>

<p class="tab"><b>Carothers</b>: If you had cable holes to the
mesa surface you also had to think about stemming those, and the cables in them
to keep gases from getting out .</p>

<p class="tab"><b>LaComb</b>: The cable holes were stemmed,
but we never claimed they were gas tight. We had to go to some extremes to take
care of them, because we had to do it a little differently in every tunnel. On
N tunnel we put a top hat on the top of the hole, with bulkhead connectors. We
squeezed grout and sand down in the hole to get rid of the boundary leaks.. As
I recall, in P tunnel we put the bulkhead connectors at the bottom of the hole.
In T tunnel we blocked the cables coming out of the downhole cable alcove, and put
plugs in the access drifts to the cable alcove. Each tunnel was unique in its
configuration. We could have said, "Well, we're just going to drill these
holes out, clean them out, and put in new cables and do it right." Or you
can try to save your investment, which is what we did.</p>

<p class="tab"><b>Carothers</b>: You obviously wanted to reuse
the tunnels. On shots where you had leaks into the tunnel to what extent could
you go back and use them again?</p>

<p class="tab"><b>LaComb</b>: Well, for Double Play, once we
ventilated the tunnel inside the gas seal plug, we really lost very little,
except inside the overburden plug. The leak was minimal. We did have to go
through and spray the lagging to tie down the dust that was generated when the
grout was scoured out. Other than that we pretty much had the run of the tunnel
within a couple of months. Door Mist, we lost everything inside the overburden
plug, but outside the overburden plug, because the nature of the leak was just
a seep, the tunnel cleaned up very well. And, so did Hudson Moon. That was the advantage
of having the blast plug in the experimental drift; we were attenuating that
release up-front, close-in. Of course, there we were providing any release with
a very small volume to dump into, so you could expect the pressures to be high.
On Hudson Moon we saw 700 psi on the front of the overburden plug. But at the
same time, the advantage of that was that it did save the rest of tunnel complex.</p>

<p class="tab">On Mighty Oak, where we had the
plugs way out, we lost just about all of the T tunnel complex. If we ever reuse
some of those openings, it will be a bunch of years. Outside the drift
protection plug though, we have full use of the tunnel for Mission Ghost, Anything
inside of there is lost. All the Diamond Skulls workings, the Mint Leaf
Workings, the Midas Myth workings - all of that is lost.</p>

<p class="tab"><b>Carothers</b>: You folks in DNA are have a
real need to protect the experiments, and you've done a lot of different
research projects. Have they all been for better ways to protect the experiments?</p>

<p class="tab"><b>LaComb</b>: I think you're oversimplifying
to a degree, because one of the drivers for our low yield test program was real
estate, and facilities reuse for the economics. A low yield test - two, or one kilotons,
and we're hoping for a half a kiloton - doesn't have near as much ground shock
associated with it. So you spend a lot less dollars hardening, a lot less
dollars shock mounting. You use up, for a half kiloton, compared to ten
kilotons, only a fraction of the real estate. Real estate in Rainier Mesa is
disappearing, so that's been a big driver in the development of the low yield
test bed. Of course, the need for the coupling experiments, like Misty Echo,
Mill Yard, and Mini Jade, and the stigma associated with Red Hot have also driven
our program. We've got to work the program so we're able somehow to do that
kind of test. S0, a lot of research has been driven by the need to understand
the phenomenology of the events.</p>

<p class="tab"><b>Carothers</b>: Bruce, what drove your
line-of-sight diameters, which affects the pipe taper and its length? Was it
the size of the hardware that people brought for exposure, or did it happen the
other way; "We're going to have a shot, it's going to have an exposure
area this big, and what have you got?"</p>

<p class="tab"><b>Wheeler</b>: I think there was some of both
in the early seventies. Primarily it was driven by military system
requirements, the Defense Department stuff. The size of, and the number of test
chambers was driven by the number of experiments there were; the need for space.
The need for sheltons was the way we quantified it. A shelton was a calorie per
square centimeter, and was a unit of barter. Many times experiments were not
approved to be on a test because there wasn't any room. That could be a reason,
and another reason could be the experimenter hadn't done his homework well
enough. But space was always at a premium. However big the exposure space was,
it was always fully subscribed, as all the DNA tests have been . We used to
talk about having a physics event about every third or fourth shot to let the
experimental physicists and experimenters play with it, and do phenomenology,
and physics.</p>

<p class="tab"><b>Carothers</b>: They still would have wanted a
lot of space on the next shot.</p>

<p class="tab"><b>Wheeler</b>: True. And, we never would have
gotten a shot like that funded, because we didn't have any system driving it.</p>

<p class="tab"><b>Carothers</b>: Were you getting participation
from all three services?</p>

<p class="tab"><b>Wheeler</b>: Pretty much, yes. As I recall,
the Army participated the least, probably because they didn't have systems
other than the Spartan and the Sprint. They didn't happen to have a system that
required that kind of testing. The Air Force was always there with ICBM missile
parts and materials. The Navy was there because of their Polaris program, and
there was always a lot of phenomenology and materials effects experiments by
contractors. And of course Sandia, who developed components for weapons, was a
big participant.</p>

<p class="tab"><b>Carothers</b>: Carl, you came to DNA in 1974.
Perhaps this was an issue that arose before you got there, and had reached some
conclusion. That was the question of what kind of tuff should you shoot in.
What should the porosity be, for example. Also there had been a lot of fussing
around with various kinds of grouts such as superlean, and rock-matching, and
so on.</p>

<p class="tab"><b>Keller</b>: Yes, before I got to DNA they
had already concluded that the rock needed to be saturated to give you the
strongest possible ground shock to the greatest range, and that the stemming had
to be as weak as necessary to allow closure of the LOS pipe as far as possible.
Now, those generalizations eventually led to, I believe, some serious stemming
failures. It was true that they tried to get the longest stemmed tunnel by
maximizing the ground shock and minimizing the grout strength.</p>

<p class="tab">The trouble with that concept was
that you also, by reducing the grout strength, suffered a lot of relief with
grout extrusion into this large pipe volume. So, it had no confining stress,
and therefore no strength, and it just had a ballistic trajectory. That was
first dramatically demonstrated on Hybla Fair, which was David Oakley's attempt
to push the state of the art. They overshot quite a bit. That was a seventy-six
foot long LOS pipe; it diverged to something like five feet at the end, and
there were no closures in it. The hope was that there would be a ground shock
stemming closure of the whole pipe.</p>

<p class="tab">We did a parameter study with
calculational models at Pac Tech after that shot, and found that there's a very
strong correlation between the pipe taper and the amount of extrusion that you
suffer. According to the calculations, if you doubled the pipe taper you started
to see a small effect. If you went to four times the normal pipe taper, you had
a very dramatic effect. At five times the normal pipe taper you just lost it
completely. That was a calculational parameter study that was done as part of
the design of the low-yield test concept.</p>

<p class="tab">Hybla Fair was premature, and
there was talk about how it might have actually killed the low-yield test
concept, because it had blown out so badly into the tunnel. But in fact, a
couple of years thereafter we dared to offer to pursue that, and we were
allowed to when funding was available. The intermediate tests were scaled model
tests done by Sandia. They put in the low-yield test design and the Hybla Fair
design side-by-side, and drove them with high explosives. Those were scaled
models which showed that Hybla Fair failed, but the low-yield test concept
didn't. The low-yield test concept went all that way, and that was the only
test design I know of that ever evolved all the way from calculations, up
through scale model tests, finally to nuclear proof-tests, and then to a
follow-up nuclear test.</p>

<p class="tab">After the FAC, the Fast Acting
Closure, was developed by Sandia we were sure we could go to double the normal
pipe taper easily, because the scaled models that were tested were at that taper.
Midnight Zephyr tested out that concept, and the proof of that design was
Diamond Ace, which had just a short part of the pipe. Diamond Beech finally
tested the whole thing. And then, just about at that time Misty Rain and Mighty
Oak occurred. The low yield test concept was then the only concept left in
which DNA had any faith. That test concept has been used many times since then.
So, that was an application of our calculational models, and our experimental
program, all the way from the smallest charges on up through nuclear scale.</p>

<p class="tab">The low-yield concept was
designed from scratch, whereas the traditional LOS designs were developed in
the field. The early tests had difficulties, and the designs evolved very
timidly. Of course, they were all tested on the nuclear scale, where you didn't
dare fail, and so the standard HLOS design came about through timid evolution
in the field. And they started long before the calculational models could treat
the whole problem. Eventually the standard design, as the product of that timid
evolution, was proven not to have the margin of safety that we'd become to
believe.</p>

<p class="tab"><b>Carothers</b>: Well, DNA had been pretty
successful with those line-of-sight experiments for a few years. There were a
series of events where they worked.</p>

<p class="tab"><b>Keller</b>: Yes. There were some puzzles as
to why the variations occurred that did occur. It was never clear, at that
time, what were cause and effect situations. When we did HE tests at Physics International
where we were imploding pipes, we found that there was a fairly strong
variation in the standard unperturbed pipe in those geometries. You had to have
a major reduction of the flow in the pipe before you could depend on it. I
believe the analogy with the nuclear experience is valid, because there we saw
also variations that we couldn't explain.</p>

<p class="tab">In fact, there were a few wagers.
I remember that Dan Patch bet two six-packs that Diablo Hawk would have a much
more docile behavior than Mighty Epic. Well, it shot out the doors and Mighty Epic
didn't. It wasn't bad though, and it was still well contained. The next event
was Misty Rain, and on that one, because the doors were in closer, the pipe
taper was larger, and there were a few other things like that, Dan was sure
that it was going to be a lot worse than Diablo Hawk. And he lost again,
because the doors held. Things like that were really puzzling.</p>

<p class="tab"><b>Weart</b>: In the days when I was
involved, almost all of the experiments, while they were emplaced underground,
were recorded on the surface, or outside at the portal. But as time went on,
more and more of the recording and the data acquisition began to take place
within the tunnel itself. Faster recording times were desired, and there were cost
efficiencies, and so forth. That made an even greater premium on not letting
any release out into the part of the tunnel where the equipment was.</p>

<p class="tab"><b>Carothers</b>: When did you leave the
containment business, and go on to other things?</p>

<p class="tab"><b>Weart</b>: My last involvement was
probably in the '74, '75 time frame.</p>

<p class="tab"><b>Carothers</b>: By then a lot of things had
been done to try to insure that there was no release of radioactive material.
What changes were made after Baneberry?</p>

<p class="tab"><b>Weart</b>: Well, there were two kinds of
changes. One involved the engineered hardware - building more massive, faster
acting closures, trying to get things across the line-of-sight pipe as quickly as
you could. Sandia has done a lot in terms of building big, fast-acting closures
for the DNA shots, for large diameter lines-of-sight. They have also done some
HE closure work.</p>

<p class="tab">We also did a lot of work, along
with DNA, in trying to insure that the last line of defense, the overburden
plugs, the gas-seal doors, really would provide effective seals against high
temperature gases. We did a lot of work with Chuck Gulick, who worked for Sandia,
and we also worked with Waterways Experiment Station to try and design cements
which, for instance, were expansive, and which would form a more positive seal
against the rock. We did quite a lot of work in that area.</p>

<p class="tab">The other advance that I think
was made was in being able to better understand and calculate the behavior of
the various interacting energy streams, such as the ground shock, and the pipe
energy. There was also a major effort instrumenting those events to try to confirm
whether or not our calculations were representing reality.</p>

<p class="tab"><b>Carothers</b>: I think that's an area where
the tunnel events have had an advantage, in that there is access. My impression
is that there was always a fair amount of instrumentation in the tunnels,
looking at the tunnel behavior and the medium behavior.</p>

<p class="tab"><b>Weart</b>: There were certainly advantages
in the kind of things you could do. The geometry afforded you a way of assuring
that the instruments lasted long enough to get the data out, because you didn't
have to be right in the drill hole along the line-of-sight pipe. So, ground
motion measurements, free-field motions, energy flow down the pipe using things
like slifers, were much easier to do in tunnel shots. We did try to do those
things in the vertical LOS shots, but it just wasn't as easy or as certain.</p>

<p class="tab"><b>Smith</b>: I had been involved in the DNA
shots to the extent that I would design the stress gauges for Bass, and help
field them. C. Wayne Cook did the recording of the data, and Bass would reduce the
data. All through those years I had my fingers in measurements on DNA shots;
principally the free-field stuff. Bass did the work on the pipe, the pipe flow,
and I was never involved in that. So, when Bass retired, and G tunnel closed I
just moved into the free-field portion of his work, and Tom Bergstress took
over the pipe flow work. Of course, Bass is still the Grand Master of all that
sort of work. And so my work for the last few years has been more or less on
the DNA shots, the free-field measurements of stresses and motions.</p>

<p class="tab">The original driver for that work
in the intermediate regime was, "What sort of stresses do we have loading
these containment structures?" That has broadened, now that those things
are fairly well known, into a number of things. One of them is failure diagnostics.
In case something happens, what measurements do we have that would let us go
back and assess what actually happened? What was the pressure and temperature
in a certain portion of the pipe when the thing blew out?</p>

<p class="tab">The other sort of measurements
are for trying to understand what happens around the F AC. In other words, what
are the stresses and pressures in front of the F AC, and what is the
interaction of the ground shock with the stemming and the rock right around it.
So, the attempt is to measure those things, and to try to get a good enough
understanding of them so you get a good feel for why that system works, and
works fairly well. It's something that has evolved, and it now seems to be a
good system, but the community still doesn't think it has a good feel for what
the forces are that load the F AC after the bomb goes.</p>

<p class="tab">DNA still has problems with gases
that come trickling out into the drift complex; there are late time leaks in
there, and they would very much like to know how long there are residual
stresses loading that portion of the stemming. So, it's the interaction of
those things that some of those measurements are used for now.</p>

<p class="tab"><b>Carothers</b>: Wendell, was this type of information
useful to you? Was there a clear enough understanding of what was going on that
you could say, "Look, see what's happening here? It shows us this, and so
we should make this change."</p>

<p class="tab"><b>Weart</b>: Well, we clearly used it. Some
of it was more immediately useful than others. Ground shock data, for instance,
was fairly easy to interpret, and it told us about how far out we could expect
high enough stresses to really squeeze down LOS systems, and things of that
sort. And we had shock velocities, which were easily obtained, and easily used.
Energy in the pipe? Not quite as easy to interpret, because of the difficulties
of getting measurements that weren't ambiguous.</p>

<p class="tab">The easiest measurements to get
were times of arrival, and those you could usually get. But the relative
magnitude of those energies in the pipe compared to the ground shock energy was
more a matter of an active imagination than actual factual interpretation, early
on. But it was useful. It was useful in the sense that we could tell in some
pipes that the energy was just far outdistancing the ground shock, and
therefore we ought to try and do something to slow it down, and minimize it.
While we couldn't get a good handle on the energy levels, we could get a good
handle on times of arrival, and that led to lots of schemes to try and do
things within the pipe structure itself to slow this energy down, things like
mufflers, baffles, helixes, and so forth .</p>

<p class="tab"><b>Carothers</b>: You mentioned Baneberry as the
event which brought to everyone's attention the importance of the details of
the geology around the working point. But you know, Wendell, if I wanted to be
a cynic I could say, "You guys didn't learn anything in the six months
between Baneberry and when you started to shoot tunnel shots again, so what was
different? You didn't have any new knowledge. All you had was somebody pointing
his finger at you and saying, 'You better not!’” So what happened?</p>

<p class="tab"><b>Weart</b>: Well, I think there was a
concerted effort on the part of DNA to locate their tunnel events in tuff which
had a high sonic velocity. And so there was an effort to select locations which
would be on the favorable side of that particular aspect. Areas which clearly
had high gas-filled porosity, which might lead to, or at least were often
associated with, lower velocities were avoided. And since this had always been
one of the factors that had been primarily responsible, that was a step in the
right direction.</p>

<p class="tab">There were changes in the
backfill, things like the specially designed grouts which would transmit the shock
well, but which had weak strengths so they would flow easily, and not resist
the closure of the pipe. There were changes like that which were made in that time
frame, after Baneberry. I don't know that there was anyone event when all of
these things came to be applied at the same time. It was sort of an evolution.</p>

<p class="tab">I think it's clearly true that
was when the major changes came. And there were changes in how the
line-of-sight pipe itself was designed, but it was never clear, at least to me,
what role those changes played in the successes.</p>

<p class="tab"><b>Carothers</b>: Do you think the better
containment was principally due to the attention to the geology and stemming,
or do you think it was the the fast closures, and the valves, and so on?</p>

<p class="tab"><b>Weart</b>: I tend to think it's not the
engineering features that makes a containment success. In my view, if you need
those things, in part you've really failed. They may succeed in providing protection
for the experiments, so from the DNA standpoint they're essential, and I guess
there have been instances where they have made the difference in a successful
experiment. I really can't judge what improvements in later years have done;
I'm just not familiar with what has gone on recently.</p>

<p class="tab"><b>Carothers</b>: Well, there were changes that
were made following Baneberry that really improved things. If you compare the
two or three years after Baneberry with the two or three years before, there's
a striking difference, both in the tunnels and with the events in the drilled
holes.</p>

<p class="tab"><b>Weart</b>: Yes, and I think those successes
were probably not due, in large part, to the mechanical hardware, from what I
can recall. When you had a success you would go back in, and you would find that
significant amounts of radioactivity, of molten material didn't reach those
features. If significant amounts of energy did reach the features, they often
weren't successful. So, you really need to do your containment, and I would say
ninety percent of it, before you get to those features.</p>

<p class="tab"><b>Carothers</b>: And that you do with the energy
of the device itself, and to use that energy properly you select your geology properly.</p>

<p class="tab"><b>Weart</b>: That's right.</p>

<p class="tab"><b>Carothers</b>: Why didn't we understand that
in sixties? Was it that it wasn't important enough?</p>

<p class="tab"><b>Weart</b>: I think it's human nature. We
had had a couple of successes, and so we said, "It's working, why change
anything? We know enough."</p>

<p class="tab"><b>Carothers</b>: Well, you can always blame it
on the management. You might go and say, "We really should understand this
better," and get the response, “Why should I spend money on that, Wendell?
You're doing fine. Keep up the good work."</p>

<p class="tab"><b>Weart</b>: Well, it's funny. People did
continue to support measurements. We always had active measurement programs on those
tunnel shots, even though things seemed to have worked okay. So, people were
trying to learn a little more. It may have been in part fear that, because we
did understand so little, we were reluctant to make a change that we thought
might be right, but maybe it wasn't. We didn't have the understanding to say
that. It looks so obvious today to say that yes, this is going to have
advantageous aspects. In those days there were people who probably argued strong
ground shocks are bad. We just had not examined the phenomenon enough to have a
good enough understanding to take a chance on something that was quite
different. When it became clear that the old ways weren't good enough, then
nobody minded taking the chances.</p>

<p class="tab"><b>Carothers</b>: Byron, the DNA, for the last
twenty or more years, has sponsored a variety of containment related
experiments, calculations, and measurements. More so, I think, than either Los Alamos
or Livermore.</p>

<p class="tab"><b>Ristvet</b>: Yes. It had to do with their
being a different philosophy. The Labs, since they got out of the vertical LOS business,
learned how to do what they wanted to do without bringing the pipe to the
surface And they also turned over, in some cases, the re-entry vehicle testing
they used to do on some of those vertical shots, to DNA. Their concerns were
different, and they were much less concerned with sample protection. DNA's research
program has been driven by experiment protection and equipment protection, and
also trying to preserve the tunnel complex, because that's a valuable resource.</p>


<a name="ch17"></a>
<br><br>
<h2>Chapter 17: Pipe Closure Hardware</h2>
<br>

<p class="tab">An integral part of the sample
protection and containment design of line-of-sight pipes has been the
installation of various massive pieces of hardware, designed to impede or stop
the flow of material down the pipe after the detonation. Sandia has done
extensive engineering and test work in the development of the various closure
devices.</p>

<br>

<p class="tab"><b>Wheeler</b>: The first of what we called an
auxiliary closure was prototyped and built by Sandia for DNA. We called them
auxiliary closures because we took the ground shock to be the main pipe closure
mechanism.</p>

<p class="tab">That was about 1972,
after the DNA fast-door blew up, and didn't work when it was tested .. Lockheed
Shipyard, in Seattle, was building a big steel contraption to close off the
line-of-sight very rapidly. It was a big housing with two opposing doors on
parallel tracks. They first obscured the line-of-sight, and then closed flat and
sealed the whole area, the whole aperture. They drove it explosively, to get
the closure time they wanted. I don't know whether somebody miscalculated, or
whether they didn't understand what they were using, but as I recall they used
something in excess of forty pounds of bulls-eye pistol powder to try to close these
doors. When they tested it, it wasn't surrounded by concrete, or the earth, or
anything else, and it just blew all to hell. That was the death of that
program.</p>

<p class="tab">At that time Sandia
came along and said, "We can provide you with doors that will do almost
everything you want done." And they did. And in a number of ways Sandia
has continued to be a great contributor to the horizontal tests, particularly
in the closure mechanisms.</p>

<p class="tab"><b>Carothers</b>: Did they receive DNA funds for
that, or was that something they did within their own Laboratory?</p>

<p class="tab"><b>Wheeler</b>: I think the first that was
built they did within their own Laboratory, and they asked DNA if they could
install it on the event to test it. That was a significant thing, because it
allowed us to get away from the old explosively-driven debris barrier system -
a high explosive
machine which created a lot of shrapnel, and sometimes tore up a lot of the
experiments. Certainly the explosive products didn't help the line-of-sight
any. So, those fast gates were a significant contribution that Sandia made.</p>

<p class="tab"><b>Broyles</b>: We designed the basic concept
of the sliding doors for Cypress, in '68, and repeated it for Camphor, and
continued the development effort on those things until the mid-seventies. We then
concluded it wasn't likely we were going to go back to that, because Sandia
wasn't sponsoring more shots. We had essentially disbanded that group when DNA
came, with a letter from their top person, asking us to please use our unique
capabilities to support their program. So, we reactivated the group, and have
been essentially designing the hardware for DNA tests ever since, and continuing
to make improved versions of that hardware. Jerry Kennedy's department has had
that responsibility.</p>

<p class="tab"><b>Carothers</b>: I've always thought those
various closures were very impressive things. So much moves so fast.</p>

<p class="tab"><b>Broyles</b>: Yes. And you should remember
that those designs from the beginning were to be debris stoppers. Any absolute
late-time containment of gases was a benefit. Somewhere along the way somebody
decided that instead of having this big TAPS (Tunnel and Pipe Seal), which we
still have for the DNA tests, you could save money, millions of dollars, if you
could really make the second closure a gas seal. So that led to redesigning to
incorporate a positive gas seal in that closure. Several of those, called the
Gas Seal Auxiliary Closure, or GSAC, have been fielded, but they still encounter
new problems each time.</p>

<p class="tab">People still don't
have a very scientific basis for what the strength of those sliding doors
should be. Some number like fifteen thousand psi was sort of the static
containment pressure strength that they came up with. It was more maybe from
the fact that that's what you could build, but you could make some arguments
that led to numbers of that order. The real thing was to get a lot of mass.</p>

<p class="tab">Now there's a big
effort going on to improve that design. That door is a twelve-inch thick
forging, hollowed out for weight. Essentially you have a bridge truss for
strength, and a certain thickness to stop projectiles. All of those designs
were still envisioned as backups for the primary closure, which was still to be
the ground shock.</p>

<p class="tab">On the newer test
designs, where instead of just those fast gates, there is the HE closure, the FAC,
or Fast Acting Closure, which is a much more substantial block, much closer in.
I think that has much more direct influence on the containment per se than the other
hardware.</p>

<p class="tab"><b>Bass</b>: I'm very proud of the FAC,
because I was one of the two designers of it. That was a perfect marriage
between experiment and calculation. I did the theoretical calculation work -
the two dimensional calculations - on the FAC. At the same time Paul Cooper did
high explosive simulations at tenth scale. We operated absolutely separately,
except we started from the same principles, and we had certain ground rules to
go by. We compared our results on a Christmas Eve afternoon. We both went home
and thought we had a Christmas present, because they had cut into the plug left
by the latest simulation firing, and every single place that the calculations had
predicted a failure in the spool, they were shown in the explosive test. You
could see every crack, every single rebound, any spallation was duplicated.
Everything was exactly the same between the calculations and the experiment. We
immediately dropped scale model testing and went to full scale test. We
estimated to DOE that we saved one to two million dollars by this jump.</p>

<p class="tab">One thing it did
cause us to do was to turn the detonation point around because we saw we had a
weak point. DNA wanted it detonated on the working point end, and we said,
"No, because you're putting a very weak structure there, and you're
spalling things back at the bulkhead end, so where's the stopper?" So we turned
around and detonated on the portal end, coming forward, and then used that as a
basis to allow us to make an ogive front end. This was all done calculationally
and experimentally in parallel, and I considered that my greatest triumph in
calculations. You can do marvelous things with hydro codes if you're lucky.</p>

<p class="tab"><b>Keller</b>: The FAC, the fast acting
closure, the thirty-inch HE machine, was developed as part of that low-yield
test design. The concept was that you would not try to close the pipe where it
was so large, because once you closed it, if the grout didn't come to rest, or
wasn't confined, it just flowed on down the LOS pipe and you lost it. The
concept was to build the big end of the pipe so strong that you couldn't lose
it - a hardened pipe section is what it was called. And, near the working point
where the pipe was small, you put in a relatively strong grout and swaged it
with the very high ground shock that you had that close-in. So, you developed a
short, high quality closure, that plugged the LOS pipe which closed in a millisecond.
That served as an absolute plug, so you could not extrude the grout through
that hole. And so, as long as the HE machine was closed, and the hardened pipe
structure was intact, you had a competent system.</p>

<p class="tab">Sandia did the scale
model tests. We specified what geometry we wanted, and they built and fielded
the scale model tests for the low-yield test concept. They also built our MAC's
and the FAC according to our specifications. They did probably a hundred half-scale
and fifth-scale HE tests, during the evolution of the FAC. If we'd had to pay
the full price of those, at a contractor, it would have added a lot to our
budget.</p>

<p class="tab"><b>Carothers</b>: Dan, do you get involved in
location of the big mechanical closures? Do you do calculations of the stresses
you expect them to see?</p>

<p class="tab"><b>Patch</b>: Oh yes. That's a very important
part of what we're doing. In a way that's almost the central part. Another aspect
of that is we really think a lot about what an appropriate piece of hardware
is, and where should it go in the pipe string. Sometimes we run into a
situation where we really need to have a closure, and it's up to us, working
with Joe LaComb and Byron Ristvet to say, "This pipe string is not going
to be safe unless we have a closure here, here, and here." If we don't
have a closure that will fit at those places, then we either have to take one
off the shelf, move it till it fits, and then see if it can stand the loads
there, and it may not. If that's the case, then we really try to be closely
involved in saying, "These are the performance criteria that we need for
new closures."</p>

<p class="tab">We've talked with
Sandia for many years about their closure design program. For example, this
Fast Acting Closure that we see all the time on the low yield shots; we really
were the ones that said such a device was needed, and kind of ball parked what
the specs ought to be. Sandia folks thought about how they would go about making
such a thing, and did the engineering analysis, which was a substantial job. We
did the 2-D design calculations, so when they said, "We need a spool
that's about so thick," we took a look at their design and said,
"Yeah, you're going to have to put so much HE on the outside, because it's
going to close on this kind of a time scale." They took that information
and went to small scale, and tuned it up and made it work. They carried the
lion's share, but we worked back and forth interactively on what was needed,
how it worked, and how to really build the thing.</p>

<p class="tab"><b>Carothers</b>: When they wanted bigger pipe
tapers, they had to move the hardware in closer because the opening in the
doors had a certain diameter, and you had to move the system forward to where
it fit the pipe.</p>

<p class="tab"><b>Patch</b>: Mechanically, that's what you
have to do, but if you do that the risk to the hardware goes up almost
exponentially as you move in, depending on what the threat is.</p>

<p class="tab"><b>Carothers</b>: But they did do that, because
they were going to bigger pipe tapers.</p>

<p class="tab"><b>Patch</b>: They did do that, but now
they've moved things back. But it's different hardware too, with this Fast
Acting Closure machine, which is very different than the gate closures, in some
respects at least. It closes in a millisecond, which is a factor of thirty times
faster than the gates. That's not so germane to its survival, but it's just one
big slug of material that gets in the way, as opposed to the gates, which are
more of a diaphragm configuration. Sandia has done a lot of work in the last
couple of years to really bring up the strength of those gate doors. Of course,
they've worked on that for many, many years, but I think what they've done
recently is going in the right direction.</p>

<p class="tab"><b>Carothers</b>: It seems that the hardware now
is going in the direction of brute forcing the problem. They're trying to make
the hardware so strong that it will survive whatever it sees, much like the overburden
plugs.</p>

<p class="tab"><b>Patch</b>: Yes. But there's a lot of
finesse that may not be obvious, and that comes in getting this big, brutal
piece of hardware in the way without giving up the timing. One can easily put
more stuff in the way, but it's not so easy to get it in the way on the right time
scale. These machines are fairly sophisticated in the design. They're going to
the very limits of the materials .</p>

<p class="tab"><b>Carothers</b>: When you talk about the timing,
are you talking about the material coming down the pipe, or are you talking
about the collapse of the pipe.</p>

<p class="tab"><b>Patch</b>: We're really talking about the
collapse of the pipe. The gates are too slow to catch the front end of stuff
that comes down the pipe. They may be able to catch the back part of it. In
cases where we've apparently had too much pipe flow you can see it interact
with the doors, in terms of slowing them down. So, they're catching the back
part of the flow, and that's the more threatening part, in my mind, because it
seems to be more massive, more capable of really loading things. The first
stuff that comes down is, I think, a pretty faint wisp. It's very energetic
material, but it's very low density. I suspect it dissipates and plates itself
out, literally, inside the pipe as it goes down the pipe.</p>

<p class="tab"><b>Kennedy</b>: The debris barrier system had
gates that set parallel to the walls of the pipe, inside the pipe, so they were
curved. They were explosively driven to close. They had interlocking fingers,
but sometimes they just went on through instead of locking. They didn't work
very well, and sometimes they made shrapnel that damaged the experiments. I'm
not sure who designed them - whether it was Lockheed, or DNA in conjunction
with Lockheed.</p>

<p class="tab">DNA also uses a
closure that was designed by Lockheed that is called the TAPS, the tunnel and
pipe seal, which is supposed to be a late time gas seal. This is a great big
toilet seat cover like thing, where the cover is latched up, and at zero time
is dropped by gravity to slam closed. It's very slow; it takes of the order of
a second to close, so any fast debris is long gone before it latches. Sometimes
it hasn't latched and sealed because some of the debris which had gotten there
was deposited on the seat, or it didn't fall all the way down.</p>

<p class="tab">One closure we
developed and used on Cypress was an HE driven vertical closure. The gate was
put up above the line of sight. Being that it was explosive driven, it came down
like a guillotine at a pretty high speed, and seated at the bottom. I don't
remember the exact closure time. We built and tested that at Oak Ridge. It was
a huge, massive gate. It was an immense monster of a thing.</p>

<p class="tab">About that time, the
group then working for Howard Viney started designing these gates that were
driven horizontally so they overlaid each other. They were fast acting gates,
HE driven. Then they decided that you could do that more safely by driving them
with high pressure gas, rather than HE. You could regulate the pressure, it had
lots of safety features, and you didn't have to have quantities of explosives
around. That design was all Sandia's, and we paid for a lot of it ourselves,
because it was for our own test, Camphor. DNA was very interested in those
gates, and we started providing them for their tests too. They started kicking
in funding to help our level of design effort for those closures.</p>

<p class="tab">Those gates have
continued to be developed to this day. Each of the doors in current years is about
a foot thick, and weighs about five thousand pounds, even with all of the holes
that are drilled in them to lighten them up, while you try to maintain
structural strength. These gates come in various sizes, but they are usually designed
for either a 60 or 72 inch diameter pipe. They obscure the line of sight in
about 17 milliseconds.</p>

<p class="tab"><b>Carothers</b>: That's a thing that has always
impressed me. Here are these big, massive pieces of hardware, and they work as
fast as a camera shutter.</p>

<p class="tab"><b>Kennedy</b>: John Weydert, who was one of
our great designers of these things loved to say, "If you stood 20 feet or
so on the other side of the door, and you aimed your 45 at me and pulled the trigger,
and I pulled the trigger on the doors at the same time, I'd be safe." The
doors would close before the bullet got there. And he also likened the problem
of stopping them to taking a Cadillac at a hundred and fifty miles an hour and
trying to stop it in about six inches without damaging it. Starting them was a
lot easier than stopping them, it turned out. It was a real problem, absorbing
all that energy, and decelerating those things, and making them stop where you
wanted them to instead of either going on to China, or rebounding. Either way
is bad. That was really the hard part of the design, absorbing that energy, and
having them stop in closed position. So, 17 milliseconds is when they overlap,
and it's around 30 milliseconds for a complete closure.</p>

<p class="tab"><b>Carothers</b>: And you had those on Camphor?</p>

<p class="tab"><b>Kennedy</b>: Yes. That was about the first
time they were used. The thing in the history of the development of the fast
closures that always stood out to me was the fact that we did provide those for
DNA. They did help fund them. We jointly funded a lot of the development work,
because we felt for a long time that we might still have a need for them. But
sometime after Camphor, a couple of years, during the early seventies, was hard
times for the Laboratories.</p>

<p class="tab"><b>Carothers</b>: There were. We had layoffs in
the early seventies.</p>

<p class="tab"><b>Kennedy</b>: Yes. So there was a lot of
pulling in of the horns. One of those was to say, “Well, we're not going to
fund to develop fast closures anymore, because we don't think we're going to
use them anymore. If DNA wants to do that, they ought to take care of it."
We were under contract with them to provide some closures through some shot
that I don't now remember. I had the duty to go back East to tell DNA that we
were going to get out of this business. We would honor our commitments through
this particular event, and we would see to the fielding of that hardware, and
so forth, but we were giving them this warning. In the future they would have
to see to having that done by somebody else. They said, “But we want you to do
that. What should we do about that?" And I said, “If I were you, I would
get the highest person I could get in this place to talk to the highest person
he could talk to at my place, and tell him that they would really like for us
not to quit doing this work, and make the argument." And, in fact, that's
exactly what they did.</p>

<p class="tab"><b>Carothers</b>: There were also some things
that were used which were called HE machines. Did you people at Sandia do those
designs, and tests, also?</p>

<p class="tab"><b>Kennedy</b>: Yes. We early on had so-called
HE machines. On Camphor we called them dimple machines. They were in on a close-in
section of the line-of-sight. We put like a shaped, or platter charge on the
side wall of the pipe. We started with one, and then put one at 90 degrees a
little further down, and another one at 90 more degrees, so when they went off
they just made the pipe go crisscross to obstruct the line of sight. All they
were supposed to do was to make a mess, and delay any hyper-velocity flow that
might want to come down there and get the other hardware. They were just
supposed to cause a delay, and a temporary obstruction. It wasn't containment.
Nobody even pretended that they thought those things could do that, but they
ought to slow down the flow.</p>

<p class="tab">In more recent years
there was a concerted effort here, funded by DNA in large part, to develop
these fast acting closures - the FAC's. They are a great big spool of aluminum
and lead and steel which is HE driven. The HE is carefully designed to close
the line-of-sight at the point where it's about thirty inches in diameter, and to
close it in about a millisecond.</p>

<p class="tab"><b>Carothers</b>: Basically it implodes the pipe?</p>

<p class="tab"><b>Kennedy</b>: Yes, there is a cylindrical
implosion of a big, thick walled section of the pipe. It is not just a standard
section of the line-of-sight pipe. It is an especially designed spool of
aluminum, principally, driven by about four hundred pounds of high explosives. It
implodes this spool, and causes a four or five foot length of solid copper and
aluminum to be in the line of sight. It just makes a solid plug.</p>

<p class="tab"><b>Ristvet</b>: The various auxiliary closures have
evolved very carefully. They are related to sample protection, and there's a
lot of engineering that has gone into them. That's been a unique thing that
Sandia has done for DNA over the years, and done very well. The FAC is just an
extension of the Livermore HE machine design, but done in a manner that reduced
jetting significantly, and improved things which the Livermore designs were not
too good at. Giving credit where credit is due, Olden Burchet and Harold
Walling and all the rest of the crew at Sandia have been a great group to work with
over the years. John Weydert also worked well with metallurgists, and the
explosives people, because they were all in the same group. And Jerry Kennedy
held that group together for years. It was just an excellent mix of people that
had a very I can do' attitude . We would set the criteria, and the basic
criteria was to catch the pipe flow.</p>

<p class="tab">Incidentally, Sandia
told Carl Keller that those doors wouldn't handle the stress loads from the
grout as you moved them in. Where we used to have them on Diablo Hawk and
Mighty Epic and those shots was really about as close in as you could get and
still have only a little less than a factor of one and a half engineering
design safety in the doors. It's interesting that they were able to develop a reinforced
door that actually almost doubled the effective strength of the doors, the
flexure strength. We tested that on Distant Zenith, and it worked fine.</p>

<p class="tab"><b>Carothers</b>: Those doors have been driven
with high pressure gas. I have always thought that was a dangerous procedure. A
fifteen, twenty thousand psi gas system is a scary thing.</p>

<p class="tab"><b>Ristvet</b>: What's really scary is having a
leak in the system, and not being able to shut the doors.</p>

<p class="tab">I think the highest
pressure we ever used was eighteen thousand one hundred psi. We have had very
good engineering people from Sandia, who were experts in high pressure gas
systems. The gas systems were always assembled and tested beforehand. The
tunnel was evacuated for that area, except for the two Sandia people who would
test the system after it was installed. Then, before it was pressurized again
it would be fully grouted in. So, except right at the compressor, which was in
a secure, shielded area, there was no potential for harm to people except for
the two or so that would be working right on the system. That's the same way
you would do a high pressure experiment in the laboratory. You try to minimize those
dangers, but you're absolutely correct. They are there.</p>

<p class="tab"><b>Carothers</b>: Why didn't you drive the doors with propellants?</p>

<p class="tab"><b>Ristvet</b>: I always wanted to. We have had
a program going with people in Olden Burchett's group at Sandia. It turns out
water-gel explosives work better than propellants. And they're much more reliable
than gas systems, in a sense, and you don't have the exposure of people to high
pressure gases and things like that.</p>

<p class="tab">I think if we had
some of the explosives folks that we now have at Sandia involved in the early
days of development we probably would have used a fast propellant, or a slow
explosive. I emphasize slow. You want the generation of gas to be a little
faster than a propellant, but not as fast as an RDX or PETN explosive. There
are explosives that are used for various metal-forming applications that would
be the right mix to use. We actually got as far as doing scaled tests at
Sandia.</p>

<p class="tab"><b>Carothers</b>: This was going to be on the next shot?</p>

<p class="tab"><b>Ristvet</b>: Yes, it would have definitely
been on one door, on Mighty Uncle.</p>

<p class="tab"><b>Bass</b>: Now, there's a containment rule
- a sample protection containment rule. If the doors hold for a hundred plus
milliseconds you've got no problems. After that it doesn't hurt you if they let
go.</p>

<p class="tab">Half the MAC doors
have been taken out in the history of the test program. All of them except
Mighty Oak and Misty Rain went out close to a hundred milliseconds. We know
that from data. We've had light beams going across the pipe, we've had pressure
gauges back there, and it's been my job for years to unsnarl all that garbage.</p>

<p class="tab">Dan Patch has called
this flow of stemming that hits the doors core flow, and Joe goes through the
ceiling because nobody really knows what core flow is. This core flow is
tempered by the doors lasting that long. Then, when it takes out that door it
has lost enough energy that by the time it gets to the GSAC it won't take it
out. The GSAC has approximately 8,000 psi strength. The MAC had approximately
10,000 psi strength - if it closed. If it is not closed, all bets are off. Then
it's just two cantilevered hunks of iron. It's got some strength, but we can't
even estimate what it is.</p>

<p class="tab">There is a new MAC
now, called the STAC, Stemming Anchor Closure. It has been developed as a
result of a small working group of me, Dan Patch, and Ed Peterson, where we
designed a new closure to prevent the Mighty Oak problem. The main change for
this closure is that the doors have steel front and back plates on them, and it
can hold probably three kilobars.</p>

<p class="tab"><b>Carothers</b>: If it's closed.</p>

<p class="tab"><b>Bass</b>: If it's closed. But we can get
it closed, because we can drive it explosively. There's no reason not to drive
that with propellant. The MAC and GSAC are driven with helium. Originally they
were driven with nitrogen, but they changed to helium to get more specific
energy. But it turns out that the primacord that blew the tanks that held the
gas was providing over half the energy. So really, we were doing a lot of the
driving with primacord all the time.</p>

<p class="tab"><b>Carothers</b>: If it were my tunnel, I would
look very dubious at you coming in and wanting to put fifteen or twenty
thousand psi gas bottles in there.</p>

<p class="tab"><b>Bass</b>: It's the most dangerous part of
the test program. It's much more dangerous than the FAC sitting there with four
hundred pounds or so of TNT in it. We're going to drive them explosively in the
future, and propellants are pretty safe to handle.</p>

<p class="tab">Well, I should say that
some work has been done, but the Tiger Team visit to Sandia stopped this last event
from having propellant drive. The laboratories were closed, for ES&amp;H
purposes, or that work would have been done.</p>


<a name="ch18"></a>
<br><br>
<h2>Chapter 18: Pipe Flow</h2>
<br>

<p class="tab">With the resumption of testing in
1961 some events with a horizontal, and some with a vertical line-of-sight were
conducted, principally for effects experiments of one kind or another. Here the
need for a calculational capability to design an opening that would allow the
desired radiation to reach the samples to be exposed, while simultaneously
containing the radioactive materials and protecting the samples, quickly became
apparent.</p>

<p class="tab">Over the approximately eight
years that vertical line-of-sight events were conducted before Baneberry some
four out of five released activity. Some releases were small, and confined to
the Test Site; many were detected off-site.</p>

<br>

<p class="tab"><b>Carothers</b>: Who designed the pipe string on
the Livermore vertical line-of-sight events? Who said what the front-end should
be, or what kind of closure hardware there should be?</p>

<p class="tab"><b>Hudson</b>: I think the design was
somewhat, I shouldn't say happenstance, but it wasn't engineered or designed on
the basis of a lot of information. It was more or less a farmer's approach to a
problem.</p>

<p class="tab"><b>Carothers</b>: "Let's put a big valve in about there."</p>

<p class="tab"><b>Hudson</b>: That's right. "Let's close
that pipe with high explosives." And those ideas were good, but they
didn't know where to put these things, by and large. So they decided putting them
in close must be better than farther away. "Let's stop that monster as far
down as we can." As a result, most of the early closures were blown right
out of the pipe, like a bullet through a gun, because they were in a region
where the energy density was too great. As they were moved farther away, they
worked better. And that's probably when people realized that, "Hey, maybe
there is enough of a basis for science and engineering here that we ought to have
a containment group."</p>

<p class="tab">We've revisited those
old designs several times. I don't recall, at the moment, what our findings
were, other than a big recollection that the primary problems of those events
was that they tried to stop things too close to the source.</p>

<p class="tab"><b>Keller</b>: At Los Alamos I looked very
hard at the LOS pipe flow measurements that were available, and they were
terrible flow measurements. They put the gauges on the pipe, fired the shot,
and the gauges gave you gibberish or they went off the air. There was no really
serious effort to measure flows in pipes. You would discover after a couple of
efforts, which took a couple of years, that the gauges they were using were
heat sensitive, and so the declining pressures you saw at strange times was
because you were heating the gauge. And a lot of the gauges were shock
sensitive, and they screwed them into the pipe wall, so when the pipe wall was
racked by the ground shock it would warp the gauge body and you'd get this funny
stuff. It was really kind of discouraging how long, how very long, it was
before pipe flow measurements ever became reliable. It was ten years later. I
think the first really good set of pipe flow measurements were on Diablo Hawk,
which was in '78. Ten years later.</p>

<p class="tab"><b>Carothers</b>: Did you also do pipe flow calculations?</p>

<p class="tab"><b>Keller</b>: No. We did do the design of the
front-end on all the Los Alamos events. The first ones were actually designed
with 1-D codes. I calculated lots of slices to determine what the probable 2-D
behavior was. The current design is different in aspect ratio, and so forth,
but it was really started about the time of Door Mist. It evolved from that
point to the larger reverse cones, the longer, more slender front-end cones,
and things like that. But it evolved rather slowly.</p>

<p class="tab">After I had been at
the Lab about two years, Chick Keller joined up; that must have been about '68
or so. Chick's job was to do front-end calculations in two dimensions, and he
came in just as eager as he could be to really do them right. He calculated the
designs in two dimensions, and after a couple of years he expressed a lot of frustration
because the designs that were developed with the 1-D codes were relatively
optimum. There was almost nothing he could offer that would be a major
improvement. The phase velocity and everything had been determined with 1-D
slices, and so the 2-D codes only confirmed the 1-D code designs.</p>

<p class="tab">And the concept was
resilient. Because of our level of ignorance we wanted it to be resilient. We
didn't want it to be sensitive to device performance or anything else. There
were some changes in things, but generally speaking it was just a very slow evolution
of those designs. The biggest changes were dictated by experimental conditions
like the aperture that was used on Cowles. It was huge compared to the norm, so
that necessitated a different design, but it was not driven by any real
revelation from 2-D calculations.</p>

<p class="tab">In '69 to '70 I was
designing Manzanas and Cowles and Yerba There was also Snubber in there, and I
designed the front-end of Snubber. Ajo was a test for that front-end design,
and it worked fine. But there's more to a containment design than the
front-end, as we found out on Snubber, and as DNA has found out recently.</p>

<p class="tab"><b>Carothers</b>: In those days it seemed as
though at every CEP meeting I went to there was an interminable series of
viewgraphs made from computer plots, with someone saying, "Well, here you have
such and such, and now you see ..."</p>

<p class="tab"><b>Keller</b>: Yes, energy ahead of ground
shock, and all that. Marshall Berman, Chick Keller, Jose Cortez - all those
guys at that time were calculating front-ends mightily. There were a lot of
frontend calculations. One interesting thing about all those pipe flow calculations,
and front-end calculations, was that there was not a realization in those days
that most of the energy flowing up the pipe was actually generated by the
ground shock collapse of the pipe. It was thought that it came through the
front-end. You could aggravate circumstances by a poor front-end design, but a
good design certainly never got rid of the ground shock generation of jetted
material.</p>

<p class="tab">I went through all of
that stuff before the CEP presentation of Huron King, more thoroughly than I
had ever done it before, and I was surprised to find that asymmetric designs
were fairly popular in the days of Eagle, and Finfoot, and Tee, and Backswing -
the vertical line-of-sight shots. There were a number of things they were doing
wrong in those days, and they didn't realize it. One was that they put the HE
machine three meters above the savior.</p>

<p class="tab"><b>Carothers</b>: What was the savior?</p>

<p class="tab"><b>Duff</b>: That was an asymmetric pipe closure
system. It was a big, massive C-shaped steel pipe with ribs on it, like gear
teeth, so it was non-uniform. The fourth side was closed by a relatively thin, flat
plate. The idea was that the flat plate would jam in much faster than the other
walls would. It was the kind of thing which has been talked about subsequently
on a number of occasions, but in the DNA program we use axially symmetric
things, largely because we can calculate them.</p>

<p class="tab"><b>Keller</b>: I'm sure something they didn't
appreciate at that time was that the source region extends out as far as the
full cavity region - out to the six kilobar range. And so they would put
everything in the first third of the source region but nothing thereafter.</p>

<p class="tab">Harry Reynolds wrote
a paper on the apparent success or failure of HE machines. His conclusion was
that you had to be outside of the cavity radius. He didn't know why that had to
be the range, but you had to be outside of the cavity range for an HE machine
to be very effective. They had placed the HE machines from just a few meters
above the can to farther and farther out, and they never seemed to do much
until they got out to a certain distance. I read that with amusement, because
about a year before we'd done experiments at Physics International which showed
that the ground shock implosion of the pipe generated a magnificent jet when
you were in the six kilobar range. That happens to be a little bit beyond the
cavity radius. And so this paper that was written by Harry Reynolds had all
this wisdom in it, which was supported later on when we discovered what was
really going on. His conclusions were right, but he was a bit baffled by why
they were true.</p>

<p class="tab">And there was an
external helix on one of the Livermore events, but I didn't know that. I also
had put a helix on the outside of the pipe on Cowles. Now I know that the
external helix on Cowles was ineffective. I'm sure of that, because when I went
to DNA we started doing experiments of that kind. Those tests we later did at Physics
International showed that an external helix worked fine for an HE imploded
pipe, but it didn't work at all for a ground shock imploded pipe. There was
absolutely no effect from some of the strongest asymmetries on the outside of
the pipe.</p>

<p class="tab"><b>Duff</b>: Probably the most relevant
thing that I did of a containment nature while I was at Livermore was on Alva
and Backswing, where we diagnosed the performance of the front-end hardware.
That's something that hasn't been done since. Interestingly enough, we got an
indication of the pressure in the iron of the savior, and it was somewhere
between 100 and 500 kilobars. We could tell by the velocity of the shock wave
that was involved. And the velocity of the jet coming up the pipe was two
centimeters per microsecond in the closure itself, and that number is the same
as DNA is getting these days.</p>

<br>

<p class="tab">The first events to use a horizontal
line-of-sight in tunnels for weapons effects studies were Logan (1958),
Marshmallow (1962), and Gumdrop (1965). It was in 1966 that the DNA began an extensive
series of effects shots in tunnels in Rainier Mesa. Most of these used a
horizontal vacuum pipe that diverged from a few inches in diameter near the
device to several feet in diameter at the far end, which might be as much as a
thousand feet away from the source. Stations for various exposures levels and
experiments could be located along the pipe. Some experiments recorded data as
the radiation from the device struck the detectors, and were finished within
microseconds. Others involved the reentry and recovery of exposed samples and
components, and their success depended on being protected from ground shock,
damage by projectiles, high pressures and temperatures, and contamination by
device debris.</p>

<p class="tab">The design of the line-of-sight
system thus involves letting the prompt radiation from the device into the
pipe, and then closing it in such a way that other material does not flow down
the pipe and damage or destroy the experiments being done. Further, the tunnel complex
should be protected, principally from radioactive contamination, so it can be
used for future experiments. And, extensive amounts of recording
instrumentation and equipment, whose loss would be quite costly, are usually
located in the tunnel. Finally, there is to be no release of radioactive
material to the atmosphere. The proper design of the line-of-sight system is
crucial to the accomplishment of all these purposes, except possibly the last.
It has been demonstrated that massive concrete plugs placed in the tunnel can,
if properly designed and installed, prevent release of radioactive gases even
if there is direct and open communication between the cavity and the tunnel
complex.</p>

<p class="tab">The first design problem is to
allow the prompt radiation from the device to enter the pipe, and then to close
the close-in portion of the pipe, called the front-end, to prevent device
debris from entering.</p>

<br>

<p class="tab"><b>Carothers</b>: Chuck, might it be fair to say
the way front-ends are today is largely due to you?</p>

<p class="tab"><b>Dismukes</b>: Well, front-end design has been
my primary occupation since about 1965, but I think that would be giving me a
little too much credit. Of course, we have to take the blame when they don't
work; they're not all successes. If I'm going to take some of the blame, I
certainly want some of the credit for the ones that worked.</p>

<p class="tab"><b>Carothers</b>: Seems fair.</p>

<p class="tab"><b>Dismukes</b>: We haven't been totally
successful. And, that's a major question; when things don't work right, what
went wrong? That's something I don't think we know the answer to.</p>

<p class="tab"><b>Carothers</b>: When you talk about front-ends,
how far along the pipe does the front-end extend? When does it stop being the
frontend?</p>

<p class="tab"><b>Dismukes</b>: That is also an issue, and it
has varied over the years. It was often a time frame of a hundred microseconds
or so where we would try to describe the phenomena. At that point the shock
might have propagated on the order of a meter outside the zero room into the
stemming. As the designs evolved we came up with this thickened pipe wall, a
heavy-walled pipe which is sometimes called a reverse cone, or extension.
That's grown in length over the years, and now it's out to a few meters. We try
to carry the calculations and analysis out to where the shock has reached that
range, or beyond. Typically we've looked out to half a millisecond to a millisecond.</p>

<p class="tab"><b>Carothers</b>: What factors do you try to include,
and what do you try to do out to that half millisecond or so?</p>

<p class="tab"><b>Dismukes</b>: The basic concept is simple.
We're talking about line-of-sight events, primarily for x-ray experiments, but
they don't have to be. We're viewing a portion of the output of the device through
a small pipe. We want to maintain this view until the device has put out its
prompt radiation, and it has had time to go through the system. That's
typically ten nanoseconds or less. It's very quick, so we don't need the pipe
to stay open very long. Then, at that point we want to close that pipe as
rapidly as possible, to prevent device debris and radiation we aren't
interested in from coming down the pipe.</p>

<p class="tab">The basic concept is
to create a a sequential set of valves, or closures. In order to close things
fast you have to vaporize them, get them very hot. And they won't stay around
forever because they're basically just a dense gas. So, we try to follow that
with a little denser gas, and a little denser, and eventually some liquid, and eventually
solid material which we hope will survive and begin to form the permanent
closure of the pipe. The whole system is designed to produce a continuous, but
only semipermanent closure of gradually increasing integrity. It's length times
density, and the cooler the better, but it's hard to get material in quickly
and keep it cool. Most of our systems, at least the way we calculate them, come
apart after we've closed them, but over a long period of time. By then we hope
to have created the ground shock closure of the pipe further out.</p>

<p class="tab"><b>Carothers</b>: What's the purpose of this
reverse cone that wasn't there originally, then gradually got there, and got
longer, and as I recall changed material a couple of times?</p>

<p class="tab"><b>Dismukes</b>: In the early days we
essentially just had a pipe sticking into a box and we worried about getting
the front of that pipe closed. There was stemming basically up to what we call
the portal end of the box, and the pipe was just there. We noticed that when
the shock propagated into the medium, the stemming tended to provide a low
density path between the hot zero room and the pipe. The place where we were
trying to form a plug in the pipe was just very hot, and of a low density.
Because the shock was strong and the stemming was of insufficient density to
really resist it, we might have a good plug at the front of the pipe, but this
could be bypassed, leaving the remaining pipe open, potentially, to the zero room.</p>

<p class="tab"><b>Carothers</b>: The pipe was being closed
basically with the pipe material and some grout?</p>

<p class="tab"><b>Dismukes</b>: Even worse, in the process of
closing components closer to the bomb we were producing a fair amount of
energetic flow, which we call plasma, which was jetting up the pipe. This stuff
was interacting with the pipe before the ground shock got there, and blowing it
out significantly. So, it was a lot larger when the ground shock did arrive,
and that made it harder to close. That whole process led to some very tenuous
looking curtains of material between the open LOS and the hot zero room. We
noticed right away that we ought to try to do something about that. Initially
we just put in a couple of feet of thick-walled iron pipe. That helped, so we
decided to make it longer, because we noticed that just beyond the end of that
thick walled section, again the pipe was exploding.</p>

<p class="tab">The impedance of the
metal was enough to inhibit the explosion of the pipe, so it didn't get as
large before the ground shock arrived. That's the basic concept. Also, when you
do close it, the material comes in more gently because of its higher density.
So, it doesn't get as hot, and it doesn't produce as much of a problem downstream.
We started doing a lot of numerical experiments on the computer, and we noticed
that higher density was better. And what's the highest density around? Uranium,
or something like that, and there was lots of that stuff available. Now, it
took a number of years to reach that state. We went to ten foot long reverse
cones of steel and we used those for quite a time.</p>

<p class="tab"><b>Carothers</b>: Wasn't there a time when they were lead?</p>

<p class="tab"><b>Dismukes</b>: No, they have never been lead.
We talked about that, and we were a little nervous about lead. It has such a
low heat of melt we were worried about squirting a lot of lead up the pipe. And,
the density isn't that much higher than steel, so it wouldn't be a big
difference.</p>

<p class="tab">Somewhere along
there, say 1975, we started experimenting with really high density, on the
computer. Uranium was much more beneficial. The energy in the pipe wasn't
sufficient to open the pipe up. And when the ground shock pushed it back in it
was relatively cool.</p>

<p class="tab"><b>Carothers</b>: Let me see if I have the
concept. The uranium is sitting here. The material that starts coming from the
zero room heats it very rapidly and starts to push it out. You would like it to
just sit there until the ground shock gets there and starts to move it in.</p>

<p class="tab"><b>Dismukes</b>: Right. And, the stuff in the
pipe that gets there doesn't have a high Mach number. In other words, there's a
lot of thermal energy as well as kinetic energy. So, it creates at least many tens
of kilobars of pressure in there. That's enough to start trying to make the
pipe bigger; to push the pipe out before the ground shock has really had time
to get there. The ground shock at first tries to stop it from moving out, and
then it tries to push it back in. Of course, the bigger the pipe has become,
and the more energy there is in it, the more work the ground shock does on it,
and adds even more energy which, potentially, can go up the pipe.</p>

<p class="tab">Now, that's one thing
everybody always assumes is bad for containment. It might not be. Letting all
that energy go up the pipe doesn't necessarily cause a problem, except it can
sure attack other things like the mechanical closures. In principle it could
even get to the experiment station and do damage to the experiments. But if we've
done our job there won't be device debris in it, and so it's not radioactive.
So, if we could let all this fast stuff go roaring up the pipe and just got
lost, and out of the way, maybe we could close the pipe even better.</p>

<p class="tab"><b>Carothers</b>: You are recapitulating a line
of thought that occurred in Livermore following the event called Eagle. It was
the one that produced a fireball at the surface. We were a little surprised to
see that.</p>

<p class="tab"><b>Dismukes</b>: I'll bet.</p>

<p class="tab"><b>Carothers</b>: I had people who did things
like fireball yields, and I said, "How much energy was there?" They
came up with a number which was kind of off the wall, not applying fireball
yield rules, of course, but HE fireballs, you might say. They said, "About
two hundred pounds."</p>

<p class="tab"><b>Dismukes</b>: I would have guessed it might
have been a few tons. Either way, it's not really very much energy, but it
looked spectacular. You wouldn't want to be standing there.</p>

<p class="tab"><b>Carothers</b>: No. It sure blew up the tower
that had the instruments on it. Anyway, "Bang." There was the
fireball, and all these pieces of the tower flying around. Then there was a
quiescent period. Not very long. Maybe a couple of seconds. Up to that point
there was no radioactivity.</p>

<p class="tab"><b>Dismukes</b>: That fireball wasn't radioactive? It was just
some hot gas?</p>

<p class="tab"><b>Carothers</b>: Yes. Following that, after this
short period, there was steam or smoke, and it was quite radioactive. And so,
doing the kind of deep thinking that we used to do in those days we said, "Well,
there wasn't any activity there in the beginning. Why don't we just let that go
by. Then, if we had some big valves, and if we could close them in half a
second, or a second, we could just shut it off." That's where ball valves
on the vertical line-of-sight pipe got invented. Of course, we discovered they
could be taken out one way or another, but that's another story. But that's
what you reminded me of when you said, "Maybe it's good to let this go by;
it's not radioactive. Then we will close things off."</p>

<p class="tab"><b>Dismukes</b>: It's not guaranteed to be bad for
containment per se.</p>

<p class="tab"><b>Carothers</b>: No, but DNA has always had two
problems. The more severe one is to preserve the experiments, to protect the samples.
I think of the tower on Eagle when you say, "Let it go by." As far as
the problem of a release to the atmosphere goes, if you folks succeed in
protecting the experiments, containment is virtually assured.</p>

<p class="tab"><b>Dismukes</b>: That's almost axiomatic, you
would think. But I don't know if that is really true. And that's because we've
had some strange results where things looked good for a while, and then later
they didn't.</p>

<p class="tab"><b>Carothers</b>: Anyway, you now have put a lot
of high-Z, high density stuff around the pipe, and hopefully it stays
relatively cool.</p>

<p class="tab"><b>Dismukes</b>: Right. And so we're really
accomplishing two things. We're keeping the pipe, which we have to close later,
from expanding. And we're also putting somewhat cooler, higher density material
into the pipe. The problem is that if you make this reverse cone longer, you
have to run the calculations longer in time to see what happens after you get
to the end of it, and we haven't explored that region enough.</p>

<p class="tab"><b>Carothers</b>: Computers are getting faster.</p>

<p class="tab"><b>Dismukes</b>: Yes. But the modeling issues
are significant. Where we think the real problems are is later in time than
where we're now talking about. It's in the few milliseconds regime where no one
is really dealing with what appears to me to be the most likely source of
containment problems.</p>

<p class="tab"><b>Carothers</b>: What do you think that source is?</p>

<p class="tab"><b>Dismukes</b>: It's that we still have gas, a
lot of hot gas, in the pipe, which is trying to expand the pipe, and we have
the ground shock coming along. The interaction of those, and treating the flow in
the pipe, modeling it well, is difficult. We don't know how to do that right now.
That area is the one that looks to us like the biggest problem - the influence
of the pipe flow on the ground shock and the stemming plug formation.</p>

<p class="tab">We ran a calculation,
one we know isn't a good calculation, out to ten milliseconds on one of our
standard designs, and things didn't happen the way we expected. We were kind of
shocked. We didn't form a good plug after we got past the end of the reverse
cone, or extension. There was quite a long period where we had very little material
in the pipe. And then finally a plug started to form. We knew that we weren't
treating the physics very well, but that was scary.</p>

<p class="tab">And some of our
reentry observations are scary. We see occasionally, "core flow." Joe
hates the words, but that's what I want to call it. That's where, when you mine
back in, down the main drift, you see a well-defined stream of grout which you
can identify because it's a different color. And that grout came from
relatively close-in. How did it get through, if we're forming a plug? It
clearly couldn't have been moving, or I don't think it could have been moving,
as fast as the ground shock. If it wasn't, then why didn't the ground shock
cause the pipe to be closed ahead of it? That stream didn't get through there
afterwards, because it is a well-defined stream, and it wouldn't maintain that
kind of definition. That implies we had a low impedance path through what we
would like to think was a plug, and this stuff was being extruded through it.</p>

<p class="tab">We've seen that more
than once, and that's very frightening. It suggests to us that this plug
doesn't always have the integrity we would like to think it does. The other
disturbing thing relating to the extensions is that, although we don't
understand why it's happening, there is some empirical evidence that we've had
more problems since we've used the long extensions than when we had the short
ones. You know, we had a sequence of events when we decided we understood
everything.</p>

<p class="tab"><b>Carothers</b>: That's right. There was a time
when you might well have thought that.</p>

<p class="tab"><b>Dismukes</b>: And those pipes had iron
reverse cones which were somewhat shorter. Then we got smart, and things
appeared to really work well for a while, but we've had a lot of problems since
then. Other things, many, many other things have changed, like pipe taper. A
number of people have studied this very hard, and there's no finger to point at
one thing and say, "That's what did it."</p>

<p class="tab"><b>Carothers</b>: I believe that. At the
presentations to the Panel there are often lots of viewgraphs which are
designed to show that the upcoming shot looks very much like previous ones.
"Well, see, here's a whole bunch of other shots, showing where the various
stemming grouts are and how long they are. And see, this one looks very much
like them, because the grout sections are pretty much the same. And so, this
one is good." And I sit there, and I think, "I'll bet there's
probably two hundred and seventeen other things that are different, ranging
from different manufacturers of the cables, to a different method of mining, to
a different tuff, to who knows what."</p>

<p class="tab"><b>Dismukes</b>: Sure, and that's one thing I
think we are really fighting, and there's no way to beat it; you can never
repeat a test. The medium you're shooting in has to be different, either
because it has been shaken by another test, or just because the earth is not homogeneous.</p>

<p class="tab"><b>Carothers</b>: How would you summarize the
state of the thinking today about the front-end, including the reverse cone? Do
people feel fairly satisfied with it?</p>

<p class="tab"><b>Dismukes</b>: I always hesitate to answer
those questions because I feel it's very tempting to be self-serving and say
they're wonderful, and there's clearly no problem, because we designed them and
we think they work.</p>

<p class="tab">On the other hand,
there are people who are concerned about it. I'm somewhat concerned about the
reverse cone, because of the number of seeps we've had since we started using
these longer, heavier ones. We had that long sequence of events with no
apparent problems, where we decided we clearly understood everything. I don't
think we did, and the one problem that I have with those shots is that we
missed a beautiful opportunity when we didn't reenter them. We didn't look at
them, so we don't know what they did in close. So, we don't know what a good
shot looks like, or we haven't seen very many.</p>

<p class="tab">We're just amazed
every time we do look because there's always something different that we don't
like to see. That's somewhat disturbing, but clearly there wasn't a lot of
radioactivity seeping into the tunnel on those shots, that's for sure. You have
to be concerned that we've done something bad making the changes that we have.
The calculations say that we've reduced the pipe flow significantly, and I
think the measurements of pipe flow tend to support that, at least
qualitatively. As far as earlier time frames, in the front-end, I feel that
that's not a problem.</p>

<p class="tab"><b>Carothers</b>: That's something that, in
principle, ought to be calculable with codes you really believe, on time scales
you understand.</p>

<p class="tab"><b>Dismukes</b>: But you won't get a universal
agreement on that . As long as we keep doing the type of devices and yields
that we have been doing, we shouldn't have to worry about it. But if we
suddenly go to very low yields, where the energy is very limited, I'm not sure we
would know what to expect. We try to design these things to be far from the
edge of a phenomenological cliff. So, if the energy changes a factor of two it
doesn't really matter, and the system doesn't respond in a non-linear way. We
try to operate in what I think is a fairly comfortable regime, where we can afford
to be wrong by quite a bit, and still have things basically work right.</p>

<p class="tab">If we start going to,
for instance, very low yield devices, it's a whole new ball game, because the
containment, in the normal sense, can't be achieved with the ground shock. Then
the game is to make sure you don't wreck one of the key elements further down
the pipe because the front-end didn't work right. There would be, maybe, more
threat of having to deal with jets of material out of the device itself, and
that's something we've only tried to deal with once, and that was not a
success. That was on the Hybla Fair event. We clearly didn't design that one
very well. Apparently the back of the test chamber got blown out by what came
up the pipe. For the kinds of devices DNA is currently using I'm pretty
comfortable.</p>

<p class="tab"><b>Carothers</b>: Really? How about the reverse cone?</p>

<p class="tab"><b>Dismukes</b>: Well, I'm a little nervous
about that, because we've seen some things that don't make me feel good. The
Bermuda Triangle of containment to me is the few meters beyond the reverse cone,
and maybe it includes the end of the reverse cone. That's the time frame of a
few milliseconds. Nobody's dealing with that problem, for a lot of reasons -
partly for the reasons you already reviewed. You have this little thin pipe in there,
stretching over many meters in length, and there don't seem to be enough zones,
even with the current fast computers, to really deal with that. Plus, there's a
combination of high shear flow in the pipe, where you have very hot gases
shearing against the pipe while it's blowing out. And, you also need to treat
the strength of the material fairly carefully, because the shocks are getting
down under a hundred kilobars. Plus there are some weak shocks of a few
kilobars out of the pipe. So, you need to treat strength carefully. You need a
Lagrangian code for that, but a Lagrangian code can't handle the shear in the
pipe. We need a different approach, I think.</p>

<p class="tab"><b>Peterson</b>: Carl Keller thought for years
that the most damaging thing coming down to the closures was the pipe flow. He
thought that even to the extent that one might be able to remove some of the
closures if you could eliminate the pipe flow. Subsequently we reduced the pipe
flow a lot, and the reduction of pipe flow correlates better with increasing bad
experience than with anything else. I don't understand why. It may be, for
example, that the flow we measure is not the damaging one. And so, we reduced
the part we can measure, but we may have increased the one which we can't measure.
It seems that for almost any technical detail you can bring up there is
evidence on both sides; there's contradictory evidence as to which way you
ought to go in changing it.</p>

<p class="tab"><b>Carothers</b>: Dan, when you talk about
late-time calculations, what is late time for you? When does it begin?</p>

<p class="tab"><b>Patch</b>: Late time for us was, and this
goes back into the history of before I joined the program, times beginning
something like a millisecond after the detonation, and in principle it goes on
essentially forever, until nobody is interested anymore. In actual practice,
late time calculationally has been from about a millisecond to about a second.
That's kind of the time span, because that's a critical time range for
containment.</p>

<p class="tab">Some of the things
that we have done were empirical, to look at data from a number of shots, and
try to understand the time scale they failed on and why they failed. Some of
the things we did were to look at fracture and fracture processes.</p>

<p class="tab">When I was at S-Cubed
I was working very closely under the wing of Jim Barthel. Jim was doing 1 112 D
pipe flow calculations with the FLIP code. So, I concentrated pretty much, for
the three years I was S-Cubed, on this energetic pipe-flow code, which was subsequently
used for Hybla Gold, and the nuclear shock tube studies. That was my primary
area of interest. In the last six months to a year I had branched out, and was
looking at ground motion from the data base point of view. It was the old issue
of HE-nuclear equivalence. What could we determine from the data base that exists
for the number of HE shots that were done, and there were quite a few HE shots
done in the early seventies, versus what the data base for the nuclear tests
had?</p>

<p class="tab"><b>Carothers</b>: When you talk about ground
motion, do you mean close-in motion? You don't care about the surface motion,
or seismic signals, for instance, do you?</p>

<p class="tab"><b>Patch</b>: We really did not look at the
surface or seismic motions at all. We were much more interested in the stress
range out to about a kilobar, where the materials transition out of the plastic
regime. The strength is very important there; the materials are plastic, but
the strength modeling is important. In a way, the late time containment,
almost, was the regime in which the motions were strength dominated from a
calculational point of view, at that time.</p>

<p class="tab"><b>Carothers</b>: People talk about the energy
release being so large that it overwhelms the strength of the rocks, so the
kind of rocks don't matter, close in.</p>

<p class="tab"><b>Patch</b>: Our primary interest was when
that wasn't true anymore. We were interested further out in time, further out
in distance. That statement is sort of true for some small time period, and in
some small regime. What we do is greatly simplify the details of the zero room
and the front-end. Then we start at zero time and basically let it grow in a
more or less spherical way. We may model some shapes, but we don't do a
detailed analysis of the hardware and its effects on the ground shock. So, we
start at zero time, and we kind of sluff through the early part. Right now
we're really trying to fill the gap between the classic early-time calculations
and the late-time work we've done. We're trying to do a better job there. What
I would say is that what we would like to do is start the calculations with the
details of the zero room environment, with the most important mechanical
details, but probably not with the sophisticated treatments that are done so
well in trying to set the timing of all the hardware.</p>

<p class="tab"><b>Carothers</b>: Do you also look at the
material transport down the pipe?</p>

<p class="tab"><b>Patch</b>: We have not done much with
that. That's an area we are just starting to work in. We have relied on S-Cubed
to give us a definition of that pipe environment. We've put that into the calculations,
as best we can do it, as a boundary condition.</p>

<p class="tab"><b>Carothers</b>: You look at the cavity growth,
the shock that moves out, and basically you try to tell people what the
stemming is going to do, and what the loads on the closure hardware are going
to be?</p>

<p class="tab"><b>Patch</b>: Yes. We try not only to tell
them what is going to happen, but hopefully we're a little more proactive. We
not only look to see what the problems might be, but to say, "You really
need a smaller tunnel in this region, and you ought to take this out a little farther,"
and so on. So, in a way we attempt to tune the geometry of the test bed, depending
on the medium properties and the objectives of the test. The basic geometry of
each test has, in some sense, experimental constraints, such as the length of
the pipe, the taper angle, the yield limits, where it's fielded, and lots of
other things. At the lowest order we attempt to identify what are the undesirable
features of the test bed, and try to figure out how they can best be mitigated.
I think I would be overstating our role if we said we were really fine-tuning
the designs. We try to, but it's a very complicated world out there.
Calculators always have to guard against the idea that they're doing something
real, that they know what they're doing, but we're doing the best that we can.</p>

<p class="tab"><b>Carothers</b>: What's the origin of the
material that makes up the pipe flow?</p>

<p class="tab"><b>Patch</b>: I think it comes from the pipe
region just beyond the reverse cone. The reverse cone keeps the pipe from
expanding, and I think that a real contributor to the flow is the fact that
when the ground shock comes along, the pipe is not what you think it is. It's some
new shape, which is a lot bigger. I think the reverse cone is probably pretty
effective in keeping that expansion from being as bad as it would be without
it. But the reverse cone is kind of tapering down; it's quite a long distance
in physical space, but it's probably coming down a little too soon. We're still
getting many kilobars of stress off the end onto a bare pipe, which can't
handle that. Of course, that pipe is blowing up, so that stress actually may be
applied to the tuff in a way, because the pipe, I suspect, fractures. It can only
expand maybe five percent for mild steel, and then it's going to begin to
shatter. So, I think that region is the source of the really serious part of
the flow.</p>

<p class="tab"><b>Carothers</b>: This serious part of the flow;
do you think it's pipe material, or some of the grout, or both?</p>

<p class="tab"><b>Patch</b>: I think it's both. I suspect
there's a fair amount of steam that's generated from the very strong collapse
forces. They're very convergent, so that tends to act like a shaped charge. I
think that these collapse forces are generating very high pressures on a relatively
limited amount of material.</p>

<p class="tab"><b>Carothers</b>: Why don't you make the pipe square?</p>

<p class="tab"><b>Patch</b>: That question has been asked
many times, and it's a question that's never been satisfactorily answered. I
personally don't think it would make very much difference. We've fought this battle
back and forth, and I don't know that anybody has shed any real light on how
important the pipe being circular is. I've heard it argued that because
seemingly very similar shots have quite different flow, therefore if we get
just perfect convergence, for whatever reason, we're in a much more serious
regime than if things are slightly off. And I've heard it argued the other way,
that the flow can't really be that sensitive to the shape, and there are other
factors that are causing these differences. I would really like to know the answer.</p>

<p class="tab"><b>Carothers</b>: I remember on the CEP, for
meeting after meeting people would talk about jets down the pipe. Why were
there jets? Well, when you make a bazooka shell you try to make a jet, and the way
to make it is you make a nice cone of HE which you light at the apex. So, you
have a conical thing that slaps shut, and out comes a jet. And so there was
always the thought, "Why do you make the pipes so symmetrical?"</p>

<p class="tab"><b>Dismukes</b>: It's certainly cheaper to do it
that way, rather than to make them oblong or oval. Not a lot though. There is
one basic argument why circular is better than the other cross sections. You get
the maximum exposure area from the device for the minimum volume of open pipe.
But I think that may be a second order effect. In fact, the symmetry in the
production of jets may be something we should try to avoid, but we've always
been very conservative, maybe to a fault, in not wanting to try things we
didn't think we could calculate.</p>

<p class="tab"><b>Carothers</b>: Are the pipes and the closures
symmetric because that's what you can calculate, or did you build symmetrically
oriented codes because that's the way things were built?"</p>

<p class="tab"><b>Dismukes</b>: I believe that primarily it's
the first thing you said. We tend to build things we think we can calculate.
But Carl Keller did bring the helical insert into the system. Clearly we don't
know how to calculate that.</p>

<p class="tab"><b>Carothers</b>: And there have been things called mufflers.</p>

<p class="tab"><b>Dismukes</b>: And those did appear to have at
least some beneficial effects. I never understood how they worked, but they sure
did something. There's no question about that. We used them for quite a while.
They've sort of fallen out of favor though.</p>

<p class="tab"><b>Carothers</b>: The helix was put inside the
pipe. One could put it on the outside of the pipe.</p>

<p class="tab"><b>Dismukes</b>: Well, we've looked at that, a
little bit. We were convinced that you ought to be able to achieve some benefit
by asymmetrically loading the pipe from the outside. However, that was never
demonstrated. It's difficult to calculate, but we did try to do some
calculations. There were also some HE experiments done to investigate the helix
effect. They tried some cases of loading the outside asymmetrically, and
couldn't see that it did anything, so that sort of fell out of favor. There has
to be something there, but we've never gotten serious about doing something
about it.</p>

<p class="tab"><b>Keller</b>: We did embark on quite an
experimental series, studying the formation and the attenuation of jets in the
LOS pipes. That really was an extension of that original debate about where the
energy in the pipe was coming from. I had decided that the jetting process was
ideal if you had a nice symmetric geometry. And, there were all kinds of extra
precautions taken in the design of things, like shells, that were to produce
jets. I thought, therefore, that there was probably a way to discourage them.
So, I had some calculations done at S-Cubed, and some experiments done at
Physics International, and people are still looking at those results.</p>

<p class="tab">We did a series of
experiments in which we imploded pipes with high explosives; just a cylinder
surrounded by high explosives, detonated at one end. It gave a jet out the end
of that pipe that was just awesome. With a two inch pipe, with about a half
inch of nitromethane on the outside, you could generate a jet that would punch
a two inch hole through six inches of solid aluminum. It was really impressive.
The PI people just couldn't believe it the first time they tried it - the
damage they did to the target they put out there. They put out a two inch
target the first time, and the jet went through it like soft butter. So, they
put in a six inch target, and it went through that. They were very impressed.</p>

<p class="tab">Well, we tried a
helix on the outside, and it worked beautifully; it just completely eliminated
the jetting. There was just a speckling on the front of the target. We took
some flash x-rays of the pipes, with and without the helix on the outside, and
they showed that the helix did perturb the implosion. So we thought, "No
problem, we'll just do that on the nuclear tests." We were trying to
simulate with this HE implosion of the pipe the ground shock implosion of the pipe.</p>

<p class="tab">I don't know remember
whether it was by E. T. Morris, from Physics International, or Russ Duff, from
S-Cubed, but the question was raised; "Well, maybe the implosion from the
ground shock is different than that from HE." And that was certainly a possibility.
So we scaled down the HE shots to three-quarter inch tubes, drove them with HE,
and still got the target damage. Then we put in three-quarter inch tubes
radiating out from a three hundred pound nitromethane charge in saturated sand,
so we generated a ground shock that imploded the pipes. We got awesome target
damage.</p>

<p class="tab">Then E.T. Morris and
I were sitting in the SRI cloakroom waiting for a DNA meeting, and we were
depicting the geometries on ten pipes that we were going to put around the next
nitromethane sphere. We tried changing the nature of the jet by lining the pipe.
One pipe we lined with paper, sort of carbon-like, one pipe we lined with
glass, one pipe we lined with polyethylene. And we thought, "Well, that
ought to really change the nature of the jet." We were thinking we could
perhaps modify the damage by modifying the material that was in the jet.</p>

<p class="tab">We also used a very
heavy walled pipe that was wrapped with lead. It was a really heavy walled pipe
because the calculations had shown that a heavy walled pipe was more effective
even than the asymmetry. These were S-Cubed calculations, and that
configuration had shown the lowest jetting, in those calculations, for years. I
heard that heavy walled pipes were better long before I ever got to DNA. But
there was some worry about trying them on a shot, because we thought that if we
really changed the form of the energy from a gas flowing down the pipe to a
cannon ball, that the cannon ball might do more damage to the doors than the
gas flow. So, there was some reluctance to try it. But since we were just doing
these HE experiments we could try it without any risk, so we put in a heavy walled
pipe.</p>

<p class="tab">We had one left and
we were asking ourselves, "What shall we try now? What's the
variation?" We decided that maybe the plastic lined pipe would show the
biggest difference, and if we made that with an asymmetric liner, it would even
be better. And so our tenth pipe had a plastic helix on the inside. The helix
was only about fourteen mils thick, and the pipe wall was about twelve mils
thick. So, it was like heavy scotch tape that we sealed to the pipe.</p>

<p class="tab">They fired the shot,
and E. T. called me up and said, "You won't believe the results." And
he went through the pipes. We had a couple of normal pipes on the shot,
standard pipes with nothing in them. They put big holes in the target. All the
pipes with the liners - paper, plastic, and glass - put bigger holes in the
target. The heavy walled pipe put the biggest hole in the target. The heavy
wall not only did not attenuate the jet, it made it the worst of all, directly contrary
to the lore. And the pipe with the plastic helix made no crater at all. We
couldn't believe that plastic helix made such a difference. There was another
pipe which had a lead helix on the outside to simulate the asymmetry we had
used with the HE so successfully. It made a big hole in the target.</p>

<p class="tab">So, of all those
things we tried, nothing worked except the internal helix of plastic. We
thought, "Well, maybe there was a mistake in the experiment. Maybe a mouse
crawled in that pipe and just blocked it off, or something." We couldn't
believe that helix could be that effective. So we tried it again. This time we
put in a steel helix, a lead helix, a plastic helix, and we tried some of the other
pipes again. We had twenty pipes around the sphere this time. We fired that,
and sure enough, all the internal helixes were just miraculous in their
attenuation of the jet. At the time we didn't know whether we were reducing the
source, or whether we were attenuating it. Eventually we learned that we were
attenuating the flow. The helix has no effect on the source.</p>

<p class="tab">We tried many things
of that kind, and it was a fascinating program, because we were studying all
this parameter space experimentally. Things that would take weeks to calculate,
you could just try. With twenty pipes we could try anything, and in a very
short time.</p>

<p class="tab">I told Don Eilers at
Los Alamos about the results, and he was really excited about them. He decided
he'd try it on a nuclear test, so he put in a pipe with an internal helix, and
one without on the Flora event, in 1980. He instrumented them to measure the penetrations
of steel plates at the end of the pipes. And he found that he got a major
reduction in the number of plates penetrated with the internal helix. Los Alamos
has used it ever since, and so has Livermore, to reduce the flow of energy in
the some of the longer diagnostic pipes.</p>

<p class="tab"><b>Bass</b>: I think the best thing we could
do to help ourselves would be to put the helix back in the pipe.</p>

<p class="tab"><b>Carothers</b>: Why was it taken out?</p>

<p class="tab"><b>Bass</b>: Every event that has had a
helix has seeped more than Joe (LaComb) wants. Now why? Why does he say it
leaks? Because you are dissipating energy quite close in, into the stemming,
more than you were without the helix. You're also getting in the stemming where
gas can go around your facility. That's the only leak that you're liable to see
through geologic features, is Joe's point. As far as I'm concerned, all the DNA
work I've done, or have been connected with where there was a leak, has leaked
in the line-of-sight pipe. Except, where the leaks came from a region where there
was a helix. There have been little leaks there. Otherwise, it has come right
down the tunnel. I don't think we have ever, or at least very rarely, leaked
through the formation. I think we leak through man-made facilities.</p>

<p class="tab"><b>Carothers</b>: How about the experiments Carl
Keller described which he had done to look at pipe flow? These were the HE experiments
with a dozen pipes with a helix of this kind and that kind in them, and they
were all on the same shot.</p>

<p class="tab"><b>Bass</b>: The trouble is, the helix on
those HE shots is not the helix on a nuclear event. The helix works in an
entirely different manner in a nuclear event than it does with HE. Carl said
the helix worked late. In fact, it works early. If the helix works, the
pressure outward on the pipe has to be increased. What we find on events where
we had a helix, the pressure at 50 meters, which on DNA events is where there
is a muffler section, the pressure out of the pipe is down by an order of magnitude
if there is a helix. That says any reduction has to have occurred earlier.
Either that or we don't have any idea how a helix works. Maybe we don't know
how a helix works.</p>

<p class="tab">We do know that on
one event the pressures went up inside the muffler section when a helix was
used, and that had never happened before. That says we added disorder to the
flow. We had pressures higher coming out of the muffler than we had going into
the muffler, and we had pressure measurements inside the muffler which were high
as you go through the muffler, higher than when you went into the muffler. This
is very unusual, and it only happened one time. That one time we had a helix up
close to the front. So, we added disorder to the flow. Where we didn't have the
helix, the muffler didn't seem to do much. Where we had the helix the muffler
did one hell of a lot. Which says to me we had all kinds of things going on.
This has been discounted completely, and nobody has paid any attention to it.</p>

<p class="tab"><b>Peterson</b>: At about the time that Pac Tech
split off from S-Cubed Norton Rimer and myself started working on what we termed
the late-time containment issues. Those are the cavity growth, the cavity
conditions, leaks to the tunnel complexes, the ground motion, the thermodynamic
and fluid flow process &ndash; the very slow processes that you see.</p>

<p class="tab"><b>Carothers</b>: When you say the late-time,
where do you pick that up?</p>

<p class="tab"><b>Peterson</b>: I suppose about ten
milliseconds. All of these times are relative, but compared to the times of the
explosion they are slow.</p>

<p class="tab"><b>Carothers</b>: I read somewhere once, and I
think about it occasionally when I think about time scales for containment,
that if you wanted to build an accurate scale model of the solar system, you would
have to make it not much smaller than the system is. There are very large
distances, and if you try to scale them to a reasonable size, then some of the
smaller things, like much of the asteroid belt, vanish. They get so little you
can't see them.</p>

<p class="tab">In a similar way,
when you think about the time scale of containment processes, which goes from
small fractions of a microsecond out to perhaps a few hours, how can you
possibly scale this to where everything fits? It's got to be in chunks, in a
way.</p>

<p class="tab"><b>Peterson</b>: That is correct, and of course,
that is one of the real difficulties in looking at it, because we do, being
people, tend to split things into problems we can digest. But when we do that,
we lose the coupling effects between them, which can be very important. You
arbitrarily split on what you think you can understand, and that has nothing to
do with what might be the most important. So, if you look at the way we
evaluate containment, we do have it split into the time scales of various
effects. We will look at cavity growth, we will look at ground motion, we will
look at pipe flow, we will look at leakage, and things like that, but they're
all very, very coupled. And one of the things I think we've fallen short on is
to look at the coupling effects between these things. In other words, pipe flow
is coupled very closely to ground motion and cavity growth.</p>

<p class="tab"><b>Duff</b>: The early efforts recognized
that the problem of flow in the line-of-sight pipe, plasma flow, is a very
complex problem and very hard to calculate. It's complex because the
hydrodynamics that we are dealing with is obscure. We don't really know the
source of this axisymmetric jet. We don't know whether it is a jet of material
which has been strongly irradiated, vaporized, modified, melted, whatever, and
then subsequently is closed off underground shock. We don't know the detailed
nature of that closure. Is it truly an axisymmetric thing, or just due to the
nature of the non-uniformities in the real world is it something less? I'm sure
those non-uniformities influence the initial conditions. Nevertheless, we made
an effort from day one to try to develop a numerical capability to allow us to
calculate the flow of the material in the pipe, and the interaction of that
flow with the pipe wall. That involves ablation, material entrainment, and all
of the processes that get involved. It is a complex problem, and I'm not sure
we ever did it very well.</p>

<p class="tab">We were also acutely
aware of the aspect ratio of the problem we were dealing with. A line-of-sight
pipe is a thousand feet long; it starts a few inches in diameter, and ends up a
few feet in diameter, order of magnitude. If you look at the numerical zoning
requirements for such a geometry, it is a horrendous problem.</p>

<p class="tab"><b>Carothers</b>: Well, the zones just have to be
little at one end and big on the other.</p>

<p class="tab"><b>Duff</b>: Sure. And things don't work well.
The codes don't work well if the aspect ratio is more than about three to one.
This was in the early seventies; we had no Crays. We were working on a link to
a Univac machine that existed somewhere else. Because of the aspect ratio
problem we developed what was known as the UNION code that tried to couple
three calculations. One was a flow of the plasma, created as well as we could
do it. It was inside a cylindrical envelope which was a 2-D calculation of the
stemming motion as a result of the ground shock as it propagated out. This was
buried inside a 1-D code. The UNION code was to put boundary conditions between
these various things. That was coming along.</p>

<p class="tab">Jerry Kent was my
assistant in those very early days, and I had passed the contract over to him
to run. Bjork was one of the major project physicists. These guys became aware
of what we now talk of as residual stress, and they used that awareness as the
basis of a pitch to DNA to fund a separate company. DNA went along, and Pacifica
Technology - Pac Tech - was formed.</p>

<p class="tab">Now, the point of
this is not to bemoan the fact that part of my staff took off and formed their
own company. The main difficulty from my point of view, and I think from the
containment point of view, was that the intellectual enterprise of treating the
phenomenology from a millisecond to infinity was broken right in the middle. A
new interface was installed. We had the job of trying to define the initial
conditions. That was Dismukes, who was doing some aspects of the very early
time steps. Then Pac Tech had the responsibility to do ground shock
calculations, not only in a one dimensional sense, but in the sense of studying
the LOS collapse, the jetting phenomena, and all that may be happening in the
pipe. And then we were supposed to worry about what happens after that. Well,
interfaces are awkward. They are awkward in the best of circumstances. They are
particularly awkward in a competitive environment.</p>

<p class="tab"><b>Rimer</b>: The pipe flow aspects have
always tended to be called late-time. They're motions that Mike Higginbotham
computes for Chuck, and that we put in our pipe flow code, or at least we used to
do that. Jim Barthel used to do that work. All that information, like the pipe
flow, goes down to Pac Tech for the stemming motion calculations. Meanwhile, we
are looking at free-field ground motion, model development, and then the later
time aspects, like hydrofracture, porous flow, creep.</p>

<p class="tab"><b>Carothers</b>: Do you generate the input for
the codes that Pac Tech uses for the stemming motion calculations?</p>

<p class="tab"><b>Rimer</b>: Yes, except the pipe flow has
not proved to be very important. You can either include it or not, and you get
the same stemming ground motion, for whatever reason. Now, what neither of us
model is how that pipe flow affects the properties of the grout. The pipe
expands, blows up, and none of us have attempted to model, because we don't
know how to model, what that does to that grout material There's a lot of
overlap between Pac Tech and us. They do a lot of just traditional,
straightforward calculations of each event. At the same time, I'm calculating ground
motions. Here I'm talking about the underground free-field motions around the
tunnel, and in the tuff away from the tunnel. What are the proper models for
the behavior of the rock? What causes the rebound? What causes the residual
stress development? Why does the rock hydrofracture or not hydrofracture? How
do we develop models to match ground motion data? I'm the guy who's supposed to
develop the new stuff, do the innovations in ground motion modeling, etcetera.</p>

<p class="tab"><b>Carothers</b>: Byron, after Mighty Oak DNA
made a number of changes in the design of tunnel test beds. The last few DNA
events seemed to perform well. What changes were made?</p>

<p class="tab"><b>Ristvet</b>: Well, first off, the devices
are lower yield, and so the driving forces on the stemming column are a lot
less. And we've moved our closures out in scaled range a lot further, so the stemming
anchor does not get challenged. Those came about after Mighty Oak, when we took
a total relook at Middle Note, which was in 1987. That was the first of the low
yield type of design that now has become our standard. We found out how to
modify the radiation environment so we could use one source to provide all the various
kinds of radiation environments. That's done with shims and filters.</p>

<p class="tab">Again, things
sometimes appear in the containment world to be cyclic. Compare the following
discussion with Byron Ristvet with the words of Billy Hudson and Carl Keller at
the beginning of this Chapter.</p>

<p class="tab"><b>Carothers</b>: I could translate what you've
said to mean that the basic cause of at least some of the problems was that the
closures were too close.</p>

<p class="tab"><b>Ristvet</b>: Basically that's correct, and
that happened in a couple of ways. We wanted to get to a standardized design.
The reason for that was so we only ordered a standard section one and section
two of the pipe, which are the sections from the working point all the way out
to the end of stemming. If we could standardize that we would save a couple of
million bucks every time we went out and bought pipe. Of course, that was for
the old higher yield shots.</p>

<p class="tab">Well, everybody
wanted everything possible. Number one, they wanted a large aperture so they
could vary the exposure area if it was needed, depending on the source. We
didn't use one source in those days, we used different ones on different shots,
and some had larger areas to look at compared to other sources. Apertures could
vary anywhere up to seven or eight inches. In order to accommodate a seven or
eight inch aperture you have to have a pretty good size bore.</p>

<p class="tab">Then we got the idea
we could save a lot of real estate and money if we made the pipe shorter. So,
the way we do that to get the same exposure area at a shorter range is to
increase the beam taper, which increases the pipe taper. And so now we had increased
our cross sectional area of the pipe, especially up in the front-end region,
significantly. In closure technology in those days we were still using the
sliding gates, the Modified Auxiliary Closure, or MAC. Because of the metals
involved you can't make those any bigger than about six feet in diameter, and
get them to close fast enough. Six feet is about as big as you can get an
aluminum billet that's forged, and that has the strength that you would like.</p>

<p class="tab">So now we had to move
things in significantly closer. Then we had them at a range where the grout
stagnation pressures were far exceeding the door strengths. In addition, in the
process of trying to perhaps eliminate pipe flow, we were actually making pipe
flow worse. On both Misty Rain and Mighty Oak we had reverted back to using
iron extensions rather than using the high density tungsten or uranium
extensions. One of the reasons we did that is that Carl Keller had felt we were
getting a fair amount of yield out of the uranium from the fast neutrons
getting up the pipe. To me that never explained why we saw plutonium against
the MAC, and even down further on Huron Landing.</p>

<p class="tab"><b>Carothers</b>: That's the way you make
plutonium - neutrons and U<sub>238</sub>.</p>

<p class="tab"><b>Ristvet</b>: Well, I know you can make it
that way in a reactor, but it wasn't that kind of plutonium. There were some
concerns about that, so Carl went back to the iron extensions. And of course,
on Misty Rain the pipe flow jumped up again, and it shot the doors out with the
pipe flow - at least the first one, and probably the second one too from the
evidence out in the test chamber. We had sort of a coating of iron, with a
coating of aluminum, followed by a coating of grout, on every surface that
faced the working point. Not only that, there was pretty good cratering back on
the bulkheads and other things, because block motion prevented the TAPS from coming
down. That is about as far out as we've ever seen significant block motion,
which is rather interesting. Anyway, it was not pipe taper alone, I don't
think. It was not bore size. It was the fact that all of those things came
together, and we brought those closures in so close that they were no longer
effective stemming anchors.</p>

<p class="tab">We did a vertical
shot called Huron King, and I and Jim Barthel, of S-Cubed, looked at all the
old history. It became rather obvious that the HE machines in those days,
because they were in so close, became shrapnel against the rest of the
closures. That's why we moved our HE machine out to a similar stress range as
we use for the FAC today. It was in part that experience that led us to put the
F AC where we do. I really think we could go back to those larger pipe tapers,
maybe 0.24 inches per foot, 24 inches per hundred feet, and be okay, if we were
in a normal zealotized tuff.</p>

<p class="tab">If we have the FAC
out at roughly a kilobar, because we know it can withstand two or two and a
half kilobars so we've got a good factor of two safety, we have confidence in
the ability of it to act as a stemming anchor, and not let the stemming go down
the LOS pipe. I think my greatest concern in our current low yield design is
the failure of the FAC to fire. Even though ground shock will close it, I don't
know how much grout will have been shoved through it at that time, and whether
the cavity pressure will be sufficiently far down so the stemming won't
continue to hydrofrac and erode as it did on Mighty Oak.</p>

<p class="tab"><b>Peterson</b>: There have been a number of
observations on some events that haven't performed just as we'd like that I
find very interesting. You can talk about pipe taper, and sort of the bad performance.
Or the performance wasn't as good once we went to the bigger pipe taper. That's
true. We also went to a longer extension, and the performance wasn't as good
after we went to the longer extension. Some of the shots worked all right, but
they didn't all work really good.</p>

<p class="tab">People say, for
example, that on Misty Rain and Mighty Oak, because we went to a bigger pipe
taper we moved our first closures in much nearer the working point. I f you
really look at that, it isn't much nearer. It's really a very small distance,
and the change in the dimensions don't even compare to changes that were made
in some previous events.</p>

<p class="tab">I believe it was Dido
Queen where, from a scaled view, we were in much, much closer, and it worked
fine. We went to Diablo Hawk, where the first containment structure was much
further out. The containment was okay, but the door got penetrated by the grout
flow. Various people pick various different things to explain these things.
People have also picked on material properties; there wasn't quite enough air
void, or it was a little bit more saturated, and all that.</p>

<p class="tab">I guess the one point
I would like to make is that if you go back and look at all of these things,
and really compare all the previous experience, you can always find one, two,
or three shots that worked fine given any of these things. And so, I know I
don't understand it, and it's confusing. I t makes you go over to what DNA is
using now, which is a really strong stemming bulkhead. Given the fact that we
don't seem to know very well what happens, or why it happens, maybe we should
build something that should stop anything in the tunnel.</p>

<p class="tab"><b>Carothers</b>: It's another overburden plug,
in concept. It's to hold whatever can get there.</p>

<p class="tab"><b>Peterson</b>: Yes. It should hold the most
extreme conditions that we've measured so far. It might not be fancy, but one
would hope it would work. I think when we want to get fancy we should understand
all the things we know, and have seen. When that will happen, I don't know.</p>

<p class="tab">When the concept of
the "residual stress" came up, people calculated it and could say,
"Oh, I can see now why the gas stays in the cavity." One of the
things that bothered Carl Keller was that now we understood the residual stress
field, and the containment cage, we didn't want a hole to go through it.</p>

<p class="tab">That seems
reasonable, but one of the things that has always puzzled me is that one of the
first designs, on Dining Car in 1975, seemed to work fine. There was a pipe
with a certain taper, and the closures were at a certain place. They had
rock-matching grout out to a certain distance, and a super lean grout out
further, and that shot worked. Now, the peak of the residual stress field on
Dining Car was in the area in the tunnel where there was super lean grout, which
is very weak. The rock-matching grout stopped inside of that.</p>

<p class="tab">At Pac Tech they
started looking at these stemming plug formation concepts in more detail, They
did a number of calculations, and it appeared that if you made the
rock-matching grout column longer, and the super lean grout column shorter, you
would set up a better residual stress field across the tunnel.</p>

<p class="tab">There is nothing
wrong with that concept whatsoever, but that was the time when we started to go
with longer reverse cones to lower pipe flow, and made a few other changes. We
also started seeing these slight bits of gas seeping into the tunnel complex.
Well, who knows? So, the Mighty Oak design went back to Dining Car. It had a
rock-matching grout length back to what it was on Dining Car, and a super lean
grout length back to Dining Car too. Well, obviously that wasn't the answer.</p>


<a name="ch19"></a>
<br><br>
<h2>Chapter 19: Codes and Calculations</h2>
<br>

<p class="tab">The development of computer codes
for the calculation of underground effects resulting from the detonation of a
nuclear device began concurrently with the first underground events. Bob Brownlee
has described his work on the Bernillilo event, fired in 1958. At Livermore
there was the Rainier tunnel event in 1957, where the principal objective was
to contain the device debris, and the tunnel events for device development in
Hardtack II in 1958. Logan, also in 1958, was the first tunnel experiment to
use a line-of-sight pipe for effects experiments, and it contained well despite
the almost complete lack of knowledge about how the detonation would, or could
be contained.</p>

<p class="tab">The Plowshare program, which
envisaged various civilian applications of underground explosions in a variety
of earth materials, needed the capability to predict many of the phenomena that
today are considered important to the containment world, principally those
associated with the response of the earth to the energy release of the device.
The device development events, fired in emplacement holes had considerably
simpler calculational requirements. The appropriate depth of burial for the
yield was really all that was thought to be necessary, and for that empirical
rules seemed to suffice.</p>

<br>

<p class="tab"><b>Higgins</b>: By Hardtack Gene Pelsor's
calculations had advanced, and John Nuckolls had developed a code called UNEC -
the Underground Nuclear Explosion Code. It was later renamed SOC when John went
to one of the device design groups. It was a simple one dimensional
plastic-elastic code with a Von Meses solid equation of state, which doesn't
allow much fracturing. But, it did do a very nice job, with the right
adjustable coefficients, of reproducing what was going on in the Tunnel Bed
tuffs. So, from shot to shot we could use that, and see that the shockwave
pressure was generating a seal in the tunnel. What was wrong with it was, the equation
of state of the material in the real world is not a Von Meses solid. It's
brittle.</p>

<p class="tab"><b>Carothers</b>: Or, maybe you could say that it is a pile of rocks.</p>

<p class="tab"><b>Higgins</b>: It's a pile of rocks with
cracks and holes. So, the rebound, that part which is really the important part
of the calculation of containment, wasn't calculated. But the tunnel closing,
and the pipes closing; all that was calculated very well. Our misunderstanding
of containment was that we thought once the material was at a density of three,
it was going to stay a density of three, and therefore we didn't have to worry
about it anymore. End of problem.</p>

<p class="tab">And that really was
the end of the problem, in a way, because we could calculate out to maybe a 100
microseconds, if we really devoted everything we had to it. And that was only
in one dimension. Peak pressures were calculated quite well, but that's about
all. Rise times and decay curves were not calculated at all.</p>

<p class="tab"><b>Rambo</b>: I think some of the very first
calculations at Livermore that had to do with containment were calculations
done for the Benham event. Benham was a high yield shot with some kind of a satellite
hole that was of concern. That was probably one of the very first sets of
containment calculations.</p>

<p class="tab"><b>Carothers</b>: That's rather late in time if
you consider that the Partial Test Ban Treaty was signed in 1963. Benham was in
December of 1968.</p>

<p class="tab"><b>Rambo</b>: That's right, but we didn't
have the material properties to do that kind of work, and they didn't do any
logging. The only times they would do special cases of logging was on Plowshare
related events. On those shots they would go in and do the best job they could
to log the hole, even though the technology wasn't really very good.</p>

<p class="tab">The K Division
people, the Plowshare group, were starting to do calculations. They had a code
which was called SOC, which was a 1-D code, that they had started with. Seymore
Sack and George Maenchen did some of the TENSOR work that was done. Then there
was a kind of a split there. K Division took up some of those codes, and put
strength models in them. Ted Cherry was the one who did most of the strength
models. He did TENSOR and I'm sure he did some of the work that went into SOC.</p>

<p class="tab"><b>Carothers</b>: The original impetus for doing
calculations on underground shots came from the Plowshare cratering program,
but the names you mentioned are those of device designers.</p>

<p class="tab"><b>Rambo</b>: Yes, those device designers did
the original SOC code, for the Plowshare people.</p>

<p class="tab"><b>Carothers</b>: SOC is a 1-D code, so that
means you spherize the world around the bomb. What's a code like that good for?
The world is not one dimensional.</p>

<p class="tab"><b>Rambo</b>: No, it's not one dimensional,
but in the early days we didn't have a 2-D code available. So, by default we
took the 1-D code and said, "Well, it seems to predict ground motion
reasonably well, at least for the outgoing peaks, before the reflections take place."
We never did any SOC calculations, or darn few, that related to containment
until after Baneberry. There were calculations done for Plowshare. Then the 2-D
calculations came along, and they were put together for the cratering shots.
They were much better.</p>

<p class="tab">Ted Cherry, in the
early days, would try to match field data with SOc. There was a lot of battling
going on as to what was really in the code, and how much truth there was to the
SOC code. It was under a lot of stress. People were not confident of what was happening.
There were problems with matching the data, but that's what you have to do in
these calculations. You take a first try at it, and then after the fact, you
see what you can learn from it. What you learn from looking at the real data is
what there is about your model that is wrong, or maybe you find out that the
code was just plain wrong. It was a good feedback loop. When we did fail, we learned
more than when we didn't fail, but we still had a lot of mysteries that we were
not able to solve.</p>

<p class="tab">Calculations played a
different part, in those earlier times at Livermore. People like Bob Terhune
would walk over to our people and say, “Look, you can't shoot this. Our
calculations indicate this, that, and the other thing." It might have been
some private theory of his own. There were a couple of places we avoided
because of that, and went to other sites. We wouldn't do that today.</p>

<p class="tab"><b>Scolman</b>: I am not aware, but I'm not
sure I would have been aware, of us ever, ever deciding that a hole was not
suitable for an event in the days before Baneberry, other than one time. Carl Keller,
who was in the containment business for Los Alamos in those days, became
concerned over an event in Area 4. I don't remember the name, but it was a
reasonably high yield shot which was to be fired fairly close to the basement
rocks, to the dolomite. Carl was convinced that we would generate enough C02
that it could not be contained in the overlying rock. And he heckled us sufficiently
that we finally moved the event to another location.</p>

<p class="tab"><b>App</b>: In 1971 Bob Brownlee hired me,
Tom Cook, and Tom Bennion to start up the calculational effort for containment.
We weren't interested in developing our own codes, not at all. We wanted to get
something that somebody else had, and if we had to convert it for our use,
fine. Tom Cook and I drew straws to see who would concentrate on which codes.
We went by Labs, and Tom got Livermore. Tom got the 1-D SOC code from
Livermore, and the 2-D TENSOR code as well. I got the WONDY and TOODY codes from
Sandia.</p>

<p class="tab">We evaluated and
benchmarked the four codes, to determine which would be the most appropriate
for us. We chose Livermore's SOC, and Sandia's TOODY. We also used WONDY to a
limited extent. Things evolved from there. SOC went by the wayside after a
number of years because, although it had a lot of containment lore behind it,
and was an excellent code, it was written in a language called LRLTRAN. When
the Cray machines arrived, LRLTRAN was not implemented, so SOC no longer
worked. Actually, Charles Snell, who now works here at Los Alamos, but who did
work at Livermore, has it running again, on our machines. He liked it, and he
converted it from LRLTRAN into standard FORTRAN.</p>

<p class="tab">The TOODY code has
actually been our mainstay. It's what I've primarily used for modeling
purposes, with a lot of modifications to fit our particular needs. It's now
more of a special purpose code for ground shock modeling than it was at Sandia.
We're in the process of benchmarking other, newer codes against it, but I
haven't found any that are a substantial improvement. It has archaic coding. It
has twenty year old architecture, based on the CDC 6600 system. It's hard
sometimes to part with old friends. I know the innards of it; another reason
for not wanting to part with it.</p>

<p class="tab"><b>Carothers</b>: Billy, when you entered the
containment business in 1968 Livermore was no longer doing tunnel events, but
vertical line-of-sight shots were being done from time to time. Were there any people
in the Laboratory doing theoretical or calculational work on containment
related problems? Things such as flow in the pipes, or ground shock closure of
the pipes?</p>

<p class="tab"><b>Hudson</b>: I wasn't aware of any pipe
closure calculations. I think they were starting to do them, but I have the
feeling that was really in its infancy. There had been a very little bit done
in terms of using the same codes that are used to design bombs to predict how a
pipe would behave and close. All that started at very nearly the same time as
the containment group was formed. We started then a program of code development
for pipe behavior, in concert with the folks at S-Cubed, and also in concert
with some folks from Los Alamos. For several years there was a fair amount of
effort expended on code development, and in trying to describe how pipes really
close.</p>

<p class="tab"><b>Olsen</b>: The codes that were available
in the beginning were not very good for that type of thing. They were basically
derived from the device codes. The early containment calculations were
essentially all on front-end things, and at that time the device codes were used
for that. We didn't really have anything beyond that, except for some
engineering codes that looked at loadings on pipes, and how hard will you hit a
valve assembly and will it hold up to 40 g's of acceleration, and that kind of
thing. We did a lot by the seat of our pants.</p>

<p class="tab">There wasn't really
any way to calculate pipe flow. We pretty much had to go in and make
measurements to see what regime we were looking at. We tried to do some
calculations on pipe flow, but in my opinion there never was any really usable
code for that. The closest was a code called PUFFL. If you diddled enough of
the many parameters in it you could get it to match things, but as a predictive
capability it was pretty close to useless. It was sort of one step better than
back of the envelope calculations. For example, if you knew what the burst
strength of a pipe was, you could sort of say that if you put that pressure in
the bottom of the pipe section, and the pipe opens up, you couldn't transmit
more than that to the top of the pipe, because the pipe would open up and dump
the flow into the medium. That's the kind of arguments we used.</p>

<p class="tab">We would do things
like put accelerometers on valve housings to find out what kind of input the
valve was seeing, and how it responded. We measured things like that, because
we didn't have much in the way of a design or predictive capability for the
dynamic environments, especially where there were multiple loadings on different
time scales. For instance, on a valve there's a shock running up the steel pipe
at one velocity, then ground shock, with a different wave shape, at a slower
velocity. And somewhere in there is a loading from flow in the pipe hitting the
closures. So, there is this multiple loading on things, and we didn't have any
first principles way of attacking that. We did it empirically, which is why there
was the emphasis on diagnostics in the early days.</p>

<p class="tab"><b>Keller</b>: On Monero and some other
events, 10 and behold, the radiation monitors in the holes showed the gas was
going by the coal-tar plugs. This absolute seal in the casing was not there.
And the pressures that were measured that were driving gas by those coal tar plugs
were modest; forty-five psi or so. It was at that time that it was clear we
needed a code to evaluate gas flow, because gas flow is a big deal in stemming,
and in containment in general.</p>

<p class="tab">And so Al Davis wrote
a 1-D gas flow code based on Darcy's equations. In a period of a couple of
months we had that 1-D gas flow code. I said to Al, "But we need to
evaluate uncased holes, so we need a 2-D code." He said, "Oh, it will
take a year to write a 2-D gas-flow code." And I said, "Come on, Al.
I just saw what you did for 1-D. We can do it in a month." He said,
"Never. Never." So I wrote the equations, and gave them to John
Stewart. John Stewart programmed them, I put in all the input-output
statements, corrected the errors in the original program, and John debugged it.
In one month we had an operating 2-D gas flow code. It was called JACTS, John
and Carls TDC.</p>

<p class="tab">With that we were
able to evaluate the differences between the cased holes and uncased holes. I
took the Monero results, where we had like five pressure measurements in the
cased hole, with the top two above the coal-tar plugs. And I took the driving
conditions at the bottom as the boundary condition, and calculated a 1-D gas
flow up the hole. From that I deduced the kind of permeability you had to have
in the plugs in order to get those volumes and pressures of gas above them.</p>

<p class="tab">Then I hypothesized
that the casing was perforated. To do that I just removed some of the no-flow
boundaries on that casing and let the gas flow out into the medium. And with
that I proved to everyone's satisfaction that the amount of gas that you
actually released out of this uncased hole was trivial, and yet there was an enormous
drop in the gas pressure that was driving against the stemming column. So,
there wasn't a containment argument any more about why uncased holes weren't
appropriate, and Los Alamos folded on the issue of uncased holes. Another
concern was that the holes wouldn't be stable enough, and would fall in during the
device emplacement, but Livermore had already proven that that wasn't a big concern
at all.</p>

<p class="tab"><b>Carothers</b>: The code you wrote must have
been for non-condensable gases.</p>

<p class="tab"><b>Keller</b>: Right. The JACTS code is for
non-condensable flow, and you can still use it for lots of things, but the next
thing that was c1ear[y needed was a steam-flow code. You need to treat the
cavity gas with a condensable-flow code because the cavity gas was thought to
be mainly steam, and that's not the same as the non-condensable gas that the
codes calculated. There were all these arguments in the TEP about what the
ramifications were of the condensable nature of steam.</p>

<p class="tab">It took me a year to
write the KRAK code. I had never written a computer code before in my life, and
the KRAK code took three thousand cards or so. It was a monster compared to the
JACTS code. So, I had to begin to be really organized in my programming. And, I
had to [earn all the thermodynamics of steam, because KRAK included a full flow
of condensation of steam in two dimensions. It did not assume local
thermodynamic equilibrium. It treated the difference between the fluid
temperature and the rock temperature, and the heat exchange between them. It
was an explicit finite difference code, so it was easy to add to or change.</p>

<p class="tab">When I finally got it
written I did a calculation which showed that condensable flow from the cavity
to the walls got nowhere. Steam did flow into the wall, and it actually got in
quite a ways, very quickly. Then it condensed and clogged up the pore space
with the condensate. That throttled subsequent flow, and from there it just crept
along as it pushed this slug of water on ahead. And that slug got longer and
longer as condensation continued. So, condensable porous flow from a cavity was
not a containment concern. It wasn't even a concern in the stemming, generally
speaking.</p>

<p class="tab">KRAK was slow,
because it was very detailed. The idea was that while it would be so detailed
that it would be too slow to ever be very useful, you would teach yourself with
the code what approximations were appropriate, and then you could relax to a more
useful speed in a simplified version. It still runs, with the same full-blown
modeling, I guess.</p>

<p class="tab"><b>Carothers</b>: Well, the machines get faster.</p>

<p class="tab"><b>Keller</b>: Yes, the machines got faster,
but it was still slow. It was dreadfully slow. Brian Travis took it over after
I left the Lab. He worked for me one summer, the last summer I was at Los
Alamos, and so finally a professional programmer got his hands on it, and he speeded
it up a lot. He also gave me the idea of using an implicit solution for the
crack flow. Al Davis was sort of the chief physicist consultant on the KRAK
code, and Al's attitude generally was, "Well, it's going to be real hard
to do that." Mine was, "Come on, Al. Let's do it. Tell me what the
physics is and we'll do it." So, we got along very well. Al kept me correct
with the physics, and I got him to hurry.</p>

<p class="tab">The next thing that
was obviously needed then was a calculation of the greater threat, and that was
that threat which had been witnessed in Bandicoot, Pike, and Baneberry, where a
fissure propagated from the cavity to the surface. In other words, a hydraulic
fracture. So I added the hydrofrac option to the KRAK code, and it's still
being used.</p>

<p class="tab"><b>Kunkle</b>: When I showed up here in April
of 1980, to begin work at Los Alamos, my security clearance was still not through
being issued, but it was only a month before it was. I started work down at the
G Division headquarters in White Rock, working on the KRAK code, which is a
multi-phase, multimedia, steam-driven hydrofracture code. AI Davis and Brian
Travis were working on KRAK at that time. Carl Keller had initiated this code
back in 1974, with a code called JACTS, but he had left to go to DNA field command,
to lead their containment effort.</p>

<p class="tab">We were trying to
develop that code into an actual working code. At the time I first started it
would simply not run calculations. Integrals would not converge, derivatives
would blowup; there were the normal programming type of problems. I spent most
of the summer of 1980 working with Brian Travis, running problems just to get
an answer. We were trying to develop the physics involved in the KRAK code so
we could get answers we thought might be right.</p>

<br>
<p class="tab">How codes and calculations are
used today varies from organization to organization. And, the importance of the
results of the calculations varies as well. The Livermore and Los Alamos events
in stemmed emplacement holes seem to require little more than empirical rules
to select a depth of burial. The DNA tunnel events involve the interaction of
many of the phenomena produced by the detonation, and extensive calculations
are done on how the experimental hardware, including the line-of-sight pipe,
will be affected. The results of the calculations done often cause changes in a
particular design.</p>
<br>

<p class="tab"><b>App</b>: We normally don't run calculations
for every event, although that's really not a bad idea just to keep in
practice, or to see if certain things pop up that are unrealistic in the
calculation, or that might be suggestive of a problem we didn't anticipate. But
normally we do not work in that mode. Usually it's a specific problem. For
example, Dahlhart. We had a nearby pipe, a fish, that was stuck in a nearby
exploratory hole. We didn't really know the condition of the pipe, and we were
having a difficult time finding out what the condition was. The worry was that
it was open, and passing through the region we regard as the residual stress
field it could provide a path for cavity gas to get high into the geologic
section. We performed some normal ground shock calculations, and used the shock
levels to determine whether or not the pipe would be closed off, and how far it
would be displaced.</p>

<p class="tab">That's an example of
how we used the code on a specific event . We don't use calculations for
absolute predictions - in fact, I don't even like that word in association with
calculations. I prefer to use them as an analysis tool, as part of the overall
analysis.</p>

<p class="tab"><b>Carothers</b>: If the containment scientist
says, "I want these calculations run for this event," how would that
be done at Los Alamos?</p>

<p class="tab"><b>House</b>: As Fred said, typically we
don’t do calculations on the events. There’s no burning need for them unless
we have some peculiar geometry in terms of emplacement. Or, a situation where
we might want to look at the effect of the structural situation, such as a
fault, or scarps, and so forth and so on. The containment scientist will, if
necessary, call for calculational work to be done on whatever particular aspect
he or she deems necessary. That’s usually done hand in glove with the
phenomenologist.</p>

<p class="tab">So, we do not do
calculations routinely. We have a situation that’s a little different from
Livermore’s. I believe that Lawrence Livermore Laboratory’s John Rambo is the
designated, and dedicated containment calculation guy. I remember John telling
me once, “Well, I take a look at everything.” And if he thinks something needs
to be done, he may contact the containment scientist, or vice versa. In our
Laboratory we don’t have either a designated, or dedicated person. We have
people who are supported by the containment program in the calculational venue,
and who are required to be responsive to needs, but they are on a call-out
basis. In some cases the phenomenologist will do the calculational work if it’s
in that person’s particular area of expertise. Tom Kunkle, for instance, runs
our KRAK code. Wendee Brunish runs a code called TOODY.</p>

<p class="tab"><b>Rambo</b>: Today, calculations are kind of
nice to use to get things through the CEP, but nobody wants to look at the
negative side of them. Nobody wants to say, "Look, we're going to have to move
the site," or do this, that, or the other because we have a calculation
that doesn't look quite right. Fred App, from Los Alamos, says, "Well, we
never use calculations any more to decide about a shot. If it's negative we
don't say we're going to make any big changes."</p>

<p class="tab">Sometimes I see
problems in the calculations that I don't necessarily bring up, because the
system has sort of bypassed them at this point. Calculations don't mean much
today. The containment scientist can elect or not elect to look at
calculations, if he so desires. He can say, "I don't need any
calculations. I think past experience is fine." And so even though I may
have a different idea on that, it doesn't matter, and it can stop right there.
So, I see the potential for going past a bad one - one that may show an
indicator, a blip, in a calculation as a potential problem. That never even
gets discussed.</p>

<p class="tab">The calculator has
his own view of things. What I've discovered over the years is that minor
differences, or changes in certain properties around the cavity, and certain
positions of layers, can make a big difference in a calculation.</p>

<p class="tab"><b>Carothers</b>: I have talked to various DNA
people who say, "Well, you know, one of the things that's really kind of
baffling is we have made what appear to be small changes in our designs, and we
get big differences in things." As Ed Peterson put it, "I cannot understand
it in the science that I learned, because if someone came to me and said, “We're
going to make a ten percent change in this,' I would say, ‘Well, we only
guessed at the first one, so what can ten percent do on the next one?'"</p>

<p class="tab"><b>Rambo</b>: Yes. I see sensitivities also.
The difficulty in answering the question has to do with which problem you are
talking about. There are so many changes you can make, and I'm not sure which
ones do make a difference. Let me give you an example. Take Galena, which I
presented to the CEP. The approach to it was, from the people who look at
geology and look at material properties, "Oh, it looks like everything
else we've presented before. We've got all these different Grouse Canyon layers
that we've shot next to." But when I ran the calculation on it, and by the
way I did it on my own, I said, “I think you people may have some problems. I think
we ought to look at it." The containment scientist didn't want to do that.</p>

<p class="tab"><b>Carothers</b>: It's like doing a test with a
weapon from the stockpile. If it works we won't have learned anything, because
it's supposed to work, and if it doesn't work they will know that, and that's
terrible. Similarly, your calculations will show the site is all right, which
we already know, or it won't look all right, and then you'll give us trouble.</p>

<p class="tab"><b>Rambo</b>: You've put your finger on
exactly what I go through sometimes. That's the biggest issue about calculations
- I really am not independent of the total system. And so I have this anchor around
me, that you might call wanting to know the truth.</p>

<p class="tab">And that brings up
the importance of the CEP, because that is the last decision making process. It
isn't the last, but it's close to the last decision making process that takes
place. As we continue with this process it's going to be harder and harder to
move to a different hole, if that was something that should be done, because the
money situation is probably going to get worse. I think that puts even more
responsibility on the CEP to make good judgments on these kinds of things.</p>

<p class="tab"><b>Carothers</b>: Well, the CEP assumes good
faith on the part of the Laboratories. Part of that assumption of good faith is
that the sponsor has looked, seriously and honestly, at the problems which
might be associated with the shot that is being brought forward. And, they are
going to bring those to the CEP meeting and discuss them, and why they believe
any such problems have been satisfactorily resolved. If they know of a
question, and they do not bring it to the CEP for consideration, they are
willfully subverting the process.</p>

<p class="tab"><b>Rambo</b>: Well, there seems to be this
idea that if you run a calculation there's something wrong with the site. And
that almost stops the process occasionally. It's hard to get away with running a
calculation on something, because the containment scientist is afraid.
"Did you run calculations on this?" "Well, yes." "Why
did you do that? What was wrong with the site that you ran calculations on
it?"</p>

<p class="tab">The CEP does have the
power, however, to demand a calculation, if they know enough ahead of time. If
you have somebody or some people on the Panel who say, "This doesn't look
right, and we want to know more about it or we won't pass on it," the
calculations would be done.</p>

<p class="tab"><b>Carothers</b>: It's my understanding that
these days there's a fair degree of collaboration between the Los Alamos and
Livermore containment people. Does it ever happen that Los Alamos would say,
"You know, you really ought to calculate this and see what it says."
Does that happen?</p>

<p class="tab"><b>Rambo</b>: Yes and no. This usually takes
place in communications before the CEP, in which we send each other questions.
That has happened occasionally. But, it's never happened that we've demanded
calculations from them. I have submitted a question and said, "Have you
run calculations on this, that, and the other?" maybe twice. But our side
never demands any calculations from Los Alamos, or at least it doesn't seem as
though we have, and we have very rarely if ever run a calculation on one of
their sites.</p>

<p class="tab">Conversely, Los
Alamos has run calculations on our sites several times. I don't know why this
imbalance exists, but I think it's the perception of calculations from
different sides of the fence. It's as though some of the management on our side
is saying, "Well, calculations don't mean much. They're useful to sell to
the CEP." When we run up against a negative calculation we're maybe a
little more leery, but we're still saying the calculations by themselves don't
make a big difference.</p>

<p class="tab">It's good to be aware
of that, because the people making the decision at the CEP are much more savvy
about this process than they used to be in the old days. I think they're able
to say, "Well, this is a negative calculation, but there are other factors
that take place that have to do with containment." I think that has
certainly changed over the years, but we're still living with the remnants of the
ideas that if you show any bad calculation to the Panel, they may give us a B
or C. I think the Panel is a little more savvy in being able to make
intelligent judgments.</p>

<p class="tab"><b>Carothers</b>: When you talk about
calculations, do you do them for events of the various yields? Do you, for
instance, do calculations on the low yield events?</p>

<p class="tab"><b>Rambo</b>: Sure. Galena was an example of
that. The yield was not high. The layers went from full saturation up to this
Grouse Canyon layer that was enormously porous. That to me was a flag that
said, "Look, this is at the extreme, and you ought to run a calculation."
Eventually I did, somewhat on my own, and that was presented to the Panel. If I
had just laid back and not done anything, that calculation would not have been
done.</p>

<p class="tab">What was kind of
interesting about it was that it was different from everything else I've seen
in terms of Grouse Canyon related calculations. There was a tremendous change
in the attenuation rate. And that produced this focusing effect that I talked
about - the flattening of the out-going wave. For a normal residual stress you
like things to go out spherically and come back spherically so it tends to
close everything up in a spherical sense. When everything runs up as a plane
wave, and comes back that way from the topside, you don't get a big residual
stress. The max cred calculation on Galena didn't show a residual stress.
Nobody knew that at the CEP because it wasn't asked. The design yield showed a
very weak ten, twenty bar stress along the stemming column.</p>

<p class="tab"><b>Carothers</b>: Refering to the Panel again, I
think they can make intelligent judgments if they have the information upon
which to base those judgments. And that's the point that concerns me. If they
don't have all the information, such as not being informed of your calculations
on Galena, how can they make an informed judgment?</p>

<p class="tab"><b>Rambo</b>: Well, you have to remember that
certainly our models for looking at containment calculations leave some things
to be desired. I see some of that after looking at comparisons between real
data and the calculations. I'm not trying to sell calculations necessarily,
because I know that there are calculations that may be misleading, and that
some of them have been misleading. But in spite of that, we don't do too bad a
job.</p>

<p class="tab">There's always been a
tendency for there to be higher rise times in our calculations, compared to the
measurements. It's like the ground is a bigger absorber than we calculate. But
I think in terms of residual stress we tend to capture some of that, and yet
there are plenty of arguments that say, "Gee, we don't think there's any residual
stress in any of the shots." The DNA people are starting to say those kind
of things.</p>

<p class="tab">The calculators tend
to believe the reason the high yield shots contain is because there's a well-established
residual stress. You don't see anything going through cables, the man-made
phenomenon of the hole is very small, and the residual stress is very thick compared
to the pressure in the cavity.</p>

<p class="tab">Now, in the
calculations you always seem to generate, for the same strength rock, the same
cavity pressure. On a low yield shot there is less protective distance than
there is on a high yield shot. When you get to low yield shots the man-made
phenomenon become large with respect to other things, and that's been one of the
ideas behind why low yield shots don't have as good a history as the high yield
ones.</p>

<p class="tab">But there is Riola
and Agrini. Looking at the geology of those two shots, there was just nothing
there to calculate. There weren't any nearby layers, and calculations would not
have done any good because they would only have shown a nice residual stress
field.</p>

<p class="tab"><b>Carothers</b>: If you look at those two
events, Riola I put down as an engineering failure. There were plugs which were
supposed to be stemming platforms, but the one that was called on to actually do
that failed, and was abraded away by the stemming which fell past it, so it
didn't do the job it was supposed to do. On Agrini there was a strange, very
deep crater which must depend on details of the geology that we'll probably
never know.</p>

<p class="tab"><b>Rambo</b>: That's right. /t's as though
there are three aspects to this; there's the cavity gas, and there's the
residual stress problem. But the third thing that can happen is a strange
collapse, or some geological path that takes material to the surface. And,
number three can bypass number two. I f there is an unusual collapse, it may not
matter whether there was a residual stress there in the first place, or what
the calculations showed.</p>

<p class="tab"><b>Duff</b>: If we are to make progress in
some of these containment issues, I think we need to think about how we calculate
things. In the containment community we have a world view which assumes that a
one dimensional, spherical expansion is the proper view of an explosion. That's
where it all starts.</p>

<p class="tab">A zero-order
approximation is a 1-D calculation. If you want to know about the effects of in-situ
stress, or lithographic stress, you go to a 2-D calculation and put in gravity.
And what do you know? You get a slightly different result.</p>

<p class="tab">So, we start with a
one dimensional world. I'm suggesting that perhaps ground motion, for instance,
in the DNA context, is governed by the scale of a fault or bedding plane type
displacement, which is large compared to the cell size of a computation. Or certainly
large compared to the size of the core we're going to squeeze in a press, but
small compared to the final cavity dimensions. And it may be that the one
dimensional approximation in this case isn't even a good zero-order
approximation to what's going on.</p>

<p class="tab">I don't know what
that means. I certainly don't know how to calculate it, or how to think about
doing such a calculation. And that's something that has been thrown at me every
time I make this kind of an argument; that we really ought to open our minds to
think about something beyond where we've been before. They say, "Well,
gosh, we don't know how to calculate it." If that's the limit of our
world, and the limit of our world view, we're sure not going to change that
view. And we may not learn the truth.</p>

<p class="tab"><b>Carothers</b>: May I rephrase what I think you
said? You're saying that the world is inhomogeneous on a scale which is large compared
to your computational meshes, but small compared to the region in which the
phenomena important to containment take place.</p>

<p class="tab"><b>Duff</b>: Perhaps. I have to emphasize
the perhaps in all this. I've made a point in my career, and I've tried to make
the point here that I was interested in trying to develop an understanding of
what was going on, more than concentrating on getting the next shot off, or trying
to meet a schedule. It's in this context of trying to understand something that
I think the containment community, and I as a significant member of that
community, have failed.</p>

<p class="tab">And that part of the
failure has been in not recognizing the lessons that were learned from Rainier.
One reason for me making this point was that within the last few years I went
back and reread the Livermore reports on Rainier. They are kind of an
interesting thing to look at. I commend them to the Panel. That event was extensively,
and very carefully reentered and studied as an example of an underground test.</p>

<p class="tab">There is a statement
in the reports that the cavity is reasonably well formed, and well defined.
It's pretty spherical. And for a meter or so outside of the cavity the rock
seems to be plastically deformed, and moves in pretty much a 1-D sense. Beyond
that, ground motion is dominated by slips on faults, on bedding planes, and on
fractures. Within a meter or so of the cavity! That is, to me, evidence in the
books, from the first shot, that says perhaps the one dimensional world view is
not the proper world view.</p>

<p class="tab"><b>Carothers</b>: Good out to a cavity radius plus a meter, maybe?</p>

<p class="tab"><b>Duff</b>: Yes. But if you have a stemming
column which goes out a little further, you may not get the right answers. But
it is very hard to get real data, and actual observations. And we deal with the
very real personal attitudes of the people in the loop. If you think you know
what's going on, and it sort of works, and there's nothing dramatic that makes
you change your view, you say, "Gee, that must be the way it is." It
has been shown time after time that we don't know that's the way it is. As
witness to that look at Mighty Oak, or Mission Cyber and Disko Elm.</p>

<p class="tab">I have criticized
continuum-mechanics based codes as inappropriate because the basic assumption
that points that start out close together stay close together during the motion
is not, apparently, what is observed in the field. Therefore, I have
recommended that effort be directed towards the development of a
three-dimensional discrete element calculational technique.</p>

<p class="tab">Discrete-element is
basically a two-dimensional calculational procedure put together some fifteen
or twenty years ago by a man named Peter Cundall. He's now at the University of
Wisconsin. The technique, basically, imagines that you have interacting blocks
of rock, which are defined preshot, unfortunately. Unfortunately for our case,
because we don't know what's in the earth in any great detail. But for civil
engineering applications, for which he developed this technique, it's adequate.</p>

<p class="tab">In such a calculation
there are predefined blocks of material, which in the first approximation are
rigid, so these blocks can interact only through interfaces, where there are
frictional forces that are defined. There have been extensions to the theory to
allow elastic type distortions to occur also. The beauty of the technique is
that one block is free to do whatever the forces that are at play ask it to do.
It can change its neighbors however it wants to. It is not restricted to the
continuum-mechanics assumption that there are proximity relationships that are
maintained, nor is it restricted by the slip-line constraints that have
sometimes been put into 2-D continuum-mechanics codes Those, I think, are
always restricted to one class of boundaries which can slip. The J lines can
slip, or the K lines can slip, but not both of them. In the discrete element
codes both can.</p>

<p class="tab">Let me give you an
example of problems I have seen calculated, on personal computers by the way.
We'll take a hopper containing an arbitrary array of defined objects; square
blocks, round blocks, triangular blocks, you name it. They're sitting in the
hopper under gravity. Remove a diaphragm at the bottom of the hopper. The blocks
are allowed to flow out under gravity, and they start sliding down. One will
fall out, and another one will fall out, and they will tumble, and fall, and
they will pile up and do what they do in complete freedom from the constraints
of usual continuum-mechanics calculational procedures.</p>

<p class="tab">Now, this
calculational technique has been known, as I said, for fifteen or twenty years.
There has been work on it at Livermore, and there has been work on it,
supported by DNA, through Waterways Experiment Station. I don't know that it
has been generalized to 3-D, but my recommendation is that a serious effort be
made to try to bring up a practical and effective three-dimensional discrete element
technique.</p>

<p class="tab"><b>Carothers</b>: My comment is that the
development of calculational tools and codes within the Laboratories has been
dominated, in the past, by the device designers. People were, and are,
intensely interested in what happens inside a device when you fire it. That's where
the big kids play. That's where the interest, the money, and the effort has
been, and so they have developed very sophisticated and elaborate ways to make
those calculations. And in a device there are no blocks moving around, or
hydrofractures, and they are usually symmetrical about some axis. If you're
just a little guy who comes along and wants to do some calculations concerning dirt
and rocks that maybe crack or jiggle around, you're probably not going to get a
lot of money to do that. And so, maybe you adapt some of those techniques that
have already been developed to your problem. That might be one of the reasons
that has led to the widespread use of the continuum-mechanics techniques you
describe.</p>

<p class="tab"><b>Duff</b>: I believe that.</p>

<p class="tab"><b>Carothers</b>: Chuck, inherent in the efforts
to model, or calculate, the phenomenology of an underground detonation,
particularly where you have a line-of-sight pipe, there is an enormous range of
time scales. Things important occur from fractions of a microsecond to more
than many minutes. Similarly, spatially, you have a thin piece of iron which is
maybe going to do something and interact with things, and then you have, if you
want to believe in block motion, a piece of rock, probably bigger this
building, moving around.</p>

<p class="tab"><b>Dismukes</b>: You're giving good reasons why
the modeling is not as simple as one would like.</p>

<p class="tab"><b>Carothers</b>: How do you deal with those things?</p>

<p class="tab"><b>Dismukes</b>: Not very well.</p>

<p class="tab"><b>Carothers</b>: You deal with it well enough to
be successful some of the time.</p>

<p class="tab"><b>Dismukes</b>: Apparently. Or we're successful
in spite of our ignorance. That's always possible. It could be that just doing everything
on the back of an envelope would work every bit as well. It doesn't give you a
lot of confidence that you know the effect of parametric changes in the design.
We do a lot of that by the way - not thinking the code is giving us the right
answer, but that it will tell us what the influence of design changes are.
Hopefully it will suggest what's good and bad when we start changing things.</p>

<p class="tab"><b>Carothers</b>: Without saying how good, or how bad.</p>

<p class="tab"><b>Dismukes</b>: Exactly. And that's the primary
use of the codes, I think. I don't think any of us are deluded to the point
where we think we're predicting exactly what happens.</p>

<p class="tab"><b>Carothers</b>: Where do the codes come from? Do you develop them?</p>

<p class="tab"><b>Dismukes</b>: It's a mixture. We've obtained
some from the Labs. One of our early-time codes is really very similar to
Livermore's CORONET.</p>

<p class="tab"><b>Carothers</b>: Your codes are all basically
two dimensional, aren't they? Which came first, the codes or the pipe?</p>

<p class="tab"><b>Dismukes</b>: The codes. The codes were
designed to deal with nuclear devices, which really were symmetric. The codes
came first, because I think we were reluctant to experiment with non-symmetric test
configurations because we didn't know how to calculate them.</p>

<p class="tab">Primarily the codes
are two dimensional. Certain radiation problems you might do one dimensionally
if you wanted. You could put in a little more sophistication because you could
put better transport in for some things. In principle you can do that in 2-D also,
but it gets expensive. The problem with 2-D codes is that they assume the world
is axially symmetric. So, you get perfect symmetry, typically around the axis
of the line-of-sight pipe. That would suggest that you probably get more
jetting and energy flow in calculations than you do in the real world, because
nothing is perfectly symmetric. Certainly the stemming and the placement of the
pipe in the tunnel is not axially symmetric; it's only quasi-axially symmetric.</p>

<p class="tab">The pipe is
symmetric, but it's not located symmetrically. The tunnel itself is not mined
symmetrically, and the pipe is not placed exactly in the center of the tunnel.
There are support structures, and possibly experiment stations on one side and
not on the other, and generally that's ignored. The codes are basically two
dimensional codes that calculate cylindrical, axially symmetric kinds of things,
and there's no dependence on the axial angle.</p>

<p class="tab"><b>Broyles</b>: I still find myself concerned
about the role of calculations and the lack of what I think of as an
appreciation of the limitations of 2-D calculations versus a real 3-D world.
There are a number of people on the CEP, and other places also, who still think
of 2-D calculations as the ultimate calculation, not recognizing what to me is
a very serious limitation of 2-D calculations. That is the fact that in the 2-D
expansion, instead of a 3-D one, you can, particularly in complex geometry,
produce a calculation which can scare you to death, when there is no reason in
the real world to be scared. In a 3-D world things go as lover R cubed when you
talk about reflections and things like that, instead as lover R squared. I suppose
that's a minor point, because it may cost you money and effort unnecessarily,
but if you're aiming to be conservative it's at least in the right direction.</p>

<p class="tab">People can certainly
do better 2-D calculations today than they could fifteen years ago. They have
also learned to do parameter studies with 2-D calculations in a much better
way, and apply them better. I think an area that can be exploited more is that
we do have 3-D calculational capabilities now, particularly for late time,
slow, ground motion calculations. In many cases those can be the important
response, particularly for the tunnel collapse, the upheavals, the fault
motions.</p>

<p class="tab"><b>Bass</b>: With the thought in mind that
block motion could affect the residual stress field, through our DNA
Containment Advisory Team working group we asked that a certain problem be run,
and that we be apprised of the results of it. We wanted a discrete element code
used, and S-Cubed was tasked to do it. We asked them to put a fault in, and see
what that does to the stress cage. And indeed, those calculations show that if
the fault is in the wrong place, it kills the stress cage.</p>

<p class="tab">Now, you don't need a
discrete element code to do that. Any finite difference code will tell you the
same thing. But the finite difference code will only tell you about one fault.
You can't put in several faults. With these discrete elements codes you can put
in numerous faults, and address an area. We have recommended, and I think
someday somebody will do something about it, that if a DNA test area shows
multiple faults in what we call the stress cage region that should be addressed
with a discrete element code. I think we need to do this.</p>

<p class="tab">Certainly a finite
element code can go 3-D a hell of a lot easier than a finite difference code.
Sandia has some going; certainly a lot of people have some going, but they are
not being used, as far as I can see. We're really falling behind with what we
should be doing with 3-D codes. We have the capability now to run those codes. People
can still think, and with the capabilities we have now we should be running 3-D
problems, and people aren't. All of the 3-D calculations have just kind of died
.</p>

<p class="tab"><b>Patch</b>: Even a 1-D code is useful in a
lot of material property studies. It's fast, and it does some of those sorts of
things pretty well. Almost all of our serious work is done in 2-D. We do
limited work in 3-D, and we're prepared to do it. It's just that one has to be
sure that there is something that is truly 3-D, and that the 3-D effects are so
important that you can either give up on the zoning resolution that you can
achieve in 2-D, or you bite the bullet and pay the cost of doing a 3-D
simulation. There are instances when one does that, but they're relatively
rare.</p>

<p class="tab">I think the most
effective way to use 3-D calculations is to home in on limited features. For
example, you could ask yourself, “Does it really matter that the tunnel has a
horseshoe shape as opposed to a circular shape that the 2-D code forces it
into?" In addition to that, DNA typically offsets the line-of-sight pipe.
They put it on one side of the tunnel so people can walk on the other side
because it makes it nicer to work. So now you have a funny shaped thing with the
line-of-sight pipe set off in one corner. Is that important?</p>

<p class="tab">The way you do that
in 3-D is not to mock up everything from the zero room to infinity, but you
take a section of it and look to see whether it behaves in a sensible fashion.
You can make a lot of progress in 3-D as long you restrict yourself to a
particular question. What you often times need in 3-D is to run a benchmark in
1-D or 2-D, so you can say it's 10% more, or it's 100% more, or 0.2% more. Many
times, using a 3-D code, you get an answer, but you don't have any scale, so
you have to invent your measurement tool to go with it.</p>

<p class="tab">We're currently
working on getting a 3-D axial, and quasi-axial symmetric code in which things
can vary with the azimuth. At that point I think we can begin to investigate
some of the things we see with more confidence.</p>

<p class="tab"><b>Carothers</b>: You'd be able to do something
like having the wall thickness vary?</p>

<p class="tab"><b>Dismukes</b>: Yes. Or you could even have a
cross section be slightly asymmetrical. The problem with that kind of code is
that if you get to large distances you don't have good angular resolution, but
maybe you don't need it there. You can put good angular resolution where you
need it, near the pipe. I have high hopes that one day we'll be able to do
something with that code. It's just about to come on line.</p>

<p class="tab">The usual event in an
emplacement hole doesn't have the complexities of a line-of-sight event in the
tunnels. So, as Fred App and John Rambo have pointed out, calculations of the
phenomenology following such a detonation are not regarded as very important in
the planning of an event. And so, development of better calculational tools is
not an very high priority project at the Laboratories. Part of the reason for
that is that one could argue better codes would have to have better input data,
which is not availabe, nor likely to become available.</p>

<p class="tab"><b>App</b>: I think the important thing is
that we are in a very data-limited environment. There's no doubt about that.
And that's the reason we're not predictive. We're not constrained by enough
data. We're data limited. I think we have pretty strong analysis capabilities, but
we have to always couch it as, "These are the limits of how this rock
might really behave." Or, “These are the limits we might have on the
phenomenology." We are not truly predictive.</p>

<p class="tab"><b>Carothers</b>: How useful would a 3-D code be?</p>

<p class="tab"><b>App</b>: I don't think a whole lot more
useful to us. There may be some special circumstances where we might want to
know what the effect of a fault is, or something like that. I think that 95% of
the cases, even if we had a beautiful 3-D code, would probably still be done in
2-D. The world is, to a first approximation, with layering and all, two
dimensional. We still do a lot of useful one dimensional calculations, and the
world certainly isn't one dimensional.</p>

<p class="tab">Now, there are
specific cases you might want to look at with a 3-D code. You might want to
look at a three dimensional geometry to assess the assumptions made in a two
dimensional case. For example, how might a sloping layer affect the results,
and in what way? But even then I think we normally would use a two dimensional
code for the main part of the study. I think that's how we would approach it. A
3-D calculation is an order of magnitude more expensive to do, and more
complicated besides.</p>

<p class="tab">And again, in 3-D we
are still data limited. How are we going to know how things vary in three
dimensions any better than we do in two? The real problem lies with the
material properties. I think that's the real issue; the material response.</p>

<p class="tab"><b>Carothers</b>: Dan, how do you get the
numbers, or the information to build your material models?</p>

<p class="tab"><b>Patch</b>: That comes about in a lot of
different ways, and hopefully each way adds a little bit of information, so the
composite of all those little bits of information makes the model, with its strengths
and its failings. The codes, because we've spent a lot of time perfecting what
I'll call numerical techniques, by and large do an extremely good job of
solving the equations of motion, and doing all the things they should do when
they have the right kind of zoning. But they only do what the material model
is. So the material model in these calculations is far and away the most
important factor, or unknown, or uncertainty in the calculations.</p>

<p class="tab">We are frequently
accused of just taking the post-shot data and tuning the calculations until
they give the best agreement, and then using that model until something new
comes in, then tuning again. While I can't speak for others, I don't think
that's an accurate description of what I do, and I don't believe it's an
accurate description of what a number of other people do either. We try very hard
to make a model based on information that comes from tests on the rock itself,
and not from some kind of global empirical data base. And so, it is always
personally bothersome to me when people say, "Oh yeah, they just tune
their models. They only reason their models do what they do is because they've
adjusted all these knobs." That, I think, is a very unfair
characterization of what we do. That's not been our approach.</p>

<p class="tab">Certainly we compare
the results of the calculations to what happens. It wouldn't make sense if we
didn't. That's just a basic way of verifying that the calculations are doing
the right thing, and often times they don't. Certainly there are sometimes
minor features, sometimes major features we're not happy with. I think the
appropriate question then to ask yourself is not which knob do I have to turn
to get this thing to come out right, but to ask yourself which piece of physics
is missing from the numerical models, or if it seems like one knob has been
turned the wrong direction, how can that be? It is not to simply say,
"Well, if I adjust this part of the model everything is wonderful,"
and go on. To me that's not science at all, and the implication that we do that
I find very bothersome. So, our approach, at least philosophically, has been to
verify the calculations, and when we have a problem to use that as a red flag
to ask what's missing, and what do we need to measure, and then try to devise
some way of getting this new material property we haven't had before. And we're
not always successful in doing that. We certainly have our mysteries.</p>

<p class="tab">There are a number of
models, and each has its drawbacks, and each has its uncertainties. I suppose,
to some extent, one rejects those models which give features that just don't
seem to be consistent with what the experience in the field is, and if someone wants
to say that's how we're tuning the calculations, by winnowing through
alternative kinds of models, in that sense I suppose we are tuning the models
by rejecting those that seem to be non-physical.</p>

<p class="tab"><b>Carothers</b>: I don't know what else you can
do. I find it hard to think that you could sit down and from first principles
derive a model that would describe what goes on in this very complicated material
under rather unusual circumstances.</p>

<p class="tab"><b>Patch</b>: If there were something else I could think of, I'd do it.</p>

<p class="tab"><b>Rambo</b>: Over the years of doing these
things I've tried to bring some ideas together about how calculations play some
role in some shots, and on other shots they really don't play any significant
role at all. I was looking at what happened after the shot. What's the report
card look like? How well did we do; did the calculations mean anything at all?</p>

<p class="tab">There's a group of
shots that we've done calculations on where we were trying to deal with issues
that were of interest for a number of reasons, where people felt there were
containment issues that needed to be calculated, and the calculations did
matter. We've run these calculations on a lot of events, and they looked okay.
And at least in looking at the post-shot analyses where we're looking at radiation,
we didn't see anything. So in a sense the calculations have been helpful to
kind of get things through the CEP, and maybe there's a connection between the
calculations and the fact that we didn't see anything.</p>

<p class="tab">Then there's the area
that I call kind of worrisome. Worrisome areas are like Roquefort and Coso.
Roquefort was probably in the thirty-some kiloton category and had
radioactivity that went past the bottom two plugs, and we'd run calculations
and presented them to the CEP. It bothers me to run these things and say,
"Well, there's still a residual stress even though there's this hard layer
that runs through it and there's a lot of perturbation, and there's this Grouse
Canyon layer that's close by. It bothers me, to some extent, to run these
things and go down to the CEP and say, "Gee, I didn't see anything
calculationally." And then afterwards, think maybe there was something I
should have talked about.</p>

<br>
<p class="tab">As a postscript to this chapter, and
a case study of the current role of calculations on an emplacement hole event,
is the Barnwell event. Barnwell, with a yield in the 20 to 150 kiloton range,
was fired in Area 20, on 12/08/89. John Rambo was the Livermore containment
scientist.</p>
<br>

<p class="tab"><b>Carothers</b>: John, I know you were quite
concerned about the containment of Barnwell. And, let me say that if anyone
were to look carefully at the post-shot data on Barnwell, they might conclude
that your apprehensions were well founded. There are people who think Barnwell
came very close to being a containment failure.</p>

<p class="tab"><b>Rambo</b>: I guess I'm one of those
people, even though I didn't say it publicly. Barnwell. Well, in the beginning
we didn't suspect there were any problems whatsoever. It was down toward the southern
end Area 20, in 20az, in new territory, so to speak.</p>

<p class="tab"><b>Carothers</b>: It had a yield in a range where we've never had a problem.</p>

<p class="tab"><b>Rambo</b>: Or never had seen a problem. Sometimes we haven't looked.</p>

<p class="tab"><b>Carothers</b>: We've never had an escape of material in that yield range.</p>

<p class="tab"><b>Rambo</b>: That's right. And we didn't on Barnwell
either. But that's what we're really discussing. In the beginning I decided to
do calculations for an issue that had to do with the CEP, and that was a
possible low scaled depth of burial. There was uncertainty in what the maximum
credible yield was. We couldn't lower the device any deeper in the hole because
the hole was crooked and we'd get alignment problems. So, as the containment
scientist I was stuck with a depth of six hundred meters, and I was going to
run calculations for scaled depth of burial purposes.</p>

<p class="tab">There, the CEP played an
important role for the wrong reasons. The whole thing was serendipitous. It was
really that way. The material properties, for up on the Pahute, came right in
the center to about everything we've looked at in past experience. And the logs
were straight as a board. We didn't see any reflections for two hundred meters.
It just looked marvelous.</p>

<p class="tab">So, I didn't see any problem with
the shot. The one thing I did see was, "Gee, the drilling rates for that
last two hundred meters look kind of slow." I hadn't seen anything that
looked quite like that, but we've had experiences in hard layers here and there
and all over the place, and the geology for the Molbo event was like that for
quite a ways, and there was no problem there. And so I just tossed it off.
"There's no problem with this shot."</p>

<p class="tab">Another factor that was important
here was that to exercise our ability to measure core samples we went in and
took some core samples and measured them in the laboratory. But as a test, before
we got the answers back, they said, "John Rambo, we want you to make an
estimate of what you think the strength is of this rock." Well, I looked
at one version, which was the Butkovich model, which gives you default values
of strength, and I looked at that. I looked at a nearby shot called Hardin,
where we had samples that were measured, and I looked at the Hardin cavity
radius, from which I could back-calculate strengths. I looked a little bit at
the drilling rates, because I had some ideas about what they tell you. Well, I increased
the strength quite a bit from the default values that you would get from
Butkovich's model, which takes average properties. I came up with a value that
was about half of what the measured values were from the laboratory measurements.
That rock was much stronger than I'd estimated.</p>

<p class="tab">Later on I had some DNA
calculators estimate it, and they said, "Yeah, that's about what we would
have estimated too," meaning their estimates would have looked like my
estimates. We looked at the inside of the hole with the movie log, and it
looked like it was uniform stuff all the way up. We didn't see any cracks, we
didn't see anything but uniform material. But, above that layer there was a
layer with a lot of gas porosity. We took samples out of that layer, and you
could break them apart in your hand.</p>

<p class="tab">So I ran the first calculation. A
big shockwave goes up, traveling in almost fully saturated material up to this
two hundred meter level in hard rock. Then it comes to this layer of very weak rock.
Lo and behold! An enormous reflection comes back. In the calculation, just as
the rock tries to hit rebound, or to set up the residual stress field, the
reflection caused motion which unloaded the residual stress field around the
cavity. I just didn't expect that. This calculation looked bad. It had three
hundred bars of cavity pressure, and almost nothing outside of it. I had never
seen a calculation show something as bad as that.</p>

<p class="tab">So, the next object was what we
could do to try to save this shot. They said, "Nothing is going to
happen." I said, "Well, I'm not sure you could even contain the gases
getting up into the stemming column on this." So they said, "Oh, all
right," and went back and measured down below the shot, where we thought
there was weaker rock, because the drilling rates were higher. And sure enough
it was weaker. I put this new model into the calculation, and yes, that helped
reduce the cavity pressure in the calculation about to the point where it was
equal or about the same level as the residual stress. That made me a little
happier, except that when you went to lower yields the effect of this weak
material below the shot point started to go away.</p>

<p class="tab">So, I knew all this, and I went
down to the CEP, prepared to present it to the Panel, if necessary. I thought
we ought to be able to contain this thing because it was right on the edge, and
besides, nobody on the Panel believes in calculations. I came down with about
six notebooks full of viewgraphs to present in case somebody wanted to get into
the subject. The rest is history. Dr. Brownlee said, “Calculations don't make
any difference." Fred App was starting to get interested in the subject,
but he was sort of swept away by Brownlee's strong statement. I was sitting
there with my mouth open, thinking, “Boy, did I get through this one
easy."</p>

<p class="tab">But I was still quite worried
about what might happen, because in my calculational experience I had never
seen anything quite like it. On the other side of the slate, we had all the
experience of high yield events that had never shown any problems. I even went
over and calculated a nearby event, called Lockney. I didn't have any measurements,
but I tried to back-calculate from the cavity radius and the drilling rates. It
didn't look good either, but it was very, very sensitive to minor changes in
strength. That was what was interesting about this whole thing. We didn't
appreciate how, with high strength you can get these enormous changes in
residual stress for slightly different properties. It comes and goes with very
minor differences in the strength, and it can be catastrophic if you hit the right
combination of timing and of reflections.</p>

<p class="tab">As I said, Lockney showed poor
residual stress also. But it contained. Lockney had something like five percent
water content, and Fred App has calculated other events where he says, “You know,
the calculations look pretty bad up there on Pahute, but there's still this
very low water content that they're shooting in." And so, I thought at the
time that maybe they were right. Maybe containment calculations don't make any
difference on high yield shots. Maybe you can shoot anywhere, in any material,
and who cares. So that did affect my thinking on Barnwell.</p>

<p class="tab">So, I was concerned already, and
then about ten minutes before shot time the device physicist came up, and
remember that this thing gets worse as you go to lower yields, and he said, “By
the way, I just did another calculation. You'll be pleased to know the yield
has gone down." It wasn't more than about twenty minutes later that I saw all
this radiation going up through the stemming column, up to the last plug. I
think we came very close on Barnwell, and the calculations certainly pointed in
that direction.</p>


<a name="ch20"></a>
<br><br>
<h2>Chapter 20: Current Practice</h2>
<br>

<p class="tab">Over the years the Laboratories
have developed certain practices for the conduct of nuclear operations at the
Test Site, including those which relate to containment. After all the
theorizing, the designing, the calculating and the planning has been done it is
the people in the field who do those things that make the reality of a nuclear
event.</p>

<p class="tab">From the earliest days of nuclear
test work it was recognized that a field operation was a very complex
undertaking. Leaving aside the many organizations that were involved in
planning, building, providing, and operating the necessary support functions,
there was the need to coordinate the activities of the Laboratory people themselves.
The Test Directors were the people who had the ultimate responsibility to see
that the plans for a particular event were carried out. They served as the
authority, at the Site, for the work that was to be done, and that would be
done for an event sponsored by their organization. There were several
interfaces to be managed; those between the Test Site management, the various support
contractors, the Laboratory management, and a multitude of Laboratory people,
each with a strong interest in having their experiment taken care of first.
Meeting the containment requirements was just another part of the job. How
these things are done has changed over the years.</p>

<p class="tab">The responsibility for the
direction of the Livermore field program is shared by two Test Directors.</p>

<br>

<p class="tab"><b>Carothers</b>: What does a Livermore Test Director do?</p>

<p class="tab"><b>Page</b>: That's a big question. I
consider the Test Director, foremost, to be an operations manager for a large
field project. A big part of the responsibility has to do with safety.</p>

<p class="tab"><b>Carothers</b>: Does it include the things related to containment?</p>

<p class="tab"><b>Page</b>: That's a part of it, but the
real focus on that belongs to the containment group. But since the Test
Director is the man responsible, on the spot, he essentially owns all of those
aspects, to first order, from nuclear safety to containment to industrial
safety.</p>

<p class="tab"><b>Roth</b>: You pick up an event somewhere
in its definition stage, and actual production stage. When the event becomes
active in the field, the Test Director becomes the lead man in charge of it at
that point in time. He picks up that responsibility from a project physicist,
who shepherds it from its inception to the point where it's going to the field.
I concern myself, first of all, with getting the fielding done, making sure the
facilities are available for the canisters and experiments that have to be
fielded, coordinating the craft support to carry that out, determining the safety
and security requirements of classified gear in the field.</p>

<p class="tab"><b>Carothers</b>: Let me start with industrial
safety. When do you become responsible for that? I would think REECO, for
instance, would do that.</p>

<p class="tab"><b>Page</b>: There a couple of aspects to
that, but the Test Director assumes ES&amp;H coordination responsibility from
the DOE for the shot site at a certain time. It's a formal transition of
responsibility. Up until that time NVO had assigned that to REECO, and so REECO
had that responsibility. When that transition happens, then the Laboratory gets
it, and the Test Director is the person who assumes that responsibility. What
that means is that he is responsible for the coordination of the activities at
the shot site to assure that they're done safely, that all the independent
contractors know what's going on, and that they know what the other people are
doing. He has the responsibility to make sure there is a well-coordinated
operation. Of course, each contractor is responsible to assure that their
people know their jobs, and that they do them safely. But the contractors take
their direction from the Laboratory, and then they apply their methods to get
the job done.</p>

<p class="tab">The craft support is
all through the contractors. REECO provides the crafts we need. For security,
we call heavily on Wackenhut to do the guard duty we require. We determine the requirements
and we lay those requirements on those people, and they, hopefully, carry them
out, and we oversee that they are carried out to our specifications.</p>

<p class="tab">As things progress I
become very busy in overseeing the emplacement of the canister in the hole - the
handling of the cables, the operation of the cranes, all the necessary
activities that go along with the carrying out of the event. Also, I oversee
the stemming and containment requirements, making sure that the materials that
are put in directly around the canister and around the bomb itself meet the
required specifications, and that the various plugs, and the gas blocks are
properly installed. There are a myriad of details like that.</p>

<p class="tab"><b>Roth</b>: The legality of it is that the
Test Director is in charge, but of course, it's a cooperative effort with a lot
people involved, and you listen to what they have to say.</p>

<p class="tab"><b>Carothers</b>: Let us say the device has been
delivered. Inside that fence is the Laboratory's area, your area, isn't it?</p>

<p class="tab"><b>Roth</b>: That's right. You're talking
about a safety and security issue now, but at a point in time, which I normally
define as a significant Laboratory presence and activity, that's when I legally
take responsibility for that site from DOE. Basically that's when the diagnostic
canister first comes out to the site and gets installed in the tower, and
significant work and activity goes on in finalizing the experiments. That's
inside the perimeter fence, of course.</p>

<p class="tab">That is not normally
the time when security is on the site. Security is usually not established
until significant classified material comes on the site. In some cases there
won't be any classified material in the tower where they're installing
diagnostic equipment, depending on what kind of event it is. So, it could be as
late as a day or two before the full power dry runs before we establish security
on the site. And full power is typically a few days before device delivery. But
from that point in time we have a secured site, where you have guards on a
twenty-four hour basis, making sure only authorized people are allowed access
to the site.</p>

<p class="tab"><b>Carothers</b>: You said that you legally take
over the responsibility for that area inside that perimeter fence. That means you
have the responsibility for the actions of the contractors' people?</p>

<p class="tab"><b>Roth</b>: We interface with those people
through a group at the Test Site which used to be called the Engineering and
Construction group, but that has been recently changed to C&amp;DE; Construction
and Drilling Engineering. They actually do the interfacing with the contractors.
They give the requirements for the number of carpenters, and wiremen, and so
forth that will be needed on a particular day. They interface with the craft
people, with REECO, on a day to day basis. And they essentially report to me,
from the standpoint of getting instructions about when we need the tower up, or
what we need there, or where we need a work station, and so on. And, they
implement those instructions. So, I don't deal directly with the crafts, but
they are reacting to my requirements.</p>

<p class="tab">I'm responsible for
safety, and security, ultimately. That again is a delegated effort; I can't be
in every location at every point in time. You have to depend on a lot of people
to uphold those requirements. But ultimately it rests on me.</p>

<p class="tab"><b>Carothers</b>: Usually only when something
goes wrong. Then it's suddenly, "Well, Bernie's the guy in charge. Go see him."</p>

<p class="tab"><b>Roth</b>: That's right. They never say
that when everything is going smoothly. When something goes wrong, everybody's
willing to admit I'm responsible.</p>

<p class="tab"><b>Carothers</b>: Do you get involved in the site selection?</p>

<p class="tab"><b>Page</b>: No. Only to the extent that the
site meets the needs of the field operation, and will allow us to do the
experiment we want to do. It has to be the right depth, it has to be the right
diameter, it has to have enough room for the trailer park. Ground motion is a
big issue, and you don't want the hole located where there could be damage to
some facility.</p>

<p class="tab"><b>Roth</b>: Somebody says, "We have a
device here of X yield, and we need a hole to accommodate it." That falls
into the containment area, and they say, "Oh yeah, we have holes A, B, C,
D. Then they look at the yield, and the device, and determine the depth of
burial that's required, and they say, "Well, this is the hole it should go
in." If there are unique requirements for some reason we may suggest differently,
but basically that's how it happens.</p>

<p class="tab">I don't say where a
new hole should be drilled. The geology - people and the Test Site people make
that decision. But we have kept a running cognizance of what holes are
available, and as a drill rig becomes available we might say, "We need
another high yield hole on Pahute someplace, so give us a high yield
hole." Then we coordinate that with other activities to see that we're not
a half mile away from another high yield event that could go off in the same time
period. But the specific location and coordinates are not my choice. That's the
geologists.</p>

<p class="tab"><b>Carothers</b>: Jack, as the Los Alamos Containment
Program Manager, what interaction do you have with the J-6 field operations people?
Do they work for you, or are they a separate organization?</p>

<p class="tab"><b>House</b>: They are separate and apart.
First of all, they are in a different division. A[though containment is in the
Environmental and Earth Sciences Division, we work for J Division. I consider
Jay Norman, the J Division Leader and Program Director for Test, to be my
technical boss. Field operations, J-6, are people we work hand in hand with
from the very first definition of an event, when we have to go pick a hole.</p>

<p class="tab"><b>Carothers</b>: Who selects the site for a new emplacement hole?</p>

<p class="tab"><b>House</b>: I do that. I and a colleague in
J-6 work hand in glove on the site selection; where are we going to drill the
hole, and how deep are we going to drill it, and so on. I may have picked a set
of coordinates on the NTS map that, when the field operations folks actually go
out with the surveyors to drive a stake, they find is in an arroyo, or is near
a power line, or what have you. So, there is a lot of interaction with the J-6
people. Those guys do not work for us; we work together. They also take our
containment criteria and develop a relatively standard and basic stemming plan
for each and every event.</p>

<p class="tab"><b>Carothers</b>: Jack, you always have the same stemming plan.</p>

<p class="tab"><b>House</b>: Well yes, more or less. It's
got the same basic ingredients. It's got alternating layers of coarse and fines
material. And it's got a grout plug here, and two TPE plugs there, but the locations
of those are specified by the containment scientist, and his or her event team.
J-6 merely translates their requirements into a blue-line drawing, which
ultimately goes to the field for execution.</p>

<br>
<p class="tab">Among other differences in the
way Livermore and Los Alamos conduct their field operations is the manner in
which they lower the device and diagnostics hardware down hole. Los Alamos uses
wire-rope harnesses, Livermore uses drill pipe. The origins of the difference
seem to be lost in the past.</p>
<br>

<p class="tab"><b>House</b>: If there are valid reasons for
the difference, I am not aware of them. I do understand that Livermore is able,
on drill pipe, to put a much heavier package down hole than Los Alamos can,
even on a four wire-rope harness. We started in the early days just using two
wire-rope harnesses. And, as the diagnostic packages got larger, and longer,
and heavier, obviously the capability to lower larger packages became
necessary, and they added more wire-ropes. There are now two, three, and four
rope configurations they use, depending on the size and weight of the package.
But as far as how the difference between the two Laboratories as to drill pipe
versus wire-rope came about, I don't have the vaguest idea.</p>

<p class="tab">In the Test
Operations Review Team activities, which has since turned into an effort that
is known as the Joint Test Organization, which has the aim of combining
Livermore and Los Alamos resources at the Test Site, there has been a
consideration of using one system or the other. Interestingly enough, long and
hard as it has been studied, I think the ultimate resolution was, "Well,
Los Alamos will stay with wire-rope harnesses unless we get a package that is
just absolutely too big, and then we'll do it using the Livermore system."
So, it's still unresolved.</p>

<p class="tab"><b>Carothers</b>: Perhaps you know, Bernie. Livermore
emplaces the device and diagnostic hardware using drill pipe. Los Alamos uses
wire-rope. Why is there a difference? I'm sure you think drill pipe is better.
Is it really, or is it just another difference between practices of the
Laboratories?</p>

<p class="tab"><b>Roth</b>: Those preferences were
developed before I became really established in the program. I remember seeing
one or two of our events put down on flat wire rope. That was still in the developmental,
or experimental stage at that time. Before I got fully on board that was put
aside and everything was done on drill pipe after that.</p>

<p class="tab">So, I grew up with
drill pipe. One reason for it that I'm aware of is that drill pipe has a much
higher weight capacity for putting down a package than a wire-rope set. It's
been developed over the years to where we can put a million or more pounds down
hole, and we have done that on a few occasions. The one event that comes to
mind was Flax, and if I remember the number right we were looking at a 940,000
to 960,000 pound load. Los Alamos has gone from one cable to two cables to four
cables, but I think even their four cable capacity does not equal our heavier
drill pipe capacity .</p>

<p class="tab"><b>Page</b>: I can't answer the question of
why we first started using drill pipe, but the reason we like using it today is
that drill pipe offers a heavy load carrying capability. We believe the joining
method is reliable, and it's something we can test. And, we've had good luck with
it.</p>

<p class="tab"><b>Carothers</b>: What do you mean when you say
it's something you can test? Do you pull test all those joints?</p>

<p class="tab"><b>Page</b>: Yes we do. Of course, then we have to unmake them .</p>

<p class="tab"><b>Roth</b>: There's a very strict quality
control program involved in all of that. The pipes are first of all threaded
and inspected, and then pull tested to some 125 or 150% of what the working
load is expected to be. They are then very carefully maintained from that point
on to see that they aren't damaged in any way, even to the extent of seeing
that somebody doesn't sabotage one of them. They're brought to the event site,
put into an enclosed area, and maintained there until they're used. The
threading operation itself has a quality control on it, in that the pipe joint
makeup has to fit within certain tolerances. The threaded joints are marked
with a small diamond, so they have to thread up into some portion of that diamond.
Going too far or too short is not acceptable. So, we have very good assurance
when we go to lift that load that joint is going to be good, and that pipe is
going to be good. And it's special metal. It's not necessarily old D-36 steel;
it's API pipe.</p>

<p class="tab"><b>Carothers</b>: Do you have to use a drill rig to put the device down?</p>

<p class="tab"><b>Page</b>: No. You can use a drill rig,
but the emplacement machine can be a crane, sub-base, and a stabbing tower. The
sub-base is a working platform that allows us to tie off the load when we let
go of it with the crane. The process works pretty well, and it's reasonably
fast.</p>

<p class="tab"><b>Roth</b>: The crane actually holds the
load, and lowers it pipe section by pipe section. And we use ancillary cranes
that feed the pipe up to the stabbing tower. The drillers thread it in, the
main crane picks up the load, releases it from the grips, and lowers it down.
People underneath the sub-base tie on the cables and put on the experiments
that go on the pipe.</p>

<p class="tab"><b>Carothers</b>: Once it's in place, you have to fill the center of that pipe.</p>

<p class="tab"><b>Roth</b>: Yes, but that's relatively easy. We just grout it up.</p>

<p class="tab">There is a stemming
plan for the hole that we adhere to that's defined, and reviewed, and accepted
prior to the time we actually carry it out. That involves perhaps a half dozen
different types of material. Boron rich material might be emplaced around the
device itself, for neutron shielding. Above that, depending on what the diagnostic
requirements are, we have overton sand, or perhaps magnetite, perhaps sometimes
a mix for neutron shielding. Once above the canister, generally it winds down
to a sand, gravel, and eventually a plug configuration.</p>

<br>
<p><i>Gas Blocks and Fanouts</i></p>
<br>

<p class="tab"><b>Carothers</b>: Who at Los Alamos designs cable fanouts and cable gas blocks?</p>

<p class="tab"><b>House</b>: The field engineering folks do
that, and then they bring the design to the containment group for review. We
have specs, and both Los Alamos and Livermore use the same specs for field installed,
or discrete, gas blocks. While the two Laboratories' field installed gas blocks
are of slightly different design, they are the same end product, in essence, in
what they are designed to do, and the pressures they are designed to meet, and
so forth. But the containment program does not design the gas blocks. They endorse
the specifications, such as the need to have a 125 psi gas block for this
particular function, and so on.</p>

<p class="tab">The fiber optic
cables are supposed to be continually gas blocked, and if they don't meet the
pressure test that's done on each and every cable, then you've got to strip the
coating back to the fibers and discretely gas block them.</p>

<p class="tab"><b>Carothers</b>: Let's say you have a reel of
fiber optic cable. You cut off ten feet don't you, and test that? What if it
doesn't meet that test?</p>

<p class="tab"><b>House</b>: Then you don't use that reel,
or you put a discrete gas block in the run. You put the blocks in at the
standard locations where you have designated gas blocks for the multi-conductor
cable. In our particular geometries there are typically three places, one in
each of the rigid plugs, where gas blocks are placed.</p>

<p class="tab"><b>Carothers</b>: What's your experience with the
fiber optic cables? Do many of them fail your pressure test?</p>

<p class="tab"><b>House</b>: It's probably about thirty
percent that fail, that leak enough so they don't meet the specs. They are
supposed to come from the factory, by design, as continually gas blocked fiber
optic cables. But, when they sit in the Nevada desert sun, or lie out in a cable
way before they've been terminated, there's a degradation that takes place. It
in many cases causes the cable not to pass the test, and then you've got to go
in and discretely gas block them.</p>

<p class="tab">The fiber optic cable
is a very small diameter cable - maybe a 112 inch outside diameter, which of
course includes the sheath and the protective jacket, and so on. By the time
you get down to the potential flow path for gas up one of those cables, it's
very small. It's hard to envision gas being driven very far up one of those
fiber optic cables, but we gas block them because that's the way we do it.
Conservatism is perhaps our most important product.</p>

<p class="tab"><b>Carothers</b>: Well, coax cables used to leak
gases to the surface. Gases were forced a long way through them - a thousand
feet or more. You look at the cable, and you wonder how you could possibly push
gas through it, but there is plenty of evidence that it happens.</p>

<p class="tab"><b>House</b>: The factory gas-blocked coax
works very, very well. I don't have any numbers in my head about failure rate,
but it is very low. Coax is good stuff. In terms of our field, or discrete, gas
blocks that are installed in the multi-conductor cables, both Laboratories' cable
gas blocks work very well. They're not a problem.</p>

<p class="tab"><b>Carothers</b>: Who makes the discrete gas
blocks Livermore uses?</p>

<p class="tab"><b>Roth</b>: They're made on site. That
process was developed over the years. The weather coating is stripped off and the outer jacket is
cut down to the electrical conductors. That section of the cable is placed
in a plastic mold, and an epoxy material is pumped into that mold from one end,
and out the other. That epoxy material hardens and encapsulates the conductors
and the shielding material.</p>

<p class="tab"><b>Page</b>: There are specifications as to
how it's done, what the materials are, and what the criteria are for a good gas
block. That process is managed by the construction engineering people. The containment
people specify where they go, and have the responsibility for seeing that
they're in the right place with respect to the formation and the location of
the plugs.</p>

<p class="tab"><b>Carothers</b>: If you look at the containment
history, before Baneberry lots of the shots seeped material through the cables,
or through the stemming. Since Baneberry, that just doesn't happen anymore. I
think that is a tribute to the people in the field who concern themselves with
the stemming, and the cables, and the gas blocks, and so on. People from the
Laboratories come to the CEP and say, "Well, we're going to use these gas
blocks and this stemming," and the CEP people say, 1I0h, fine, that's good."</p>

<p class="tab">Making those
statements good really depends on somebody out there in the dust and the gravel
and the sun, or the rain and the wind doing that stuff right. And the record is
that they haven't missed once, on lots and lots of shots, and on thousands of
cables. A whole bunch of hot, dusty, sweaty, or maybe wet, cold people deserve
a pat on the back for that.</p>

<p class="tab"><b>Roth</b>: Yes. For a number of years we
did that discrete gas blocking right out in the cable ways, in whatever the
weather was, and built tents over the stations. In the present day, as much as possible
we try to do that back in the cable yard, under a more controlled environment,
and with better conditions. What that means is pre-cutting cables, and
pre-locating those gas blocks so they fall in the plugs in the right places,
and that works out very well. That alleviates some of the labor involved in
discrete gas blocking, but it's still not a trivial kind of task. As much as
possible we try to do it away from the shot area, but there are still
occasionally late-time requirements where it has to be done out in the field.</p>

<p class="tab"><b>Carothers</b>: Byron, “out in the field"
for DNA is in a tunnel. What's your experience with leaks from cables? Is it an
easier problem?</p>

<p class="tab"><b>Ristvet</b>: I like to point with pride
that, with the exception of Diamond Fortune, which I predicted would probably
seep into the tunnel through the medium at late times, we've not had one atom into
the tunnel on anything I designed. That's in part because I changed our gas
blocking schemes on the cables. I think the cables were allowing gas to get a
long way down the stemming column. With a low yield you just don't smash the
cables hard enough to prevent them from being a pathway. We know we get
communication through the stemming itself to the FAC. And then we have all the
cables wide open, because when the FAC detonates, it just cuts all those cables. We saw that on reentry. So
now all the multiconductor firing cables are sitting there wide open, and they
go all the way back to the TAPS area and near the end of stemming. And you know
how it is with radioactive gas; if there's any possible pathway, it will find
it.</p>

<p class="tab"><b>Carothers</b>: A thing that is a little
surprising is to calculate the volume of that radioactive gas that's bothering
you so much. It's a few cubic centimeters, or even less.</p>

<p class="tab"><b>Ristvet</b>: I'll give you a good example.
On Disko Elm we had to describe to the Admiral, the Secretary of Energy
himself, that we did not have a major containment failure. We saw activity that
came down via the cables, then back into the LOS pipe on the wrong side of the
gas blocks. How much was it? It was four curies, maximum, of zenon and a little
bit of krypton 85. It was almost all zenon, and the volume turned out to be
nine microliters. That is a very small amount.</p>

<p class="tab"><b>Carothers</b>: Aren't you proud of those
people who develop the monitoring instruments? They sure do a good job, don't they?</p>

<p class="tab"><b>Ristvet</b>: They are fantastic. They have
to use cyrogenic traps to actually collect it, and pump millions of cubic
meters of air through the traps, but they can get it .</p>

<p class="tab"><b>Carothers</b>: And they can measure how much there is.</p>

<p class="tab"><b>Ristvet</b>: That's exactly correct. And
every time they measure a little bit better the standard goes down.</p>

<p class="tab">Disko Elm was the
last time we saw anything flow down the pipe, and that's when we realized - in
fact I caught it in the middle of Distant Zenith - that we weren't separating
our cables like we used to. We were using predominately Livermore devices, and Livermore
likes to use this four conductor Number 2 for the firing cables. That is an
unbelievable leaker, because not only does the jacket have lots of holes in it,
but it is a stranded cable. It's a great power cable, and of course, that's
exactly what it's used for - for charging up the x-units. But we tested it, and
I think the permeability was two or three darcys over a hundred foot length.
So, you could imagine it's just a conduit. But, it works real well once you separate
the strands. You do that and you cut it down at least into the millidarcy
range. You don't even have to take the insulation off.</p>

<p class="tab"><b>Carothers</b>: There used to be some people at
the Livermore Laboratory who were very touchy about their firing cables,
because they had some experiences they didn't like very much. I'm surprised
they let you mess with their firing cables.</p>

<p class="tab"><b>Ristvet</b>: Well, I talked it over at
length with Mr. Ray Peabody et al, who do Livermore's firing, and Ray and Mike
Bockas stood and watched every step that was done. And they were there even
when we did the same thing on other shots in the same way. When we did it on
the Los Alamos device, Everett Holmes and crew stood there and just watched
everything that was done, and assured themselves that everything would be okay.</p>

<p class="tab"><b>Carothers</b>: It's called attention to
detail. Joe LaComb would have smiled and nodded approvingly.</p>

<p class="tab"><b>Ristvet</b>: That's certainly right. I can
understand the sensitivity. I can remember one DNA shot where we were down to
the last set of firing cables because we had a little water getting into the
RTV boxes. And the thought of retrieving a live nuclear device on a reentry
does not appeal to me. We've thought about it many times though, and we actually
have a contingency plan for such.</p>

<br>
<p><i>Plugs</i></p>
<br>

<p class="tab"><b>Page</b>: Was coal-tar epoxy the first material Livermore used for plugs?</p>

<p class="tab"><b>Carothers</b>: They used concrete plugs on a
few shots, but they weren't very enthusiastic about those after they lost the
cables on Duryea because somebody forgot about the exotherm when the concrete
set up. The cable insulation softened, or melted, and all the cables shorted
out. Including the firing cables. It's actually quite embarrassing not to be
able to communicate with the device. A lot of people get very upset about that.</p>

<p class="tab"><b>Page</b>: That would be a Test Director's nightmare.</p>

<p class="tab"><b>Roth</b>: Emplacing the coal-tar epoxy
mix was an attempt to solve the exotherm problem you can have with concrete,
and still get a rapidly setting up plug. And, it was an attempt to get a
tighter seal. All those kinds of things drove the development of that material.</p>

<p class="tab"><b>Carothers</b>: I've never talked to a person who liked coal-tar epoxy plugs.</p>

<p class="tab"><b>Roth</b>: They were smelly, they were
carcinogenic, and they were messy. If you got some of that stuff on you, you
couldn't get it off. It was gooey, sloppy stuff that ruined your clothing, and
it was difficult to put in place, but for years we did that.</p>

<p class="tab"><b>Page</b>: It was miserable stuff. It was
just terrible stuff to deal with, to be in direct contact with. It was put
together in transit trucks, and it was difficult to control the mix. The
coal-tar was just dumped in the hole, along with the gavel, and you were never certain
where the coal-tar and the gravel ended up. We made some of those plugs in surface
casings, and when we pulled them out, cut them apart and looked at them, the
uniformity through the plug never did look good to me. I think they just
depended on the fact that there was a lot of it there to give something that
was going to do the job. I think we did ourselves a big favor when we got rid
of that.</p>

<p class="tab"><b>Carothers</b>: There were several components
to those plugs; the coal-tar, the epoxy, the hardener, and all that had to be
mixed together.</p>

<p class="tab"><b>Page</b>: That's right. In fact, we
usually had a chemist, Phil Fleming, be there when we were putting those plugs
in. That's more precision work than you ought to have in the field. Another
thing that people have said is that the coal-tar was a carcinogenic substance,
and people working with it were required to wear protective clothing - lab
coats and gloves and boots.</p>

<p class="tab"><b>Roth</b>: When the gravel and the
coal-tar got down there, there was a tendency for the gravel to settle out, and
maybe the coal-tar epoxy flowed a little bit. Hopefully it flowed into the
interstices of the gravel, but maybe the gravel built up preferentially on one
side of the hole. We couldn't know that, but the plugs were thick enough that
we thought we had adequate containment.</p>

<p class="tab"><b>Carothers</b>: After the coal-tar epoxy plugs
Livermore went to two-part epoxy plugs for a while. Los Alamos still uses them.
What did you think about those plugs? Why did you give them up?</p>

<p class="tab"><b>Page</b>: I don't remember much about
that stuff, but I don't think it was a whole lot different from the coal-tar,
myself. Take the requirements on quality control. Here we had two different products
that came in from different vendors. Both had to be stored properly, and we
built a special facility for them. You always worried about running out of one
or the other material at a bad time. And, it had to be blended properly, and it
had to get to the hole in a timely manner, because it came from the mixing
plant, near the shaker plant, which is a ways away. It might have been a little
better product than the CTE in terms of uniformity in the kind of plug it produced,
but it still was a difficult thing to work with.</p>

<p class="tab"><b>Roth</b>: So, a few years ago we went to
the sanded gypsum plugs. That's a cement, sand, and gypsum mixture that has
good qualities with respect to expansion or shrinkage. It's mixed on the
surface, so we know it's a homogeneous mixture, and when it gets down in the
hole it flows very well. Its qualities are such that it can be emplaced without
an exotherm that is higher than the cables or experiments close to it can
stand, and in special circumstances we can mix it with chilled water. A big
attribute of the sanded gypsum for a Test Director is that we don't have to
wait for it to set up. We can put it in the hole, and within a half hour to
forty-five minutes it's hard, and we're ready to continue stemming. By the time
you get the pipe extracted and the equipment cleaned up it's hard, and we can
continue the stemming operation. From a cost standpoint it's a fairly expensive
material, but so was the coal-tar epoxy.</p>

<p class="tab"><b>Carothers</b>: What makes it expensive?</p>

<p class="tab"><b>Roth</b>: I'm not sure. Perhaps the
gypsum. The equipment to mix it and pump it not commonly used. It's not a
transit mix truck. It's a batch mixing operation where they pneumatically blow
the gypsum into a mixture of water and sand, and tumble that. Eventually it
gets pumped out, over to the hole and down a tremmi pipe. We've had cameras
down there, and it comes squirting out quite violently down at the bottom. It's
a good material, but it is expensive compared to concrete.</p>

<p class="tab"><b>Page</b>: It seems to form a nice
product, and when it's set it's got a strength of about 3,000 psi. And we think
it's fairly compliant when it's hit with high ground motion.</p>

<br>
<p><i>The Role of the Containment Groups</i></p>
<br>

<p class="tab"><b>Carothers</b>: Jack, how much authority does
your containment team have with respect to their event?</p>

<p class="tab"><b>House</b>: When I assign the containment
scientist the responsibility for an event it also includes a team of - and it
may be a mix, or one person might be wearing two hats - typically a geologist,
a geophysicist, and a phenomenologist. If you take the Icecap event, for
example, Nancy Marusak was the containment scientist, and she was also the
geologist. Mark Mathews was the geophysicist, and Tom Kunkle did the
phenomenology work. That was the event team for that particular activity.</p>

<p class="tab">Once the containment
scientist has the assignment, she and her team have the responsibility, and the
authority, to do the event design. Now I, as part of the team as a sort of
ex-officio member, have the purview to look over their shoulders, as it were.
When we go to a peer review of the containment design, the principals in the containment
program at our Laboratory that we consider as primarily the containment
scientists, and the two CEP members, have every right and privilege to take pot
shots at it and pick it apart.</p>

<p class="tab"><b>Carothers</b>: Can the containment scientist
specify what logs she wants? Can she have them rerun if she doesn't like the
quality of the ones she gets?</p>

<p class="tab"><b>House</b>: You betcha. She also negotiates
if necessary with the field operations, the J-6 guys, if they want to
reposition a plug so it fits a particular harness connection scheme; they work
that out together. The event team is pretty much autonomous; they certainly
have the responsibility and the authority to get or take what is needed to
successfully design and/or complete the event.</p>

<p class="tab"><b>Carothers</b>: Do they specify the locations
of the plugs and the plug materials?</p>

<p class="tab"><b>House</b>: They do locate the plugs. The
plug material, if we are considering the rigid plugs, would be the grout and
the two-part epoxy. For instance, again considering Icecap, we had three rigid plugs.
One of them was HPNS-5 grout, or Husky Pup Neat Slurry, and two of them were
two-part epoxy. We worked hand in glove with the field operations people,J-6,
in getting this new to us HPNS-5 mix. It was designed for Los Alamos by the
Waterways Experiment Station folks, who are the grout experts.</p>

<p class="tab"><b>Carothers</b>: What else does the containment scientist have to do?</p>

<p class="tab"><b>House</b>: Well, containment is his or her
total responsibility. Once the site is selected, then next thing we have to
produce is what we call the containment criteria memo. That defines the plug locations,
the types of plugs and material, and of course the working point depth, or
depths if it happens to be a multiple, where the radiation and pressure
monitors, typically known as RAMS, will go, and how many there will be. The
only thing the containment scientist does not specify with regard to the down
hole stemming plan is the amount of magnetite. That is defined by the
experimenter. We, so to speak, take it from there.</p>

<p class="tab">We have recently been
required to, essentially, develop stemming plans for underneath the device. We
at Los Alamos in particular have had holes that were deep enough to require
that. There was one in Area 3 for a shot called Laredo, which was deep enough
that it actually intersected the Paleozoic rocks. The environmental folks have
come on the scene and said, “Gee, you've got to do something about that. You
have a potentially preferential path for contamination to go down hole."
We said, “My gosh. We've just thought about stuff going up. We don't care if it
goes down hole, do we?" “Well, you better start thinking about that, because
we care about it. And, we carry a pretty big club, us folks at environmental
restoration." Or the Earthworms, as they are so fondly known. So, we have
specifications for the downwards stemming now.</p>

<p class="tab"><b>Carothers</b>: If the Livermore containment
people wanted some logs run, would they go through you?</p>

<p class="tab"><b>Roth</b>: Not normally. They have their
own support at the Test Site, and they pretty much determine what's required to
carry out the containment plan; what information is required to present to the CEP.
They would go directly and say they need a gamma log, for example.</p>

<p class="tab"><b>Carothers</b>: These logging requirements
occur certainly well in advance of when the device gets there, don't they?</p>

<p class="tab"><b>Roth</b>: Oh yes. It may be as much as a
year in advance. That information is accumulated and analyzed by the
containment scientist. It is documented, and eventually there is a report, or
an input document, that is presented to the CEP for their review.</p>

<p class="tab"><b>Carothers</b>: When you start to put the
system down hole, who supervises that?</p>

<p class="tab"><b>Page</b>: Well, the Test Director owns
that operation. He has a project group that works on accomplishing it. The
device systems engineer has primary responsibility for the early part of the
emplacement - getting the device package prepared, moved to the hole, and
inserted. The Test Director's right hand operational guy is again a
construction engineer, because he's the interface with the contractors. We
always have a plan as to how we're going to do the work, and the implementation
of that plan is generally managed between those two engineers, with the Test
Director serving in an oversight role.</p>

<p class="tab"><b>Carothers</b>: Once upon a time, and I don't
mean this in a derogatory way to your colleagues at Los Alamos, they were
putting a device down hole and they didn't put in a cable fanout that was called
for. How can you forget a fanout? That's a big thing, and it takes some time to
do during the down hole operation.</p>

<p class="tab"><b>Page</b>: What can I say? It happens.
Lack of attention to detail, poor criteria, whatever. You hope you have enough
checks and balances so things like that don't happen. We depend on Raytheon, for
example, to keep tabs of everything that happens and everything that goes into
the hole. They're generally successful, but if they have a bad design drawing,
and the requirement is somehow missed on that drawing, they would miss it.
We're supposed to have enough checks and balances so those things don't happen.</p>

<p class="tab">There are a lot of
things like that, that can keep a Test Director awake at night. There are a lot
of things to worry about, because those operations are complex operations.</p>

<p class="tab"><b>Carothers</b>: Okay, the device and the
diagnostics packages are down hole. Now you have to do the stemming. Who does
the stemming? Who says, "Okay, the gravel goes here, and there is where
the plugs go," and all that?</p>

<p class="tab"><b>Page</b>: The containment program people
have the responsibility for designing a competent stemming plan. But, you're
right, somebody has to do it, and that's an interesting situation, in a sense. I
think the containment group has the philosophy, and I think they have had this
for a long time, that they need to maintain a presence at the hole during that
operation to assure that the job has been done right. Now, there's been a lot
of discussion that it is a field operation, and the construction engineer can
do that job just fine. I could argue that one either way, but in my opinion the
way that it is done these days is through oversight by the containment engineering
group. The actual operation is directed by the construction engineer, but the
presence of the containment engineer is the element that assures that the
containment packages are installed properly. That's the way I see it.</p>

<p class="tab">There is another
element that supports doing the stemming right. That is the Raytheon Services
Nevada role. Their job is inspection and verification. They're given a very
detailed design package that includes all of the specifications for all of the
features that are supposed to go into the hole. There is a gravel
specification, there's moisture criteria. There are a lot of elevation features
they keep track of, such as where the fanouts are, where the gas blocks are,
where the bottom gas block is, where the top gas block is in each fanout, where
the elevations stop when you change materials, where the bottom of the plug is,
where the top of the plug is. All those features are called out. Many of them
are measured at the hole, and RSN rigorously tracks all that information as
it's established. They essentially establish an as-built data package for the
hole. We depend on that quite a bit for establishing our confidence, once the thing
is done, that we have a competent containment package.</p>

<p class="tab"><b>Carothers</b>: When a hole is stemmed, how do
you know the stemming that's supposed to be in the hole is actually in there?</p>

<p class="tab"><b>Roth</b>: Well, first of all, there's a
material balance on the stemming that is determined. We weigh it, or volumetrically
measure it.</p>

<p class="tab"><b>Carothers</b>: Bernie, you don't volumetrically measure it. You weigh it.</p>

<p class="tab"><b>Roth</b>: Okay. We weigh it. You're
right. But we know what the weight per unit volume is, and so from that point
we get a volumetric quantity. The entire depth of the hole is volumetrically characterized
ahead of time. So, within a given area wherever a given plug is supposed to
fit, or a given section of sand, or gravel, or whatever we can calculate from
the logging information what volume of material fits in there. Then weighing
that volume of material across our weightometer instruments at the top of the
hole can pretty well determine what we put into the hole.</p>

<p class="tab"><b>Carothers</b>: How do you know the volume of the hole?</p>

<p class="tab"><b>Roth</b>: We have a down hole logging
system that uses a laser to bounce a beam off the hole wall, and records the
distance to the wall. Caliper logs were used up until a few years ago, and they
still are as a rough guide. But we now have an instrument that goes down hole,
bounces a laser beam off the adjacent surface, picks up the reflected beam, and
determines what the distance is. That beam rotates in a full circle as the
instrument is very slowly lowered or raised in the hole, so you get a very
shallow helix measurement that determines the volume to much closer than one
percent. So, we really know what the volume of the hole is.</p>

<p class="tab"><b>Carothers</b>: One of the things that came as
a surprise to engineers, physicists, whoever, in the 1961, '62 time frame was how
hard it was to pour stemming material down the hole and not have it bridge. It
seemed incredible that you could have a four, or six, or eight foot diameter
hole and the material would bridge in it. How could that be? But it did, and
when the stemming slumped it sometimes broke the cables. Do you ever have any
difficulty of that sort these days?</p>

<p class="tab"><b>Roth</b>: I have heard of those kinds of
problems, but since I've been the Test Director I have had neither sloughing or
bridging problems. Those were problems early on that people were surprised about.
I think that maybe the moisture contents of the sand or gravel would let it
build up on pipe strings, so it would tend to bridge. That concern was still
present as late as, I think, 1978. The Test Director at that time said we could
not fill the emplacement pipe with grout by pouring it in the top. It would
never make it to the bottom.</p>

<p class="tab"><b>Carothers</b>: I could believe that.</p>

<p class="tab"><b>Roth</b>: I had a hard time believing it. The pipe was 9 5/8 drill 
stem with an 8 1/2 inch ID (inside diameter), or whatever that dimension is.</p>

<p class="tab"><b>Carothers</b>: Don't you grout that
emplacement pipe from the bottom up? That is, pump the grout down through a
pipe near the bottom and force it up the pipe?</p>

<p class="tab"><b>Roth</b>: No. But yes, we did that for
years, but not anymore. My concern was a safety concern. We were stabbing a
tremmi pipe down the emplacement pipe just to do that fill operation. First of all,
it was time consuming. Second of all, if one or more lengths of that tremmi
pipe ever got loose, it had a rifle barrel right down to the top of the canister.
I could see a real catastrophe occurring, and that was an ongoing concern,
especially watching some of the crafts handling those tremmi pipes. It never
happened, but it was a concern to me. These days we just put the concrete,
mixed with a bentonite solution, into the top of the hole and let it free fall.</p>

<p class="tab"><b>Carothers</b>: How do you know it's full?</p>

<p class="tab"><b>Roth</b>: Again, by material balance we
know it's full. The inside of a pipe is readily calculable, and there's not
much question about how much volume is involved. Once it is full we put a bull
plug on top of it as a precaution. That probably isn't necessary, but it gives everybody
a warm fuzzy feeling. That's what's being done today with respect to filling
the emplacement pipe.</p>

<p class="tab"><b>Carothers</b>: How about knowing that the
stemming was emplaced as it was designed to be?</p>

<p class="tab"><b>Page</b>: We make every effort to install
it just as designed, because if it meets the criteria it makes everybody's life
a lot simpler. Then you don't have to deal with deviations, and they can be a
real problem. There's a lot of motivation to put the stemming in just as the
stemming plan specifies.</p>

<p class="tab"><b>Carothers</b>: I do believe that. So, the hole
is stemmed, and the plugs are in. At that point your job is about done isn't
it?</p>

<p class="tab"><b>Page</b>: Getting close. There's another
couple of days of worrying about final dry runs, and analyzing the containment records
and the containment plan. One of the final jobs of the Test Director is to
present the as-built stemming plan to the Test Controller's panel. That's done
on D minus 1.</p>

<p class="tab"><b>Carothers</b>: Yes, and that's when an event
called Galena came to a halt. As I recall, there was considerable to-do over
the possibility that there was a thirty foot or so void in the stemming on Galena.
How could that be, Jim? Why couldn't you convince people that wasn't the case?</p>

<p class="tab"><b>Page</b>: Well, I was the Test Director
for Galena, and we had a number of different kinds of information that we had
to try and interpret. We had stemming switches, we had a measure of the quantity
of material we put in the hole, and we had strain gauges on the pipe at the
surface, and above and below the canister. So, there was a lot of different
intelligence, and when it was all analyzed through a rational process, you
could arrive at some conclusions.</p>

<p class="tab">We became aware that
we had a problem over the couple of days that we were stemming one part of the
hole. We had strain gauge readings that changed over a weekend, after we had
passed that point in the stemming. We had other changes that indicated the material
was moving around. We alerted the Los Alamos containment community, and gave
them the information we had. We told the Test Controller we had this concern,
but that we were proceeding to complete the stemming. As people thought about
it, and did their own analyzing, Los Alamos asked for a more formal review of the
issue. As that started to come into place we decided we wouldn't proceed until
the Panel was notified. The approach was to poll the Panel without pulling them
together, but people weren't comfortable with that, and it was decided that
wasn't sufficient, so a Panel meeting was called.</p>

<p class="tab">That was how it went.
There were independent looks at the data. People relying on their own
experience, and making their own interpretations, felt there was enough
uncertainty that we couldn't go ahead without a formal review. We're still
totally satisfied that we did not have a void there.</p>

<p class="tab"><b>Carothers</b>: Sure. But the important thing,
for the Panel, was you couldn't prove it one way or the other. And so people on
the Panel then said, "Well, in that case we have to assume that void is there."</p>

<p class="tab"><b>Page</b>: I can't argue with that. I
think that's a reasonable attitude. Now, you'd like to be able to say that you
have absolute certainty of what's going on a thousand feet underground, but we can't
always do that.</p>

<p class="tab"><b>Carothers</b>: There was a Panel meeting on a
Saturday afternoon in Las Vegas, and after hearing what was presented, the
Panel felt the shot could go ahead. So, you fired it, and it performed just
fine, as far as the containment aspects were concerned.</p>

<p class="tab"><b>Page</b>: It did. Radiation didn't get high in the hole at all.</p>

<p class="tab"><b>Carothers</b>: Neither Laboratory has done a
line-of-sight shot for a long time. If one were needed it would be like
starting all over, wouldn't it?</p>

<p class="tab"><b>Page</b>: I don't know where we stand
with regards to being able operationally to do one of those, but we recently
did re-certify our HE closure design. About four years ago we thought we were
going . to do a shot like that, and we knew there would be a large line of sight.
So we rejuvenated an old technology, where we drew from the old design drawings
that we had available, and from the experience of people who had been there. I
was one of the people who had been in on the early development of that system
back in the late sixties and early seventies. We were able to rebuild the machine,
and we did one test, with new people. They were all new people doing the work,
and they demonstrated that it closed very nicely. There was a situation where
twenty years had passed, and we had not lost the technology.</p>

<p class="tab"><b>Carothers</b>: It gives you to think though.</p>

<p class="tab"><b>Page</b>: Oh, you bet it does. But now
there's a bridge for another ten years, perhaps. If ten years from now somebody
wanted to develop one of those, we have three or four young people who, if they're
still at the Lab, could do it then. I'll be long gone, but those people might
still be around.</p>

<p class="tab"><b>Carothers</b>: One thing that I think has been
true at both Laboratories - I will leave DNA out because they have a different set
of problems in that they have to protect millions of dollars’ worth of samples
- is that there is inherently a kind of conflict of interest between the
containment people and the field people. Your job as the Test Director would be
easier, and the shot quicker and cheaper to do, if you didn't have to do all
the logging, and special stemming, and put in cable gas blocks, and so on.</p>

<p class="tab"><b>Scolman</b>: I think one way of looking at
it is, going underground, particularly with the containment criteria we've got
now, puts a buy-in cost, a base cost on any shot that is so high that what you
do on the shot does not appreciably effect the cost of the shot. In other
words, the difference in cost between a very minimal test and a very maximal
test is certainly not as much as it would have been if it wasn't for the
containment.</p>

<p class="tab"><b>Carothers</b>: I've heard the argument put the
other way - that the shots are so complicated and expensive today that what you
do for containment is only a small part of the cost.</p>

<p class="tab"><b>Scolman</b>: In some sense, if what you
count as costs for containment is what is necessary to run an event through the
CEP, and the additional containment hardware you put in, that may be true.</p>

<p class="tab">But, first off,
there's the fact that you do, indeed, need to drill holes, which requires the
maintenance of a drilling capability both for the emplacement holes and the
post-shot sampling. You do, indeed, need to have plants that generate the kind
of stemming material you use. You do, indeed, need to do all the logging and those
kind of things.</p>

<p class="tab">Then you put in the
cost of just maintaining the Test Site - the EPA, the weather service, all of
these people who are there regardless of how complex the event is.</p>

<p class="tab"><b>Carothers</b>: Yes, but you can't fairly charge that against containment.
Those people would be there if you were doing atmospheric shots.</p>

<p class="tab"><b>Scolman</b>: Well, that's true.</p>

<p class="tab"><b>Carothers</b>: After Baneberry life for you as
the Test Director must have changed. You had a lot of other things that you now
had to do to prepare a shot, and fire a shot.</p>

<p class="tab"><b>Scolman</b>: Yes, of course. The TEP was
never a particular problem. One didn't worry about getting shots through the
TEP; one worried mightily about getting shots through the CEP. The other thing
was that the operational requirements that came after Baneberry were much, much
different than they were before. We used to draw a line between Area 4 and 9. I
f it was a Livermore shot we just cleared above that line. If it was a Los
Alamos shot we cleared below that. Now we clear the whole forward area on every
shot.</p>

<p class="tab">And there was a push
made, largely driven by NVO, which said, "Okay, let's get everything out
of the forward area that we don't need to have there." The reconfiguration
studies that were done really didn't lead to an awful lot other than we moved
some things that had been out in the forward area back into Frenchmen Flat.
Some of those changes, which in general increased costs, were not necessarily
involved directly with containment, but more with how one reacted if you had a
containment problem when you fired. One of the things on Baneberry that got
people's attention, other than the fact that it vented and got off-site, was
the fact that we did, indeed, contaminate some people and some facilities. A
lot of changes were made to prevent that from happening again.</p>

<p class="tab"><b>Brownlee</b>: There's always been a curse,
here at Los Alamos, that I haven't quite known how to fight. It has been a very
insidious thing, because down through the years, after Baneberry, we never had
another failure. And worse than that, we didn't even have a seep. So there has
been the attitude, "Why should we do anything different than we've been
doing? We had those experiences, we did these things, and since then we've never
had a single problem of any kind. Why then do we need these people working in
containment? Let's just keep doing everything the way we're doing it, and get rid
of all of those people."</p>

<p class="tab">And that attitude is
still around. The idea is that we only need one person now, we don't need five
or the six. We don't need any containment research now, because everything is
doing all right. It's easy to be logical, but that doesn't win the argument.
It's very hard to make an argument that can win against that attitude. Livermore,
meanwhile, had two episodes, and that helped, because we'd say, "There are
still things we don't know." And then the DNA has had things happen, and
that helps, but then the argument is, "Why should we hire people to work
on some of those things? Let them do that. It's not any of our affair."</p>

<p class="tab">And it's that
argument which is the real reason why we had the same stemming plan forever,
and we did our plugs the same way forever. We never could win the argument with
our local engineers that there needed to be any change. You don't need to do it
better if what you're doing is all right. We said, "We can do it
better," but that didn't matter.</p>


<a name="ch21"></a>
<br><br>
<h2>Chapter 21: Sometimes the Dragon Wins</h2>
<br>

<p class="tab">There have been several events
where the containment design has failed, for one reason or another. Some of
these, such as Des Moines, Eel, Pike, and Bandicoot have been mentioned in
earlier chapters. In the course of the interviews other events were described by
people who were personally involved with them. In many cases, even though there
may have been extensive post-shot efforts to understand the reason or reasons
for a particular failure, often there is not agreement of a definitive cause.
What follows is not an attempt to analyze and develop an accepted scenario for
these events, nor is it a complete listing of all of the events that have had substantial
releases.</p>

<p class="tab">There is one point that should be
mentioned. Following the detonation of a device in a tunnel, while there may be
satisfactorily containment of all of the radioactive products, there is often
an accumulation of gases which make it hazardous to reenter the tunnel.
Hydrogen and carbon monoxide in particular form explosive mixtures in air,
given sufficiently high concentrations. (See the description in Chapter Sixteen
of the hydrogen explosions which took place following the detonation of the
Tamalpais device.) There may be some level of radioactive gases in the tunnel,
none of which have leaked out to the atmosphere due to the efforts made
pre-shot to form gas-tight barriers to such leakage.</p>

<p class="tab">However, after the detonation
reentries must be made to recover the experimental samples and various
equipment, and to prepare the tunnel complex for future experiments. At a time determined
by the Test Controller, which may be several days after the event, a
ventilation system can be activated to replace the air in the tunnel with fresh
air. The hydrogen and carbon monoxide and other inert gases can be safely
dispersed into the atmosphere. Any radioactive products are passed through
filters, and the biologically inert noble gases are released in monitored low
level amounts over a period of time. As a result of this tunnel ventilation process
detectable amounts of activity may possibly be found on-site.</p>

<p class="tab">For example, the Misty Rain and
Mighty Oak events both were successfully contained by the definitions in the
CEP charter and the Nuclear Test Ban Treaty. No activity found its way to the atmosphere
following either event, but there was radioactivity in the tunnel complex
itself. During the ventilation process activity was detected on-site, and both
events are listed as having a controlled release. This is an operational
procedure that is not part of the containment design, and does not indicate a
containment failure.</p>

<br>
<p><i>Gnome - December 10, 1961</i></p>
<br>

<p class="tab"><b>Weart</b>: In addition to shots like
Marshmallow and Gumdrop, another shot that helped me formulate some of my
thoughts in the early days was Gnome, in the Carlsbad area. It did have a
prompt sampling pipe on it. It also had a tunnel with a line-of-sight pipe down
it. It was reentered, and I was on that reentry team. The observations there -
the fact that the line-of-sight that went straight up pinched off and nothing
came out, even though we were trying to get samples through it, the fact that
the line-of-sight pipe that we wanted to seal off quickly may have contributed
somewhat to the release, the fact that the buttonhook principle wasn't
successful in that particular case, and it didn't seal things off - did
contribute to some of my early thinking. And some of the early DNA designs followed
that thinking. We went along on that course until we had a problem, and then we
had to change things.</p>

<p class="tab"><b>Carothers</b>: From your observations on the
Gnome reentry, to what would you attribute the leak that occurred? You say the
line-of-sight pipe may have contributed.</p>

<p class="tab"><b>Weart</b>: Well, Gnome was in a location
with a bedded stratigraphy, and the line-of-sight pipe went right along
parallel to those beds. The combination of the cavity growth and the
line-of-sight pipe energy caused the ground to open up preferentially, all
along the bedding planes. And that allowed energy to squirt out of the cavity,
and out into the tunnel. Whether it would have happened if the bedding planes
hadn't been there, I don't know, but it appears to have been a plane of
weakness that allowed separation to occur.</p>

<p class="tab"><b>Carothers</b>: On reentry could you see
radioactivity, injected material, along those planes?</p>

<p class="tab"><b>Weart</b>: Yes. Whether it would have gone
on the same path without a bedding plane you don't know.</p>

<p class="tab">So, because of that,
the design for a subsequent shot there, called Coach, which was never fired,
would have avoided this situation by having an incline going up on the button
hook part. That way you didn't have a plane intersecting both the working point
and the tunnel. And in a lot of the rocks that we fired in subsequently, alluvium
and the tuffs, we've usually not had a bedding plane problem to worry about.</p>

<p class="tab">Higgins: I and three
other people reentered the shaft and tunnel, and recovered one of the pieces of
experimental hardware about December 20, 1961. I can say with certainty that
there was no leakage down the drift or the line-of-sight pipe. The gas seal door
was bypassed in a clay seam that was a foot or so above the top of the tunnel.
There was no evidence of anything except steam in the fracture or shaft.
Leakage must have come from the cavity after it formed, through that seam,
bypassing all the engineered features.</p>

<br>
<p><i>Eagle - December 12, 1963</i></p>
<br>

<p class="tab"><b>Brownlee</b>: I approached containment from
the point of view of containment of LOS shots, and I saw the whole thing in
terms of closing pipes with various kinds of things to keep energy from getting
out after they had made their measurements. Now, as I saw it, the Livermore
experimentalist had an upper hand to a greater degree than they did here. And
that started with AI Graves and Bill Ogle; they were determined to allow me to
try to keep things from coming out. At Livermore, it seemed to me, closures
were kind of secondary. With Los Alamos, closures were kind of first; you had to
do that .</p>

<p class="tab">When Eagle came along
it was for sure, I thought, going to allow the experimenters to get their
information, but there was no way to close the pipe. I was convinced that Eagle
was going to leak. Almost by accident I told AI Graves, "I think Eagle
will come right out. I don't think it's designed right." We had the treaty
then, so that could have been a violation of the treaty if it did that. It bothered
AI when I told him I thought it would leak. So, he called up the Livermore
Director, who was then Johnny Foster, and as a result we had a meeting in Las
Vegas. That was the summer of '63, and Eagle was fired later that year.</p>

<p class="tab">I took a lot of heat,
because Livermore was offended that Al had asked them to tell him about the
Eagle design. But I came home after the meeting and did some calculations, and
I was still convinced that it would come out. So I have to admit I took a
certain amount of perverse pleasure when it did come out, because I had been
taking a lot of heat.</p>

<p class="tab">Now, I am absolutely
convinced that Eagle was not fired as designed. Los Alamos people went out and
watched them put Eagle downhole. They came back and said, "Here's how that
was assembled." I said, "It's not supposed to be that way." And
so, I think the amount of energy that came out was more than there should have
been.</p>

<p class="tab">The difference was
this. In the very bottom of the pipe there was to be a series of lead rings. My
guys say that all those lead rings were piled right on top of one another, like
a lead collimator. I'm absolutely convinced that there was a lead cylinder at
the very place where there should not have been a lead cylinder. The ground
shock had no way of penetrating that lead in time to close the pipe. It squeezed
off, in time, but obviously a lot of stuff went by. Of course, it was an
awkward thing because the Livermore guys didn't dare own up that they hadn't
done it right, so they assured the system that they had done it exactly as
drawn. But the Los Alamos people at the Test Site, who lived there, said,
"Those lead baffles were put cheek to jowl." And there were a lot of
them, so there was just a big lead cylinder.</p>

<p class="tab">We had thought about
line-of-sight pipes for some time, but I regarded Eagle as the first modern LOS
shot because it was the first LOS shot with the treaty in place. There had been
the argument, "Let the energy pass and then close the pipe." Now,
that's right, in the sense that the Eagle fireball didn't have any
radioactivity in it. Is that all right? I said, "It's not all right if it
blows everything apart."</p>

<p class="tab">Before Eagle, people
were saying, "It won't do that." And I was saying, "There's
enough energy that it will. It should do damage." And it did. There was
more energy there than I was expecting, but as I said, I think there was a
reason for that. But after Eagle we no longer had the debate about letting
energy pass before you closed the pipe. So, the concept of closing everything
fast was solidified, reinforced, and became doctrine after Eagle, for us. Eagle
was a big experience for us.</p>

<p class="tab">I think the Eagle
design, if it had been emplaced right, would almost have worked. I think it
would have changed history if it had been emplaced right. As it was, it looked
as though the design allowed all that energy out, and I don't believe that. But
Eagle heavily influenced the next designs.</p>

<br>
<p><i>Double Play - June 15, 1966</i></p>
<br>

<p class="tab"><b>LaComb</b>: There was radiation behind the
overburden plug within like the first second. The radiation got outside the
overburden plug within minutes, but it was a slow release. It wasn't dynamic;
it was throttled through about a six inch hole and about a two inch hole. These
holes were each about eight feet long, so " there was quite a bit of
throttling there. And we had a very slight seep through the ventilation valves
and the gas-seal door, and a seep up through the cable bundles.</p>

<p class="tab">I think we got
permission to ventilate about a day or two later, and we pumped gas reading
better than a thousand R per hour out of the tunnel complex for better than two
days. That was as high as the rams went. And that was where we were reading
what was coming out of the tunnel complex. Of course the filters, after the first
ten minutes, were a thousand R and stayed there.</p>

<p class="tab">We had three what
were called DBS boxes, which were supposed to fire closed. When it broke loose
and came out, it hit those boxes and the test chamber moved about forty feet
towards the portal. We were very fortunate, because the door of the chamber
ended up right beside the little tiny car-pass alcove we had. If it hadn't,
nobody would have ever been able to get in. Those DBS boxes moved over eighty
feet.</p>

<p class="tab">Further out there
were these huge glass bubbles - just huge bubbles, of glass. They were six feet
in diameter. They weren't full round; they were hemispheres, as a rule. I
assume, because of the prompt release, they were from molten rock from the
cavity. And, because the DBS boxes were slowing everything down there, the melt
was stagnating there, more or less, and depositing that glass. But there was
enough gas coming with the glass that it formed those bubbles. The same kind of
bubbles were seen in the tunnel on Red Hot. It was the same kind of failure in
the same time frame. So, I think that glass must have come from the cavity.</p>

<p class="tab">There were also glass
stalactites hanging down from the ceiling. That glass, on the rock itself, I'm
not sure whether it was where the tunnel had been melted and dripped down in
place, or whether it was sprayed on and then dripped down.</p>

<p class="tab">It was kind of funny,
because when we first reentered that area, it was several R. As we walked
forward, into the stemming region, it went down to ten mR. Everything had come
out so fast that area was clean.</p>

<br>
<p><i>Door Mist - August 31, 1967</i></p>
<br>

<p class="tab"><b>LaComb</b>: On Door Mist, as I recall,
radiation started to show up in the tunnel in something like eleven seconds.
There were two TAPS - tunnel and pipe seals - in the pipe string, and two or
three DBS boxes. On reentry we found that the close-in TAPS door had closed down
about thirty degrees. It had been caught by something, and looked like that
must have been a two foot square chunk of steel, because that door, as strong
as it was, was just folded. We had put a pile of sandbags forward of the
walkway door in the close-in TAPS; there was about a three foot space between
the sandbags and the door. That door had at least a ten inch wide flange
embedded in the concrete. We never did find the door that was in the walkway. Apparently
the sandbags had gone in motion, and they just took it some place out of this
world.</p>

<p class="tab">The far-out TAPS had
a hole eroded above it which was about a foot to a foot and a half high by
eleven feet wide.</p>

<p class="tab"><b>Carothers</b>: Joe, you say the walkway door
was gone. It had to be in the tunnel somewhere, right?</p>

<p class="tab"><b>LaComb</b>: Well, there's so much rubble
you don't know where anything is, and the radiation levels are such that a lot
of times you've only got five or ten or fifteen minutes to look around. If we had
spent any effort looking for that door it would have been called "natural
curiosity," and that's not of benefit to the program. I'm sure it was in
there someplace, because we didn't see any signs of melt on Door Mist.</p>

<p class="tab">When we reentered
from the overburden plug, just inside the overburden plug it looked like a prehistoric
monster. The steel sets were all in place, the tie rods were still in place,
but all the lagging was gone; there wasn't even any ashes around that you could
see. All we could see going on down the tunnel was just this string of steel sets.
It looked like a skeleton. And the back of the tunnel was just flat.</p>

<p class="tab">I was team chief on
that reentry. We didn't have any ventilation because the vent lines were down,
so we'd take three steps forward, stop, and say, "What's the
readings?" "It's like a hundred mR, and about five hundred ppm's
CO", and so much, maybe five percent explosive mixture. We'd take three
more steps and stop. About this time my face mask had fogged up, and I was trying
to use my hands like a windshield wiper. We got about twenty feet forward of
the plug and it went to over a thousand parts per million CO, and over ten
percent explosive mixture. Our face masks were fogging up so fast we couldn't
keep up with it. At that time I said, "This is unsafe, guys. We will go
around the other way."</p>

<br>
<p><i>Scroll - April 23, 1968</i></p>
<br>

<p class="tab"><b>Olsen</b>: Probably the earliest event
where material properties really made a difference to anybody was Scroll, up on
Pahute, where they were hunting for a medium that would decouple as much as possible.
So, they wanted to know the in-situ density. Well, we found an air-fall tuff of
very low density; it was 1.3 to 1.4.</p>

<p class="tab"><b>Carothers</b>: It contained?</p>

<p class="tab"><b>Olsen</b>: Well, it probably would have if we had plugged the holes properly.</p>

<p class="tab"><b>Carothers</b>: What was wrong?</p>

<p class="tab"><b>Olsen</b>: Again, it was a lack of appreciation
for the time scale of things, and what can happen after the initial bang. We
poured some sand down the hole, and we also poured some cement in. Except, we
poured the cement in at a location where it would be eaten up by any ordinary
subsurface collapse, which is what we got. So, because the only plug we had was
eaten up by the subsurface collapse, all the granular stemming drained out, and
there was an open hole to the surface, and lo and behold, it started leaking.</p>

<p class="tab">In retrospect, some
of these things, in fact a lot of these things, you think, “God, why were we so
dumb? That's obvious." Well, at the time it wasn't obvious. We didn't
appreciate subsurface collapses, we didn't really have any information, any
data base, that said that a subsurface collapse was likely to go to six cavity
radii, give or take some number. We didn't have that kind of information.</p>

<p class="tab">At the time of Scroll
we didn't know much about what happened on Pahute Mesa at all. We didn't have
much experience with the normal geology up there, the density two, give or take
a little, stuff that we see all the time now. Much less did we know about one
of these unusual sites that we went hunting for, for Scroll. So, as we started
to learn things, like where collapses might go to, we started to put in things
that would attack that problem.</p>

<p class="tab"><b>Carothers</b>: Well, Rainier had been fired in
1 957, and it had a subsurface collapse. There were extensive post-shot
explorations done at the Rainier site during the moratorium, having to do with,
among other things the height of the chimney, and so on.</p>

<p class="tab"><b>Olsen</b>: That is true. But it wasn't
appreciated at the time we did Scroll.</p>

<br>
<p><i>Hupmobile - November 18, 1968</i></p>
<br>

<p class="tab"><b>Olsen</b>: Hupmobile was a disaster. It
was a vertical line-of-sight shot, and the experimenters wanted collimators in
the pipe, because they did not want shine bouncing off the walls, so we put in collimators
at almost every pipe joint. This was a fairly large line-of-sight - it went up
to several feet in diameter at the surface. We had these relatively massive
collimator rings, and for ease of installation they had a little, very thin
metal lip around the outside. So, they just sat on a pipe joint, and there was
virtually no strength in the thing that attached them to the pipe.</p>

<p class="tab">When the flow came
along, going upward, and started dumping energy on the downstream side of these
things, this little rim of fairly thin metal that was holding them in place
gave way. So, these rings went up the pipe, became a tangled mass of stuff at
the top, and blocked all of the valves. We recovered, on reentry, something
like sixteen hundred pounds of twisted up collimator rings at the top of the
line-of-sight pipe. We could even identify which collimator it was that had
been torn loose.</p>

<p class="tab">There was a transient
ground shock closure at the bottom, and it took like twenty-five seconds or so
for the cavity to find the weak spot and erode it enough that it really blew
its cork. There was a good sized cloud, but the flow was going through the
pipe, so it didn't erode as much dirt and dust as Baneberry. The release was smaller
than on Baneberry, but I think it was within an order of magnitude. It was big.</p>

<p class="tab">We had a large,
several story exposure station at surface ground zero, on top of the pipe, and
because of the venting that large exposure station caught fire, and we lost a
large share of all the things that were in it. The experimenters didn't like
that at all.</p>

<br>
<p><i>Baneberry - December 18, 1970</i></p>
<br>

<p class="tab"><b>Weart</b>: I have a little trouble
recalling the exact time people started to look for more favorable geology for
the tunnel shots. Certainly a marked turning point within the entire community,
recognizing the influence of geology and so forth, was with the Baneberry
event.</p>

<p class="tab"><b>Carothers</b>: You were part of the
investigating committee. Looking back on it, what is your view of the
understanding that was reached at that time, which may still be the right one?</p>

<p class="tab"><b>Weart</b>: As I recall, there were a
couple of circumstances which we felt contributed to the Baneberry release. One
was the fact that whereas events of this particular yield were normally
detonated in alluvium, in unsaturated rock where we had come to expect a
certain phenomenon, Baneberry was detonated in saturated clay. There was a very
high water content, and much more effective coupling of energy into ground motion.</p>

<p class="tab">That simply wasn't
anticipated. In one simplistic way of looking at it, with that equivalent
seismic energy it looked like a much bigger event. And therefore by our
criteria, which were empirical, of course, it was underburied. I think the
water may have contributed in another sense in that it provided an immense reservoir,
a far greater reservoir than usual of not easily condensable gases. That left
the cavity at a very high pressure for a very long time. And the third
circumstance was a fault, through which the eventual release occurred, which
intersected an interval underground which saw these high pressures. It took a
long time; it was three minutes or so before the release started.</p>

<p class="tab">So, it may have been
that a combination of all of those things were necessary, and that anyone of
them, by itself, would not have caused trouble. You don't know, of course, in
retrospect, but I think all three of those things contributed to the Baneberry
release.</p>

<p class="tab"><b>Carothers</b>: And that focused attention on the geology.</p>

<p class="tab"><b>Weart</b>: Yes, it did. There was the
fault, there was the unanticipated degree of saturation, the moisture, and the
clay. People thought that if we had been smart enough, and had looked for these
things, we might have anticipated that there could be a problem. So, maybe we
ought to start looking for those things in the future.</p>

<p class="tab"><b>Hudson</b>: The primary problem with
Baneberry, we think, had to do with geology. I say we think, because there is
still not a complete agreement as to what caused the Baneberry release. And we
had not given as much attention to what I should almost call civil engineering,
prior to Baneberry, as we have afterwards.</p>

<p class="tab"><b>Carothers</b>: What do you mean by civil engineering?</p>

<p class="tab"><b>Hudson</b>: Engineering design based on the
strengths of the overburden. Behavior of the overburden. We had basically
relied on the density of the overburden in the past. And built into that density
was all the features that led to successful containment of past events, that we
had been ignoring. Such as strength. Clearly, while you may have the proper
overburden density in a fluid, it's pretty easy to imagine how some of the
device material could get to the surface.</p>

<p class="tab">In the case of
Baneberry we were almost in a fluid, in that the working point was in a
saturated clay zone. We were still operating almost entirely from experience.
We didn't really know what to expect from the saturated clay. And, we really
didn't know that we were in saturated clay. All we knew was that they were
having trouble constructing the hole, a lot of trouble drilling.</p>

<p class="tab">But as far as the
other parameters were concerned, it appeared to be a good high impedance
medium, which would cause the pipe to close, and it seemed to be favorable for
containment. At the same time, there were some of us who had questions we would
have liked to have had answered before Baneberry, but I don't think any of us
who had questions really had reason for believing it was going to vent. We just
had unanswered questions we would like to have had answered before Baneberry.
Had we answered all those questions, it's not clear whether we had enough
understanding of containment at that time to have avoided Baneberry.</p>

<p class="tab"><b>Carothers</b>: It's my understanding that it
did not vent through the line-of-sight pipe. That closed off.</p>

<p class="tab"><b>Hudson</b>: That's true. I think the pipe
had little or nothing to do with the venting on Baneberry. The overburden
structure was too weak to contain the event. As a result, as the cavity grew, probably
fissures were formed close-in and hot steam entered the fissures, and pushed
them outward. And it found the easiest path to the surface and came out through
a crack, known now as the Baneberry fault. My personal opinion is that had that
fault not been there, it would still have come out through the path of least resistance.
It might have been a crack some place that wasn't associated with the fault,
but I believe it still would have come out.</p>

<p class="tab">The conditions that
you needed to not have a hydrofracture out of the cavity just weren't there on
Baneberry. You need some strength to keep hydrofractures from occurring, and
apparently on Baneberry we didn't have that, so gases came to the surface. Another
reason why I think it is related to hydrofracture is because it took three and
a half minutes. If it had been something really prompt, associated with the
line-of-sight pipe, it probably would have been at the surface in well under a
minute. I think we stepped into Baneberry largely due to our ignorance.</p>

<p class="tab"><b>Rambo</b>: There were a lot of
calculations that were done after Baneberry, using I-D calculations. They were
not successful. In going back and looking at this residual stress field again,
those calculations seemed to show a residual stress field. I think the one person
who came closest to having some success, using I-D codes, was Norton Rimer,
from S-Cubed. He alluded to weak clay at the shot point as being a possible
reason.</p>

<p class="tab">Things kind of got
left that way for a number of years. In the meantime, we were developing, with
Don Burton, who was the code physicist, much easier ways of working with this
2-D code called TENSOR. For instance, we found that instead of having to zone everything
as constant squares for different layers for different angles, and then try to
fit it together, which was almost impossible, we could pull all the zones into
a straight line, so we could then put our material models in without having to
do it by hand. We could do that with a computer code. And so, what we call
constraint lines, in the business I'm in, were put into this code.</p>

<p class="tab">As the codes
improved, I thought we could go back and do a 2-D calculation of Baneberry. So,
we went into the business of assembling this Baneberry calculation. There were
certain features that we looked at and said, "Oh my gosh, we ought to put
this in, or we ought to put that in." There had been a lot of exploratory work
done on Baneberry, after the shot, to pull out properties that hadn't been
measured before the shot, because that was not what we did in those days.</p>

<p class="tab">One of the things I
identified in that calculation was the fact that there was a saturated layer up
to a certain surface, and we had to put that in. Above that layer the material
becomes very porous. And, we did measure strengths, so we ought to put this
weaker material in and a higher strength material around it. The geologists gave
us a picture of what it looked like in cross section, and there was a big fault
going off to the side, and there was a Paleozoic hard rock scarp off at a
certain distance. We put all this together.</p>

<p class="tab">Some of the work I
had done on the slifer data on Baneberry indicated to me that it was very weak
material, down in the working point region. What I had developed over the years
was a way of looking back and getting a rough estimate of what the intercept of
the particle velocity was, and if it's down close to zero, I made the assumption
that it's very weak rock. If there's a high intercept, then maybe it's a
stronger rock. Well, Baneberry just went right through zero. It just looked
like a fluid. If you were to shoot in a fluid, the intercept of this curve
would be down at zero. Baneberry looked like that, when I backed out from the
data. I tried to back out some material properties, but we eventually went to a
model developed by Ted Butkovich for putting this together. The strength curves
we used came from rock measurements in the laboratory.</p>

<p class="tab">We ran the first
calculation, and essentially it showed the whole thing going belly up, in terms
of a residual stress field. It happened on the first try. We were shocked,
because we had not had any success with the 1-D calculations, but the 2-D
calculations showed this effect right away.</p>

<p class="tab">Probably I have a
different view point from most people on that shot. There is a layer of
saturated tuff above the shot, and above that there is a very porous layer, and
so there was this strong wave-flattening effect, what I call a focusing effect,
that happened when the shock wave went from the saturated tuff into the porous alluvium.
So, we saw what I called a focused event.</p>

<p class="tab">That was an important
learning point in calculations, I felt - that you could get this kind of
enhanced ground motion. We had looked at Tybo before we had looked at
Baneberry, and so when I saw this saturated layer I felt that it was going to
cause a lot of things to go on in the calculation that might not normally
happen. And indeed, we saw this effect in the Baneberry calculation.</p>

<p class="tab">One thing that was
interesting about Baneberry was that the fault was right at the edge of this
wet, saturated area. There was a pocket of saturation that did not go flat
across the fault. It stopped at the fault, according to what the geologists
told us. That particular geometry was important to what we saw. The wave going
out caused a lot of ground motion going up, along one side of the fault, and when
it crossed over, the saturation was different and the motion was less and that
tended to cause a lot of ground motion running along one side of the fault as
opposed to the other side of the fault. That was probably an important part of
the calculation, in that you saw a lot of motion on the fault.</p>

<p class="tab">So you've got motion
along the fault, plus an almost plane wave rarefaction that comes back, and you
get a lot of tensile failure around the cavity in this weak material. The net
result was we just didn't end up with any residual stress, after you put all of
this together.</p>

<p class="tab"><b>Carothers</b>: To oversimplify, you've
described a mechanism where you're not going to get residual stress, and where
there will be tensile failures in a weak material. That sound like a situation where
you would expect a lot of hydrofractures.</p>

<p class="tab"><b>Rambo</b>: Sure. Plus there was a large supply of water to drive that.</p>

<br>
<p><i>Camphor - June 29, 1971</i></p>
<br>

<p class="tab">Camphor was a line-of-sight
tunnel event, sponsored by Sandia, which was originally scheduled to be fired
shortly after Baneberry. It was delayed for some six months by the AEC investigation
of the Baneberry release, and was the fourth event fired after testing was
resumed with the Embudo event on June 16, 1971. In some respects its
containment behavior resembled the Mighty Oak event fired some fifteen years
later. There was a release of a small amount of gases, where Mighty Oak did not
have such a release, but there was extensive damage to all of the equipment and
experiments in the tunnel itself, and the loss of essentially all of the tunnel
complex due to the fact that there was direct communication from the cavity to
the various drifts. Jerry Kennedy, from Sandia was the Test Director for
Camphor.</p>

<br>

<p class="tab"><b>Kennedy</b>: Cypress worked perfectly well,
from a containment viewpoint. It was a storybook test from start to finish. At
that time what I think was going on was the DNA events were quite frequent, as
compared to now in these later years. So shots were happening numerous times a
year, and they were big effects tests, and they were being very successfully
contained. Clearly the containment plans were working. So, everybody said, “A
piece of cake." I think that was a little of the attitude, but that's not
saying people were being slip-shod about it.</p>

<p class="tab">Then, roughly two
years after Cypress, along came Camphor. The containment and stemming plan
changed from Cypress. I'd say it was, maybe, more daring. We were going to use
less stemming, because we had convinced ourselves we didn't need as much as on Cypress.
These DNA shots had happened, and so it must be okay. You could follow the
logic that said it was well designed. We certainly did that. Of course, it did
not contain. We didn't have a venting to the outside, but it was a complete
disaster inside the tunnel.</p>

<p class="tab">We had a couple of
big overburden plugs, and after the shot we finally decided that there was a
little bit of geology that perhaps we didn't quite understand, around the
forward overburden plug, which was at the aft end of the line-of-sight pipe.
The other was out at the main gas seal closure. That was a big, keyed-in
concrete plug, which was designed to hold overburden pressure, and so on. As near
as we could ever tell, a leak formed around the outside of the close-in plug,
through a crack we were unaware of, went around the plug, and then it quickly
eroded into the LOS drift, and then the work drift.</p>

<p class="tab">The LOS pipe was
rolled it into a ball at the forward overburden plug, into a space of about two
to three hundred feet long. That was originally over a thousand foot string of
pipe. It was all fairly compacted right up against that overburden plug. You
just don't really realize from calculations and numbers how much energy there is
there, and what it can do to things. You have to see what happens.</p>

<p class="tab">The flow didn't go
through the gas seal plug in the main pipe drift, at the aft end where the
diagnostics were. It went across into the parallel work drift, and then went
through the plug over there. That plug had all the cables in it; all the
instrumentation cables went through it. The eventual hole, which I walked back
through on reentry, was through that area where the cables went through. It was
clean as a whistle. It took all those cables out.</p>

<p class="tab">The gas seal door was
the final thing between us and the great out-of-doors. It was a swing-shut door
which you closed on button up. It was just a big steel swinging door with big
seals. It was supposed to be spec’ed at a thousand psi and a thousand degrees.</p>

<p class="tab">We tried to test that
door for leaks. It was all in a big, grouted bulkhead, and we worried about leaks
in that thing. It had been there for a long time, because it wasn't a one shot
thing. That was there for all time. We worried about leaks in that, and in the
course of preparation we had closed that door I don't know how many times. At
night on the late shift, when people didn't need to be in and out of tunnel, we
closed that thing, sealed it, and then we would pressurize the inside with big
blowers and compressors. Then we would check for leaks all over that face. We
did it with little squirt guns with soap bubbles. And it leaked. We pressure
grouted that plug, and did it I don't know how many times. We thought we were probably
wasting a lot of money, because it was a massive effort, but I think it saved
our bacon in the end.</p>

<p class="tab">Inside that door we
measured the temperatures and pressures, and it was pretty clear we had a bad
environment right at the door. Later you could see the cables that were inside
by that gas seal door, and the insulation was hanging down in festoons. It was
really the last barrier, but it held.</p>

<p class="tab"><b>Carothers</b>: My recollection is that there
was a seepage of a few hundred curies of gas, but there was no venting, and no
particulates. </p>

<p class="tab"><b>Kennedy</b>: That's right. It took about one
minute for it to cut loose. At plus thirty seconds, in the control room, we
were patting each other on the back. There had been a perfect, flawless
countdown through zero time. Everything turned on the way it was supposed to,
and it was ideal technically, from the data standpoint. Everybody was really
beginning to feel wonderful.</p>

<p class="tab">Then I got a call at
plus one minute and they started giving me RAMS readings. "RAMS reading
inside the overburden plug is greater than 10,000 R." That meant the meter
was pegged, and they didn't know what it was. Well, the one by the LOS pipe you
would expect to go very high, because it was in a high shine area. And then
they said the same thing inside the other overburden plug, in the work drift.
And then at the gas seal door. When they said that I had this terrible sinking
feeling. That's when we all turned as one and looked at the CCTV picture of the
portal, just waiting to see it belch fire, or whatever.</p>

<p class="tab"><b>Carothers</b>: And after about plus one minute
or maybe two, probably everybody looked at you and said, "Well, you're the
Test Director. What are we gonna do, Jerry?"</p>

<p class="tab"><b>Kennedy</b>: I remember quite well what
happened. I was in the control room, and we had a hot line to the Test
Controller's table. A guy handed me that phone, and said, "They want to
talk to you," and it was Byron Murphy. He was the Scientific Advisor for
the event, and he was sitting down there with Bob Thalgott, who was the Test
Controller. He said, "Jerry, I know you're going to be a little busy up
there, but do you think you might be able to stop down and see Bob and I?"
I said, "Yes sir, I think I can." I remember walking down the hall to
the War Room, like I was on stilts - kind of in a shocked feeling. It was a
bleak day.</p>

<p class="tab"><b>Carothers</b>: You did reenter?</p>

<p class="tab"><b>Kennedy</b>: Yes, after a long while. I
can't tell you the date right now, but it was many moons later. Of course,
right at first it was hotter than heck. The tunnel was hot all the way out to
the gas seal door, so the whole tunnel complex was contaminated. To get back to
the drift where the pipe was we mined parallel drifts all the way back, because
we couldn't go through the old way - it was too hot, and too difficult to
decon, so we mined new drifts.</p>

<p class="tab"><b>Carothers</b>: That wasn't just a gas leak in
the tunnel. It sounds as though that tunnel was in direct communication with
the cavity, and that there was device debris all over the place.</p>

<p class="tab"><b>Kennedy</b>: Oh yes. It was very bad. We
parallel mined all the way back in, parallel to the pipe drift itself, and made
cross cut entries at interesting points into the drift. In some places we couldn't
go still, so we would just put a hole in so we could insert some instrumentation
and look around. Some drifts we crossed in the reentry mining we had to stem
because they were rather hot areas. There were places where you couldn't stop
and look around. In 5 R fields you don't loiter, and we didn't.</p>

<p class="tab"><b>Carothers</b>: You had the overburden plugs,
and the gas seal door. Did you have any closure hardware on the pipe?</p>

<p class="tab"><b>Kennedy</b>: Other than the front end we had
a thing called a dimple machine up front, which was to cut off flow in the LOS
pipe close in. We had some experiment recovery packages that we hoped we would
be able to mine in and pick up and take out, which we did do. Then farther out
we had our fast gate, and then one of those gravity fall doors as a backup, the
way that DNA did it.</p>

<br>
<p><i>Mighty Oak - April 10, 1986</i></p>
<br>

<p class="tab"><b>Carothers</b>: Bob, what are your thoughts about Mighty Oak?</p>

<p class="tab"><b>Bass</b>: Mighty Oak. I cannot give an
official statement about what happened on Mighty Oak. That's somebody else's
province, but I know what happened. I can tell you exactly what happened on
Mighty Oak. On Mighty Oak there was too much pipe flow, immediately, and the
MAC doors were taken out. We did not have a FAC, the fast acting closure, so
those doors were our first line of defense.</p>

<p class="tab">The MAC doors came
across, and we monitor how those doors move, and where they are. Those doors
came together, and they got just about to where they overlapped, and they
slowed down. That is the time when the pipe flow gets there. Now, pipe flow is my
field. That's where I really have worked on measurements - what's going on in
the pipe, and in the stemming material around it. We monitor those pressures,
and we know when things get down there to the doors. We saw that the pressure
got there when the doors were just beginning to overlap. They didn't hit, but
just as they obscured the pipe, they stopped. Right at that same time, after this
happened, the pressure gauge in front of the GSAC, which is fifty feet further
down, picked up pressure.</p>

<p class="tab">Now, there are two
flows of material to analyze. There is the radiation blowoff, and material from
the closure of the reverse cone spool. Both of those produce material running
down the pipe. There are approximately ten kilograms of blowoff material in an
event like Mighty Oak. It moves at two to three centimeters per microsecond, so
it gets down to the MAC doors when they are still back, but there is hardly any
pressure, because it's a very low pressure situation. It's just a little puff
of ten kilograms of material. You hardly can see it.</p>

<p class="tab">But as the doors
close, the second flow comes along, and the second flow is the material
injected by the ground shock beyond the reverse cone, closing it down. You have
water vapor from the stemming material, you have iron vapor from the pipe, and
the pressure at that point is approximately 200 kilobars. When that goes on
axis that takes you to megabars, so you vaporize a little iron and everything
else. That material comes down at a half centimeter per microsecond. It gets to
those doors in 15 milliseconds, which is exactly when the doors meet.</p>

<p class="tab">Okay, something is
happening here, and what I firmly believe is, because of an error and a change
in the pipe structure up around the reverse cone, they had a much heavier pipe
than usual. They had a heavy pipe there to support the helix, and then they
took the helix out, but left the heavy pipe in. So, we have a lot of pipe now. On
two events, Misty Rain and Mighty Oak, that shrapnel followed the early blowoff
flow down, got there just as the doors were coming together, knocked the doors
out, and so the second pressure came through. When you get to those doors
there's a hole big enough that we had 500 psi against the GSAC, which is the
next closure down.</p>

<p class="tab">Anyway, we knocked
that hole in the pipe. I am firmly convinced that we injected some close-in
iron that got down there, and knocked a hole in the doors. With the doors
knocked out early, then you had a path for stemming flow. So, when the stemming
got there after thirty to forty milliseconds, a huge amount of stemming went
through those front doors, and that took out the next door back, and it kept
right on going. We just had a ram running down through there, and it took
everything out.</p>

<p class="tab"><b>Carothers</b>: Dan, what do you think happened on Mighty Oak?</p>

<p class="tab"><b>Patch</b>: Well, I think the focus we had
on Mighty Oak was really what we think of as material property problems, both
with the site itself, and also interacting with the design. This was one of the
designs in a series that used a taper that was larger than had been done in the
past. It used stemming that was weaker than had been used, and the weaker
sections were brought in closer. Also, if I'm not mistaken, some of the grout
formulations were twiddled toward the weaker direction. And, the site itself was
highly saturated; there was very little air void.</p>

<p class="tab"><b>Carothers</b>: That's supposed to be good.</p>

<p class="tab"><b>Patch</b>: It's good if you don't
overdrive the stemming, but if you overdrive the stemming, then you can
generate a lot of pipe flow, which Bob Bass feels was a very serious problem,
because it stalled the doors. One of the things about these gates is, if
they're only partially closed, and not fully closed, their strength is very
low, because they're not fully supported. My feeling was the doors were knocked
out, and there was enough extrusion so the stemming continued to flow.</p>

<p class="tab">All of these
materials, in comparison even to water, certainly in comparison to air, have a
very high modulus. They're very stiff. A tiny amount of flow makes a great deal
of stress relief, because the materials are almost incompressible. So, I think
there was a low state of stress down the stemming column, and flow started
through what was probably a relatively small path down through the stemming.
That built up stresses on the TAPS that caused it to fail. The thermal stresses
and the pressure loads on the TAPS were such that it couldn't stand the load.</p>

<p class="tab"><b>Carothers</b>: In thinking about your small
path I am reminded of an interesting tape recording that was made on Camphor.
You may have heard it. When they fired Camphor, for whatever reason they had
some microphones in the tunnel. For a few seconds it's quiet, and then there's
a little hissing noise that in a few seconds builds up to where it sounds like
a train. That opening was eroded from very small to very big very quickly.</p>

<p class="tab"><b>Patch</b>: I haven't heard that recording,
but we think that's exactly what happened - that Mighty Oak had a relatively
small path, which was capable of supplying a credible amount of gas. There's a
fair amount of volume back there, but nothing compared to the volume of the
cavity. It wasn't really a nasty flow at first, but once the TAPS let go, and
it began to really flow through that path, I think it just cleaned things right
out of there. And also I think there's a lot of evidence to suggest that's how
Hybla Fair failed also - that the real failure of the stemming was not a prompt
stemming blowout, but from an flow that just eroded the stemming out.</p>

<p class="tab">I don't think that
Mighty Oak was an impossible test. I think one could successfully design for
that site, and I'm not even convinced that one couldn't use that pipe taper,
and successfully contain that shot.</p>

<p class="tab"><b>Carothers</b>: What would you change?</p>

<p class="tab"><b>Patch</b>: Well, that's a fair question. I
think one of the things Sandia has done is make the doors on those gates about
four times stronger, and they've speeded the gates up significantly. An improvement
they've done a lot of work on, and are about ready to field, is to use a
propellant, a powder charge, if you will, to drive the doors, as opposed to gas
from gas bottles. I think we could speed the doors up enough so we'd have a
better chance against them getting stalled in the ways. I think we've got doors
that are significantly stronger, like factors of about four. Maybe that's not enough.
I don't know.</p>

<p class="tab"><b>Ristvet</b>: While I was at S-Cubed I predicted
Mighty Oak would be Mighty Oak about six months before the event.</p>

<p class="tab"><b>Carothers</b>: What led you to that conclusion?</p>

<p class="tab"><b>Ristvet</b>: I happened to be training Dave
Bedsun at the time, and doing reentries. That was my only involvement, because
my Pacific work really was occupying my time. But I did take the time to come out
and help Dave do a reentry, primarily on Misty Rain. Once we got into Misty
Rain, which was really the first shot we reentered in the kind of detail you
needed to see everything, it became obvious that the only thing that had been
saving us from a containment failure on the previous shots, including Huron
Landing and Miner's Iron, was what I call serendipitous block motion. We were
shooting the closures out before the stemming even got to them. And, if you didn't
have something holding the stemming in, it would go down to the test chamber,
and of course, the cavity would follow shortly thereafter.</p>

<p class="tab">Misty Rain was just
fortuitous. We were a gnat's eyebrow from Mighty Oak on Misty Rain. I said that
because of the Mighty Oak geologic setting, the kind of block motion we needed
probably would not occur in the LOS drift. There would be block motion on the
one fault, but it would occur too late. This was based on the breaking of
timing wires, and other studies we had done, so we kind of knew when block
motion triggered with respect to ground shock. If Pac Tech's calculations were
anywhere near being correct, most of the stemming would be past the fault
before the fault would move. My advice to DNA at the time was that it would
cost more money to fix Mighty Oak than there was equipment underground. And so
my advice was to go ahead and shoot it, and pray that there would be the block
motion to keep the stemming in.</p>

<p class="tab"><b>Carothers</b>: That must be a characteristic
of a particular site or a particular area, because there are a lot of tunnel
shots that behaved perfectly well.</p>

<p class="tab"><b>Ristvet</b>: Really only N tunnel is where
we've seen a lot of block motion, and that's because of the frequency of the
faults and fractures. Also the orientation of them is such with respect to the residual
stress field that they move easier than they do in P tunnel, say. There we
virtually don't have any faults or fractures, and in P tunnel we don't see very
much block motion.</p>

<p class="tab"><b>Carothers</b>: Ed, is there a reasonable
consensus on the reasons for the damage that happened on Mighty Oak? I have
heard various opinions expressed.</p>

<p class="tab"><b>Peterson</b>: There are a few people in the
community who say, and believe, that they understand exactly what happened on
Mighty Oak. I think that those people have never been able to convince a reasonable
group of other people. And I think if you really had enough sound scientific
evidence to show what happened, everybody would be willing to accept it. People
are out looking for the answer.</p>

<p class="tab">So, it's interesting.
DNA formed the Containment Advisory Team that has looked at Mighty Oak in great
detail. I think the people on that committee have tried to look at it very
objectively. Everybody has been trying to find an answer, and I think we have been
unsuccessful in finding something that we can point to and say, “It's because
of this that Mighty Oak did what it did."</p>


<a name="ch22"></a>
<br><br>
<h2>Chapter 22: About the Containment Evaluation Panel</h2>
<br>

<p class="tab">The Laboratory or Agency which
conducts a nuclear detonation is responsible for the selection of the site, and
for the design of any features necessary for containment. The Manager of the
DOE Nevada Office is responsible for the safe and proper conduct of the experiment,
including the requirement that successful containment be accomplished. The
Containment Evaluation Panel serves as an advisory body to the Manager, NVO. It
is the responsibility of the Chairman of the Panel to give due consideration to
the judgments of the individual Panel members, summarize them, and make a
recommendation to the Manager as to whether, from the point of view of the
containment design, the event should proceed.</p>

<p class="tab">How well and how effectively the
Panel has operated is, in some measure, reflected in the fact that there have
been only four releases of radioactive material since June of 1971. For these
four cases the total amount of material released was quite small - a total of
some 10,000 curies - and was principally due to the seepage of noble gases from
the cavity. A comparison of the post-CEP releases with a few of the major
pre-CEP releases, and the total release into the atmosphere for the atmospheric
detonations at the NTS is given in the table below. Recall that for an atmospheric
event the total fission fragment inventory is released. For underground events
the release is fractionated to some degree by the passage of the material
through the earth, the tunnel, the pipe, or whatever the leak path was, and so the
comparison numbers should be regarded with that reservation in mind.</p>

<br>

<table class="table">
	<thead>
		<tr BGCOLOR="#d9d9d9">
			<td>ALL POST-BANEBERRY RELEASES</td>
			<td></td>
			<td></td>
		</tr>
		<tr>
			<th>Event</th>
			<th>Date</th>
			<th><p class="text-right">Release (in Ci)</p></th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<td>Camphor</td>
			<td>1971</td>
			<td><p class="text-right">220</p></td>
		</tr>
		<tr>
			<td>Diagonal Line</td>
			<td>1971</td>
			<td><p class="text-right">6,800</p></td>
		</tr>
		<tr>
			<td>Riola</td>
			<td>1980</td>
			<td><p class="text-right">3,100</p></td>
		</tr>
		<tr>
			<td>Agrini</td>
			<td>1984</td>
			<td><p class="text-right">690</p></td>
		</tr>
		<tr>
			<td><b>TOTAL</b></td>
			<td></td>
			<td><p class="text-right"><b>10,810</b></p></td>
		</tr>
		<tr>
			<td></td>
			<td></td>
			<td></td>
		</tr>
	</tbody>

	<thead>
		<tr BGCOLOR="#d9d9d9">
			<td>SOME MAJOR PRE-CEP RELEASES</td>
			<td></td>
			<td></td>
		</tr>
		<tr>
			<th>Event</th>
			<th>Date</th>
			<th><p class="text-right">Release (in Ci)</p></th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<td>Platte</td>
			<td>1962</td>
			<td><p class="text-right">1,900,000</p></td>
		</tr>
		<tr>
			<td>Eel</td>
			<td>1962</td>
			<td><p class="text-right">1,900,000</p></td>
		</tr>
		<tr>
			<td>Des Moines</td>
			<td>1962</td>
			<td><p class="text-right">11,000,000</p></td>
		</tr>
		<tr>
			<td>Baneberry</td>
			<td>1970</td>
			<td><p class="text-right">6,700,000</p></td>
		</tr>
		<tr>
			<td><b>TOTAL</b></td>
			<td></td>
			<td><p class="text-right"><b>21,500,000</b></p></td>
		</tr>
		<tr>
			<td></td>
			<td></td>
			<td></td>
		</tr>
	</tbody>
	
	<thead>
		<tr BGCOLOR="#d9d9d9">
			<td>RELEASE FROM ALL NTS ATMOSPHERIC TESTS 1951 - 1963</td>
			<td></td>
			<td><p class="text-right"><b>12,000,000,000</b></p></td>
		</tr>
	</thead>
</table>

<br>

<p class="tab">To the extent that the Panel has
been successful, or deserving of some credit for the record of containment,
that success is based on several things, the most important of which are these:</p>

<p class="tab">1. The Manager, NVO, and
officials of DOE and its predecessor Agencies have been consistently and
strongly committed to the need for successful containment of the events. They
have also been consistently supportive of the Panel's activities and recommendations.</p>

<p class="tab">The CEP Charter, in Section III -
DOE Policies, Paragraph D, has the following words:</p>

<p class="tab"><i>Considerations of cost, schedules, and test objectives shall
not influence the containment review of any test.</i></p>

<p class="tab">This charge is unusual in its
breadth and in the authority it gives to the Panel. Since the formation of the
Panel in 1971, every Manager, NVO, and every person in the Headquarters who has
headed the Division of Military Applications, or the Office of Military
Applications, or the Deputy Assistant Secretary, Military Applications, when
asked, has emphasized that it was their intention that this charge be followed
by the Panel. No member of any sponsoring organization has ever challenged it,
to the Chairman's knowledge, or sought through those channels to modify or
overturn a recommendation of the Panel. And, there have been occasions when the
Panel's actions have caused considerable costs and schedule delays for a
proposed event.</p>

<p class="tab">2. The Members and Alternate
Members of the Panel do not serve as representatives of any organization. This
is a critical point. They are individuals with experience in the field of
underground testing, and knowledge relevant to the containment of underground
detonations, who are nominated to serve as independent experts and give their
individual judgment concerning the containment aspect of an event.</p>

<p class="tab">The Panel members do not vote as
to whether an event is expected to be successfully contained, with the majority
opinion being the one that necessarily goes forward. The concern of a single member
regarding some feature of a containment design has many times been demonstrated
to be sufficient to require further review and resolution before the event can
continue.</p>

<p class="tab"><b>House</b>: I remember one case where Bill
Twenhofel, on the Rousanne event, gave it a C! Well, a C is the death knell.</p>

<p class="tab"><b>Carothers</b>: I would not send something
forward that carried a C. In such a situation I generally suggest that possibly
the sponsoring Laboratory might wish to have the opportunity to present further
information and explanation before I send my recommendation to the Manager.</p>

<p class="tab"><b>House</b>: And boy, did we. And as it
turned out, it was a fairly simple matter. There was a site characterization
technique we had employed that was a little new to the Panel, and Bill didn't completely
understand it. So we journeyed to his lair at the USGS in Denver, and explained
to Dr. T what it was we were doing, and what we thought was significant about
it, and how it substantiated our structural interpretation. He said, "Oh,
I see. I understand that." So, he changed his statement, and we went
ahead.</p>

<p class="tab">It can be a difficult thing to
convince skeptical critics of nuclear test work that the Panel is not some kind
of rubber-stamp group, staffed by the sponsoring organizations to give a public
facade of responsibility for their activities. Individual integrity has unfortunately
been so often shown to be lacking in governmental processes that to claim it
for the Panel members is usually met with a raised eyebrow and clearly
expressed doubt. Fortunately, the record of the Panel members' activities and
actions has been sufficient to convince anyone willing to consider the evidence
that the members do, indeed, seriously and honestly review the containment aspects
of an event in the full spirit of the Charter.</p>

<p class="tab">3. The sponsoring organizations,
and their acceptance of a need for successful containment, are an essential
part of the process. Here again, the matter of integrity and honesty is paramount.
The Panel fundamentally takes the position that the material presented to them
is, in fact, correct within the limits of the Laboratory's and the presenter's
knowledge. A mistake may be made, but the assumption is that, if so, it is an
honest mistake, and not a lie. A clear example is the number that is given for
the maximum credible yield of the device. This is one of the most important
factors in determining the depth of burial, and the overall phenomenology of the
event. That number as given is accepted by the Panel as the best that can be
given for the particular device, and that uncertainties which might exist in
that number are fully accounted for in the containment plan.</p>

<p class="tab">In the same way, the Panel
accepts as fact that the containment plan as reviewed by the CEP will be
implemented in the field, and that the characteristics of the various
containment features as built are as they were described to the Panel. The
seeps and the leaks that can occur are really prevented by the people in the
field who install the cable gas blocks, the cable fanouts, the stemming and
plugs, and so on. The Panel relies on the integrity and competence of those people
to do the job right, and to describe promptly and accurately any deviations
which may occur.</p>

<br>
<p class="tab">In any organization or Panel that
has operated for over twenty years, how it operates and how it might operate in
a different manner is a question seriously to be considered. A number of
people, CEP members, presenters, observers were asked their opinion of the Panel,
and how it operates .</p>

<br>
<p><i>Billy Hudson, LLNL, alternate Panel member:</i></p>
<br>

<p class="tab"><b>Hudson</b>: I think that by its very
existence the Panel has a strong effect on the way testing is carried out.
Knowing that you have to satisfy a Panel of relatively bright people who can
ask penetrating questions causes you to look very carefully at your designs. It
stimulates attention to detail.</p>

<p class="tab"><b>Carothers</b>: At a CEP presentation a person
is in a public forum, where the Panel members are going to ask questions. Most
people have a certain amount of pride in a situation like that. Not that they're
proud of being there, but they don't want to appear stupid in front of
everybody.</p>

<p class="tab"><b>Hudson</b>: That's right. That's part of
it. Another part of it is they don't want to be caught doing something that
appears to be stupid after the fact, if indeed there is a failure. So, the CEP
is in many ways a public hearing before the fact, only to be brought to light
should there be a problem. In that sense I think it has been a very valuable
body.</p>

<p class="tab"><b>Carothers</b>: What changes would you make in it?</p>

<p class="tab"><b>Hudson</b>: It works. Why change it? You
know it could be done cheaper, and you know it could be done faster, but you
don't know it could be done better. If you said, "Well, gee. That's not a
good enough answer. We really should try to do things as efficiently as we can,
without sacrifice of quality," then I would say that we could probably
make some changes in the CEP. I'm biased though. It's my opinion that
phenomenology is the important thing to consider in understanding containment,
or affecting containment. Disciplines like geology, for example, are only
supplying data for the phenomenologist to think about. In that context then,
the role of a geologist, or a hydrologist, should be to say, "Yes, I think
you have the right descriptive information," or "No, I don't think
you have the right descriptive information." They shouldn't have an
opinion about the containment of the event. I would say that in some ways you
might have a more effective Panel if it were comprised basically of
phenomenologists, and the geologists and hydrologists were cast in the same
role as the drilling and cementing people. They would say, "Yes, we agree.
You've got the right description," or, "No, we think there's a
problem," but not make a statement per se, or categorize.</p>

<br>
<p><i>Evan Jenkins, geologist, USGS, alternate Panel member:</i></p>
<br>

<p class="tab"><b>Carothers</b>: How do you feel about how the
CEP operates, Evan? What differences would you like to see?</p>

<p class="tab"><b>Jenkins</b>: I think the trend towards
certain data, and the presentation of only those data is a mistake. In other
words, not discussing all the data. I think that our purpose in existing as a
Panel is to review all aspects, no matter how benign they might be. And I think
it would certainly be beneficial, in a legal sense, should we ever have a
problem, to have reviewed all of the data that are available, all that were
collected.</p>

<p class="tab">Much of the data that
has been collected is included as backup data that the Labs have at every
meeting, but don't show. For example, the commonly accepted practice is to show
the generally east-west cross sections, but not the north-south cross sections.
For some events they don't even have a north-south cross section. They should
have it and show it. Those cross sections are usually just horizontal lines,
but it's comforting to know that all those lines are horizontal. I think that
trend of not showing data could get us into trouble.</p>

<p class="tab">As a point of
deviation from what I said, I think that the Panel is good enough to recognize
points in the document that should be brought up. I hope that we on the
geologic side are bright enough to pick up things that should be brought up. I
sometimes feel uncomfortable because I certainly don't have expertise in the physics,
or the chemistry, or the engineering parts of the presentations.</p>

<p class="tab"><b>Carothers</b>: Those people don't have the
expertise in geology that you have. That's why there is a Panel.</p>

<p class="tab"><b>Jenkins</b>: Well, yes. I have to rely on
those other people for these other points. The geology, I think we can handle
all right, but I rather hate to sign my name to anything where I haven't seen everything.</p>

<br>
<p><i>Tom Scolman, LANL, former Los Alamos Test Director:</i></p>
<br>

<p class="tab"><b>Scolman</b>: Let me say something that I
think ought to be done. A great deal of what we have done and do with the CEP,
I believe, is to lay down a record that could be examined by whomever. Come back
later, and that record offers rational reasons for doing what we've done. It is
a record that says, "Yes, indeed, we did look at the proper things. We
considered the proper things, and the fact that this thing vented and killed
eight thousand sheep in Utah can't really be blamed on our particular
community." Frankly, if I were NVO, or if I were even Watkins (Secretary
of Energy), I might be inclined to have somebody who could come in with a more
or less clean slate, but some scientific appreciation of what we are trying to
do, and look and see if we really are doing the right things. Are they
defensible? Should we be doing things the way we are, even though some of them
were developed for other situations?</p>

<p class="tab"><b>Carothers</b>: Well, there are a couple of
responses that I'd like to make. One, to take the example of using, as
stemming, the coarse and fines layers that were developed for cased holes, in
uncased holes. The defense is that they have worked just fine, because LANL has
never, on any shot since Baneberry, had seepage on one of their events. So,
whether you can justify that stemming design or not, the fact is that it has
worked successfully many, many of times.</p>

<p class="tab"><b>Scolman</b>: And that's the answer I get every time I bring it up.</p>

<p class="tab"><b>Carothers</b>: The other part of my response
is that one of the reasons I think the CEP stays the way it is, and does its
business way it does is that, like the coarse and fines layers, it has
demonstrably solved a problem hundreds of times. Another reason it stays the way
it is, is because today it is addressing a political problem as well as a
technical problem.</p>

<p class="tab"><b>Scolman</b>: That's the point I was making.
And I wonder if is it addressing it properly.</p>

<p class="tab"><b>Carothers</b>: Well, from the point of view
NVO, DASMA, DOE it is. On several occasions I have gone back to Washington for
one reason or another; sometimes because there was a worry about the containment
of a particular shot, and I am the Chairman of the CEP. I go there and say, “I'd
like to tell you about containment." And these are very capable, concerned
people who are probably thinking, “If this shot blows out of the ground,
there's my career on the line." We go through it, and hopefully they're
reassured. Then I say, “You know, we've been in business a long time. The
Charter for this Panel basically comes from you, and it says the following '...'.
Maybe that's appropriate, maybe it's not, in today's world. If you want to
change it, certainly that is your prerogative, and we'll do it the way you want
to do it." The answer always is, “I don't want to change a thing."</p>

<p class="tab">So the Panel stays,
and it produces this public record that you're talking about - we have looked
at these various things, we have made no radical departures, our record has
been very good, and we stay close to our previous experience.</p>

<p class="tab">Suppose you, Tom,
decided there was a cheaper, better, but very different kind of stemming, so
you changed to that stemming plan. Suppose some leak happened that had nothing
at all to do with that, but it happened. You wouldn't be able to justify the
change economically, calculationally, theoretically, or however. Somebody would
say, “Well, Tom, you had two hundred shots where they didn't leak, and then you
changed your stemming."</p>

<p class="tab"><b>Scolman</b>: Exactly. No, I agree. It's hard to argue with success.</p>

<p class="tab"><b>Carothers</b>: And that's what the people in
Washington do not want to do. Nor does the Manager of NVO. I have gone in and offered
my resignation to every new Manager. "No, that's fine. We like it the way
it is. I don't want to change anything." Actually, I don't think they
should.</p>

<p class="tab"><b>Scolman</b>: Well, I think the CEP is
certainly necessary. I think it's doing good service, and I frankly think, for
example, that the chances of us having a Pike-type event, with the CEP, are
zero, other than having some designer blow it and get a yield that is perhaps a
factor of two or three over design. We might have trouble containing that. On
the other hand, I know enough about the design business to think that is pretty
damn unlikely these days, so I don't particularly worry about that one.</p>

<p class="tab">For a long time I was
of the opinion that probably you could come in and present Baneberry over again
and get it okayed. I think that's extremely unlikely the way things work these
days. Baneberry had enough things against it that you probably couldn't do it.</p>

<p class="tab"><b>Carothers</b>: I don't think there's any chance you could get
Baneberry approved. The drilling history alone would get it turned down.</p>

<p class="tab">There are really two
parts to containment. You don't want a venting, and maybe the Panel has helped
there. The rest of containment is really the guys in the field, taking care of
the seeps and the leaks. Those are really prevented by the guys in the field doing
their job right. And, the Panel doesn't really know much about that. The
presenter says, "Well, these ,cables are gas blocked." We say,
"Oh, that's good," because cables can leak. But the Panel relies on
the integrity and competence of the people in the field. So, maybe the best
thing, or the only thing, that the Panel really does is to try to prevent a
Baneberry or a Pike.</p>

<p class="tab"><b>Scolman</b>: Well, it's interesting, because
at least once a year my containment people would come back from the CEP just infuriated,
because they felt they had been badly mistreated. That we, Los Alamos, get
treated much differently than Livermore does.</p>

<p class="tab"><b>Carothers</b>: I don't happen to believe that.</p>

<p class="tab"><b>Scolman</b>: Oh, I know that. I take it with
a grain of salt. suspect the same thing happens in Livermore. In fact, Bob
Kuckuck has asked me, "How come, why do your containment people pick on my
containment people?"</p>

<br>
<p><i>Wendell Weart, geophysicist, Sandia, former Panel member:</i></p>
<br>

<p class="tab"><b>Carothers</b>: What did you think of the CEP
while you were on it? Do you think it provided a useful function, or was it just
a bunch of hoops that the people had to jump through?</p>

<p class="tab"><b>Weart</b>: I think that in the early days,
clearly, it did serve a useful function, because it tended to formalize and
focus people's thinking and investigations on areas which experience had shown could
be critical. There's probably a lot that went on that wasn't necessary, but it
was one of those things that you never know until you examine it. There has to
be some formal process for forcing that examination to occur. It's a
containment quality assurance program, sort of. And I think that while some of
the investigations and things would have proceeded without it, this was a way
of making sure that they did, and did in a formalized sense. Everyone knew what
was expected, and what kind of information had to be provided. It was more
structured than just progress by normal trial and error.</p>

<p class="tab">I know there were
some instances where one of the Laboratories had to make significant changes -
sometimes in locations, sometimes in designs - before proceeding. And that is
something that clearly would not have been done for that particular event without
the CEP.</p>

<br>
<p><i>Bob Brownlee, LANL, Panel member:</i></p>
<br>

<p class="tab"><b>Carothers</b>: What are your thoughts about the CEP, Bob?</p>

<p class="tab"><b>Brownlee</b>: That brings up a point which I
think is fair to talk about. I worry a little about the CEP when Jim Carothers,
and Gary Higgins, and I are no longer there. I've learned not to trust some of
those other guys, because they have not only no memory of the past, which is to
be expected, but they really do not have the lessons of that history either.
And therefore, they're capable of just going way off on crazy things, and there
needs to be some old hands to balance things there.</p>

<p class="tab">We used to not have
any turnover on the Panel, but we've had a lot of turnover in recent times.
There are some people that you are just not going to educate, but there are a
good many others that don't take the time to get educated. And in a while
there's not going to be anybody to educate them. When I say that there can be
human error, that we're apt to do something really dumb, one of the places where
that can emerge is at the CEP.</p>

<p class="tab">I've done a thought
experiment. Do I think that now, right now today, I could, on my own endeavor -
although I'd like to consult Gary Higgins about it - design a shot in such a
way that the probability of failure was enormously increased, but I could still
get it past the CEP without them catching it? Could I get all A's on it? There
was a time when I would have thought, "No, I couldn't have." And now
I don't think I could either because of Jim, and Gary, and me, and Carl Keller.
But if I did just the right things, and conspired with the Chairman, and with
Gary, I think I could put through something that would have a very much higher
probability of failing than normal, and get straight A's on it. I'll bet you
that in five years the ease with which I could do my thought experiment will be
greatly increased. And that worries me. Part of it is because the people only
go back to '63, and as the years go by they don't even do that.</p>

<br>
<p><i>Joe Hearst, LLNL, observer:</i></p>
<br>

<p class="tab"><b>Carothers</b>: You've seen the CEP since the
first days, when it was formed. Do you think it does anything useful? Is it a
function that once was useful, and now isn't? What are your comments about the
CEP as a body, and about what it does.</p>

<p class="tab"><b>Hearst</b>: I think, on balance, it's a
useful thing to keep the Laboratories honest. Sometimes the Panel does things
on the basis of gut feeling, but I think there has to be some sort of reviewing
body to uphold standards of some sort. I'm not convinced that the CEP does that
as well as it might. I think a great deal of effort is wasted in getting
presentations just ever so, and in all the nitpicking - all the pre-meeting
meetings, and all the worry about two decimal places when you can only measure
something to zero decimal places. I think something like the Panel is
desirable, but I'm not sure that a lot of what the Panel does is worth the
effort needed to make the presentation acceptable.</p>

<p class="tab">You might find it
interesting to go to a pre-CEP meeting, and listen to the discussions of,
"You don't want to say this because it might raise a question," or,
"You don't want to say that, because it might inspire someone to ask
questions," or, "You don't want to present this information. Keep it
as a backup, because it will just lead to a long discussion."</p>

<p class="tab"><b>Carothers</b>: No, I have not been to such a
meeting. The Panel operates on a presumption that I think is most clearly
demonstrated in the question of yield. The Panel takes the given numbers at
face value. The belief is that the Laboratory is really telling them the truth
about what the design and maximum credible yields are. The fundamental
presumption upon which the Panel operates is that the Laboratories will be
honest. That shades off into an area with no clear boundary. If everything the
Laboratory presents is the truth as they know it, but they don't present
everything they know, is that being honest?</p>

<p class="tab"><b>Hearst</b>: There is the feeling in these
meetings that yes, you should present what you know, but not necessarily all
that you know. And you should be very careful about how you work things so you
won't get somebody to follow something up and ask questions.</p>

<p class="tab">It's like Brownlee
saying, "Show me the viewgraphs you haven't shown me. You always make
those backup viewgraphs. What are they for?" Those are things they know
that they aren't going to tell the Panel, unless they are specifically asked.
"Gee, this may make somebody think about differential compaction, so maybe
we shouldn't say that sentence. Maybe we should say something different."</p>

<br>
<p><i>John Rambo, LLNL, presenter, observer:</i></p>
<br>

<p class="tab"><b>Carothers</b>: When did you first start interacting with the CEP?</p>

<p class="tab"><b>Rambo</b>: I think I went to my first CEP
within a year after Baneberry.</p>

<p class="tab"><b>Carothers</b>: What's your view of the CEP?
Does it serve a useful function? Was it always, or has it turned into, a
political bureaucratic creature, which just serves to validate things in a
rubberstamp way?</p>

<p class="tab"><b>Rambo</b>: I think it has changed over the
years. I think in the beginning people were honestly frightened of what they
didn't know about what causes containment. That led to many ideas, and many discussions
about things that may not have pertained to containment. Now it's as though
those things have played themselves out over the years.</p>

<p class="tab">Years ago somebody
who had a personal idea about what containment was all about might have said,
"I think this one is a B, or even worse, because I've got my private ideas
on containment." When those shots contained, and we went on and on, fewer
and fewer ideas were able to live through this whole mish-mash, because the
history said, "Look, we're containing, we're containing."</p>

<p class="tab">And so, I think this
has kind of all evolved down to the place where people have played out their
ideas. Things seem to be going pretty well, and we've fired in a number of
different kinds of geology, and we can't really sort out any more what's good
and what's bad. But the thing that scares me is that every once in a while I
see something in a calculation that scares the hell out of me. But then you go
back to the usual things like material properties and things of that sort, and
they fall right in the middle. And yet, what I'm seeing in the calculations can
be pretty scary at times. So, what do I do? I go to the CEP, in the current
frame of things, and things seem like they're just going through like a train
running past the station. It's the same old c1ick,"Look at this,"
c1ick, "Look at that," and the shot passes without any problems.</p>

<br>
<p><i>Byron Ristvet, DNA, Panel member:</i></p>
<br>

<p class="tab"><b>Carothers</b>: Is the CEP of any value to the DNA?</p>

<p class="tab"><b>Ristvet</b>: Yes. Oh yes. Let me tell you
how the CEP helps me, at least. I've always approached the CEP as if I were
taking my qualifying orals again for my doctorate. It is a similar type experience,
especially in the days of old, when the CEP was little more rigorous, perhaps,
in its questioning. But then again, I've thought that maybe it isn't that
they're less rigorous than they were, it's just we're a lot better prepared,
and we have convinced ourselves, based on our CEP experience, of what lurks in
the minds of the people sitting at that table. Some people talk about, “Well, do
you think we can sell that to the CEP?" and I don't approach it that way.
I have never thought that way.</p>

<p class="tab">I approach it in the
manner that the CEP is going to base their judgment primarily on experience,
and if we don't have direct experience we have to indirectly derive experience
on things. Take the plugs, for example, the drift protection plugs. I started, when
I worked for Carl Keller, actually going out and field checking these things
myself, to make sure that they were pretty much like we say the were to the
CEP.</p>

<p class="tab">Now, I know nobody
from the CEP, though they could if they wanted to, could go out and field check
what we have built. It just helps me be prepared. I put myself in the position
that I'm a CEP Panel member when I'm putting the prospectus together, in that
we want to get the Panel to accept the shot, but we also want to assure ourselves.
That's why in our vessel concept we proof-test our vessels. And it turns out
that our proof-tests at three to five psi above ambient in the tunnels is
really a more severe test on the plugs than if we did it at real pressures of
perhaps one or two or three hundred psi.</p>

<p class="tab">That is because
basically we use the Bob Kennedy type keyways, and that is where the plugs seat
as you press against them, and as they seat they create a hoop-stress in the
rock surrounding the plug. With our pressure grout rings behind those plugs
it's impossible for gas to flow around the plug, assuming a fairly impermeable
media, which we have in the zealotized tuff. We've done a lot in suggesting the
designs, but again, it is these engineering practices, and the attention to
detail that is so important.</p>

<p class="tab">And that's what's
scary in the future, as we lose these people who know what to look for through
experience, and who know the tricks of the trade.</p>

<br>
<p><i>Irv Williams, DASMA staff, DOE Washington:</i></p>
<br>

<p class="tab"><b>Williams</b>: One of the things the CEP has
done is try to make sure that the Laboratory people have done their homework. And
if they haven't, you know, it's embarrassing to be asked certain questions. I
think the CEP is an absolute must, because with a venting, I think we would go
out of business permanently. Another Baneberry, and I think we would be shut
out of Nevada. And I don't know any place we could ever go back and test,
without a furor, and that includes Amchitka. Therefore I think it behooves us
to maintain the integrity and the questioning ability of the CEP to make sure
the homework is done by the Laboratories, and that we feel relatively confident
that we're not going to have a leak. Without that I think we jeopardize the
future of any testing. And potentially the end of the weapons program.</p>

<p class="tab">You do need to test,
I'm convinced of that. I've been through too many experiments, and too many
times we've had people who said, lilt's a piece of cake." And then we get surprise. Some are little, and some are big. We can
generally stand the little ones. The big ones make you go back and do your
homework. And you can't do it on a computer. You can't do it on a shot table at
Site 300, or on a Fermex machine. The only way you can do that experiment is
underground.</p>

<p class="tab">We have to have the
confidence the CEP brings to the Directors (DASMA) here, because they do read
the reports, and they do ask questions. Occasionally I have to come back and
ask the Panel, “What did you mean?" The words are read, and it's amazing
how well they are read by the Directors. The Directors, once they take the job,
and they understand the responsibility that goes with it, want to make sure
that things are complete, and we try always to make sure it is a complete
package.</p>

<p class="tab">I've watched the
Panel a long, long time, and I've attended meetings where there were some...
inspiring discussions, let's say. I think you need to keep inquiring minds in
there, and continue to realize that strange things do happen on shots. The
people on the Panel need to realize that. That's the big thing, I think.
They've got to realize that we get surprises out there. And I feel that maintaining
our record is crucial.</p>

<p class="tab"><b>Carothers</b>: The CEP Charter contains an
unusual sentence, which says that in considering the containment design the
Panel shall give no weight, pay no attention, to money, schedule, or data acquisition.
That's an unusual charge that the Panel has.</p>

<p class="tab"><b>Williams</b>: Yes, and it was intended at the
time to say, "We know people will cut corners. We want to make this so
corners aren't cut and there aren't incidents and accidents as a result of that."
It was meant to give a strong hand to the Panel. That's also why they insisted
on the independence of the Panel members.</p>

<p class="tab">I have felt
comfortable with the way the Panel has operated, and the fact that it remains
inquisitive. I would encourage them to keep the Laboratory people on their toes
in doing their work, because we all have a tendency to think we're old hands,
and dismiss things. Try to make sure that the young bloods coming up are inquisitive,
and very serious about their endeavors, so they really fully categorize the
experiments. I think the life of the program, from the technical side, rests on
our ability to assure containment.</p>

<p class="tab"><b>Carothers</b>: I think the people on the
Panel, and in the Laboratories believe that too. But an attitude can develop in
the Laboratories that the object of the CEP meeting is "to get this thing through."
Rather than, "Let's go talk about it together, and see if there's
something we missed." That worries me.</p>

<p class="tab"><b>Williams</b>: That worries me too. I think
there should automatically be full disclosure to the Panel, because, what you
might consider to be inconsequential, someone else can consider to be very
serious. I feel that to be responsible they should have full disclosure, and do
it in descriptive terms, so you can communicate with people back here, so we
all understand it.</p>


<a name="ch23"></a>
<br><br>
<h2>Chapter 23: Thoughts, Opinions, Concerns</h2>
<br>

<p class="tab">There are many uncertainties and
ambiguities that surround the subject of containment. Persons working in the
field are certainly aware of them, particularly in the areas of their own
expertise. Still, they have been called on many times to pass judgment on
things such as the acceptability of a proposed event location, or the possible effect on containment of a
particular experimental configuration. Calculations can sometimes offer
guidance. Past experience is useful, but not infallible. Ultimately it is the
opinions and beliefs of the people involved that weigh heavily in the decisions
that are made.</p>

<p class="tab">What follows is a collection of
some of those opinions and thoughts held by various of the people who have been
quoted in the previous chapters.</p>

<br>
<p><i>Cliff Olsen</i></p>
<br>

<p class="tab"><b>Olsen</b>: I think one of the problems in
containment is something I had to learn, and I think I learned it slowly. In
school, and I think it's almost reinforced in graduate school, you focus
closely on something. You have to look at something in great detail, and you tend
to lose sight of the fact that there's something else close by. You look at the
mechanism of a particular reaction, and you isolate it, and you figure that all
out.</p>

<p class="tab">In the containment world the
scenario is always changing; the environment, and the mechanism concerned, is
always changing. For example, if you design a collimator having in mind only
what it does to the x-ray flux, and you forget that something else is going to
happen after the x-rays are long gone, you can get in real trouble. So, you
have to constantly keep thinking about what is going to happen next. Where do
we go from here? You have to keep looking at different mechanisms all the time,
and how they keep interacting. You can't just say, "Okay, that thing did its
job. Now I can forget it." For instance, on the early shots there were
people who would design an x-ray experiment, and they would install it, and
forget all about it. Eventually we learned that you can't do that. You have to
look at all the pieces, and you have to look at how they behave promptly, and
intermediately, and later on, and maybe even after collapse, when the guy who
designed it couldn't care less what it's doing.</p>

<p class="tab">I think that was one of the
hardest lessons. We had to learn to look through the entire time span of the
test, which meant from the time of lighting the HE on the primary to possibly
way after it collapsed, and we had to appreciate how everything was going to behave
through that whole time period, which is ten decades or more, because a lot of
it was uncontrollable. And we just didn't do that in the beginning. We did
things that worked fine for part of that time span, but were dumb for a
different part.</p>

<p class="tab">It was on Umber where a
particular thing that became obvious was that you had to concern yourself with
things that happen as late as collapse, and that you better be careful about
how you engineer stuff to survive collapse. Los Alamos had a line-of-sight pipe
with a bunch of valves going off to various things at the surface, and when collapse
occurred a couple of those valves sheared off. So, it just started leaking, and
there was nothing they could do about it. And it leaked quite a bit.</p>

<br>
<p><i>Bob Bass</i></p>
<br>

<p class="tab"><b>Carothers</b>: Bob, what do you think is the
fundamental mechanism that leads to containment?</p>

<p class="tab"><b>Bass</b>: Mass.</p>

<p class="tab"><b>Carothers</b>: Billy Hudson, years ago said
that he believed a foot of overburden was more effective for containment than a
foot of printouts.</p>

<p class="tab"><b>Bass</b>: I think that's probably true.
The question of the right overburden has often worried me in Rainier Mesa.
We're always firing in the same part of Rainier Mesa, but occasionally there's
been a reason why we wanted to pull one out closer to the portal. Then somebody
says, "We've got the same amount of overburden, so it's okay." But I
don't know that it's as good overburden when you get out towards the portal.
It's more of a chopped up mess there. It's got more stringers through it, it's
got more damage from erosion. I don't know that I would trust the same amount of
overburden there as I would way back in that mountain. I think you need a competent,
solid mass to contain a shot.</p>

<br>
<p><i>Paul Orkild</i></p>
<br>

<p class="tab"><b>Orkild</b>: I look at the structure first,
then the rock type, and then the water. And then at the stemming. Sometimes
stemming, to me, is the all important factor if the geologic media is benign. Stemming
is very important.</p>

<p class="tab">One of the things that I rely
heavily on is past experience. think predictions about containment depends
largely on judgment developed from past experience. I believe that's very, very
true. If we didn't have the past experience of the people who are on the Panel,
I think that it would be much more difficult. I think that what's going to
happen, when you get a new, younger generation, is that they'll struggle.</p>

<p class="tab"><b>Carothers</b>: No, they'll have this book.</p>

<p class="tab"><b>Orkild</b>: Oh, that's right.</p>

<p class="tab"><b>Carothers</b>: “What did Paul Orkild say about this situation?”</p>

<p class="tab"><b>Orkild</b>: Oh God!</p>

<br>
<p><i>Russ Duff</i></p>
<br>

<p class="tab"><b>Duff</b>: I guess as far as containment
is concerned, I would summarize my understanding of it by saying, “I don't.” I
have been working in aspects of containment-related science since the early sixties,
and I've been running the DNA late-time containment contract at S-Cubed for the
better part of twenty years. In that period of time I've become very aware of
the extreme complexity of the issues of containment. Containment is complex
because the phenomenology involved in the explosion includes not only shock physics,
but coupled to it are many other processes - thermal conduction, chemical
reactions, diffusion, condensation, and so on - which occur simultaneously at
extreme conditions. And they occur in modified media, and those media aren't
well known even before they were modified.</p>

<p class="tab">Those phenomena are extremely
complex, and our knowledge base is so limited, and our diagnostics are so
incomplete that not only do we not know very much, but we're not learning at a significant
rate either. I think that in the containment world we're dealing with a
situation where a lot of people don't realize how ignorant they are. If it ain’t
broke, don't fix it is an attitude which is unassailable in many respects, from
an engineering point of view.</p>

<p class="tab"><b>Carothers</b>: Or a bureaucratic point of
view. One of the things I've always felt hampered the achieving of a better
understanding of containment is the fact that the present system is
demonstrably successful - really remarkably successful considering how little people
know. And so, anyone quite reasonably could say, "Why in the world should
I spend any money on that stuff? You guys are doing great."</p>

<p class="tab"><b>Rambo</b>: That's a very strong argument,
and that's what I hear all the time. You have to convince somebody you need to
know something, for a dollar value, and that's where the nebulous part of this
decision making comes in. What more do you need to know? Until you have a
problem, you'll never know that you needed to know it.</p>

<p class="tab"><b>Duff</b>: I would make an alternative
argument. We know that Haymaker is the only event that has leaked in the 60
kiloton or so range. We have shot I don't know how many events that have yields
higher than that. Even in the days before Baneberry, without all the things we
do these days, there never has been a leak from events in that yield range, no
matter what was done or not done.</p>

<p class="tab">So, using that as an example, I
respond to your statement, "We have a successful program, so why spend
money," by arguing, "We have a successful program which is wasting a
lot of money in a lot of respects. If we better understood what was going on we
might save a bundle." It might well be that if we understood what was going
on we could bury events at, say, just to make up some numbers, a scaled depth
of burial of 80 meters, with an attendant savings of hundreds of thousands of
dollars in cables, and drilling, and stemming, and time. I can't prove any of
that, and that's the problem, but nobody can prove it's wrong either. We can't
really make a risk-benefit analysis and show that if you put out this much money,
you'll save that much. We can't do it because we don't know what the answer is,
or even what direction the search should take.</p>

<p class="tab">And we deal with a management
system, a real world environment, where containment is often a necessary evil.
You, Jim, have called it a reluctant science, because it is a drain on
important resources; time, money, and thought. And therefore, the Laboratories have
been very conservative in their designs. They have done very little in the way
of what I would call containment research. Their containment programs have been
largely minimalist programs. They do whatever is required to get the job done,
but no more. No more. The science of containment has not, to me, appeared to be
a matter of much concern to the Laboratories.</p>

<p class="tab">Now, I understand that, but as a
scientist who has lived and worked at both Los Alamos and Livermore, and who has
fond memories of those days, I am frustrated, and have long been frustrated, by
the propensity to rely so heavily on experience. And by the fact that so little
is done that is aimed at trying to understand what's really going on. There has
been relatively little research and analysis through the years by the people
who are doing most of the work, and progress has been relatively slow.</p>

<p class="tab">DNA, on the other hand, has at
least had a long-term, consistent program aimed at trying to understand what is
going on in some areas. Even there, however, there are very strong elements of
conservatism, and very strong parochial views, and play pens of one sort and
another. The economic, administrative, and political constraints which have
influenced the DNA effort are very real, and they are constricting to the
research aspects.</p>

<p class="tab">As a result, after spending a
very fair fraction of my technical career as a containment specialist, I can't
claim to understand what's going on very well. I think I have a broader
understanding of aspects of the phenomenology than many of the people who work in
the program, but that's only a comparative statement, not an absolute statement
in any way.</p>

<br>
<p><i>Bill Twenhofel</i></p>
<br>

<p class="tab"><b>Carothers</b>: Bill, when you look at a
proposed event, what do you look with regards to containment. What do you think
is important?</p>

<p class="tab"><b>Twenhofel</b>: I look to see whether there's
anything about this new shot that differs from previous experience, with
emphasis on geology of course. Are there any flags that come up that say,
"This location is different."</p>

<p class="tab">An active fault nearby that would
move a lot would concern me. And big acoustic interfaces, like the Paleozoics.
We don't have a lot of experience shooting near the Paleozoics. Obviously, high
carbonate content is a culprit. To summarize what geologic factors should be
looked at; faults, acoustic interfaces, carbonate content, clay content, and
anything that is not within experience.</p>

<br>
<p><i>Tom Kunkle</i></p>
<br>

<p class="tab"><b>Kunkle</b>: Why is it a hundred twenty
scaled meters keeps a shot in the ground? We have had shots vent. Only a few
times, but shots buried at eighty scaled meters have, on occasion, vented. Even
ones at larger scaled depths have. There is certainly historical precedent. Baneberry,
for example, a shot that was buried at what we considered a conservative scaled
depth of burial was able to push gas to the surface. So it is possible for
shots today to do that.</p>

<p class="tab">That's a point that we, in modern
times, tend easily to forget. We have such confidence in our calculations and
our history that we tend to forget that it really is possible that shots buried
at a hundred and ten, or a hundred and twenty, or a hundred and thirty scaled meters,
or absolute depths of four hundred meters, could vent to the surface. There's
some reason that they stay in the ground, and we think we understand that
partly, but we don't have any good corroboration. And so it's possible for me
to get worried about events, even very large, very deeply buried events.</p>

<br>
<p><i>Bill Flangas</i></p>
<br>

<p class="tab"><b>Flangas</b>: We tend to think of one kt as
just a little shot, but one kt is a fearful amount of explosion. If you convert
that to boxes of dynamite, you realize what a great amount of energy you've got
there. You do that under a variety of conditions, and a variety of ground
conditions - sometimes saturated with water, sometimes not, sometimes perched
water tables, sometimes a pattern of fractures that may or may not lead into
the ground zero, so there are a lot of variables. Sometimes they react
differently, but in one lifetime I think the testing community has just done an
extraordinarily good job of dealing with violent explosions, and controlling them.</p>

<p class="tab">Again, when you're dealing with a
dynamic force this big, after you've called your best shot, there are still
surprises. And they will continue to be there. I think though, between all of
us, we have certainly minimized them. I've seen published numbers of the shots that
have been done, and it's perfectly obvious we could not have done, in one
generation, our generation, that many hundreds of atmospheric events to achieve
the reliability of the weapons we have today. I can just not imagine us having
shot hundreds of atmospheric shots.</p>

<br>
<p><i>Bob Bass</i></p>
<br>

<p class="tab"><b>Bass</b>: I'll tell you where money ought
to be spent, when it is, if it ever is. I'm effectively quoting Billy Hudson's
ideas on this. I think it's important that containment not rule the
experiments. I think there has been a tendency in recent years for containment
to be the driving feature. "You can't do that, because it isn't a good containment
idea." Billy says, "No. Tell us what you need to do, and we'll figure
how to do it."</p>

<p class="tab"><b>Carothers</b>: That's exactly right. I know
that the Laboratories don't present some things to the CEP. They say, "Well,
we will just get hassled about this, so we won't do it." That's wrong,
because the CEP might say, "You ought to calculate this," or
"You ought to do that, and I'd feel more comfortable, but it can be done.”</p>

<p class="tab"><b>Bass</b>: Yep, “This is the rule, and
this is what we follow." I say, “Experimenters, come. Propose your
experiment. There's a way to do it." And if somebody comes up with a
reason to do something, we will find a way to do it.</p>

<br>
<p><i>Norton Rimer</i></p>
<br>

<p class="tab"><b>Rimer</b>: For containment, clearly
absolute depth helps. There's an example that's important that I don't think
has ever been brought up at the CEP. For example, if we ever shoot an event in
granite, we need a totally different depth of burial criteria to avoid seeps. I
did a number of calculations, probably fifteen years ago, for various reasons,
about shooting an event in granite. I think the containment depth I came up
with was at least 150 meters times the yield to the one-third.</p>

<p class="tab"><b>Carothers</b>: By the existing criteria, that
would be very conservative.</p>

<p class="tab"><b>Rimer</b>: Well, I don't think it would be
very conservative at all for granite. I'd be happy with 180, but you know what drilling
costs are. It's another medium, and for releasing gases it's a different ball game.</p>

<p class="tab">The stronger the rock is, the
more it's likely to have tensile failure. That's a funny thing to say, but it's
a question of equilibrium at the end. It's the question of continuity of radial
stress, which is a boundary condition. The amount that the radial stress can
differ from the hoop stress depends on the strength of the medium, so a stronger
medium can have hoop stresses much lower in compression than a weak material
like alluvium or tuff. A hard rhyolite is the closest thing to a granite that
we shoot in at the Test Site, but it's not near as strong - it doesn't have
near as high a wave speed. The hardest rhyolite I've seen, the seismic velocity
is 4,200 to 4,400 meters a second, and you can get a shear modulus out of that. Granite
is 5,500 meters a second.</p>

<p class="tab">I calculated Pile Driver ad
infinitum. Tensile failure occurred from the surface down to below the Pile
Driver cavity, in those calculations. Then we calculated deeper shots, on a
scaled basis, and even then I got fractures down to the cavity. It was only
when I got to higher than 150 scaled meters depth that there was a small -
twenty, thirty meters - zone of unfractured rock above the cavity . Now, the
porosity in some of those fractures was very small; ten to the minus three. On
the other hand, I didn't assume there were joints down there, so even 150
meters scaled depth I'm not all that happy with, for late time seeps.</p>

<p class="tab">That's based on tensile failure
calculations that we did for different yields and different depths. I think we
did 100 kt at 1,000 meters, 20 kt at 1,000 meters, 20 kt at Piledriver depth,
which was 460 meters. We did a number of calculations. We didn't do the whole
parameter space, and of course, the models were not as good back then. We've
improved some of the things in our description since.</p>

<br>
<p><i>Bob Brownlee</i></p>
<br>

<p class="tab"><b>Brownlee</b>: I really think that we have
reduced the probabilities of venting so low that what we're apt to get caught
up on is something trivial. That's what I think. I am convinced that nowadays
the probability, by the time we get a shot reviewed and down hole, of it
venting is very low for most of our shots. Of course, it's not the same for all
shots, so when we do a certain kind of shot, the probability could be much
higher. Now, I have argued you ought to react differently depending upon what
the circumstances are. You can take the view, and I understand it, that it's
good to always look for the worse case and plan your activities accordingly. My
response to that is, "Yes, but that communicates the wrong idea to
people."</p>

<p class="tab">My feeling is that on the average
shot now, if it cannot be compared to any previous failure, then we have to
postulate something brand new to have it fail. And we have been testing long enough
with a variety of different kinds of things that something brand new is highly
improbable. Our luck has been that if it is likely to have happened, it would
have happened to us. We would have given it the opportunity to happen already.</p>

<p class="tab"><b>Carothers</b>: Would you say, "That's
true as long as you confine yourself to the Nevada Test Site."</p>

<p class="tab"><b>Brownlee</b>: Oh, yes. That's implicit.
Notice what I said. "If you can't compare it with any failure we've
had." That means at the Nevada Test Site. If I go to a brand new area, in
a brand new medium,' I now have nothing to compare to. I have to assume, therefore,
that I have to start over.</p>

<p class="tab">When we talk about containment,
I've always lived in fear of some perfectly simple thing that everybody knows
is important doesn't happen to get done. Once in a while I know that I annoy the
dickens out of people here, because I ask, finally, "Did you get the
stemming in the hole?" What I'm really asking is, "Have you looked at
the things everybody takes for granted?" And they hate that question. They
just hate it. But I still think that we've got a chance one day of buying the
farm for the most indefensible, grossest, error.</p>

<p class="tab"><b>Carothers</b>: Duane Sewell would thoroughly
agree with you because, when he was at Livermore, he really was quite concerned
with safety. An often used expression of his was, "I'm concerned about ten
year-itis." You put some new people on a job, or project where something
bad could really happen. They didn't know what they were doing, so they
worried, and they worked hard, and they learned, and after a time they got to
where they were, in fact, experts. And they did this risky business all the
time.</p>

<p class="tab"><b>Brownlee</b>: And ten years later?</p>

<p class="tab"><b>Carothers</b>: Ten years later, of course,
"This is a piece of cake." But it's not a nicer piece of cake. It's
no less a hazard than when they first looked at it.</p>

<p class="tab"><b>Brownlee</b>: And it may be more of a hazard,
because in the meantime they've changed a cable, and they've changed the firing
set, and they've changed something else. And you've also probably changed out
the person who did it, and who remembers?</p>

<br>
<p><i>Byron Ristvet</i></p>
<br>

<p class="tab"><b>Ristvet</b>: Let me emphasize we have two
definitions of containment at DNA. One is in the classic CEP sense. At one time
our containment experience with horizontal line-of-sight shots wasn't much
better than the vertical experience of the Laboratories. Today, with regards to
the CEP kind of containment, I have very little concern about uncontrolled
leakage to the atmosphere from a DNA event. That is especially true now with
the lower yield events. For low yields our tunnel volumes are huge, so any
threats against the plugs are rather small, and it really makes that part
pretty straightforward. Especially because we proof test everything, and we do
spend a lot of time on attention to detail.</p>

<p class="tab"><b>Carothers</b>: The DNA people really work very
hard to protect the samples. If they achieve that, any release is very
unlikely.</p>

<p class="tab"><b>Ristvet</b>: That's exactly correct. Sample
protection is our other definition of containment, and that is very important
to us. We have spent a lot of effort trying to understand how to be as
confident of that as we are about a release to the atmosphere, but there can
still be surprises there.</p>

<br>
<p><i>Ed Peterson</i></p>
<br>

<p class="tab"><b>Peterson</b>: Let me tell you what I think
our design philosophy for the line-of-sight events has been very recently, and
in which I really believe. I think that in a containment design you have to
make the first closure, the one that's closest to the working point, sufficiently
strong so it can act as a bulkhead to the stemming. You have to know that
closure works, and no matter what pressures you get in that stemming for
whatever reason, you won't extrude the stemming out through that bulkhead. In
the low yield case this has so far worked satisfactorily with the FAC. I
suspect in the standard yield shots we have from now on the first closure will
be a real heavy-duty closure that can do that. DNA has been designing one like
that. So that's sort of number one.</p>

<p class="tab">I think the second thing you have
to do is, once you understand within your error bars what the conditions of the
formation are where you're working, and you know your yield so you know where to
place that closure, you then make your line-of-sight pipe so it fits the
closure at that place. In other words, you don't move your closure just to
accommodate a bigger pipe taper.</p>

<p class="tab">I think those two things are
basic. Make sure that first closure can act as a stemming bulkhead so you can't
extrude your stemming out, and then make sure you position that closure
correctly, and make your line-of-sight pipe taper accordingly. I think those
are the two major design features. All the other stuff is nice, and all the other
stuff you should probably do, but those are the ones I think will save you if
something goes wrong.</p>

<p class="tab">Of course, you have to go into
things you consider sort of QA, such as making sure your tunnel diameters are
right, making sure that the grouts are in per their design characteristics, and
on and on like that. We aren't to the point where we want to throw any safety margin
away.</p>

<p class="tab"><b>Carothers</b>: To oversimplify, "Don't
get too sophisticated. You've got to have some strength close in to handle
things. If you have that, it will make up for a lot of what you don't
know."</p>

<p class="tab"><b>Peterson</b>: I think that's true. I think we
do a lot of, call them good analyses or sophisticated or difficult analyses,
and I think they've been very good in that they have given us a way of thinking
about things. In other words, they give us some idea of how things may be
occurring, and what parameters may be important, and which ones may affect you.
But I don't think that at this point you can consider them predictive type
analyses you can base a design on. I think that since you don't want it to
leak, you'll want to look at the things that will serve as a brute-force type
of containment.</p>

<p class="tab">One of the calculations we do
routinely is to look at the conditions at both the overburden plug and the
gas-seal plug. We've looked at them compared to events where stuff has gotten
into the tunnel, and we have not as yet measured anything in the tunnel that is
worse than our worst case prediction. Exactly why I don't know, but we haven't.
And I think those plugs are very important as far as backup goes. Everybody
wants to design the tunnel stemming right so nothing gets into the tunnel complex,
for obvious reasons. But I don't think you could ever guarantee that something
won't happen.</p>

<p class="tab">It is a little frustrating, and
discouraging sometimes, to look at what you've done, and realize that you
cannot really model containment as such. I suppose one would like to, but I
don't know how soon that will be possible.</p>

<p class="tab"><b>Carothers</b>: Well, there are people who
believe you can build an expert system and just punch in the parameters of the
shot, and it will tell you what to do.</p>

<p class="tab"><b>Peterson</b>: I think those are only the
people who don't understand. My picture of the expert system may be different
than yours. I see the expert system as being able to provide you with some idea
of things that have gone on before, and some idea as to why they've gone on. In
other words, if you come up with a particular problem you might be able to
access your expert system and put in that problem, and then you might be able
to call up what Joe LaComb says one should do. But I think it's going to be meaningless
unless you also get the Joe LaComb type person to tell you why he thinks that
is why you should do it. If you don't get the understanding behind it, I think
just having the facts are worthless . So I think the expert system might give
you some aid in being able to learn how to think about it, or at least know
what previous people have thought about it.</p>

<p class="tab"><b>Carothers</b>: There's more to knowledge than
facts. I have a little poster my daughter Margaret once gave me. It has a
picture of three apples. One is green, and one is yellow, and one is red, and it
says, "Time ripens all things. No one is born wise." And so sometimes
it is worthwhile to talk to a person who has had time enough to get a certain
amount of wisdom. It's often easier to find facts.</p>

<p class="tab"><b>Peterson</b>: That is true. People like Gary Higgins
and Russ Duff and Bob Brownlee and Joe LaComb have an insight, from having been
around the program for so many years, that other people just do not have. And
it will eventually get lost. You can't learn from them all the things that they
know.</p>

<p class="tab">I think when I first came to S-Cubed
people sort of believed they understood containment. Now, there were always
disagreements within the community as to what we understood, but one cannot
really argue against success. I think it has become apparent, in the last seven
tests, say, even though most of them have worked extremely well, that some of
the things we thought we understood we really don't understand well at all. And
I think everyone, or nearly everyone, in the community is beginning to believe
that. I think that belief is also necessary in order for people to go forward, and
so I think that has been a benefit in gaining understanding .</p>

<p class="tab">If you get down to the more
technical detail of things, I think we have hurt ourselves by
compartmentalizing things. There have been various efforts over the years not
to do that, but for whatever million reasons, that is the way it has come out.
We have divided things up on time scales, and divided things up between work groups.
As an example, we look at pipe flow, and we look at cavity growth and cavity
conditions, we look at ground motions, we look at stemming plug formations, and
we look at late-time leakage. All of those things are very important, and they
all ought to be looked at. And the capability to look at each one of these
needed to be developed. But when you break them up in order to develop them, I
think you lose sight of the fact that you've only broken them up so you could
look at them individually and develop some type of model. You lose sight of the
fact that they are interactive, and you forget to look at the interactive part.
I personally believe, in terms of the modeling and the understanding, that is
the next direction that one has to go.</p>

<p class="tab">In other words, if I understand
material properties perfectly, I'm not sure I'm going to be able to calculate
containment anyway, because I don't know how material properties interact with
all of these other things. So, I see that as the thing that really has to be addressed.
I have no idea how to do it. Everyone has ideas, but it's nothing trivial, so
one shouldn't look at it and say people over the last fifteen years have
neglected it, or something like that. It's an extremely difficult thing to do.
I'm not sure how one can do it, but I think you have to look at it.</p>

<p class="tab">Another thing is that I think we
don't even know how to proceed on some of the problems from the physics
standpoint. It isn't that you don't have an expert; you don't even know what
you should be expert in. Jim, you're very familiar with it, you've sat through all
of these things for years. You know, for example that even on something like a
Mighty Oak, the leakage doesn't come until on the order of seconds or minutes.
Our calculations stop at less than a second. If we have a stemming column that
"fails" enough to let something leak, maybe it has another half a
percent porosity compared to one that works perfectly. You don't even know
exactly what physics to start building in, or how to do it. So, I don't even
know how to interact with a neighbor who's doing a different calculation. I
don't even know what kind of an expert I ought to go talk to. It's just that
there are very fundamental questions that are hard to get an answer to. I don't
know the answers. We've learned a lot, but I'm not sure that we understand containment.
We know a lot more about it than we did, but I don't think we really understand
it.</p>

<br>
<p><i>Carter Broyles</i></p>
<br>

<p class="tab"><b>Broyles</b>: I think we at Sandia still take
seriously the charge we got when we went back to testing after Baneberry, which
was that each of the three Labs was charged with an aggressive, active R&amp;D program
for containment. And I've used that to justify our program. A lot of people say
Sandia doesn't sponsor tests anymore, so why should it waste its time? It seems
to me that we have served a useful purpose as an independent group, without an
ax to grind, a lot of times. Perhaps it's useful to have that third party there
at the CEP, and other places.</p>

<p class="tab"><b>Carothers</b>: It is. And, your people have
produced a lot of very useful data.</p>

<p class="tab"><b>Broyles</b>: Well, we certainly have had a
better record than a lot of other organizations. We've had a lot more
continuity and devotion, but you can get into all sorts of philosophical
arguments having nothing to do with containment about what produces good results.
I still hold, as a personal belief, that if you have the total responsibility
for the program, as well as the measurements, you're going to come out on the
whole with better results. It's not that you've got better people, but you
don't have the artificial divisions where things tend to fall through the
cracks that you have if you have six different contractors doing different
parts of the job, and then trying to have what is essentially a contract
monitor put it all together.</p>

<p class="tab">Something I've seen over the
years, probably more in the last five than in the early days, is a more
cooperative, not only attitude, but effort on the part of all of the players
toward working together, sharing their capabilities. I think DNA, and LASL, and
Livermore working together, reinforcing each other, has contributed a lot more
now than it did in the early days of Baneberry and prior to that.</p>

<p class="tab">But everybody has, Sandia just as
much as anybody else, the feeling that if we didn't do it we can't trust it.
When you've got the responsibility - that's something that a lot of people in
the system have never faced. It's like the General who's developing the Minuteman,
or the Admiral who's developing the Trident. When his neck is on the line, and
he has to guarantee something, that's one thing. If you sit down and ask for a
scientific judgment, that's another thing. What you demand in proof, I think,
is justifiably different in the two cases. I can be scientifically very certain
that something is true, but am I willing to bet the nation's security on it? That's
different, and the proof I'm going to ask for is going to be different. I can
recognize that, when I sit back and try to be objective. There are a lot of
people not connected with the test business who don't really understand that,
because they've never been in those kinds of positions.</p>

<br>
<p><i>Tom Scolman</i></p>
<br>

<p class="tab"><b>Scolman</b>: Frankly, my biggest concern
about containment is that the CEP, over the years, has evolved into some kind
of ritual rain dance, which forces us to do things not because they make a hell
of a lot of sense, but because it's what we've always done. Unfortunately,
while we at one time had an organization called a Containment Research
Committee, one really can't do research on containment, because you're not
allowed to do an experiment that pushes you beyond the known containment
boundaries. So, we are more or less forced to do things the way we've always
done them before. Take one of the points that I referred to earlier; the fact
that the containment scheme that Los Alamos uses, at least, was largely designed
in the days when all holes were cased, and I think many of the things we do
don't really make an awful lot of sense, or are completely justifiable in the
days when a majority of our shots are done in uncased holes.</p>

<p class="tab">For another example, I think
there's a great deal more to the containment business than depth of burial,
which always comes from the same scaled depth. That assumes you're shooting in
a known, homogeneous media, and you never do. I argue, for example, that with
the faulting that exists at the Nevada Test Site we have probably, without
knowing it, fired in almost any configuration you could have managed with
respect to a fault. And yet we sometimes reject shot locations because of
proximity to faults. We worry about reflections from hard layers, and yet we
can't find those hard layers when we do seismic work. We know the layers are
there, but do they matter?</p>

<p class="tab"><b>Carothers</b>: What you're saying is seismic
work uses acoustic reflections and you can't see those layers. So, how can the
shock wave from the shot see them?</p>

<p class="tab"><b>Scolman</b>: I've asked that question
several times and haven't had any answer yet.</p>

<p class="tab">Local geology is important. There
are blocks, joints, faults, little ones, big ones. I think what you come back
to is the fact that you cannot calculate in the detail that would be necessary,
for a number of reasons. The thing you really fall back on is previous experience.
And that drives you into doing things that, while they may not be completely
justifiable in a theoretical sense, at least they've worked, and it's hard to
go away from them.</p>

<br>
<p><i>Carl Keller</i></p>
<br>

<p class="tab"><b>Keller</b>: At DNA I think we had a
different concept of what the future held than the Laboratories did. We had the
time to develop test concepts, and the presumption was that we were going to
keep on testing, and that we would need these things. The Laboratory people
tended to be in a reactive situation where, if they were going to spend
anything on research, it had to be identified as necessary to do a particular
shot. And that shot almost never was more than a year or so away, and so all
the work had to be done at least six months before the shot. So, what was done
was generally only in reaction to a unique geologic circumstance, or a unique
test geometry.</p>

<br>
<p><i>Bruce Wheeler</i></p>
<br>

<p class="tab"><b>Carothers</b>: To what extent do you think the
containment requirements, which were severe, had an impact on the programs you
were trying to accommodate? Did they really constraint you?</p>

<p class="tab"><b>Wheeler</b>: I don't think the containment
requirements had a great impact in terms of how long it took to get the test
ready - to build it, and get ready to go. They added some cost, but it wasn't a
lot in terms of the overall cost. Back in Misty North times, that was a
twenty-five million dollar shot. Diamond Skulls was thirty-two million. Those
two shots today would probably be a hundred million each.</p>

<p class="tab">So, whatever incremental cost you
could attribute to the increased containment concerns had to be a small
percentage. So, I never looked at containment as something that got in our way;
rather I looked at it as something that if we did it right would help the
program continue.</p>

<br>
<p><i>Billy Hudson</i></p>
<br>

<p class="tab"><b>Carothers</b>: Billy, it has been my
impression that you are not a strong believer in the residual stress field as a
basic, or the basic, mechanism for the containment of a shot. Comments?</p>

<p class="tab"><b>Hudson</b>: So there's residual stress. We
may always have residual stress of some sort, but is residual stress the key to
containment? I can imagine residual stress in a medium comprised of marbles,
but marbles wouldn't be a very good container for high pressure gas. Cracks can
open, the ground can shift, rocks can shift around. At a quarter of kilobar or
so, which is sort of where the residual stress regime is, you wouldn't expect
these openings to be smashed shut again. So it's not clear that residual stress
can affect containment in the first place, even if it is there.</p>

<p class="tab">An interesting puzzle is
Baneberry. We didn't talk very much about residual stress before Baneberry, if
we did at all. The Baneberry release didn't begin until something like three
and a half minutes after the shot. It's hard to tie that time into the models
that have been proposed. Most of the models would show failure at much earlier
times.</p>

<p class="tab">I think containment is a
combination of hydrofractures, leakage into porous storage areas, residual
stress fields which prevent continuing hydrofractures, good stemming plugs.
It's all of that. We know that the failure of a stemming column can cause a
release, but probably there's not nearly as critical a relationship as far as
the residual stress, or the hydrofractures are concerned.</p>

<p class="tab"><b>Carothers</b>: What about the difference in
the containment between the hundred kiloton shots and the one kiloton shots?</p>

<p class="tab"><b>Hudson</b>: There was a perceived
difference that the big shots didn't leak, the little ones did. But as we started
to take measurements, as we began to get some data down hole in the stemming column
on the higher yield events, we discovered their behavior, at least in the
stemming column, was much more like the low yield events than we had suspected.
At one time the data seemed to indicate that if events were of higher yield
than between ten and twenty kilotons, gas just didn't get out of the cavity.
But then we started making measurements in the stemming column on events with
yields in those ranges, and we discovered that gas got out of the cavity just
about as often, and went as high, as it did on low yield events. So, high and
low yield events may not be as different as we once thought. It may be a matter
of depth more than yield. If you bury them deep enough, even though the yield
is a lot higher, they may be more likely to contain. We really don't understand
the difference, but the phenomenology is not as different as we once thought it
was.</p>

<p class="tab"><b>Carothers</b>: There is an argument about the
observed lack of releases from high yield shots, advanced by Gary Higgins. He
says, "Well, that's easy to understand, because you guys are using the wrong
scaling law. The containment depth really doesn't go as the yield to the 1/3
power. Because there's the gravity field it really goes as the yield to the 1/3.4
power, properly. There's no difference at one kiloton, but the higher the
yield, the more conservative you're being if you use an exponent of 1/3 instead
of 1/3.4. You could have shot Cannikin at 4,000 feet, rather than 6,000,
perfectly safely, using the right scaling."</p>

<p class="tab"><b>Hudson</b>: The scaling laws, it seems to
me, only concern prompt venting, not the seepages. With regard to seepages, I
don't think the bomb knows how deep it is. It just tries, however it can, to
find its way to the surface. In the dynamic case there are all sorts of things
going on. There is spall. If it's deep enough spall is not a problem. You have
large fractures formed radial to the cavity. Clearly, if it's deep enough none
of those are going to get close to the surface. As far as the dynamic features
are concerned, Gary Higgins may be absolutely right. It could very well be that
the scaling rules we use really don't apply. Unfortunately we don't understand
these relationships well enough to argue convincingly that we should bury
higher yield shots at shallower scaled depths.</p>

<p class="tab"><b>Carothers</b>: Well, after Baneberry there
wasn't any testing for about six months. Prior to that time, about a third of
the shots released activity, sometimes a lot, sometimes a little. After Baneberry,
that pretty much stopped. What happened? I don't think you learned anything new
in those six months, but all the leakages stopped, with the exception of four
events over twenty years. What do you think accounts for that?</p>

<p class="tab"><b>Hudson</b>: One cause was that we adopted a
minimum depth of burial. Statistically, for events sited in alluvium before
that time, approximately twice as many events involved a release if they were buried
shallower than 500 feet, as those events buried deeper than 600 feet. And so,
one of the things we did was to adopt a minimum depth of burial. What that did
was to avoid some of the higher carbonate content alluvium near the surface.</p>

<p class="tab">Even before Baneberry we had
adopted the practice of putting cable gas blocks on all cables. I think that
was just shortly before Baneberry. The combination of those two acts - putting
in the gas blocks, and increasing the depth of burial - I think was primarily responsible
for eliminating most of those releases.</p>

<p class="tab">Right after Baneberry we did
quite a few things that we later stopped doing, because we didn't need them.
For example, when we had experiments in the emplacement pipe we had sections of
the pipe that were malleable. We thought that would help the ground shock
closure. These soft pipe sections were fairly expensive. We never did show
whether they helped or didn't help, and after a while we decided we didn't need
them. We did a lot of things right after Baneberry. Everything we could think
of, almost, became a viable suggestion as a solution to some problem.</p>

<p class="tab"><b>Carothers</b>: The minimum depth of burial of
600 feet has carried on to today. There are people who occasionally grumble about
that when they do a twenty ton shot. Do you think it's really needed for shots
like that?</p>

<p class="tab"><b>Hudson</b>: The answer is, "Of course
not. It's not always needed." The problem is, you never know exactly what
the yield is going to be. You never know for sure when you're going to need that
depth. If the maximum credible yield is really twenty tons, you probably don't
need the 600 feet. Then you have to decide what you do need, and why the shot
is going to be contained as well at a shallower depth. After a while people
would probably decide that it was easier and cheaper just to use 600 feet.</p>

<p class="tab">Actually, it's questionable
whether we should be shooting in alluvium at all. You will notice that there
have been very few shots in alluvium since Agrini. Agrini was a shot in
alluvium, and there was a release through a strange subsidence crater. The
crater was something like 200 feet deep; very deep compared to its diameter. So
there was probably much less rubble to filter the gas and debris before they
got to the surface than on a normal shot.</p>

<p class="tab">After intense study of the Agrini
event, we decided the only thing we could have done that would really have
guaranteed that we didn't have that late time release would have been to avoid
the non-condensable gas, which is primarily the carbon dioxide released from
the carbonate minerals in the cavity region. While no one made a public
statement about it, for several years we did not fire events in alluvium.</p>

<p class="tab">Statistics suggested that it you
stayed at carbonate contents below 5% it was unlikely that you would have a
late time release problem. Above 5% you're much more likely to. We had the
Riola event, which was a case where a plug failed, and we had a late time release.
The carbonate content for Riola was only about 2.5%, so people tended to
ignore the carbonate problem, and focus on the plug that failed. Then Agrini
came along, where we had a late time release with a strange subsidence crater;
and the carbonate content was 2.54%.</p>

<p class="tab">I argued that in both cases we
might very well have had a release without the strange occurrences associated
with those events, and that if we wanted to avoid that sort of release we
should stay out of the alluvium. Often we really can't tell what the carbonate
content is. We make measurements, but they're not representative, and it could
be that the carbonate content at either of those two sites was high enough to
cause a release.</p>

<p class="tab">In tuff we've only had one event,
as far as I know, in the history of testing, where there was a late time
release, and no one really understands why it happened on that shot. I talked
to Larry McKague about that, and he suggested that perhaps there was a pocket
of stream gravel, in the vicinity of the working point, that could have given
rise to that release. If you throw that one out as maybe being a weird
geometry, there just isn't enough carbonate in tuffaceous material to be a
problem. But you can always have it in alluvium.</p>

<br>
<p class="tab">Billy Hudson's closing words
perhaps make a suitable summary and ending for this book:</p>

<p class="tab"><i>I guess the upshot of all that
is, we still don't really understand containment very well.</i></p>


<a name="appendix"></a>
<br><br>
<h2>Appendix</h2>
<br>

<p class="tab">The people who made this book possible.
Some things about them in their words.</p>

<br>
<p><i>Fred App, LANL - Alternate Panel Member</i></p>
<br>

<p class="tab">I went to school at Penn State,
and my degree is in geophysics. I graduated from there in 1959. From there I
went into the oil patch with Continental Oil Company, and spent six years in exploration
geophysics, mostly with seismographs. It was mostly field work, but there was
some analysis. About the first four years were field work, and the last two
were mostly in the office.</p>

<p class="tab">In the field we did a standard
type of reflection geophone seismic survey to determine the structural
configuration of the strata. One way of doing that is to put the energy source,
dynamite, down a hundred foot deep hole. You have several holes spaced some
distance apart, depending on what kind of a survey it is, and then there is a
surface geophone layout to pick up the signals. We have done them at the Test
Site.</p>

<p class="tab">There are various types of
surveys that are made; there are explosion surveys, and vibroseis surveys. The
vibroseis sends out a sweep of signal frequencies in about six or seven seconds, and no frequency repeats
itself in the sweep. So, it's a unique wave form that goes out, and they cross
correlate what comes back with the sweeps, and you end up with your actual time
history recording. The vibroseis system was invented by Conoco, and at the time
I was working with them nobody else was licensed to use the system. Only Conoco
had it.</p>

<p class="tab">There were two reasons why I left
Conoco. One, I simply got tired of that particular line of work. I wanted to
move into hard rock geophysics, that I thought would be more interesting. The
other reason was that in order to be successful, and really advance with the
company, you would, almost by definition, end up in Houston. That was the
headquarters, and was not an end point I desired to be at.</p>

<p class="tab">Another option was Ponca City,
Oklahoma, which was better. It's north of Oklahoma City. Of course, if you look
at a frequency chart for tornados, you'll see a contour closure that takes in
Wichita to the north, and Oklahoma City to the south. And Ponca City is right
in the middle. But it's a nice place.</p>

<p class="tab">So, for those reasons I decided I
wanted to try something different, and for a short while I was with Anaconda,
in Butte, Montana. That was a mistake. It was copper mining, in deep mines. In
Montana I was working below sea level, an indication of how deep the mines are.
One mine was 6,000 feet deep. It took a while to get down, and to get back up.</p>

<p class="tab">As far as I was concerned, that
whole operation was very dangerous. The company itself was not very safety
conscious. There were many ladders with rungs missing, and that sort of thing. They
had No Smoking signs right at the shaft, and of course everybody would be
smoking - and that was the only way out. I left primarily because of the safety
problems.</p>

<p class="tab">I returned to my wife's home town
in North Dakota. I had quit Anaconda without having another job lined up. I
started reading the classified ads in the papers, and applied for and got a job
with Control Data. Control Data at that time was a booming outfit, and the
reason they were booming was because places like Los Alamos and Livermore were
buying their 6600 at that time.</p>

<p class="tab">At that time Control Data was
flush with cash, but they were shy of programmers. So they decided to try an experiment.
They decided to take applicants from everywhere - one person might be an art
major, just out of school. Another person might be an electrical engineer who
had been in the business for ten or fifteen years. In one case they took a
seismic explorationist, namely me. I believe there were about 35 in the group.
We were brought in to Minneapolis, but they did not bring our families because
it was quite intensive training; days, nights, and weekends. You had enough time
to sleep and that was it. A second reason for excluding families was because if
you failed the course, you were not hired. I successfully completed the course,
and became a permanent employee of Control Data. I stayed with them for five
years. However, all along I knew I did not want to remain in a large city, so I
continued searching for employment.</p>

<p class="tab">In 1971 I read an ad in the
Minneapolis Tribune, offering jobs at Los Alamos, with talk about the beautiful
mountains, and skiing, and hunting, and all that sort of thing. These jobs were
for C Division, which is the computer division. I applied, and they invited me
down. I talked to two C groups. In the meantime Bob Brownlee happened to see my
resume, and he asked to interview me as well. After I had interviewed the three
groups I had no doubt about my first choice. The way Bob described the
containment work, and what was involved, appealed to me.</p>

<br>
<p><i>Bob Bass, Sandia - Shock Physics</i></p>
<br>

<p class="tab">I'm a physicist, so to speak. I
went to school in Lawrenceburg, Missouri, which is near Kansas City, in my grade
school days and high school. My high school background is rather mixed-up, and
strange, and messy - screwed up by the war.</p>

<p class="tab">Missouri had a very strange, and
little known situation. It was patterned after the University of Chicago, where
you can start to college whenever you're ready, and whenever you can pass the entrance
exams. There was not even a limit, at that time, on how many hours of high
school credits you had to have. So, I and about four or five other people in my
high school class decided we had had enough of high school We decided, "Hey,
we've had enough of this. We know everything. Let's go to college."</p>

<p class="tab">So, I started in college, at the
age of fifteen, at a place called Central Missouri State College, which is now
Central Missouri State University. By the time my high school class graduated I
was well along as junior in college, mainly because there was this Navy V-12 program
at the school, so it was on a trimester basis. So, you could get sixty hours in
one year, and I did. By the time my high school class graduated I think I had
about seventy hours of college credit. And I had no problems with that at all.
It was easy, duck-soup easy. I was also helped by the fact that I was six feet
seven inches tall at that time, and weighed about 220 pounds.</p>

<p class="tab">I stayed there for one year plus,
and then went to the University of Missouri. I started out in chemical
engineering, or something like that. I had studied more chemistry than anything
else, but it was all physical chemistry. Then the draft came along, and I ended
up in the Navy, at first.</p>

<p class="tab">I went to San Diego, and went
through part of boot camp there, and then they discovered I was too tall to be
in the Navy. The war was over, so they said, “Out." I said, “Fine. I'll
go." So, I went back to Central Missouri State, and graduated right away.
Over all, I think I finished in two and a half years. The degree turned out to be
a double major in chemistry and physics, with some background in economics, of
all things. And what are you going to do with that?</p>

<p class="tab">So, I went looking around a
little for a few months, doing nothing, and I ended up going to graduate school
at the University of Missouri, in physics. I had discovered that chemistry was
a nice, interesting field, with some very nice people as professors. Some of
the most entertaining people I have ever known were organic chemists. But, I
didn't feel too comfortable with all of that, so I ended up at the University
of Missouri, in physics. I fiddled along at Missouri, not being the greatest
student in the world, to be honest about it all. But I was chugging along, and
then came Vietnam.</p>

<p class="tab">At that time there was no such
thing as an educational deferment, and so I was draft bait, and I ended up in
the Army. I ended up in Fort Hood, Texas. Just about that time they were beginning
to think there should be educational deferments, and they had begun selecting
out people with some educational background. They were sending these guys back
through the Pentagon for assignment, as enlisted men, all over the United
States. I ended up at Fort Myer, in Washington, and at that time they were
getting ready to do a thing called Operation Windstorm.</p>

<p class="tab">Operation Windstorm was an
underground shot, scheduled for Amchitka in 1951. It was to be a cratering
event. So, they had all these plans going forward, and the Signal Corps had a
major project to measure the residual contamination from a cratering burst.
They contracted this job out to the National Bureau of Standards, and lucky me,
I got to go to the National Bureau of Standards, in Washington, as a civilian
guest worker. The Army sent me there, on travel status, and I spent two years
on travel status for the Army, working at the Bureau of Standards.</p>

<p class="tab">Then it became obvious that
Amchitka was the wrong place to be using as a test site, because, for one
thing, the Russians were listening in on it all the time. At the NBS we had
built a huge system, to be used on Amchitka, to measure residual contamination.
Everything was in waterproof packaging. It was to be installed in prefabbed
underground concrete structures that had been built by the Navy up in Seattle,
or somewhere. We were all done; we were ready to go. The Navy was ready to
start shipping these prefab structures to Amchitka. And what did they do? They
turned around and shipped them all to Nevada, and this became instrumentation on
Jangle ESS. So, we had all these waterproof concrete bunkers out in the desert.</p>

<p class="tab">The detectors were all
underground in these structures, and they jumped up out of the ground after the
blast wave went by; there were elevators to raise them up. There were 121
channels, and we recorded 121 channels of perfect data. Of course, we had two years
to get ready. And in those days we had an unlimited amount of money, and we had
the whole backing of the National Bureau of Standards to get good data. I have
never been associated with something like that before or since.</p>

<p class="tab">When I got out I went back to
finish my doctorate. Then I made the greatest mistake of my life. I left the
Signal Corps in July, drove back to Missouri, drove back to the campus of the
University of Missouri, and went to visit friends in the veteran's housing
area. I looked at the poverty those guys were living in, and I said, "I can't
do this. There's no way." I was making 850 dollars a month in 1953. That
was pretty good income. I was single. When I was living in Nevada we were
getting expenses the whole time. I was very rich. It was more money than I knew
what to do with.</p>

<p class="tab">Looking at the campus
environment, I couldn't do it. I said, “I'm not going to do that. That's not
for me, right now. I'm making too much money." So, I went to work at a
radio station, and fiddled around. At the time, though, I had met some people
from Sandia, working at the Test Site. I liked what I saw, I liked what they
did, and I said to myself, “The Department of Defense is on the outer edge of
all this. I'd rather be in the middle." So, I knew people from Sandia, and
that's where my formal education stopped for a while. I decided to capitalize
on what I had done through the years, and keep on making money. But I went to
work at Sandia for 500 dollars a month, so I took a big cut.</p>

<br>
<p><i>Robert Brownlee, Los Alamos - Panel Member</i></p>
<br>

<p class="tab">I did my undergraduate work at
Sterling College, which is a small four-year college in central Kansas. When I was
an undergraduate I couldn't decide whether to major in math or physics, so I
majored in both of them. I got my degree, but meanwhile a war had intervened.
Then I went to the University of Kansas, where I got my master's degree. After
that I decided, "I think I'll just go into astronomy." It turned out
that all my training was not immediately applicable to astronomy, so I had to
go back and pick up all the undergraduate courses in astronomy. I then went to Indiana
University, where I got my Ph.D. from Indiana University in 1955. I got my
degree in astronomy and astrophysics.</p>

<p class="tab"><b>Carothers</b>: Well, that's an impractical, but interesting
branch of physics.</p>

<p class="tab"><b>Brownlee</b>: Precisely what my
father said. When I graduated the astronomy world was a closed system. The
heads of the astronomy departments in these several schools decided, in some
dark closet, two or three times in the course of the school year, which of
their students they would graduate, and which they would flunk out. What they
did was match the graduates with the openings they were going to have the
following year. So, when you graduated, the head of your department whispered
in your ear, "You should apply for that job over there. You'll have a good
chance of getting that one, but don't bother applying for that other one,
because you don't have a chance." I think the year I got my Ph.D. there
were four of us in the U.S., because that was all the openings there were. But
the year I graduated I had two job offers, which was twice as many as you were
supposed to have.</p>

<p class="tab">It came as a great shock to my
father. "Why would anybody pay you to know this stuff, which does not
contribute to the growing of any food of which I'm aware?" As you can see,
I grew up on the farm. That roots you in a tradition that allows you to see
pretty clearly, and detect pretty quickly, city slickers and charlatans of various
kinds who always think farmers are, after all, dumb or they wouldn't be
farming. Some of the wisest people I've ever met have been sitting out there on
the farm. Why and how do they get wise - not just knowledgeable, but wise?
Well, I'll tell you. They sit plowing. You can plow one field for weeks where I
grew up, and you do something with your mind during that time. You can't sleep,
but you can think. And you have time to sort out a lot of things. I think all
farmers are philosophers.</p>

<p class="tab">I think I was about five when I
asked my father what made the sun shine. He said, "Nobody knows."
Well, I was greatly shocked, and I can remember saying, "But Uncle Mason
would know." And he said, "No, Uncle Mason doesn't know either,
because nobody knows what makes the sun shine." I was in awe that here was
something that no one knew.</p>

<p class="tab">It turns out that was almost
identically the time that Hans Bethe first figured it out. He used to come to
Los Alamos regularly every year, and he still does occasionally. Sometimes I
would work with him on something, and when I would sit in the room with him I would
think, "Here is the man, the very first man in the history of the
world who understood what makes the sun shine, and he's right here in this
room." As a matter of fact, I still feel that kind of awe. Because you
see, to me that was vastly more important than how much wheat we were going to
get that summer. But, of course, I was living on the wheat, so that was
important too.</p>

<p class="tab">I regarded that question, “What makes
the sun shine?" as just awesome. My dad didn't realize that would change
the history of the world. I didn't realize it either, but I came along at just
the right time. When I got my degree in '55, I took the job that nobody counted
on me getting. That was the one at Los Alamos. The other offer was for the
vacancy in the Astronomy Department in Nashville, Tennessee. That was the job
that had been programmed for me to get.</p>

<p class="tab"><b>Carothers</b>: Were these professors
aware that Los Alamos was interested in astronomers, or willing to hire them,
or was this a surprise?</p>

<p class="tab"><b>Brownlee</b>: They were aware of it,
and unalterably opposed. It turned out that a colleague also came to Los
Alamos, and he and I were ostracized by the astronomical community for some
years because we had gone to Los Alamos against all the programming we had. We
were slated for these other jobs.</p>

<p class="tab"><b>Carothers</b>: What led a nice boy
like you to fall in with this bunch in New Mexico? You had an offer for a reputable
job in Tennessee.</p>

<p class="tab"><b>Brownlee</b>: Yes, but after I had
done my thesis work on W Ursa Majoris I had done a solar model, a model of the
sun. I had worked it out for one moment in time. Here is a model of what the
sun was - never mind that it's evolving one minute every minute. This is what
it was, static. I did that the last year, and I was very intrigued by that.
There were a number of questions we couldn't answer; things we just didn't
know. Los Alamos was at that time the only place in the world that I knew about
where you could get your hands on the center of a star, and have a chance to
make observations on it. And one of the things they at Los Alamos wanted to do
was to measure the opacity of materials in fireballs.</p>

<p class="tab">Now, that was exactly the kind of
information I needed for models of the sun, or for stars in general. It seemed
a great oddity, even to me - of course, I was influenced by my father - that somebody
would pay me to do an experiment on a fireball which gave me exactly the
information I needed for stars, which were hopelessly out of reach. So, it seemed
to me to be a very clever thing to trick them into paying me to help do
experiments in fireballs. I didn't tell them that the real reason I was
interested in fireballs was because I wanted to understand something about opacities
- which of course they didn't know anything about - because I was interested in
stars, and wasn't really interested in bombs.</p>

<p class="tab"><b>Carothers</b>: And you didn't realize
they were tricking you into studying opacities, which they needed to know for
calculations about their bombs.</p>

<p class="tab"><b>Brownlee</b>: I learned very quickly
what they were doing, but that was fine. It was parallel to what I wanted to
do. And so, the answer to your question is, they, at Los Alamos, were paying me
to do something I could do nowhere else in the world; namely, get my hands on a
real, honest-to-goodness stellar center.</p>

<p class="tab">And, not only did they pay me,
they gave me vast sums of money to do experiments. In 1956 we did the
experiment called Lacrosse. It was at Enewetak, forty kilotons, and we had
forty lines of sight, trying to measure the opacity of uranium, plus a lot of
other things. The opacity of aluminum, for instance, is very relevant to models;
there's lots of aluminum in the universe. So, this experiment was forty lines
of sight, forty kilotons, forty million dollars. A fellow astronomer and I did
that experiment. We were just given the job, and nobody told us how much money
we had. It was just, "Do the experiment." When we got all through it
had cost forty million, but we didn't know that.</p>

<p class="tab">We got the opacity of uranium
very nicely, but the number laid around for some years until they finally got
to the point where they could use the real number for the opacity of uranium as
measured by experiment, and calculate things that had happened to them in the
past. We got the numbers, but they weren't used in weapon design for years,
because any time they put them in their codes nothing came out right. So, you
know the decision - throw out the truth. I want to say that's the first time I
really recognized what charlatans bomb designers were, but it's not true; I had
sensed it earlier.</p>

<br>
<p><i>Carter Broyles, SNL - Panel Member</i></p>
<br>

<p class="tab">I was born in Eckman, West
Virginia. I was in the Army from 1942 to 1945. After that I went to the University
of Chattanooga, got my BS in 1948, and went from there to Vanderbilt, where I
got my Ph.D. in Physics in 1952.</p>

<p class="tab">I came to Sandia in 1952, in the
Weapons Effects Department. My first work with nuclear effects work was on
Upshot-Knothole in '55. From there I did various things, such as being the
supervisor of the Nuclear Burst Experiments Division, starting in 1957. I spent
some time on high altitude physics work, and managed the High Altitude Physics
Department starting in 1967.</p>

<p class="tab">When Marshmallow came along in
1962, I was the Scientific Director, and I did that job, although they changed
the name to Scientific Advisor, on Midi Mist and Hudson Seal. Also on Cypress and
Camphor, the or Sandia shots. In 1972 I became the Director of Field
Engineering. This organization was responsible for conducting Sandia's
underground nuclear test program, and was also responsible for the operation of
the Tonapah Test Range. We also supported programs like oil shale retorting,
coal gasification, and radioactive waste disposal programs.</p>

<p class="tab">I retired from Sandia in 1989,
and I now have a position as grandfather, babysitter, and general handyman.</p>

<br>
<p><i>Robert Campbell, Los Alamos - Test Director</i></p>
<br>

<p class="tab">I spent World War II as a
civilian, and as a commissioned type for the Navy at the Naval Ordnance
Laboratory. It started out with mine location schemes, and ended up with a mine
testing station on the Bay of Fundy, west of Halifax. It was a nice place for
that. It had a 55 foot tide; you'd go along in the aircraft and drop stuff in the
water at high tide, and come by a few hours later with your vehicle and drive
right up to the things you'd dropped.</p>

<p class="tab">After World War II stayed with
NOL for roughly a year, and that year was spent in closing up the station. I
was the officer in charge of the place at the end. Some of my friends had
already made the jump to Los Alamos. So, I learned of the place, and I made an assumption
which turned out to be incorrect. I was chafing, like a lot of us did, with the
rules, regulations, customs, traditions, of the United States Navy. And the
black shoe, brown shoe type of thing. The AEC had been formed just a few months
before, and I figured that never in my lifetime could anything starting as new
as the AEC, and this Laboratory was kind of new, ever get as hidebound, dogmatic,
and bureaucratic as the United States Navy.</p>

<p class="tab">Well, I was wrong. What I found
out rather quickly was that for most of the things that you go through in Naval
Regs, something had happened somewhere, maybe years ago, but there was a reason
for it being that way. I very quickly found, in this new organization, that
they didn't have that history, but they still needed rules, so they made them
up. And a lot of times there was no reason for doing it. Somebody just thought,
"We'll do it this way." This place was much more awkward than the
Navy.</p>

<p class="tab">I was married when I came here,
and my wife and I arrived in Los Alamos on the 3rd of July, 1947. I guess the
decision had been made that this was going to be more or less a permanent place
by the time we got here, but the funds hadn't caught up with the decision yet.
We had to have a place to live, and all that was available were the wartime
four-foot modular - because that's the way a sheet of plywood comes -
structures of one sort or another. We were assigned to a little house down on
Canyon Road. Two little bedrooms, a little living room with an oil stove in the
middle of it to heat the place, a little kitchen, a little bathroom - no tub,
just a shower. I think, but I'm not sure, that building was about 32 feet square.
It was rather crowded.</p>

<p class="tab">I came here without a specific,
"that's going to be your job", type of thing. At the time it was
awfully hard to get anybody to say they'd come to Los Alamos, so they were
taking almost any warm body and making what they could of the people when they
arrived. I ended up in a place called R Site. These were people who were doing
hydrodynamic testing, as it's called today. I had the fun job of trying to get
two metal jets to collide in front of a spectroscope to see what the ionization
was.</p>

<p class="tab">After a few years at R Site, I
don't know whether my feet got itching or I could see there wasn't a hell of a
lot of future for me, I jumped. I got into the radiochemistry business for
Greenhouse in 1951. Someone, and I think it was dear Edward (Teller), dropped an
idea that it would be interesting to know what a fireball looked like as a
function of time, from the inside. One of the games that was thought of was to
make a vessel which you would put out there, engulf it in the fireball, and then
close it at various and sundry times. So, we were going to get grab samples
inside the fireball.</p>

<p class="tab">The concept was to take a
cylinder, hold that in the flow, and on each end have some sort of valve or
gate that would close quickly, and so on. To do that we made ourselves some
gate valves that were to operate one time only. They were powder driven, about
an inch and a quarter thick, maybe four inches, five inches wide, in a body about
ten inches long. The gate went sliding across the opening and jammed into a
tapered seat, because they were not to bounce.</p>

<p class="tab">The shot was like ten kilotons on
a three-hundred foot tower; the collectors were out about fifty feet, so they
were engulfed in the fireball. We had some that were through-pipes, set
horizontally about six feet above the ground, and we had another variety that
was flush mounted. That was a tube closed on one end, with a valve on top, and
we took whatever got jammed in. We had five of each kind on the event.</p>

<p class="tab">We went in and got the things out
very quickly after the shot, mucking about at the bottom of the tower a day or
two after the shot. And we did manage to get them out, but there were no samples.
They were clean. The part of it we didn't get right was that we didn't get any
flow through the damn things. They had sort of a funnel type opening in a
teardrop shaped casting, but there was no flow, because it stagnated in the
throat of the thing.</p>

<p class="tab">Of course, we weren't asked to
repeat that experiment. So, I jumped out again. A guy named John C. Clark had
more or less watched the criteria, and construction requirements, and every other
damn thing for the early phases of Greenhouse. But Jack was pulled out of that
when the need for Ranger came along. He was given the problem, essentially, of
setting up the Ranger operation.</p>

<p class="tab">Ranger was in January 1951, and I
was at Enewetak, setting up the rad chem samplers when Ranger was being
conducted in Nevada. So, I missed Ranger, because I was already in the field on
Greenhouse. Anyhow, they needed some sucker to start this construction
business, gather up the criteria, get it to the A&amp;E, get it back, get it
approved, and all that sort of jazz. So I took that over in August 1951, and
that's how I got into what became the Test Director business.</p>

<br>
<p><i>Rod Carroll, USGS - Geophysics</i></p>
<br>

<p class="tab">I have a master's degree in
mining and a bachelor's degree in electrical engineering. I have a background
in mining, and I worked in geophysics in a private concern in the East. And, I worked
in mining in Arizona.</p>

<p class="tab"><b>Carothers</b>: So you're really a miner?</p>

<p class="tab"><b>Carroll</b>: Well, I got out of that
business very rapidly. I took a look around and said, "I'm not a glorified
ditch digger." I preferred a little more of what I thought were
intellectual challenges. Mining is a sad profession today. One of the country's
tragedies today is to travel the old copper belt from Bisbee up through Ajo,
all the way north to Montana, in Butte, and see the deterioration of an
industry .</p>

<p class="tab">It's much more devastated than
the steel industry in this country. I thought I needed a broader contact with
earth science. I had worked in Mississippi, and I had worked on the Mississippi
River, and in the Virgin Islands, and I worked here and there, It was very interesting
work for a young man, but I suddenly realized I wasn't getting any intellectual
stimulation from the people in the group.</p>

<p class="tab">I had a good friend in the Survey
who had been a professor of mine in Missouri, and he called me up when I was in
the Virgin Islands. He also called me at my home in New York when I came back,
and asked if I wished to join the Survey. I said I certainly did. He was in, at
that time, what was called the Special Projects Branch. It was the initiation
of the Branch. So, I joined the GS in 1961, Labor Day of 1961. I got off the
plane in Denver, and there was snow on the ground.</p>

<br>
<p><i>Chuck Dismukes, S-Cubed - Codes and Calculations</i></p>
<br>

<p class="tab">I got my doctorate from UCLA in
theoretical nuclear physics. Then I went to work for Ted Taylor at General
Atomics on something called the Orion project, which was nuclear space propulsion.
The idea in Orion was to expel small nuclear explosions out the back, and use
the expanding gases to push a big plate, which was coupled to a spaceship with
shock absorbers. It was designed to direct as much of the momentum as possible
directly at the ship.</p>

<p class="tab">That's how I cut my teeth in
learning about calculating radiation coupled hydrodynamics in two dimensions,
and got familiar with the codes, which are really the basis for the codes we're
still using in the underground test business.</p>

<p class="tab">I was working in related areas at
General Atomics when SCubed was formed as a new company, as a spin-off from
General Atomics. Actually, I was one of the founders, although that's probably
an exaggeration of my role in the whole thing. I joined them in 1967, about
five months after they were officially formed.</p>

<br>
<p><i>Russ Duff, S-Cubed - Panel Member</i></p>
<br>

<p class="tab">I went to the University of Michigan.
I was fortunate enough as things turned out, to have been chosen for the Navy's
V-12 program in 1944, and assigned to the University of Michigan as part of an
officer training program. My military “training" started at the University
of Michigan on July 1st, 1944. I was a V-12 for a year, then I transferred to
NROTC, and I graduated in '47 with an undergraduate degree in engineering
physics, and that was the extent of my Navy training and military service. In
1947 the Navy was busily demobilizing, and what they did not need most was a green
ensign going to the fleet. So, they asked if I would please accept assignment
to the reserves. I graciously accepted their offer, and went back to school in
September.</p>

<p class="tab">I arranged to do a thesis in
solid state physics. By this time I had married, and we had one child, with
another on the way. There was the small matter of beans for the table. I had
the GI BII, ninety dollars a month, but it was not enough to support a family.
There was an opportunity to work in the shock-tube laboratory for Otto LaPorte.
He was a German physicist who had been involved in solving the mystery of the
iron spectrum - the LaPorte selection rules. It turned out that not only could
I work on shock tubes and get paid for it, but he was also perfectly happy for
me to do thesis work there. So, due to a pure accident of economics, I became a
hydrodynamicist, sort of, instead of a solid state physicist. Everything seems
to come from these minor beginnings.</p>

<p class="tab">My thesis subject was the use of
real gases in a shock tube. All early shock tube work was basically with air,
or an ideal gas. I began to look at the possibility of using gases with
different indices of refractions, and specific heat ratios. These things have
been investigated much more carefully in the years since, but we had very limited
instrumentation at that time. This was the dark ages - the earth hadn't yet
quite cooled.</p>

<p class="tab"><b>Carothers</b>: Well, it had cooled,
but the dinosaurs had not yet appeared, except in some Departments where they
had a few dinosaur-like professors.</p>

<p class="tab"><b>Duff</b>: Exactly. I finished my
thesis in early '51. I applied to three places, and I had three job offers.
They were Sandia, in Albuquerque, Armor Research Foundation, in Chicago, and
Los Alamos. The Sandia folks paid the most, and Los Alamos paid the least. I
went to Los Alamos, because Los Alamos had attracted a large fraction of the
graduating class from Michigan for several years. It was an interesting place
to go, there were interesting things to do, and I wanted to do them.</p>

<p class="tab">For the first five years at Los
Alamos I was assigned to the GMX division office, with the interesting title of
Research Coordinator. That was a job that had no authority and no
responsibility, but it paid, and it was fun. My job was to try to help the
various researchers who were scattered throughout the groups of the division,
and to suggest things that they might do that would be a little more relevant
to the Laboratory mission than what they were doing.</p>

<p class="tab">This assignment as Research
Coordinator went on for about five years, and I began to suggest the
desirability of a little more order in the research activity of the division.
In response they suggested I move to GMX 7, and put together a small section
doing shock tube and gas detonation research. I did, and so we had a group of
six to ten people working there doing truly fundamental research on shock and
detonation physics.</p>

<p class="tab">We had all of the support of a
major Laboratory, had the freedom to do anything we wanted to do, but the
Laboratory really didn't care whether we did it or we didn't. What we were
doing was actually irrelevant to the Laboratory's work, but they were willing to
support us. I came to realize that if my whole group ceased to exist, fell off
the face of the earth, or whatever, nobody in the Laboratory would know or care
until the following Friday when the secretary called to ask what to put on the
time cards.</p>

<p class="tab">In about 1961 I had an
opportunity to go to Washington and spend a year on a sabbatical with the
Institute for Defense Analysis. I took that opportunity, and was concerned with
the early stages of the arming of the South Vietnamese. And also with aspects
of the Defender program, which was an ABM system. And also with some problems
associated with very large yield explosions. The Russians had recently fired a
60 or 70 megaton device. It was an interesting year.</p>

<p class="tab">I came back to Los Alamos in '62
with some hope that there would have been some reconsideration. There hadn't.
Johnny Foster, at Livermore, made a pitch to me. Why didn't I come there and
set up an equation of state group in the Physics Department, working with Ted
Merkle? Johnny can be a very persuasive salesman when he wants to be, and I was
sold.</p>

<p class="tab">I remember that he made an
interesting comment to me. He said, "You know, Los Alamos can beat
Livermore at anything it wants to do, anytime it wants to do it. But it never
will, because they cannot marshal their resources. They will not put them together,
they will not overcome their internal inertia, to do that." That was something
that struck a responsive chord in me, because I had been frustrated by the
inefficient use of resources at LASL.</p>

<p class="tab">So, I came to Livermore, working
for Ted Merkle. Ted died shortly thereafter, and my activities were taken up in
the Physics Department with a thing called S Division, under Teller. Our job in
S was to look at theoretical and experimental equation of state problems. We
did a fair bit of work which was in direct support of the Laboratory, and
maintained a pretty active research activity also.</p>

<p class="tab">We also did some diagnostic work
in the field, and I was impressed, and I said so at the time, by how little the
diagnostic people knew about things other than what they were immediately concerned
with. They didn't seem to care, and that was always a frustration and an
annoyance to me.</p>

<p class="tab">Well, after five years I again
got the itch. I said, "Look, I came here to do a particular job. That job
seems to be going very well. Okay, now what? What's the next challenge?"
They said, "Hey, you're doing real well. We really like what you're doing.
Keep it up." The same words I had heard at Los Alamos.</p>

<p class="tab">Then Mac Walsh, who had been a
friend and an associate at Los Alamos, called me from General Atomics and said,
"We are setting up a new company. It's called Systems, Science, and
Software, and we sure would like you to think about joining us." So, I
came down and met with Mac, and Bert Freeman, and a number of other people that
I'd known for a number of years, and was intrigued. It turns out I was the
first employee of S-Cubed who didn't come from General Atomics.</p>

<br>
<p><i>Paul Fenske, Desert Research Institute - Panel Member</i></p>
<br>

<p class="tab">I was born in Ellenburger,
Washington, May 15, 1925. My family left there when I was four, and moved to
Milwaukee, Wisconsin, where I attended grade school. We then moved to Albert,
South Dakota, where I attended high school. Then I got drafted. I was eighteen
the May before I graduated in 1943, and in a small town like that there were
not many guys who were free, because a lot of the young people had farm labor
deferments. So, I got out of high school, I knew the draft board was looming
over my shoulder, and I didn't know what to do.</p>

<p class="tab">I was kind of wandering around
not doing anything, and my mother, who was a tough lady said, "Well, you
know, the School of Mines starts in two weeks, down in Rapid City. Why don't
you go down there for the summer?" And so, the next thing I knew she put me
in the car, with my little suitcase in my hand, and drove me to Selby, which
was the county seat. That was also on the road which connected Bismark and
Pierre - Pierre being the capitol of South Dakota and Bismark being the capitol
of North Dakota. There was a bus there, called the Jackrabbit Line, which ran
down to Pierre over this washboard gravel road. I got down to Pierre, and I had
to wait until two or three in the morning for the Chicago Northwestern train to
come through Pierre. I took that to Rapid City, took my little suitcase, walked
to the School of Mines, got registered, found a place to stay, and there I was.
It was the first time I had been away from home. But you know - if you can't
swim, throw you in the water, and you learn how. I registered there as a
physics major, and I got drafted out of there into the ASTP program. I first
got sent down to Fort Benning, Georgia, which we used to call the Benning School
for Boys.</p>

<p class="tab"><b>Carothers</b>: I went through the parachute school at Fort
Benning, and I sure didn't think that was a school for boys.</p>

<p class="tab"><b>Fenske</b>: Well, the ASTP program
was different. It was fairly rigorous infantry draining. One of the reasons for
it was that we had a bunch of non-corns who weren't going to school, and they
thought this was a good time to take it out on all these college guys. We were there
about three months, and then the Army abandoned the ASTP program. So, what to
do with these guys? Well, they were in the infantry school, so put them on a
train and ship them out to the infantry. And so I was in the infantry in Camp
Van Doren, Mississippi, which was the hell-hole of the South.</p>

<p class="tab"><b>Carothers</b>: Paul, that's what everybody says about wherever they were.</p>

<p class="tab"><b>Fenske</b>: Yeah? Well, that's
because they weren't at Camp Van Doren. Camp Van Doren was it. I had some
difficulty there where I had to go to the hospital. While I was in the hospital
they shipped my outfit, the 63rd Infantry Division, over to Germany. When I got
out of the hospital I went to the Corps of Engineers, where I became a
construction equipment mechanic. From there they sent me to the Mariannas
Islands, where I fixed bulldozers and things like that. When I was growing up
in Wisconsin and South Dakota I never realized that you didn't have to be cold
in the winter. So, I was on Guam, and Saipan, and then I had enough points to
come home in '46.</p>

<p class="tab">I went back to school, and
ultimately graduated with a degree in Geological Engineering. I got out of
school in 1950, and so did everybody else. The job market for engineers was not
good; there weren't really any positions available. I had some feelers from
some iron mining companies, but I didn't know about the iron mining business. I
had some more GI bill left, and I had a brother-in-law who was going to the
University of Michigan. So, I went to visit my sister, who was in Ann Arbor. I
thought it was a pretty neat place, so I decided to go back to school, to the
University of Michigan.</p>

<p class="tab">I finished a masters in geology
there, and then I was hired by one of the subsidiaries of Mobil Oil Company,
the Magnolia Petroleum Company. At the time I was hired the Williston Basin in North
Dakota had just had a discovery well drilled, and so they sent me out to do
exploration there. I went out and ran around the Badlands of North Dakota for a
couple of summers. Magnolia really didn't have any operation there; they
drilled a few wildcats, but they didn't have any production up there, and so
they sort of bowed out of the thing, and transferred me to Midland, Texas.</p>

<p class="tab">There, I just did a lot of
well-site geology. I lost track of the number of wells I shepherded down to
paying production zones after I got to 150 or so. From there I went to a small
independent in 1956, and I worked for them for about three years. Then in 1959
the oil industry was going to pot. You could import Arab oil, and have it for a
dollar a barrel, delivered on the dock. To produce oil in West Texas cost us a
minimum of two and a half a barrel. It looked to me that the oil industry was
going to pot; the Arab oil was too cheap.</p>

<p class="tab">And so, I went back to school. I
was kind of planning that anyway, and I could see the oil industry was going
down, and it was getting to where it wasn't much fun anymore either. I went to
the University of Colorado and got a Ph.D. in Geology there, in the summer of
'63. Working for that small company I had done fairly well, so I had enough
money for three and a -half years at the University of Colorado. Of course, at
the end of that time I was flat busted.</p>

<p class="tab">Then I borrowed some money, and
went to Idaho State University, and taught there. So, I was at Idaho State for
a couple of years, and it just didn't seem like they were going to do anything for
me, in the sense of increasing my pay, which was 6,300 dollars a year.</p>

<p class="tab"><b>Carothers</b>: Now Paul, academicians
by and large, are not highly paid people, but they get the advantages of the collegial
atmosphere, the inspiration from the students - they get all of those things,
and all of those things are tax free.</p>

<p class="tab"><b>Fenske</b>: Well, Idaho State wasn't
all that great that way either.</p>

<p class="tab">So then I went to Hazelton
Nuclear Science Corporation in Palo Alto, in 1965, and I got associated with
DOE projects. The company was Hazelton, then it became Isotopes, then it became
Teledyne Isotopes, and every time it changed names it went further down the
drain. But I had been associated with DOE projects, and at that time they had a
panel of consultants. George Maxey was on it, and I had gotten pretty well
acquainted with Maxey at that time. He kept telling me I should come over to DRI.
And, when it seemed that Isotopes was running out of gas, I just went ahead and
went over the mountain. George Maxey was on the Panel when I came to work for
DRI in the latter part of August, 1971, and shortly after I was attending Panel
meetings. I wasn't a member or alternate; I had no official status with the
Panel. Two or three months later I became Maxey's alternate. Then, in 1976,
Maxey died, and I was made a member of the Panel.</p>

<br>
<p><i>Bill Flangas, REECO - Mining Superintendent</i></p>
<br>

<p class="tab">I was born and raised in this
state, in Nevada, in a town called Ely, in northern Nevada. I went to the Macky
School of Mines, in Reno, Nevada, and I'm a graduate mining engineer. So, I've
really stuck to Nevada, except when I was in the service. The U. S. Navy doesn't
operate in Nevada. My kids asked me, "What did you do in the war?" I
said, "I painted." They said, "What did you do when you weren't
painting?" and I said, "I thought about painting." I was on a
destroyer. It was great duty. In fact, I asked for destroyer duty.</p>

<p class="tab">Harry Truman deprived me of my
first invasion when he dropped the bomb in August, 1945. My relatively short
naval career (1945-1946) was a great learning experience, and I had the honor
of participating in the early occupation of Japan in the Fall of 1945.</p>

<p class="tab">After the war, and after I got
out of school, I worked for Kennecott Copper in an underground copper mine.
Then, early in 1958 I got a couple of calls suggesting that there was some work
to be done down here at the Nevada Test Site. My name had come up through Mr.
Reynolds, who was the owner-manager of Reynolds Electric, who at that time was in
New Mexico. He had been hobnobbing in Rotary, or one of those clubs, with the
people from one of the Kennecott operations in New Mexico. He mentioned that he
was looking for a mining engineer.</p>

<p class="tab">It was through that trail I got
contacted. I was asked two or three times to come down to the Site and take a
look at what was going on. My answer was that I didn't want to get involved in
any radioactive work. Then time went on, and a couple of months later I got
another call. They said, "Look, without making any commitments, will you
come down? We're starting a tunnel, and we just want you to spend a couple of
days to help us get started, and you're free to leave." So, I agreed to
come down and take a look.</p>

<p class="tab">Reynolds was a construction
company, and they were trying to dig a tunnel with construction people.
Obviously that didn't make sense. I walked into E-tunnel, and they had managed
to dig it in two or three hundred feet. I don't how they got there. When I
walked in there it was just painfully obvious that they needed miners. So, the
question was put to me, “Do you know where there are some miners?"
Obviously I did. So, I made a number of calls, and started rounding up some
miners, and started putting that force together.</p>

<p class="tab">I came down here, to the Test
Site, in May of '58 when the Livermore Lab was digging E-tunnel, and they had a
little activity going in B-tunnel. It was at the time when they were first considering
taking the program underground. In the climate of the times, there was just a
great deal of anxiety on the Test Site, even for those of us not connected with
the nuclear business, over the confrontation with the Soviets. It just became
immediately apparent. And so, I agreed to stay a few days and get that thing
started. And, by the time I got it started I got caught up in the excitement, and
here I am, thirty-six years later.</p>

<p class="tab">From my very first days I grasped
the national significance and felt the dynamics of the NTS. I have had the good
fortune to have been a participant and member of this highly skilled and
disciplined cadre of scientific, professional, technical, government, and craft
personnel that in my opinion has no equal anywhere in the nation. Although each
of was individually focused in his own field of responsibility in a rather
complicated organizational structure, objectives were very well met. This
mission oriented and schedule driven, “can-do" team's outstanding
successes were significant factors in the outcome of the cold war. I am both
grateful and proud to have been involved.</p>

<br>
<p><i>Joe Hearst, LLNL - Logging</i></p>
<br>

<p class="tab">I started out at Reed College,
and I chose Reed college because it had a combined program with MIT. My father
was a businessman, and he wanted me to take the MIT course in business and
engineering administration. With a five year program I could go to a liberal arts
school first. Reed was the only liberal arts school that had this arrangement
with MIT, where you'd get a degree from each school, that did not have
compulsory chapel. I therefore chose Reed. I later learned it was one of the
finest liberal arts schools in the country, but that was not a consideration.</p>

<p class="tab">Reed was small; there were a
thousand people, something like that. Then I went to MIT, took my degree in
business and engineering administration, and decided I didn't like it.</p>

<p class="tab">From there I took a masters in
physics at Boston University. When I finished my masters it turned out I was
the best graduate student in their physics department. The other guy wasn't
quite as good. They recommended I go on for a Ph.D., which I subsequently did,
at Northwestern. And at Northwestern, which had a mediocre physics department,
I just barely squeaked through my qualifying exam. I did a thesis in nuclear
physics, and my big recollection at Northwestern was, when I finished my Ph.D.
there was some sort of party to celebrate my degree. And there was a recorded
message from the department chairman, who couldn't be there. He said, "Joe,
I want you to remember that a second-rate physicist can be a first-rate
anything else." And so here I am.</p>

<p class="tab">I interviewed several places, and
at that time the requirements for being hired at the Lab were a Ph.D. in
physics and vital signs. Be vertical, breathe, have a heartbeat, and that was
it. This was just after Sputnik in 1959. And I did learn that the size of the
offer I got was inversely proportional to the amount of time I spent interviewing.
I went to Oak Ridge for two days, and they didn't give me an offer. I went to
Los Alamos for one day, and I forget what happened. I came here for one day or
less, and they offered me $800 a month. At Boeing, where I never went at all,
they just phoned me and offered me more.</p>

<p class="tab">One reason I came here was, I saw
this beautiful green valley. I also went to Hanford. At Hanford they gave me a
series of slides of the area, and I came back and showed them to my wife. That
was the end of that; she said, "No!" I came here in something like December,
or maybe in the early spring. It was beautiful and green, and I thought it was
that way all the time. Nobody bothered to tell me. So, when we drove out here
and all the hills were brown, I couldn't figure out what was going on. I said,
"Well, when we get to the Livermore valley it will be beautiful."</p>

<p class="tab">I ended up in B Division, and I
first worked for a year doing experimental physics, and I really liked that. I
was designing ways of doing photography, designing ways of doing pins, things
like that.</p>

<p class="tab">Then I was put into this bomb
design business, and for a while I designed bombs, and I found that pretty
boring. Those were the days where you would make a bomb design, more or less by
hand, and you would then do some code calculations to see what the result was.
Every morning I would go in, and this was before Cal Comp, and hand-plot the
results of the calculations. Foster would come in every now and then and look
over my shoulder at some of the plots, even though he was an Associate Director
then. But my current leader dictated every aspect of what we did; the colors in
which we plotted the scales, everything. He was the one person I've ever worked
for at the Lab whom I detested working for. He was a little dictator and I had
no freedom whatever.</p>

<p class="tab">I did write some codes to
simplify my job and automate some of the things I was doing. Writing codes was
fun, and I enjoyed that. I came in one day, knowing nothing about programming,
and went to the guy who was in charge of the programming, and I said, "What's
this thing called FORTRAN?" He said, "Take this manual." I took
the manual home for the weekend and came back and wrote a program. Nowadays
there are courses in this, and I found you could learn it in a weekend.</p>

<p class="tab"><b>Carothers</b>: Well, Joe, just
remember, a second-rate physicist can be a first-rate anything else.</p>

<p class="tab"><b>Hearst</b>: Right. Anyhow, I got
unhappy with bomb design, and didn't do very well at it. When the moratorium
ended we got into a rush, crash program. Eighteen day turnaround with designs -
from hydro shot to hydro shot was eighteen days. I had to do the calculations,
do the ramrodding, make sure the parts were put together correctly, all that
sort of thing, and then design the next one. That was okay. I think if I hadn't
been working for the guy I was working for I might have enjoyed it, but he was
such a tyrant that it was really not fun. And so I helped design another device
for a while, then I went back to doing experimental work.</p>

<p class="tab">We were trying to do a series of
experiments to look at the face of a pit, as it imploded, and trying to see
what was going on, in detail. We were doing very fast photography. This was
full time Site 300 work, and I enjoyed trying to make what were very high
quality measurements, for the time. That was fun. It was optical, with the fastest
shutters you could get. We had our own little bunker, and I also still did my
own code work development, which I liked.</p>

<p class="tab">I liked doing these experiments,
but as you may know, I'm irreverent and like to tease people. And one of the
people I liked to tease was the guy who became the division leader. So, when he
became B Division Leader, and I insisted on staying in experimental work rather
than going back to bomb design, I was asked to leave B Division. I went to K
Division, after going the interview route again, doing exactly the same thing
that I had been fired from B Division for doing, except now we were trying to
develop experimental methods to analyze the effects of shocks on rocks.</p>

<br>
<p><i>Dick Heckman, LLNL - Chemical Engineering</i></p>
<br>

<p class="tab">My stepfather was a regular in
the Marine Corps, and I'm a Marine brat. There was the war, and my high school
time period was during World War II, so we moved around a lot. I think I
probably attended some fourteen high schools. I spent a spring semester at Mount
Diablo Union High School in 1943, and my first interaction with the Livermore
site would have to be in late April or early May in 1943. My stepfather said,
"I'm going out to the Air Station.</p>

<p class="tab">Would you like to take the
afternoon off?" Well, any high school kid would, so I came out to
Livermore, to the Air Station. I did my lower division work at San Diego State,
with the idea of transferring up to UC Berkeley. I had a very fine chemistry
prof at my high school in Santa Barbara. Work with him convinced me I wanted to
be a chemical engineer, and I knew Berkeley had a good chem engineering school.</p>

<p class="tab">I started in Berkeley was in '48,
and graduated in June of 1950. My principal professors in the Chern Engineering
Department were Donald Hanson and Ted Vermuelen. I had decided to take a job up
at Hanford to work in the 200 process area, the old Purex plant. When Vermuelen
discovered I was interested in going into the nuclear energy field, he said,
"Gee, we've got some really interesting things up on the Hill." He
made me an offer, and so I came up on the Hill, at Berkeley.</p>

<p class="tab">I came to work in July, the 5th
or 6th, in 1950. I had to laugh looking at my Q clearance number. I suddenly
realized I got my clearance before I reached my twenty-first birthday. So, I've
had a Q clearance all of my, quote, adult life.</p>

<p class="tab">I basically worked under
Vermuelen, did my undergraduate work, and research project under him, and then
went to work as his chief staff guy on the Lab portion of the old Materials
Testing Accelerator, the MTA project, out at Livermore. Standard Oil had been
approached about setting up an operating company, California Research and
Development, for this big accelerator project. My first assignment was to act
as a liaison between the Standard Oil subsidiary guys, California Research and
Development people, and the Laboratory.</p>

<p class="tab">Then, I had an interesting thing
happen. On the annual evaluation, Vermuelen called me in and said, "You've
done good work, and should you wish to stay here at the Laboratory, there's no
problem. However, being an engineer, your future really lies with this
engineering organization. And I've already called up your new bosses and
arranged for your interview." This was in July of '51.</p>

<p class="tab">So, I quit the Lab, and
transferred over to CR&amp;D. I continued to finish up some of the cyclotron
irradiation experiments in Berkeley. Then I actually came out to this site, and
my office was in what was called Building 13, the old administration building.
I went to work for Bill Browning, in the radiation damage area.</p>

<p class="tab">I'd gotten married in December of
'50, and we moved to Livermore, into a house here, in December of '51. We came
out in August to look around, and at that point Livermore was still the original
one square mile. The Jensen tract had not been annexed by the city. It was
still outside of the city limits, but they were in the process of the
annexation. Those houses were more money than we could afford. I mean, they
were actually asking ten thousand five hundred for those houses over there.
That was just way too much money. There were none of the flat-top duplexes to
rent then, so we had our choice of three houses in town. And so we bought over on
north K street, behind the Eagles Hall. Harold Moore was in the process of
building one, and when we looked at the house, and agreed to buy it there were
just some foundations there. Harold finished that house, and we moved in
December. When we moved here there was definitely a lot of open space in the
town.</p>

<p class="tab">On the MTA project, very early on
it became clear that one of the problems in the target area would be radiation
damage. And so, Vermuelen had directed my career off towards radiation damage work.
We went through a whole series of projects, but by the spring of '53 it became
very clear that CR&amp;D was not going to make it. It was just scuttlebutt, but
it was very clear. I guess for me, in looking back, the real time was when we
realized there was going to be a confrontation between the CR&amp;D group and
E. O. Lawrence, about who was really directing things.</p>

<p class="tab">Well, of course, there was no
question about that in Lawrence's mind. The CR&amp;D president, Fred something
- I forget his name - went off to Washington, left on a Monday. He was going
off to do battle at the AEC headquarters, and so I called up some of my buddies
in Berkeley and said, "Hey, this is going on. What do you guys hear?"
They laughed, and said, "It's all settled. E. O. left for Washington on
Friday, he came back Sunday, and it's all settled."</p>

<p class="tab">Don Hanson was getting involved
in a lot of materials stuff over on the Whitney project. I went to talk to him
in May, and he said, "Yeah, we've got a place for you, so if you want to
come over, fine." Well, I went to talk to my boss in CR&amp;D, and my boss
at CR&amp;D told me, "Hey, you're top of the line. The company will fold
before you go." So, it was very interesting when he called me in about a
month and a half later and said, "I've got some bad news for you. I've got
to lay you off." So, I jumped the fence then and came to work for Don
Hanson, here at the Lab in September of '53.</p>

<p class="tab"><b>Carothers</b>: That must have been
very convenient. You didn't have to move. You didn't have to sell your house.
You just went in this gate instead of the other gate.</p>

<p class="tab"><b>Heckman</b>: It was more than just
convenient, because believe me, the guys who couldn't find jobs in the area
were stuck with making house payments, in some cases for three or four years, because in a
sense there was literally nothing out here, in Livermore.</p>

<br>
<p><i>Gary Higgins, LLNL - Panel Member</i></p>
<br>

<p class="tab">I grew up on a farm. I went to a
one-room school house in Hartington, Nebraska; Branch Creek District 14. We had
eight people in the eighth grade. There was one teacher. No janitor. We hauled
our water from the farm next door in a bucket, and of course the big boys had
to do that, and put the wood in the furnace and get it started in the morning.
And then I went to a big school, the unified high school. In Hartington there
were about four hundred students, and I think there were forty or fifty of them
that made it through senior year. Then, since I was only seventeen, and not subject
to the draft yet, I started college.</p>

<p class="tab">I started at Macalester College
in 1944. The war was on and I was not eighteen yet. My dad, who had lost an arm
in the first World War, said, "No way are you going to go in until you are
old enough. I'm not going to sign". I started out as if I were going to attend
a full year, but when March of '45 came I went around to all the profs and I
said, "I'm going to have to leave and go into the service pretty
quick." Most of them said, "Okay, your mid-term averages are up,
don't worry about taking the final. I'll give you the grade, so you just stick
it out until your birthday," which was May 19th, "gets here. If you
get your call to go into the service, whenever it is, I'll give you a grade and
you won't get an incomplete."</p>

<p class="tab">I was discharged in the late
summer of '46, early enough to be able to register for school again in the
fall. I missed twelve months of school. I graduated in 1949 with majors in
chemistry and physics, and a minors in mathematics, German, and English
literature, so I was not really anything.</p>

<p class="tab">That fall I entered the
Department of Chemistry at U. C. Berkeley. I was awarded a PhD in June of '52
after we had discovered elements 99 and 100 in the debris recovered from the Ivy-Mike
nuclear test. I went directly to work for California Research and Development,
which was a subsidiary of Standard Oil, but I found very quickly I was not
suited for work for Standard Oil. I terminated in November 1952, and restarted
at the Laboratory, then UCRL, as a radiochemist. I worked on nuclear explosion phenomenology
from 1958 until 1983, when I retired from active programmatic work.</p>

<br>
<p><i>Jack House, LANL - Containment Project Manager</i></p>
<br>

<p class="tab">My family came to New Mexico when
I was nine, and my parents owned a ranch over in the mountains about twenty
miles west of Los Alamos from 1946 until 1968. So, I essentially grew up in the
neighborhood here, you might say.</p>

<p class="tab">I went to the University of New
Mexico, in Albuquerque, where I got a bachelor’s degree in geology with
basically a civil engineering minor. UNM had set up a joint program with the Geology
and Civil Engineering Departments, and I took that program. The subjects do to
some degree fit together.</p>

<p class="tab">In the summer of 1966 I started
working for Los Alamos, at the Nevada Test Site, out in Jackass Flats, as part
of the Rover nuclear rocket engine program. The group I worked with was designated
as J-9, and we ran the R MAD building, where we did the assembly and
disassembly, remotely, of the nuclear rocket engines in the Rover program. We
lived in Las Vegas, and rode the bus 92 miles each way, each day out to the
site.</p>

<p class="tab">After about a a year, not liking
the bus ride or living in Las Vegas very much, I started seeking opportunities
back in Los Alamos. An opportunity became available, and I relocated to Los Alamos
in 1967, still with the J-9 group, but doing engineering things back here for
the Rover program. Then, in early 1970, Bill Ogle, who was then the J-Division
leader, decided to get out of the Rover program support activities entirely. So
he disbanded J-9, as we knew it then, and a number of us were sent scurrying
looking for other employment.</p>

<p class="tab">I didn't get reassigned, I had to
go hunt up another job. And so, I went to talk to my old friend Walt Wolff, who
was the deputy group leader of J-8, which did timing and firing. He said, “Yeah,
I can use you." So, in March of 1970 I went to work for J-8, and became
very well acquainted with the Nevada Test Site weapons work, working with the
timing and firing folks. I never actually heard anything about containment
until that December morning in 1970 when Baneberry vented.</p>

<br>
<p><i>Billy Hudson, LLNL - Alternate Panel Member</i></p>
<br>

<p class="tab">I got the idea that I wanted to
be a physicist because I wanted to understand things. Why this, why that? When
I was just a little boy I asked these questions. Why? No one seemed to know
very many answers. Unfortunately, early in my career I realized that physicists
don't know the answers either, but by that time I was too far along to turn
back.</p>

<p class="tab">I grew up in Kansas, probably
thirty or forty miles from where Bob Brownlee grew up. We lived on relatively
small farms, moving from one farm to another when I was in high school, until I
got into college. But it was pretty much in the same general area around Salina,
Kansas, where I was born.</p>

<p class="tab"><b>Carothers</b>: Well, Brownlee, as you
know, believes in old farmers. He thinks they're the best kind of people you
can have on something like the Panel.</p>

<p class="tab"><b>Hudson</b>: I think there's a reason
for that. On the farm, as a rule, you're too far from the hardware store to run
and get a part if something breaks. So, you make sure you have plenty of baling
wire and a pair of pliers. It's amazing what you can do with baling wire and
pliers.</p>

<p class="tab">When you get to be a physicist, I
think in many ways you continue doing the same thing. You don't use pliers
anymore, and you don't have the same kind of wire, but basically it's solving problems
the same way. Maybe that's why Bob likes the idea of a farmer in containment,
because many of the problems are of the type which more closely resemble farm
problems than big-science problems.</p>

<p class="tab">After high school, I went to
Bethany College, which is a small Lutheran church school. It turned out that it
was less than one mile from where I lived, and so it was the obvious place to
go to school. In those days the tuition was relatively low, and I went to
college for about the same cost as I went to high school. I graduated from
there in what seems to me to be relatively recent times. That was in 1958.</p>

<p class="tab">I then went to Kansas State until
January 1966. I was basically a mix of teaching assistant and research
associate, so I don't think I went to school more than about half time.</p>

<p class="tab">My first thesis advisor was Bob
McFarland, who worked at the Livermore in the summer time, as part of the
precursor to the fusion program. He came back to Kansas State each fall with
such glowing reports of how great it was out here at the Lab that I think most
of his students came out here. There were six or eight students who were in
school at that time, and they all came out here.</p>

<p class="tab">So, I went to work for the Lab in
1966, and we moved to Livermore. My clearance came along, and I was then
invited to interview many people at the Laboratory, which was a procedure that
it's really too bad had to go by the wayside a number of years ago.</p>

<p class="tab"><b>Carothers</b>: That was an
interesting process. The idea was that you were hired to be a part of the
physics staff, and as such you would find an appropriate place in the
Laboratory after you got your clearance and could go talk to people in all the
different areas. That's very different from, “We have this job, and do you want
this job, and do you fit this job?"</p>

<p class="tab"><b>Hudson</b>: Yes. I talked to the
people in almost every type of work at the lab, including John Nuckolls, who
was a group leader at the time. I was especially interested in what he was
doing, and I went back a second time to talk to him, but I couldn't quite
swallow the idea of doing experiments on a computer. I was just a little bit
too much experimentally inclined. That just didn't seem like physics to me.
I've always enjoyed working with my hands. I didn't realize it at the time, but
it was always going to be somebody else's hands.</p>

<p class="tab">I considered several different places,
but I homed in fairly quickly on the Test Program, for a couple of reasons. For
one thing, it sounded as though they were doing what I considered bona fide experimental
work. It was more similar to what I had done in my own little laboratory as a
graduate student. And, at the time, they gave me the feeling that they wanted
me more, because I was interested in experimental work, than some of the other
areas did. It seemed like a good fit, and I joined L Division. I think in retrospect
it was the best choice by a fair amount.</p>

<br>
<p><i>Evan Jenkins, USGS - Alternate Panel Member</i></p>
<br>

<p class="tab">I went to the University of
Colorado for my Bachelor's although I came from Nebraska. My grandfather and my
great uncle were in the oil business in West Virginia, and we went bad there the
last time when I was in high school. The geology in the Appalachians is much
more visible than it is around Omaha, and I think that's where I got
interested. The geology around Omaha, Nebraska, is obscure. There's just a lot
of junk there. It raises good corn, but to a rock geologist that geology is
junk. So, I came out here to Colorado where, obviously, there's much more
geology exposed than even in the Appalachians. That was 1949.</p>

<p class="tab">I spent four and a half years at
the University of Colorado, then I went into the Army. After that I went to the
University of Texas for a master's degree, under Steve Clabaugh. He was, and
is, a fantastic man. I graduated in 1959, and then I went to work for an oil
service company in Houston for a year or so. They supplied companies with
drilling fluids, and the technology that goes along with it.</p>

<p class="tab">Then Dub Swadely, a good friend
of mine with whom I did my thesis at the University of Texas, phoned me from
Kentucky. He was with the USGS, and he said, "Hey, we're hiring." So,
I joined the USGS in Kentucky, on the joint mapping project, doing the whole
state. At that time, when we finally finished, it was the most thoroughly
geologically mapped state in the country. And I suppose that still holds,
because of the money problems that have developed since then.</p>

<p class="tab">I spent five years there, and my project
chief in Kentucky thought, "Well, you better get around and meet the
Survey a little bit." So, I came to the central region here in Denver, and
the Nevada Test Site, and I really haven't gotten around to meet much of the
Survey since. So, since 1966 I have put my roots down on the Test Site.</p>

<br>
<p><i>Gerry Johnson, LLL - Test Director</i></p>
<br>

<p class="tab">I grew up in the Northwest, in
Washington state, in the little town of Spangle, just south of Spokane. While attending
high school I happened to be one of those troublesome students, but I was a good
one. I had no trouble with the courses, and I had time to spare, which I wasted
by causing other people problems. But when I was finishing up in high school
the superintendent said, “Gerry, what you have to do is go to college. Go right
straight through and get a Ph.D. in physics."</p>

<p class="tab">My first question was, “What is a
Ph.D.?" They didn't teach physics in high school there, but he knew I was
interested in scientific subjects. So, he volunteered one year to give me a lab
course, as a student of one, in physics. We had a little laboratory, did little
simple experiments, but it went very well. That was all the physics I had
before leaving high school.</p>

<p class="tab">In 1933 I enrolled in the State
Normal School in Cheney, Washington, and then entered Pullman as a junior. In
those days no one had any money, especially me. Many of us worked our way through
by doing odd jobs, and in my senior year I received a teaching assistantship. I
completed my undergraduate work in 1937, and then they gave me a post-graduate
teaching assistantship; a half-time job. I stayed on two years, did a little
laboratory research, and received a master’s degree in 1939.</p>

<p class="tab">From there I went to Berkeley,
and it was while I was doing my graduate work the war broke out. I'd been
guided by a statistical mechanics and kinetic theory professor, Paul Anderson,
at Pullman, to work for Leonard Loeb, which I did. And, if you worked for Leonard
Loeb, the story was that as a graduate student you always knocked on his door
before entering. As soon as the door opened you were advised to say,
"Goddamn the Radiation Laboratory." Then you were permitted to enter.
Loeb had no association with the Lab, and in fact, he had developed a lot of
resentment between himself and the Lab. It was just a personality problem
within the Department.</p>

<p class="tab">Loeb was involved with the
degaussing of ships, and he was a reserve Commander or Captain, in the Navy. In
the beginning none of us took the war seriously. We were all anti-war, and Over
the Hill In October, if anybody were to try to draft us. But when France fell, 1940,
we suddenly realized that there was going to be a war, and we would be
involved.</p>

<p class="tab">About that time, the summer of
1940, there were three of us under Loeb, who advised us, “You fellows ought to
take commissions in the Volunteer Research Reserve," which was a Navy
unit. We allowed as how that might be a good thing, and so we took our correspondence
courses in Navy regulations, and ordnance, and gunnery, and they commissioned
all three of us. Towards the end of 1940 Professor Loeb went on active duty, so
there went my thesis advisor. Soon after he reported, Loeb called me up and
asked how soon I could come on active duty.</p>

<p class="tab">I was well along on my research
and had one prelim to go, an oral, to qualify for a Ph.D., so I replied, “I'd like
to take my last oral before coming. I think I could be ready around the first
of February. Any time after that I'll be prepared to join you." Well, I
passed that oral; I suppose not with distinction, but I did.</p>

<p class="tab">At that stage of my life the Navy
looked like a great adventure. We had a different feeling at that time, after
the war started, but prior to the war we were no different than any other young
people. I put my thesis on the shelf, and went on active duty in late February or
early March, 1941. I was assigned to the Naval Proving Ground, which is south
of Washington, on the Potomac. At that time it was essentially a test range for
experimental and acceptance tests of armor and armor piercing projectiles, and
for various other kinds of ordnance, like mines. I became involved in armor and
armor penetration, which I continued for five years.</p>

<p class="tab">Specialists, like myself, in
various technical areas, were sent to various places, and essentially locked up
for five years. We missed the war, so to speak. They wouldn't let us enter
combat areas. They had the attitude that they shouldn't expose technical people
to combat, because of World War I experience. They usually referred to Moseley
being killed at Gallipoli.</p>

<p class="tab">I thought it was a mistake at the
time, and I still think it was a mistake, because we didn't get a feel for the
war. We were just there, and problems would come in for us to work on. It's not
the same as getting associated with a combat operation and defining the problems
yourself. All of us kept trying to get out, at one time or another, to get
involved in something else, but they just wouldn't let us. And the work we we’re
doing was fairly pedestrian after we got the experimental facilities and
programs set up and going. After the first two years it was nothing but
routine. Shoot this bullet at this armor, and make the measurements.</p>

<p class="tab">I was in Washington until '46.
Then I went back to Berkeley and finished my thesis. I got my degree, and I
concluded, "Now what I want to do is get a teaching job and let ivy grow
all over me."</p>

<p class="tab">So I did that. I heard of a
teaching job at Pullman. I got hold of my old friend Anderson, my former
professor, and said, "I'm looking around. I want a teaching job." He
said, "Can you teach physical metallurgy?" I replied, "Of course."
I thought, "I can certainly teach the theory because I've had physics of
solids, physical chemistry, and thermodynamics." But what was more to the
point, they wanted it to include a laboratory course in which metallographic
specimens were prepared. That is an art. I'd never done anything like that. But
I didn't tell them that, and I took the job and went to work. I had a tough
time polishing and etching specimens, but I finally succeeded in getting some
pictures. I felt sorry for those students, but they were patient with me.</p>

<p class="tab">I really enjoyed teaching, and
the students, and I was learning. But then, after about two and a half years, I
realized that here I was teaching these people, or trying to, and I hadn't
really done anything in physics. I had no experience, except that little bit of
doing a thesis, and reading books and passing prelims - I had no substantial
research experience. And I guess I was a little bored. Pullman is pretty
isolated after you've been any place else.</p>

<p class="tab">So, I went to the head of the
department one day, and I said, “This is not what I want to do. I don't know
enough to teach. I want to do some research for a while." And I followed
that up at the Brookhaven Laboratory, where I finally got a research assignment
in 1949.</p>

<p class="tab">Then the Korean war broke out,
and I volunteered to go back on active duty again. I went to the Special
Weapons Project in Washington, and there I started to work on nuclear weapons.
At the end of that, which was two years, I returned to civilian life and joined
the Atomic Energy Commission, as a special assistant to Tom Johnson, the
Director of Research of the Atomic Energy Commission. There I worked on
controlled fusion, using the same propaganda lines we use today. First you show
a picture of the rolling waves in the ocean ... “Think of that as gasoline,
give us some money, and we'll have it for you in twenty years." So, we
should have had it on line by 1970. We didn't quite make that.</p>

<p class="tab">While at the AEC, because I had
the necessary weapons clearances, I read the progress reports of Los Alamos and
Livermore, which described the nuclear weapons development programs. I thought,
“Well, maybe one of those places would be an interesting place to work." I
concluded that the Livermore reports were more imaginative. It was just that
they were better writers, I guess, but the way it came out to me it looked to
be more exciting and more interesting work. So I decided I wanted to go
Livermore.</p>

<p class="tab">I was told that a man named Herb
York, whoever he was, was running the Laboratory, so I wrote him a letter, and
said, “Look, I've decided I want to work for you. What do I have to do, to do it?"
Not too much later I got a response from him, and an interview was arranged. I
didn't know what they wanted, or what they wanted to know, but it turned out
that they finally hired me. There were about four hundred people at the Lab
then, give or take a hundred. Everybody knew everybody.</p>

<br>
<p><i>Carl Keller, Panel Member</i></p>
<br>

<p class="tab">I was a reactor physicist by
training. I had been working at the Connecticut Advanced Nuclear Engineering
Laboratory, on the Snap 50 reactor. They decided to close that down, and Pratt-Whitney
was going to make a jet engine expert of me. So I sent out my resume, and I
interviewed at Oak Ridge, Argonne, and Los Alamos. And I accepted the lowest
offer, which was from Los Alamos. It required that I take a job, not with the
people I interviewed at Los Alamos for the full day, but with the people I interviewed
for maybe a half an hour before Bob Brownlee had to run off and catch a plane.
And I had to change from the reactor physicist business to the containment
business as Bob Brownlee's assistant. That was in 1966.</p>

<p class="tab">Actually, my first interest was
in living in New Mexico. And I had decided that the reactor business was
declining. The big companies were taking over most of the reactor research, and
the government was doing less and less. I had decided not to try really hard to
stay in reactor physics and reactor design, and I took the job for the variety.</p>

<p class="tab">The nice thing about the reactor
physics background was that I had the nuclear physics I needed. In the reactor
business I had done neutron transport calculations, and other radiation
transport calculations. So, my background was in radiation transport. I had not
done any hydrodynamics calculations before, so the job was initially highly
instructive. Actually, in the containment field it has always been that way. I
was learning more than I was doing for many years.</p>

<br>
<p><i>Joe Kennedy, Sandia - Tunnel Closure Mechanisms</i></p>
<br>

<p class="tab">I came to Sandia in 1963, March
of 1963. I had wended my way through graduate school, like everybody else, I
guess. I worked for a time with the Lockheed Missile and Space Division in Palo
Alto. They paid for my master’s degree in physics, at Berkeley. Then I went on
to work for a Ph.D. in Physics at Lehigh University. I had never been east of
the Mississippi before that. My training there was in solid state physics, but
I never practiced solid state physics, except for the first years.</p>

<p class="tab"><b>Carothers</b>: Well, Jerry, those tunnels are pretty solid state.</p>

<p class="tab"><b>Kennedy</b>: Condensed matter they
call it now. That's far more sophisticated than solid state.</p>

<p class="tab">I came directly to Sandia out of
graduate school in 1963. My wife is a physicist also; we were graduate students
together, and she said, “Well, it will be a nice place to stop for a year or
so, before we get back to California." And I said, “Right." And so we
came here, and we never quite did get away.</p>

<p class="tab">I came here, like a good many
fresh Ph.D. students, into research. That was frequently kind of an entry place
for the new Ph.D. at Sandia I came into a research group which did explosive driven,
high pressure physics. So I sat and wrote papers in that for about the first
five or six years that I was here.</p>

<p class="tab">Then some number of friends of
mine kind of jumped over into field test, full scale field test, and it was
kind of right upstairs, in the same building, and I got interested in it. And I
had gotten tired of writing papers, and wondering if anybody ever read them.
Then a friend who had gone to field test said, “We actually do stuff."
That appealed to me a lot, so I went there, and stayed there the rest of my
career here. The very first event I worked on was called Diesel Train. It was a
DNA event, and that was my introduction to tunnel events.</p>

<br>
<p><i>Tom Kunkle, Los Alamos - Panel Member</i></p>
<br>

<p class="tab">I was an undergraduate at the
University of Arizona, and I attended graduate school at the University of
Hawaii. I chose Hawaii because I was an astronomy major, and at the time the Mauna
Kea observatory was being built, and it had more square inches of glass on the
summit of the mountain than you could find anywhere else.</p>

<p class="tab"><b>Carothers</b>: It seems a bit
strange. There have been several people at Los Alamos in the containment
business who originally were astronomers or astrophysicists. Here are people
who've been looking out at the infinite heavens, and now they're looking down in
the ground.</p>

<p class="tab"><b>Kunkle</b>: Well, there are some elements in
common. In both cases you have to deal remotely with your subject. There's very
little opportunity to learn directly the effects or the nature of what you're dealing
with. In one case, the underground nuclear tests are inaccessible because of
their extreme depths of burial; in the other, the stars and other astronomical objects
are inaccessible because of their distance. So both use remote sensing.</p>

<p class="tab">In Hawaii I studied galaxies -
the structure of galaxies, and especially the material between the stars, the
obscuring dust and gas. My specialty is dust between the stars.</p>

<p class="tab"><b>Carothers</b>: Well, there you are.
Now I see the connection with the Test Site. There is a lot of dust there. When
did you finish your degree?</p>

<p class="tab"><b>Kunkle</b>: Well, I have two Ph.D.'s. I
finished one in 1978 and one in 1979. They're two very different fields. I
became something else, as it were, nearly out of necessity. Having arrived in
Hawaii to go to graduate school in the fall of 1973, I discovered that there
had been an election the preceding year. The only precinct in the state that
voted against the incumbent governor, Mr. Burns, was the university precinct.
The university budget had suffered mightily since that 1972 election, and there
was no money for us, the graduate students.</p>

<p class="tab">That left six of us, myself and
five others, who had graduated to go into astronomy, looking for employment to
keep body and soul together. I started doing statistics for a group over in the
College of Medicine. That group was interested in bubble nucleation in
supersaturated liquids and fluids. They were motivated by an interest in diving
medicine - the decompression problems which are believed to be caused by the
formation of bubbles in the tissues, in the fluids of the body.</p>

<p class="tab">They were doing some very
interesting lab experiments, but they hadn't the least idea how to analyze them,
or write up the results. I had a fairly good idea how you might go about
analyzing and writing up the results, and I found I could learn how to handle the
glassware almost as good as the other medical students. And so, within a year
or two I was spending a lot of time doing that. It became a regular hobby for
me. That just progressed for a while, and by and by I finished with a Ph.D. in
diving medicine, or medical physics as it's really known .</p>

<p class="tab">I still needed a job, and that
was a problem. Many of us - many of us being the graduate students of the
university - were discussing at the time about what will we be, now that we're
grown-up. There were, it seemed, two opportunities; one for university
research, and one for employment in the government, or government-sponsored functions
and laboratories.</p>

<p class="tab">Very few universities seemed to
offer actual jobs. The academic posts were transient, short term, not very well
paid, and without benefits. I considered a position at Washington University in
St. Louis, which would have been involved Fabre Perot spectroscopy of various
stellar objects. That would have been very interesting, and probably could have
been slowly developed into a more secure faculty-type position, but it was
short term. It would have been up to me to try to develop it into something,
and, gee, it would have paid much less than the auto workers in the same city. So,
it didn't seem like too good an employment opportunity.</p>

<p class="tab">I also discussed a science
research fellowship at the Science Research Consulate in Great Britain -
Edinborough, in this case. I very seriously considered taking that position,
which would have offered me halftime a year in Hawaii at the National Infrared Telescope
- the British Infrared Telescope, as it is known over here - and then the other
halftime in Edinborough, reducing the data. That would have been quite an
acceptable position. I very seriously considered that.</p>

<p class="tab">But, I had replied to an ad which
Eric Jones, who was then the J-9 group leader, had run in Science magazine. He
was looking for someone to work in weapons effects at Los Alamos. I replied to Eric's
ad, and he had me come out and talk to him, and I liked the position quite a
bit. It involved a lot of theory and computations, and statistical analysis of
data bases. It was an interesting subject to me, and the group was staffed
largely with people I could get along with quite well. There were physicists,
astronomers, geologists, and people I had already grown to know somewhat at the
University of Hawaii. And so I elected to take that position.</p>

<p class="tab">I interviewed here in August of
1979, and accepted the position the following month. I showed up on April 13,
1980, I believe it was, for employment.</p>

<br>
<p><i>Joe Lacomb, DNA - Panel Member</i></p>
<br>

<p class="tab">I was born in northern New York.
My family was in construction, so we moved a lot. I went to high school
numerous places - Mesa, Arizona; Gold Hill, Oregon; Boulder, Montana, and a number
of places in northern New York. I graduated from West Seattle.</p>

<p class="tab">After that I went to the School
of Mines, at the University of Montana. I was married, I had two children, and
I was number one on the draft list in Jefferson county. They called me up and
said, "Would you like to sign up for your ROTC deferment?" I said, "That
sounds like a reasonably good idea." So then I was stuck doing ROTC until
I got a commission. I got out of school in '55, as a mining engineer .</p>

<p class="tab">Then I was in the Air Force,
stationed at Alstrom, in Great Falls, Montana, as a KC97 pilot, doing air
refueling. When I got out of the Air Force, I spent three years in business for
myself, operating a silver mine. We did pretty good for a while, but the
problem was that in the winter time the snow is fairly deep, and getting from
town to the mine at the Continental Divide was interesting at times. You only get
about six months of productive time per year. And, you starve the rest of the
year.</p>

<p class="tab">After that I went to work for
what was then called Porter, Urqhart, McQuery, and O'Brien. Porter, Urqhart,
and McQuery are all renowned civil engineers. O'Brien was a young partner. They
had the contract for doing the site exploration for the Minuteman. I started
with them up around Great Falls, and we did two locations in North Dakota, then
went to Missouri, and Lubbock, Texas.</p>

<p class="tab">Finding the sites is like trying
to site one of our tests, to a degree. You have certain criteria. It can only
be so close to a school. Believe it or not, you can only be so close to a
cemetery. And you can only be so close to a town. And there is certain topography
you would prefer to have. You would like to try to get in on a good blacktop
road, if possible. You try to take all that into account. And you could only
have the sites within five miles of each other. So, you tried find a place to
cluster eleven sites - ten silos and one living quarters. First, you did a map
study, and tried to locate these sites in an area on the map, then you went out
and drove around and relocated them to fit what you found in the field.</p>

<p class="tab">Land use was another thing you
tried to pay attention to. You didn't want to pick a site in the middle of some
guy's million dollar orchard. You tried to pick fields. In North Dakota, most
of the time we were siting in the center of wheat fields. In Oklahoma we were in
cotton fields all the time.</p>

<p class="tab">After they were sited we went
back and drilled to a hundred and thirty feet. We took undisturbed samples
every ten feet, and took penetration samples every alternating ten feet, so we
had something every five feet. We provided that to the designers of the silos
for their structural design. Every site was drilled; any site that made water
had a pump test run on it. It was interesting work. That's where I first got
involved in soils and foundation work.</p>

<p class="tab">In Montana a lot of the silos
were semi-dug. They were bucket augured because most of that was soil. When
they got to where they had rock, they were mined. They were excavated by drill
blasting and typical shaft sinking methods. North Dakota was mostly glacial fill
with big chunks of shale. I mean big boulders -I couldn't believe their size.
Some of them had fifty to seventy-five foot dimensions. Of course you can't see
them. You just know that boulder was there because of the drill pattern you'd
put in. Glaciers are pretty big, and they move big rocks.</p>

<p class="tab">My wife had moved from Montana to
Vegas because my parents were here. When I got through my last job with the
sites, I was sick of it. I was working seven days a week, twelve hours a day, and
that gets old after a while. So I just said, "I'm going home," and I
came to Vegas. I was here a week, and they wanted me to go down to Vandenburg
to drill some holes down there. I went down there for two weeks, which lasted
ten, and came back here.</p>

<p class="tab">The Nevada Testing Labs
advertised for a soils engineer. I went down and applied, got the job, and
started working for them. I was with them for two years.</p>

<p class="tab">From that I went up to Reno and
managed a lab in Reno for about a year and a half. Then they were changing
hands, and I decided to get out. So I was leaving, and I went around and talked
to my clients. I said, "I'm going to be leaving, and this is where I'm
going to be. If there's anything that I've left undone, pick up the phone and
call me.” I was really proud; I got fourteen job offers in one day.</p>

<p class="tab">I got offered a job to be a
project engineer on the remodeling of Harrah's Club up in Reno, and I took
that. My goal was to become a project manager for big construction jobs like
the Mirage that's being built here - places I could work for two or three years
on a big program, and then maybe go goof off for a year.</p>

<p class="tab">Then I got a call from Ken
O'Brien saying he had the contract with what was then DASA, in Albuquerque, and
they needed a mining engineer. I thought, "You know, as long as I've been
out of college, I've never worked as a mining engineer. I've worked in a mine
for myself, chased drill rigs, done a lot of other things, but I've never been
a mining engineer.” So I said, "I'll take it.” I went to Albuquerque, and
got there in September of '65. There was the contract, but they didn't know
what they wanted us to do. I used to go berserk - I'd go down the hall, door to
door, trying to find work, something to do, something to get involved in.</p>

<p class="tab">Then they needed a test group
engineer for an event called Double Play, but Jack Noyer had said he'd never
have a &amp;@**%! contractor as a test group engineer. Then he changed his
mind, and said, “Well, have him go do it." So I came out to the Test Site
in mid-December '65, as test group engineer on a tunnel test in Area 16.</p>

<br>
<p><i>Roy Miller, LLNL - Drilling Superintendent</i></p>
<br>

<p class="tab">I have a BS in petroleum
engineering, so I guess I'm a petroleum engineer. There's several different
fields of petroleum engineering, and I happen to, for the most part, be
interested in the drilling phase of it.</p>

<p class="tab">I worked for El Paso Natural Gas
Company, in Farmington, New Mexico, when I got out of college. For a short
period of time I worked in the Division Office in Salt Lake City, in a pipeline
department dealing with gasoline plants, and compressor stations, and
pipelines, and that sort of stuff. I worked for them for eight years before I
came to the Test Site. I couldn't wait to get back to the drilling fields. So,
in 1965 I went to work for Fenix and Sisson. I worked for them until August,
1966, a very short period of time, and then I went to work for the Lab.</p>

<p class="tab">It was surprising to me how much
the hole drilling on the Test Site was adapted from the oil fields. The holes
just got bigger is all; same equipment, same people.</p>

<br>
<p><i>Cliff Olsen, LLNL - Panel Member</i></p>
<br>

<p class="tab">I went to high school in
Sacramento. I'm a native Californian, born in Placerville. The family wandered
around Northern California. During the war we lived in Berkeley. In 1945 we
moved to Sacramento, and I stayed there. I went to high school in Sacramento.
UC Davis was just down the street, and so I ended up getting both my bachelors
and Ph.D. at Davis.</p>

<p class="tab">My degree is from the University
of California, at Davis, and I'm a physical chemist. I worked for Charlie Nash,
who is still there as one of the gray-haired types now. I was his first Ph.D.
student, or his first Ph.D. student who got a Ph.D. He had just gotten out of
UCLA, and he had done work with Bill McMillan. I did my work on exploding
wires. You might ask, "What does that have to do with chemistry?" All
I can say is that a lot of people wondered that. From that work I got a fair
background in what, at that time, was high-speed electronic diagnostic
techniques.</p>

<p class="tab">I got aimed here originally
because Charlie Nash had a consulting contract here, looking at exploding
wires, and high speed switching, and thing like that. The obvious connection is
that such things have something to do with detonators, and so forth. And so, he
had a little bit of money, and lo and behold, starting about 1958, Livermore funded
my graduate research. They gave us a nice high speed capacitor bank, and some
very nice oscilloscopes, which would now be considered something for the
Smithsonian.</p>

<p class="tab">So, it seemed logical to come
down here and look around, and they said, "Why don't you apply for a
job?" So I did, and they took me. I came to Livermore in 1961, and in only
a couple of months got my Q-c1earance. These days that's absolutely amazing.</p>

<p class="tab">I ended up in N Division for a
couple of years, before N Division folded up. I worked for a while on samples
of fissionable materials and other things that we put in the Kukla and Fran reactors,
which were prompt burst reactors. One of the primary things we were looking at
was vulnerability, at that time.</p>

<p class="tab">With Kukla, which was a bare
sphere, you could just put little things in it. Fran was a little bigger, and
was cylindrical, with a cylindrical opening where you could put in a two
dimensional sample. The 2-D samples were a little more of challenge for the calculators.
We would instrument those, stuff them into the reactor, and expose them to a
radiation burst, which was primarily neutrons.</p>

<p class="tab">Then, in '64, when N Division
started to go the way of the dodo bird I left, and a guy named Jim Carothers
offered me a job in L-Division. And, I took it. I started off as a reaction
history physicist on Club, and on Fade and Links I did the reaction history. Then
I moved on to project physicist, starting with Plaid, which was a line-of-sight
shot, but by the time Plaid was finally fired I was no longer the project
physicist - I was in containment by the time it leaked.</p>

<br>
<p><i>Paul Orkild, USGS - Panel Member</i></p>
<br>

<p class="tab">I grew up in a little place
called Northbrook, Illinois, north of Chicago, and east, on the shoreline. I
guess the way I got interested in geology was that I just happened to be
looking at rocks one day when I was a wee one and decided that was something
I'd like to do. And, later I decided it was a lot better than working on
construction, pouring rocks into forms. I figured it was better to pick up the
rocks and describe them.</p>

<p class="tab">I went to school at the
University of Illinois, from 1946 to 1952. I was one of the lucky ones who went
through ROTC officers school. But, after they ruined my hearing with a bazooka
they decided they didn't need me. One of the classical demonstrations for young
officers was to show how a bazooka worked, in the classroom. The sergeant
demonstrating the bazooka held it up and said, "This is how you fire
it." It went off, and it went out right through the wall. Luckily, it
missed everybody. But now I wear hearing aids in both ears, and the whole class
of 36 people were hard of hearing after that, I think. It was very interesting,
but I decided right then and there that was not the place for me. It made for a
short career.</p>

<p class="tab">I stayed in school and finally
graduated. After doing graduate work in '52, I finally got very hungry, and the
USGS had a very lucrative offer, so I went to work. I joined the USGS to work
in Alaska, but I never saw Alaska. I ended up working on the Colorado plateau
looking for uranium. Those were the days when they thought all the uranium was
in the Belgian Congo and up in Canada, and the US didn't have any.</p>

<p class="tab">There was an award program for
prospectors. There wasn't anything like that for us, even though they used our
maps. One of our jobs was to produce photo-geologic maps of the Colorado plateau,
which we were doing. The Survey didn't make any money selling those, but the
blueprint companies that sold them made fortunes, literally. And the guys who
bought the maps and found uranium, they made fortunes. They bought the maps for
seventy-five cents. It cost us probably ten thousand dollars to make them.</p>

<p class="tab">At that time we were working in
what we called the photogeology section, in Washington, from 1952 to 1956.
Photogeology is where you analyze aerial pictures that were taken of various
areas, and make geologic maps based on looking at them, and inspecting them
with stereoscopes, and so on. You infer the kind of rocks there are by looking
at a picture, the various tones and colors. And being very clever, of course.</p>

<p class="tab">We used colored photographs,
which were very primitive at that time, but they were useful, and black and
white photos. Then we would go out into the field, and field check what we were
looking at so we'd have a data base to work from in identifying the various rock
units. It was a very interesting approach. Many of the old time field
geologists thought it was heresy that we could look at a photo and make a
geologic map.</p>

<p class="tab">Anyway, in 1958 I got involved in the mapping of the Test Site, where
they wanted to do the west part, using photo-geology mapping. Then they formed the
Special Project Branch for Test Site work, and it's still here today.</p>

<br>
<p><i>Jim Page, LLNL - Test Director</i></p>
<br>

<p class="tab">My first exposure to the Lab was
as a summer employee, back in the summer of 1961. I came into Mechanical
Engineering and spent three months working on projects in the high pressure laboratory.
Then I went back to school and finished up my Master’s degree in 1962, at
Cornell.</p>

<p class="tab">After that I came back into
Mechanical Engineering, in what was then Device Division, and went to work on
some of the very early stuff that was being done in weapons control. I spent a
couple of years working there, and then I went back into device work, and did
about a year and a half of auxiliary systems work. Then the Department decided
to form an engineering division that would pull all the test work together,
into something called NTED - the Nuclear Test Engineering Division. I joined
that division the day it was formed, and was in the containment group under
Palmer House.</p>

<p class="tab">I left that engineering group in
1972, when I took a one year assignment at Oak Ridge, in Y-12, in their
engineering organization back there. I did a number of things there. I worked
in their special orders group, which was the group that deals with customers
like the Laboratory. I worked in their engineering organization for a while. It's
an facilities type engineering group that worries about the type of equipment,
and where they put it, and how it operates. I got a good look at how the whole
outfit works. There must have been a half dozen people from here who went there
on an assignment like that, and a half dozen people from the other parts of the
complex who came here. I found it to be a very interesting year.</p>

<p class="tab">When I came back I spent about
seven years doing device engineering for events. Then I got involved in the
W-79 as the project engineer. It was in Phase 4, so it was mostly a production engineering
job. From the W-79 work I went back to NTED as the deputy division leader, and
I spent about eight years doing that, which, of course, had a heavy focus on
the engineering that was done for the Test Program.</p>

<p class="tab">I left that job and went over to
the Test Program, working in the field operations activities, doing planning
and some of the management of elements of the program. From that assignment it just
sort of transitioned into a Test Director assignment.</p>

<br>
<p><i>Dan Patch, Pacifica Technology - Codes, Calculations</i></p>
<br>

<p class="tab">I got a bachelor's and master's
degree in mechanical engineering at the University of Minnesota. I started in
'61, and got done with that in '67. Nobody told me you got a master's degree automatically
if you went through a Ph.D. program. U of M was an old timey school, and they
had a five year engineering program. I got into a fast track program that said
we could get out in four years if we would be good scouts and promise to stick
around for a couple of more, and that's kind of what I did.</p>

<p class="tab">Then I came to California to go
to school at the University of California, San Diego in the AMES Department,
which was Applied Mechanics and Engineering Sciences. It had originally been
the Aerospace Department, but the aerospace industry went kaphooy in about the
middle sixties, so they kept the same letters, but changed the name of the
department.</p>

<p class="tab">I came to San Diego because I
wanted to get out of the snow, and because my advisor said that there was a new
engineering school out here; they hadn't graduated a complete class yet when I
came out. I think they had been in operation about three years. It was hard to
tell what kind of a reputation they had, but the UC system had a good
reputation, and they had some very fine faculty members. They had recruited
good faculty, so I thought, "What the heck. I'd really like to see what
the West Coast looks like, and give this a try."</p>

<p class="tab">It took a long time, but I got a
Ph.D. in Engineering Physics. That seemed to be a broad enough title to cover
all sins. It took five years, plus I stayed on a little longer as a post-doc
because my advisor took his sabbatical, and he needed somebody to keep track of
his grad students. So I stuck around for an extra nine months.</p>

<p class="tab">I knew, through a number of
strange connections, some of the people who worked at Science, Systems, and
Software. I had known some of these people for several years. It seemed like a
nice bunch of people, and an interesting place to work. I thought it would be really
nice if I could get into S-Cubed, but I sent resumes out all over, to General
Atomics, the Navy, and out of town to various places. Interestingly enough, one
ofthe places I sent my application to was SAIC, at the time. The two places
were very comparable. They spun off from GA at about the same time, and they
were both about the same size, but because I knew the S-Cubed people, and I had
kind of an inkling of what the corporate culture was like I thought it would be
nice if I was offered a job there. Well, I was.</p>

<p class="tab">I would guess that S-Cubed was
about a hundred and fifty people at that time. I interviewed Chuck Dismukes,
and Jerry Kent. Jerry was the late-time containment guy, and Chuck was what
Chuck was, and still is, of course. Jerry offered me a job, and I didn't quite know
what I was getting into, but it sure sounded like what I was looking for. I've
never really looked back from there, in a way. I worked for Jerry for two
years, and then Jerry left S-Cubed, with a couple of other people - Bob Bjork
and Mike Giddings, and a little later Bob Allen. Those four guys left and
formed Pacifica Technology as a little bitty company. After they had thrashed
around for a year or so they were in need of some help, because they were doing
pretty well. Jerry had continued on with part of the containment work, part of
it. We really in some sense split it with S-Cubed at the time.</p>

<br>
<p><i>Ed Peterson, S-Cubed - Panel Member</i></p>
<br>

<p class="tab">I was born in northern Wisconsin
and have moved many places since then. I have a bachelor's and master's degree
in Mechanical Engineering from the University of Washington. I worked at Boeing
for a while after I had a bachelor's degree, mostly on airframes. After I
received a master's degree I worked for Ford Aerospace in Newport Beach, not a
long time but a few years, on rocket engines and things like that. I interacted
with numbers of people who had doctor's degrees, and my personal view was that
a Ph.D. was sort of a union card that let you do some of the more interesting
work that you get locked out of if you don't have one. They don't pick people to
do work because they're smart, and good. The Ph.D. is sort of a union card, and
that's the basic reason I went back to school. It's sort of the circumstances
of life. It was probably worth it. Who knows, but it was interesting.</p>

<p class="tab">So, I have a Ph.D. in Engineering
from UC Berkeley. I received that in t 968. Following that I taught at the
University of Minnesota for four years. In the sixties there weren't enough
Ph.D.s to go around, but by t 970 or '7 t the market was glutted. For example, at
the University of Minnesota we had lost maybe half our students, and there were
a half dozen assistant professors. It didn't take too much foresight to see the
writing on the wall.</p>

<p class="tab">I had worked in Newport Beach,
which is sixty miles up the road from here. Now, nothing against Minnesota -
it's very nice, the people are very nice, and all that, but it is not nearly as
warm, and they aren't near nice beaches. So, I was looking around for some
place between the Mexican border and Newport Beach, and missed it by five
miles.</p>

<p class="tab">A fellow named Gary Schneyer,
whom I had gone through graduate school with, had by pure chance found S-Cubed.
I happened to talk to him, came here and interviewed. My bachelor's and
master's degrees are in Mechanical Engineering, but the Ph.D. is in
Engineering. In going through Berkeley in the department I did, one takes a
major, which for me was fluid mechanics, and two minors. Mine were physics and
mathematics, so it wasn't really disassociated from the type of things they do
here. They made an offer, and I decided to go to work here. The company was
very small at that time. So, I came here in 1972. And the principal reason was
because it was San Diego. It may not be a good reason, but that was the reason
I did. The person who really hired me was Chuck Dismukes, and the people here
were interested in front ends at the time, and plasma flow in the pipes. It was
really a fluid mechanics type problem that they were most interested in.</p>

<p class="tab">There was another person here,
who didn't hire me, that I ended up working with some in aerodynamics. He was
doing truck aerodynamics and things like that, and I had done some work in aerodynamics.
If you look at trucks today, you will see these new aerodynamic trucks. The one
that's put out by Kenworth now is almost identical to one that we designed for
Freightliner about ten years ago. The new trucks have the whole front end,
including the fenders, the cab top, and everything designed as a complete aerodynamic
unit. In the very new ones the aerodynamics goes all the way down to the
bumpers, and along the sides. I ended up doing a reasonable amount of work on
that. All engineering problems from many standpoints are the same. They're all
a little different, but they all have a lot of similarities. The work on the
trucks was very technical, and a lot of fun.</p>

<p class="tab">A lot of the people that are in containment really only work in one
area, but there are others of us that have done other things.</p>

<br>
<p><i>John Rambo, LLNL - Codes, Calculations</i></p>
<br>

<p class="tab">I graduated from the University
of Portland in June of 1963, and a slight depression was going on at that time.
I had been looking for a job for about six months when some interviewers from
the Nevada Test Site came to Portland. So I went down, and they were looking
for some technical people. I said, “I'm a physicist, but I certainly would be
willing to do most anything. I really would like a job, and I'm interested in
working for the Laboratory." They said they were looking for a physicist,
they just hadn't advertised in the newspaper. I continued to write them letters
that I was still interested, and at the same time I was also possibly going to
hire on at Bremerton, with the Naval shipyard.</p>

<p class="tab">It was rather odd. I had an
interview at Bremerton that was really quite extensive. I was really put to the
carpet, technically, and there were a great deal of questions from the Navy
people. I really felt uptight during the whole interview. About that time I got
to go down to the Nevada Test Site, for an interview down there. They showed me
around the Test Site, took me up to CP-1, and as we were driving back one of
the physicists, Bill King, the head of Health and Safety, said, "You know
all about radiation and that sort of thing?" I said, "Yes," and
that was about the extent of the interview.</p>

<p class="tab">I proceeded to be very interested
in joining the Laboratory in Nevada, and I was hired on by John Ellis, who was
then in charge of a small group developing, as a group, how to measure slifer
yields for the nuclear test program. I came to work in November of t 963. I
lived in Las Vegas, and worked at the Test Site for five years.</p>

<p class="tab">I came in as the physicist who
would analyze the slifer data, and then proceed to write reports telling people
how the devices went in terms of yield. Things were quite different during
those days. Some of my first visits out in the field involved looking at how
the engineering construction people, Joe Snyder and Dick Hunter, sat in a small
trailer and directed the entire operation from that trailer. We were shooting a
shot every week or so at that time. That's something that I doubt we could do
today. It was rather phenomenal to see how they would get all this activity
going just from that one trailer. People would show up, and they would tell
them where they were to go. They were on the net a lot of the time, and it was just
that very small operation that was doing the whole thing.</p>

<br>
<p><i>Norton Rimer, S-Cubed - Codes, Calculation</i></p>
<br>

<p class="tab">I got my undergraduate, masters,
and Ph.D. degrees at City College of New York. I started as a civil engineer,
then obtained a masters in hydraulics, and a Ph.D. in plasma physics. From hydraulics
to plasma physics was a real switch. Most of the people were doing experimental
theses. I was more interested in the computational aspects, coming from fluid
mechanics, where I was doing computational fluid mechanics. That change to
plasma physics meant taking a lot of new courses, a lot of physics department courses
that I hadn't taken.</p>

<p class="tab">I finally turned in the document
for my degree in 1972, and I came here, to S-Cubed in 1973. Actually, I had
been teaching at the University since 1967. I was in no hurry to get out of
there, because I was interested in teaching. I loved college teaching, but it
was recession time. I must have applied to 200 universities, including everyone
in Hawaii and Florida - I'm a beach person. I think I got about ten or fifteen "no"
responses, and two interviews, one of which accepted me. That was a junior
college, and I wasn't very interested in that.</p>

<p class="tab">When I got here Jerry Kent had
just taken over Russ Duff's late time containment contract. He needed help out
here, so he called me up, and I came out for an interview, and they hired me.
Partially it was to work for him, and partially to work on plasma physics. I spent
about five years writing some of the plasma physics codes that they used then.
I was working part-time on containment in those days. Nine months after I was
hired Jerry left and formed Pac Tech. Four or five months before that he asked
me to go with him, but I like this company. I felt I had a lot to learn from
the people here, and I decided to stay.</p>

<p class="tab">So, I've been here since
September '73. But I'm leaving S-Cubed as an employee right after I come back
from vacation. I'm retiring, but I'll be a consultant; I have a half-time
commitment. So, I guess I won't get my twenty year watch. I'll stick to the
business at least as long as the people I can work with stay around. If someone
strange comes in that's difficult to deal with, I probably will just cut out
completely.</p>

<br>
<p><i>Byron Ristvet, DNA - Panel Member</i></p>
<br>

<p class="tab">I was born and raised in Puget
Sound country, in Tacoma, Washington. Undergraduate school was at the
University of Puget Sound, where I got a Bachelor of Science in Geology, with
minors in chemistry, physics, and aerospace studies.</p>

<p class="tab">I always liked rocks, and I had
an aunt and uncle who were avid gemologists. They got me interested in it. And
I've always been an outdoorsy person. I used to like to go out camping,
roughing it, and all that. I still do it occasionally, but I've gotten to where
a motel is roughing it. In 1969 and 1970 I was a geologist with the Keivel Mining
Group, which is Canada's largest Canadian-owned mining firm. I was an
exploration geologist the first summer, and an exploration geology manager the
next summer. I guess working a couple of summers in remote northern Canada kind
of gets you out of the camping experience.</p>

<p class="tab">They were long summers and we
made good money. There I was in Canada, with a permanent work visa, which I
still own, and I still have a Canadian social security card. The Vietnam war
was raging, and it was hard to come back. I originally wanted to go to the
University of Calgary, since I was on an educational delay from active duty in
the Air Force. They were all worried, and said, “You can't go to Canada. You
might not come back." Nobody knew I already had a permanent work visa.</p>

<p class="tab">Then I went to Northwestern
University for graduate school and received a Ph.D. in geology, with the
emphasis on low temperature aqueous geochemistry. I left Northwestern in 1973. I
was prematurely called to active duty by the Air Force, so I did not have my
thesis even started, as far as the writing. In fact, until the day I left to
drive to Kirtland via my home in Tacoma, I was doing lab work. That was about
an eight month premature extraction from the University. I went to Kirtland to
what was then the Air Force Weapons Lab. I was originally to go there to do
environmental chemistry work, which was waste water problems. I got to
Kirtland, and in a few days’ time, three days exactly after I in-processed, was
on a plane to Enewetak, where I got involved with trying to understand the
Pacific nuclear craters.</p>

<p class="tab">Off and on, that took until 1985
to finally resolve, with many, many trips and about seven hundred days out
there. I think the longest trip I took was nine to nine and a half weeks. I
think we did a very good job out there, in understanding that these craters
really were small. It was all these late-time liquefaction related processes that
made them become so large and shallow.</p>

<p class="tab">My first visit to the Test Site
was in 1974, where I assisted in emptying ejecta collection pans on the
pre-Mine Throw event, which was a hundred and twenty ton nitro-methane shot out
on Yucca Lake. It was a cratering shot, and the ejecta collection pans were to
collect whatever came down where they were.</p>

<p class="tab">I was with the Air Force Weapons
Lab at that time. I really got in on the original Enewetak project when it was
a DNA funded project to look at all the explorations of the craters. I was also
involved with DNA on the Minuteman upgrade program, and the silo upgrade
program, and a number of other programs. We were working very closely with the
shock physics folks, and to some extent the test folks. The characterization of
the islands started in 1977, when I was still on active duty, and I was
involved as a technical advisor there. It was in 1977 that I decided I really
didn't want to stay in the Air Force on active duty, but I continued on as a
reservist, even until today.</p>

<p class="tab">I was looking then for a job, and
originally I had planned to go to an oil company, a research and development
organization. I had completed my Ph.D. while on active duty. I was seriously
looking at joining the Chevron Research Corporation, but a few things changed
my mind right at the last minute. They had to do a little bit with salary and
the cost of living in southern California, and the fact that my wife was
pregnant, and she had a good job in Albuquerque, and her family is in
Albuquerque, and there was this geophysicist job open over at DNA.</p>

<p class="tab">So, then I was a civilian
employee at DNA. I continued on as a reservist at the Weapons Lab, primarily
doing environmental impact analysis, which I still do today. I started in
October 1977, and I worked at DNA as the geologist-geophysicist for six years. Then
I left DNA to go to 5-Cubed, and the purpose for that was so I could be the
technical director of the Pacific Enewetak Atoll Crater Exploration. That was
finally the realization of what we had wanted to do, which was to drill the
craters, which we did very, very successfully.</p>

<p class="tab">It was funny. If I wanted to do
that, even though it was a DNA sponsored program, I had to leave DNA because my
duties in the underground test program would have prohibited me from devoting full
time to a program that was very near and dear to my heart at the time. And so I
went to S-Cubed with the intention of probably coming back to DNA as a
government employee. I was at S-Cubed a little over five years, and then I
returned to DNA in 1988, as the chief of the containment technical division.</p>

<br>
<p><i>Bernie Roth, LLNL - Test Director</i></p>
<br>

<p class="tab">I'm a mechanical engineer. I
graduated from San Diego State College in 1959, and stayed in that general area
for five or six years. I came out of the aerospace industry, where I had spent
eight years at several different jobs for several different aerospace
companies. I had three jobs in San Diego, and then one in Connecticut. I worked
on the Atlas program in San Diego for General Dynamics, in the astronautics
division. I had two different jobs there. I also had a job at Ryan Aeronautical
for a short period of time in San Diego. That was in anticipation of a contract
that never developed. The custom of the time, and maybe is still, is that there
is feast and famine. You're hired and fired at will in the aerospace industry. Then
my last aerospace job was with United Aircraft in the Hamilton Standard Division
in Windsor Locks, Connecticut.</p>

<p class="tab">After those seven or eight years
in aerospace I decided that it was too transient a life, and I wanted to look
for something a little more secure. The other part of that story was that I
didn't want to live on the East Coast. I had been there for a couple of years,
and decided that I'd like to go back to the West Coast.</p>

<p class="tab">And so, how did I get here? One
September or October weekend there was an advertisement in the local paper that
the Livermore Laboratory in Livermore, California was interviewing for all
sorts of people. I had already decided that I was going to leave United
Aircraft, and had talked to people like Lockheed and so on. So I thought,
"Gee, What is this outfit?" And I decided I would go down and at
least talk to them.</p>

<p class="tab">So, I proceeded with the
interview process, and was invited out for an interview at Livermore. That
progressed through the various administrative requirements to a job that I
started, I believe, on the 20th of June, in 1967. I got hired into what at that
time was the Nuclear Test Engineering Division.</p>

<p class="tab">I was almost immediately assigned
to an event called Hupmobile. All this was new to me, and I didn't know what to
expect. I think it was six or seven months before that event was fired. At the time
I was very new to the Laboratory, and that was my first test. I didn't realize
how complicated that shot was at the time. I just thought they did that all the
time. Then I just went on from there to one event after another, in the
capacity of what was then called, and is presently called, the diagnostic
engineer.</p>

<p class="tab">Things just progressed from
there. I spent probably four or five years as a diagnostic engineer, and then a
position became available in the readiness group. That program ended about two
years after I became associated with it.</p>

<p class="tab">I jumped from there to the laser
program for a couple of years. But, I guess the Test Program had become
ingrained enough in my interests that I decided I liked it better back in the
Test Program. And so, I came back into the diagnostic group, and took a
position as a group leader, which happened to be available. We fielded a number
of events, I advanced to section leader of the entire diagnostics section in
NTED. I went from there to become a device systems engineer, which job I had
for seven or eight years, and then became a Test Director, which is what I am
now.</p>

<br>
<p><i>Tom Scolman, LANL - Test Director</i></p>
<br>

<p class="tab">I came direct to Los Alamos in
1956, after getting a Ph.D. in experimental physics at the University of
Minnesota. I came to Los Alamos for several reasons. One, I had several friends
I had been with in graduate school who had come to Los Alamos, and they were very
high on Los Alamos, not only as a place to work but as a place to live. I'm a
small town boy. I wasn't particularly anxious to go to a large city, and so I
found Los Alamos very appealing, and the work was challenging and interesting.</p>

<p class="tab">When I came to work I went to
work for the weapons division, which in those days was responsible for the
engineering design and production of weapons, both for stockpile and for
testing. I worked with a group that was largely responsible for interfacing
between designers and engineers, and my involvement with Test was through the
fact that this particular group had the responsibility of monitoring and
certifying the gas handling for test devices. With this I was involved with the
Hardtack operations, both in the Pacific and later when we came back to Nevada,
although I was not part of the test organization, per se.</p>

<p class="tab">It wasn't a bad life, out in the
Pacific, if you didn't mind being away from where you lived for a while. That
certainly was the most negative side of it. I think in many ways it was harder
on the families back here than it was on the participants in the field. It
turns out the group I was in was not engaged in the construction in the field, so
as a result we did not have to go out and spend six months in the field for
every operation, as much of J Division, the test division, did in those days.
For example, on Hardtack Phase I, if I remember right, I spent probably not
more than like six weeks at Enewetak.</p>

<p class="tab">We did, as some people remember,
then come back and do Hardtack Phase II, which was very different. I remember
one time where we were out arming a device, preparing it to go up on a balloon
so it could be fired at dawn. While we were out arming, three shots were fired
within probably five miles of where we were.</p>

<p class="tab"><b>Carothers</b>: I've talked with
people at Livermore, and the things they have said about that operation are
hard to believe these days. Bob Petrie said that they once went out, got the
carpenter foreman, and said, "We want a tower. How high can you make it by
tomorrow night? Can you make it about this high, and about that wide? And, we'll
need some steps." And Walt Arnold told me, "I remember carrying a
device up those stairs." I said, "Aw, come on." Do you believe
that, Tom?</p>

<p class="tab"><b>Scolman</b>: Yes I do. I never carried a device up the stairs,
but I did carry one on my lap, in the backseat of a sedan, out to the zero point.</p>

<p class="tab">It must have been the fall of '62
that I got into J Division. I had become closely acquainted with Bob Campbell
during our involvement in the operations, and I said, "Is there anything
in J Division that might be interesting?" He suggested that I look at
their timing and firing group, which was J-8. It wasn't really in line with my
background, but it was sufficiently interesting, and had some involvement with
the field activity. I enjoyed the testing business. I like to go out and do
things, and the test people do things.</p>

<p class="tab">I worked in the timing and firing
organization until about '65 or '66. Then we started branching out, doing
things other than tests at the Nevada Test Site. We got involved with some of
the Plowshare operations. We got involved with the first shots on Amchitka, and
then there was a need for another Test Director. Initially, Bill Ogle asked me
to come to the division office and work with Bob Campbell and Bob Newman, as a
Test Director. What was supposed to be initially a one year assignment turned
out to be the rest of my career at the Laboratory.</p>

<br>
<p><i>Carl Smith, SNL - Shock Physics</i></p>
<br>

<p class="tab">My family were mechanical
engineers, and there seemed to be, at first, the typical role of following my
father and older brother. But it turned out that there was a physics course in
high school, with a very good teacher who steered me in that direction.</p>

<p class="tab">I started at a little college in
Indiana called Earlham. Then I went to Washington University in St. Louis for a
year. It turned out that Brown had a big program in acoustics, with people like
Robert Byer, and Robert Bruce Lindsey. After a year at Washington University I
decided, “Hey, I'm real hot about acoustics, and the field of
ultrasonics." And so, I transferred after one year of graduate school at
Washington to Brown University, in physics. There I did my thesis on finite
amplitude acoustics - underwater water waves and finite amplitude effects. I
got my degree in 1966.</p>

<p class="tab">I went to Stanford Research
Institute in 1966, and was there for almost ten years. SRI was still associated
with the University when I started. For many years there had been a loose
federation with Stanford, but the students rabble-roused at Stanford in terms of
making the University pay more attention to what SRI was doing in some of their
defense related work. The upshot of all their rabble rousing was that the two
institutions were cut apart. That happened while I was there.</p>

<p class="tab">There were student protestors
outside and stuff like that. I was reminded at that time of Emerson and
Thoreau, years ago. Thoreau was thrown in jail for civil disobedience, and
Emerson came to see him. Emerson said, "What are you doing in there,
Henry?" and Henry Thoreau said, "What are you doing outside?"</p>

<p class="tab">The separation didn't really make
any difference to the people at SRI. The work didn't change. The place had been
on its own for a number of years, and was very much entrenched in what it was doing.
It was a minor name change as far as the way the place operated. Our work
continued, and the place ran very much as it had before. I stayed there until
the end of 1975, and then I went to Sandia, and started there in January of
'76.</p>

<p class="tab">Actually, I started doing for Sandia exactly what I had been doing for
SRI, but it was a job with far more attractive opportunities to advance.</p>

<br>
<p><i>Bill Twenhofel, USGS - Panel Member</i></p>
<br>

<p class="tab">I went to school at the
University of Wisconsin, in Madison, Wisconsin, and my father was a professor
of geology there. And so, of course, I had to take the beginning geology
course, and I just sort of followed in my dad's footsteps. I got a bachelor's
degree in 1940, with a major in geology and a minor in mining engineering. I
went to graduate school at Madison for one year, and then I went to graduate
school at the University of California at Berkeley.</p>

<p class="tab">When Pearl Harbor occurred I was
at Berkeley, and I left graduate school and went to work for the U.S.
Geological Survey in Washington DC. Shortly thereafter I was drafted, and I
entered the Navy. I went to work at the Naval Research Laboratory in Washington
DC, doing research on the growth of artificial crystals for sonar. I worked
there until the war was over, and then went back to graduate school at Madison.
After another year there I had met all the requirements except the thesis, and
I went back to work for the Geological Survey.</p>

<p class="tab">I finally got the thesis done. It
was on the geology of the Alaska-Juneau gold mine, in Juneau, Alaska. The
Alaska-Juneau gold mine is unique. It had, at the time it was operating, the
lowest grade ore of any mine in the world, and it still made a profit. So, I
got my Ph.D. in geology, from the University of Wisconsin in 1952.</p>

<p class="tab">When I went to work for the
Geological Survey in the early part of the war, and before I was drafted I was
assigned to the Alaskan work. Then, later, after the war, and while I was in
school I went up to Alaska to do field work in geology every summer. After I
left Madison with all my requirements for my degree except the thesis, I was
transferred by the Survey to Juneau, Alaska, and lived there year round, and
worked there. I loved it. For a young fellow, Alaska is a great place, and
Juneau was a great little town. It was just wonderful. You feel isolated a
little bit, but the hunting, the fishing, and the outdoor recreation was just
great. So I lived in Alaska for a time, and then I was transferred from Juneau
in 1952.</p>

<p class="tab">I went to Denver, Colorado, with
the Geological Survey again. I was assigned as the assistant group leader to a
group studying the uranium deposits of the United States. The particular
assignment of the group I was in was to make estimates of the reserves of uranium
in the United States, and in the rest of the world. I was not involved in the
rest of the world, only in the United States.</p>

<p class="tab">It was a lot of guess work, but
we took reports from mining companies, or from government work. There was a lot
of government work, AEC work. You take the reports, and you construct conceptual
geologic models in your mind of how deposits were formed, and therefore
something about their size.</p>

<p class="tab">Before 1952, about 1950, the only
known uranium ore bodies in the United States were the yellow and orange
oxidized uranium minerals that are oxidized because of the surface processes.
With drilling they discovered the primary uranium ore, which is not oxidized,
and that led to some big discoveries in the Colorado plateau. I was involved
with that until about 1956, when the underground test program began out here. I
then got assigned to the Geological Survey group that supported the AEC at the
Test Site.</p>

<br>
<p><i>Wendell Weart, SNL - Panel Member</i></p>
<br>

<p class="tab">My undergraduate school was
Cornell College, not to be confused with Cornell University. I got my
undergraduate degree in '53, and then worked for about three years at the
Ballistic Research Laboratories at the Aberdeen Proving Grounds, in Maryland.</p>

<p class="tab">Then I went back to get my degree
from the University of Wisconsin. I was really interested in geology, but as I
went along I felt a desire to get a little more into the hard physics of the
thing, rather than the interpretive aspects that geology mostly involves. So, I
just gradually migrated into geophysics.</p>

<p class="tab">I became associated with Sandia
in a fortuitous way. I had never heard of Sandia Laboratories, and one day I
got a letter in the mail saying, "We have just visited with your professor
at the University of Wisconsin, who says you are in the process of completing
your degree. We'd be interested in sponsoring that if you'd be willing to come
to work for us." So I started looking around to see who is this
"Sandia Laboratories." The part about sponsoring my work sounded
great, because their offer was a lot better than the teaching assistantships
that were offered in those days.</p>

<p class="tab">So, I joined Sandia in August
1959. It was, I think, primarily because Sandia was trying to address some of
the problems of a possible test ban treaty that was being much debated at that
time, and they needed a seismologist and geophysicist. At that time we were a
rare breed.</p>

<p class="tab">I got my Ph.D. in 1961, from the
University of Wisconsin. They didn't grant a degree in a specialty, so the
degree was in geophysics, and I did my thesis in the area of seismology. That
was back in the days when there were very few universities that had separate
geophysics degree programs. It was about to change greatly because of the Vela
Uniform program, and all the studies that went on in conjunction with trying to
understand the seismic effects of underground detonations.</p>

<p class="tab">So I did join Sandia, primarily
to do seismologically oriented work. But one of the first things I got involved
in when I went to Sandia, which eventually led to my containment related
duties, was to reenter an event called Marshmallow, which was a tunnel shot that
had been conducted in Area 16, in 1962. It was a shot with a long line-of-sight
pipe, in a tunnel. It was conducted for experimental purposes, rather than for
developing a device, and was considered to be a relatively successful event.
There had been only a small amount of experience with tunnel shots, and
particularly with pipe shots in a tunnel.</p>

<p class="tab">It was fired about six months
after the Gnome event, which incidentally was, and I find this hard to believe,
only about eight miles from where I have spent the last fifteen years of my
life working on a project, trying to find a suitable means of disposing of radioactive
waste.</p>

<br>
<p><i>Bruce Wheeler, USAF/DNA - Test Operations</i></p>
<br>

<p class="tab">In 1951 I was here, in
Albuquerque, being trained to take care of the nuclear weapons the Air Force
had. After graduating from the assembly course I volunteered for, and was
accepted in, what they called the nuclear officer course. So, I got to go to
Los Alamos and train there, and that was a lot of fun.</p>

<p class="tab">So, I was a second lieutenant
when they put me in the nuclear business, and I stayed in it virtually the rest
of my thirty years in the Air Force. And it was good to me; I got promoted, and
I got some interesting assignments, like DNA.</p>

<p class="tab">I became involved with DNA and
the test work through Ted Jones, who was the Director of Test. That was late in
1971, and I had just been promoted to full colonel. I came to work here in Albuquerque,
and served as the head of operations. That meant I was involved in the details
of construction, the entire test bed, the experiment package of the whole
facility, and all the aspects of it. That included the calculations, the
predictions, and the whole nine yards. At that time it seemed to me that people
were being very careful, and a very worried. They were very desirous of putting
together a shot that wouldn't do anything untoward.</p>

<p class="tab">There were things changing even
as I came there. At that time there was not a well-founded, formal,
well-managed research program to try to understand more about the containment
of these tests, and I thought we needed that. One of the things I tried to encourage,
and did encourage after I became the boss, was to go back and look at
successfully contained tests; to mine back and see how things had worked right.
As I perceived it, the only time the DNA dug back in to see what happened was
when something went wrong. I thought there was a void there that ought to be
filled with some understanding of the phenomenology of a successfully contained
test. We routinely planned to use our contingency fund on every test for
reentry mining, if there was any left, and usually there was some.</p>

<p class="tab">That job in DNA, when I became
Director of Test, was the best job I ever had. I wouldn't trade that for
anything. It was a field operation, and I could get the hell out of the office.
Somebody asked me, "Why do you spend so much time out there in the tunnels?"
I said, "That's where I go to regain my sanity." I enjoyed that kind
of work, being part of putting something together, even though we blew it up
afterwards.</p>

<br>
<p><i>Irv Williams, DOE/DASMA Staff</i></p>
<br>

<p class="tab">I did my undergraduate work at
the University of New Hampshire. I joined the Air Force in 1950. I got into the
ordnance business, and from there was put into the nuclear weapons business. In
my early days I was a bomb commander on the old B-45's. I was non-rated, but
assigned to a crew as a weapon commander for the B-45's, in 1952.</p>

<p class="tab">Then I went to Albuquerque for
bomb-commander training. I had been trained as an engineer, and had a lot of
ordnance, armament, fire control, radar work, and so forth, with the Air Force.
And so they flipped a coin, and this unit, which was the first tactical bomber
unit that was equipped with nuclear weapons, won me. I stayed with them, and
went to England for three years with that group. We were at Sculthorpe, which
is about fifteen miles from Sandringham, up in the Wash beyond Norich. Norich
is in Northrop County, and it's quite near the ocean, where England juts out
into the North Sea. There is a big bay area, which is called the Wash. We
operated there for three years, from a British base that the United States had
used during World War II. We went in there, rehabilitated it, and operated out
of that for three years. That place was really damp, wet, and rainy, and cold.
The North Sea is very cold. It never gets much above about 34 degrees.</p>

<p class="tab">Then I came back and went to
school at the Air Force Institute of Technology, at Wright Patterson. I was in
a course called Air Ordnance Engineering, and as a result of that I was picked
up, and zinged out to Kirtland to go back into the weapons program. This was
after I came out of graduate school.</p>

<p class="tab">After three years at Albuquerque,
which was a wonderful assignment, doing nuclear weapons work for the B-58
Hustler, and going through command and staff school, I was surprised by my next
assignment, which was to Livermore. It was out of the blue. I had asked to go
to the West Coast, and I got a letter sending me to Livermore. I was there
assigned to the Defense Nuclear Agency's predecessor. I first came to the AEC,
I would say, when I first went to Livermore. That was in 1961.</p>

<p class="tab">I worked with the engineers and
the chemists in explosives, for B Division at Site 300. I kept track of every
test design as it grew up during those early days. I followed all of them all
the way through, and I did that for a good part of three years. I also spent time
down in the plutonium building with Bill Ramsey, and with Gus Dorough in
explosives. And occasionally I got to the Test Site.</p>

<p class="tab">I was at Livermore from '61 to
'64, and I was there before we resumed testing. I was in the office with Marv
Martin when the alert came to move and do a test. I don't know who called with
those instructions, for sure, but I know people moved, and they went in all
directions that afternoon. Immediately, after a short council, things started
to move immediately.</p>

<p class="tab">So, I was there at the beginning
of the resumption of testing. I was able to follow through the full three
years, and follow the preparations for Dominic, the Pacific operation. I also
did some work with the Laboratory people at Travis, and I spent several times there
with the Hotspot team, with Marv Martin. I had a very good introduction to the
program. I wasn't part of a design or device team, but I followed the designs
and all the work in the Laboratory. On a few occasions I did help with a little
assembly work at the Laboratory, and I worked down at the Test Site with some disassemblies,
with Ken Beckman and other fellows from W Division. I got to know a lot of
people because of the opportunities I was given, working with Marv, to work
with the Laboratory people. It was a way to really learn about the program. It
was a tremendous experience.</p>

              </div><!--/hero-unit -->
        </div><!--/span9 -->

      </div><!-- /.row-fluid -->
	</div><!-- /container-fluid -->

<!--
    <div class="row">
      <hr>
      <footer>
        <p>&copy; Eric Shiflet 2015</p>
      </footer>
    </div><!-- /row -->

    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../bootstrap-232/js/bootstrap.js"></script>
    <script src="../js/eric.js"></script>

  </body>
</html>
